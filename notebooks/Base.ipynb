{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 not supported (please install/reinstall h5py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-26 12:15:35,761] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from numpy.random import choice\n",
    "import random\n",
    "from tensorbuilder.api import *\n",
    "import tensorflow as tf\n",
    "\n",
    "env = gym.make(\"FrozenLake-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def next_action(actions, e):\n",
    "    n = len(actions)\n",
    "    \n",
    "    if random.random() < e:\n",
    "        return random.randint(0, n-1)\n",
    "    else:\n",
    "        return np.argmax(actions)\n",
    "    \n",
    "def naive_gd(error, expression):\n",
    "    ws = tf.trainable_variables()\n",
    "    gradients = tf.gradients(expression, ws)\n",
    "    \n",
    "    return [ tf.assign_add(w, error * g) for w, g in zip(ws, gradients) if w is not None ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_actions = env.action_space.n\n",
    "n_states = env.observation_space.n\n",
    "model_name = \"shallow.model\"\n",
    "model_path = \"/models/\" + model_name\n",
    "y = 0.95\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    with tf.device(\"cpu:0\"):\n",
    "        s = tf.placeholder(tf.int32, [None], name='s')\n",
    "        a = tf.placeholder(tf.int32, [None], name='a')\n",
    "        r = tf.placeholder(tf.float32, [None], name='r')\n",
    "        maxQs1 = tf.placeholder(tf.float32, [None], name='maxQs1')\n",
    "        lr = tf.placeholder(tf.float32, [], name='lr')\n",
    "        QSA = tf.placeholder(tf.float32, [None], name='QSA')\n",
    "\n",
    "        ops = dict(trainable=True, weights_initializer=tf.random_uniform_initializer(minval=0.0, maxval=0.01), biases_initializer=None) #tf.random_uniform_initializer(minval=0, maxval=0.01))\n",
    "\n",
    "\n",
    "        Qs = Pipe(\n",
    "            s,\n",
    "            T.one_hot(n_states)\n",
    "            .relu_layer(32, **ops)\n",
    "            .linear_layer(4, scope='linear_layer', **ops),\n",
    "            T\n",
    "        )\n",
    "        \n",
    "        idx = tf.stack((tf.range(tf.shape(a)[0]), a), 1)\n",
    "        Qsa = tf.gather_nd(Qs, idx)\n",
    "        \n",
    "        maxQs = tf.reduce_max(Qs, 1)\n",
    "        \n",
    "        \n",
    "#         error = tf.placeholder(tf.float32, [])\n",
    "        loss = Pipe(r + y * maxQs1 - Qsa, tf.nn.l2_loss, tf.reduce_sum)\n",
    "        update3 = tf.train.GradientDescentOptimizer(lr).minimize(loss)\n",
    "        \n",
    "        error = lr * (r + y * maxQs1 - Qsa)\n",
    "        update = naive_gd(error[0], Qsa[0])\n",
    "        \n",
    "        ws = tf.trainable_variables()\n",
    "        dws = [ tf.placeholder(w.dtype, w.get_shape()) for w in ws ] \n",
    "        update2 = [ tf.assign_add(w, dw) for w, dw in zip(ws, dws) ]\n",
    "        gradients = tf.gradients(Qsa[0], ws)\n",
    "\n",
    "        writer = tf.summary.FileWriter('/logs/' +  model_name)\n",
    "        saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  5.65255852e-03   8.46439693e-03   3.95233277e-03   9.35507752e-03\n",
      "    9.17865057e-03   6.39708014e-04   7.97517039e-03   4.48554754e-04\n",
      "    1.33927225e-03   7.39349332e-03   2.46193400e-03   4.95461561e-03\n",
      "    5.83832711e-03   2.48491760e-05   6.16815686e-03   2.73495913e-04\n",
      "    4.66776127e-03   1.24621147e-03   7.66848773e-03   8.25199392e-03\n",
      "    4.48218221e-03   6.35457132e-03   2.13983166e-03   7.07066036e-04\n",
      "    9.54912859e-04   6.21412508e-03   5.78961475e-03   6.78531639e-03\n",
      "    5.66460844e-03   6.86134677e-03   8.62788502e-03   5.77358808e-03]\n",
      " [  1.69945718e-03   3.97772901e-03   2.90793763e-03   7.83976074e-03\n",
      "    1.60481455e-03   2.05958844e-03   4.81131300e-03   3.66271357e-03\n",
      "    2.44214409e-03   5.03819203e-03   4.99379728e-03   4.28048708e-03\n",
      "    9.10380855e-03   7.60943396e-03   6.79889927e-04   1.83818571e-03\n",
      "    5.94038703e-03   7.44578941e-03   9.15263966e-03   5.03937108e-03\n",
      "    8.25659023e-04   5.06838411e-03   6.78669661e-03   1.02294201e-03\n",
      "    9.88058932e-03   5.73773589e-03   6.15251530e-03   9.54885688e-03\n",
      "    3.72900604e-03   7.09699350e-04   1.02985732e-03   6.30844943e-03]\n",
      " [  6.02216925e-03   1.79680821e-03   4.42430843e-03   5.79273794e-03\n",
      "    6.03802549e-03   9.89063643e-03   5.43300156e-03   7.89117534e-03\n",
      "    6.37924438e-03   7.93317892e-03   8.92850105e-03   2.93395878e-03\n",
      "    5.37579879e-03   3.94967897e-03   7.45288003e-03   3.89102451e-03\n",
      "    6.99434616e-03   5.26986225e-03   5.89709496e-03   8.97424482e-03\n",
      "    2.13550334e-03   7.36742374e-03   3.48494155e-03   7.48590101e-03\n",
      "    9.19484813e-03   3.01629887e-03   3.14852595e-03   4.73468303e-04\n",
      "    5.49244275e-03   4.39882251e-06   8.26730020e-03   3.77217511e-04]\n",
      " [  2.75813462e-03   1.61035173e-03   2.02158326e-03   4.90597729e-03\n",
      "    8.63822701e-04   1.77832844e-04   4.71796375e-03   7.02047208e-03\n",
      "    9.26835369e-03   6.77128788e-03   3.18096508e-03   8.03752895e-03\n",
      "    2.48447526e-03   9.25482996e-03   9.16746724e-03   6.31656265e-03\n",
      "    3.36613652e-04   1.25741120e-03   7.32052093e-03   9.69052271e-05\n",
      "    8.70926864e-03   9.17549804e-03   1.49982923e-03   5.36182988e-03\n",
      "    8.13988037e-03   2.15524319e-03   2.55273702e-03   9.81285796e-03\n",
      "    7.39013311e-03   5.78851812e-03   2.15888012e-05   5.01130102e-03]\n",
      " [  5.01227006e-03   6.07835734e-03   6.62525278e-03   6.02578046e-03\n",
      "    5.42863621e-04   8.60907789e-03   8.59238766e-03   7.54823303e-03\n",
      "    4.12800768e-03   1.15505094e-03   1.37114521e-05   5.33398846e-03\n",
      "    6.08423352e-03   5.74514130e-03   2.76595470e-03   9.29201953e-03\n",
      "    9.39301215e-03   9.32476297e-03   6.96302392e-03   6.89087156e-03\n",
      "    4.35059518e-03   2.18495354e-03   1.30842568e-03   5.14069293e-03\n",
      "    5.44539094e-03   8.37971922e-03   2.58656382e-03   1.74826500e-03\n",
      "    1.36214498e-04   2.83763395e-04   9.79300495e-03   9.30708367e-03]\n",
      " [  6.84372149e-03   6.88668480e-03   4.76443302e-03   1.14230393e-03\n",
      "    7.74017209e-03   1.64713856e-04   6.19951123e-03   6.52463175e-03\n",
      "    7.85374828e-03   2.90933717e-03   6.18991489e-03   7.88997114e-03\n",
      "    8.36165529e-03   9.05027706e-03   9.67895146e-03   2.93317554e-03\n",
      "    6.37488253e-03   6.60011033e-03   4.60693706e-03   4.87475144e-03\n",
      "    8.92588682e-03   6.63943868e-03   9.17875394e-03   7.74435978e-03\n",
      "    3.19598895e-03   1.33098720e-03   1.21561170e-03   2.90678022e-03\n",
      "    5.01047820e-03   1.30704395e-03   5.73936570e-03   3.50899925e-03]\n",
      " [  1.45936839e-03   9.52259172e-03   1.39993546e-03   8.23075604e-03\n",
      "    5.33753866e-03   7.94784259e-03   2.51243217e-03   8.16565659e-03\n",
      "    5.99062908e-03   6.91803917e-03   2.41055712e-03   4.23686253e-03\n",
      "    1.65437581e-03   7.45717622e-03   4.23920760e-03   1.95801258e-03\n",
      "    3.32404836e-03   4.23769001e-03   9.91036883e-04   7.65548553e-03\n",
      "    6.49170764e-03   2.71930918e-03   6.50102831e-03   2.20093969e-03\n",
      "    2.42200959e-03   3.86193977e-03   2.88600312e-03   4.33381321e-03\n",
      "    5.97238541e-03   4.07186383e-03   1.89255236e-03   1.01386907e-03]\n",
      " [  1.98500161e-03   2.32596998e-03   1.65454031e-03   1.59640785e-03\n",
      "    6.75922865e-03   4.20652516e-03   1.57029263e-03   5.90602029e-03\n",
      "    6.06272556e-03   7.24030717e-04   8.26526340e-03   2.08904617e-03\n",
      "    3.40749137e-03   3.95930978e-03   9.97260585e-03   2.12511304e-03\n",
      "    9.52922099e-04   1.60351989e-03   3.00000072e-03   6.77966932e-03\n",
      "    6.63101301e-03   3.06800962e-03   4.04362055e-03   4.37858468e-03\n",
      "    6.36927364e-03   4.39038733e-03   4.74688504e-03   2.21433397e-03\n",
      "    8.57072789e-03   2.10236548e-03   5.56432968e-03   4.60069999e-03]\n",
      " [  8.56474228e-03   2.23373994e-03   6.23905426e-03   6.27521845e-03\n",
      "    6.36771903e-04   9.54096206e-03   9.08301305e-03   5.47769899e-03\n",
      "    6.49464689e-03   2.72094249e-03   6.70008641e-03   8.97158403e-03\n",
      "    4.63536987e-03   6.57589780e-03   1.37788057e-03   3.39413877e-03\n",
      "    6.37894124e-03   9.71402600e-03   9.98994708e-03   7.26714497e-03\n",
      "    8.77073500e-03   4.75660432e-03   5.84206544e-04   1.95852877e-03\n",
      "    1.00364687e-03   7.19594350e-03   6.12423895e-03   8.33392143e-03\n",
      "    7.08962674e-04   7.35381572e-03   9.58088692e-03   9.29764938e-03]\n",
      " [  7.90559966e-03   6.17921213e-03   8.51077773e-03   4.25983546e-03\n",
      "    2.25017057e-03   3.99135100e-03   9.34512727e-03   8.63339286e-03\n",
      "    8.80242558e-04   9.92174260e-03   4.09562560e-03   2.85625458e-03\n",
      "    5.46163926e-03   9.35057271e-03   2.01909547e-03   7.86752068e-03\n",
      "    6.63227309e-03   5.71072102e-04   1.37103314e-03   4.25136415e-03\n",
      "    3.42721096e-03   4.69410885e-03   8.73714406e-03   7.78173888e-03\n",
      "    6.25009881e-03   8.46365653e-03   5.88038424e-03   8.56890995e-03\n",
      "    3.14143999e-03   3.19086900e-03   3.87060991e-03   4.86464705e-03]\n",
      " [  6.18581381e-03   6.16180897e-03   4.18521510e-03   4.30939207e-03\n",
      "    5.64029440e-03   3.98929114e-04   1.26869680e-04   2.56003602e-03\n",
      "    8.59928969e-03   2.36055371e-03   3.20214871e-03   5.57623245e-03\n",
      "    7.30719185e-03   6.69051369e-04   3.72375245e-04   7.54436944e-03\n",
      "    9.44493059e-03   9.19468515e-03   4.02434217e-03   8.57925788e-03\n",
      "    9.90641955e-03   4.54408163e-03   6.83395006e-03   6.99959602e-03\n",
      "    8.36951006e-03   9.79941897e-03   2.15438590e-03   2.49758596e-03\n",
      "    3.73945455e-03   2.58205412e-03   7.68247247e-03   9.15734190e-03]\n",
      " [  3.19526438e-03   8.81250389e-03   8.53918213e-03   4.53577982e-03\n",
      "    3.73172748e-04   5.56748500e-03   1.51816243e-03   9.03627649e-03\n",
      "    2.77656899e-03   8.44764803e-03   2.37819063e-03   9.13781580e-03\n",
      "    8.90068430e-03   2.34918948e-03   1.38260121e-03   8.51115771e-03\n",
      "    5.19468170e-03   8.11004647e-05   9.25451983e-03   5.91184478e-03\n",
      "    1.10144611e-03   3.79130477e-03   8.08049273e-03   6.94038719e-03\n",
      "    1.86104176e-03   8.07041489e-03   6.40754914e-03   9.91801452e-03\n",
      "    6.56278944e-03   6.98395818e-03   5.63057046e-03   7.12914206e-03]\n",
      " [  5.44495787e-03   9.95803066e-03   8.71919387e-04   2.42197281e-03\n",
      "    9.77630634e-03   5.69265010e-03   4.07048222e-03   2.78044929e-04\n",
      "    2.72603030e-03   8.84049758e-03   1.48214214e-03   2.69714597e-04\n",
      "    2.72318232e-03   8.94561503e-03   8.80762469e-03   7.91857578e-03\n",
      "    8.25118739e-03   1.08688115e-03   7.70175923e-03   5.53007098e-03\n",
      "    6.58689020e-03   5.34332404e-03   3.38816643e-03   6.50748028e-04\n",
      "    6.73647737e-03   1.73956866e-03   9.03589372e-03   7.25824712e-03\n",
      "    8.69950838e-03   4.65000002e-03   4.00748849e-03   5.83059527e-03]\n",
      " [  6.61493046e-03   9.24494956e-03   8.25878512e-03   4.12097108e-03\n",
      "    6.63841097e-03   1.32478948e-03   9.72985756e-03   4.30115452e-03\n",
      "    2.18286514e-04   6.10664254e-03   5.91924042e-03   8.74690153e-03\n",
      "    3.00987717e-03   8.24931823e-03   1.58556341e-03   5.09198429e-03\n",
      "    8.08674749e-03   6.41598087e-03   8.91769771e-03   8.89355410e-03\n",
      "    2.59195920e-03   1.61610718e-03   7.47554982e-03   1.89421407e-03\n",
      "    5.95572824e-03   1.22242095e-03   3.86822107e-03   5.70233818e-03\n",
      "    3.69220250e-03   6.94123236e-03   6.53996319e-03   1.52096746e-03]\n",
      " [  9.96743329e-03   1.84841629e-03   3.11732292e-03   2.16990337e-03\n",
      "    1.80260779e-03   8.98716447e-04   4.25788295e-03   7.28412112e-03\n",
      "    2.26685288e-03   7.26083759e-03   8.31185654e-03   9.15930234e-03\n",
      "    1.18808029e-03   2.73389579e-03   6.91196090e-03   6.98838208e-04\n",
      "    2.61061196e-03   8.60600360e-03   6.90692151e-03   2.60557770e-03\n",
      "    5.58188651e-03   2.24024057e-03   7.56348716e-03   2.08863849e-03\n",
      "    1.64739008e-03   1.92567345e-03   5.03365137e-03   8.92703049e-03\n",
      "    3.23907123e-04   8.55195243e-03   7.95636151e-04   2.76942243e-04]\n",
      " [  2.49959575e-03   1.39672752e-03   7.36049982e-03   9.60006937e-03\n",
      "    3.92286293e-03   9.05519351e-03   5.71971992e-03   2.96768663e-03\n",
      "    2.25635525e-03   1.98300485e-03   3.39163770e-03   1.75611256e-03\n",
      "    5.47223678e-03   2.16841209e-03   1.16652483e-03   5.57460869e-03\n",
      "    4.45224764e-03   4.94092703e-04   2.74603232e-03   4.75371117e-03\n",
      "    9.92694683e-03   3.50541109e-03   1.37521501e-03   6.63488265e-03\n",
      "    4.65675583e-03   3.63876205e-03   3.39504820e-03   6.15392812e-03\n",
      "    5.26052725e-04   3.11603886e-03   8.65482632e-03   6.13299338e-03]]\n",
      "2.69212\n",
      "W1 [[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.01120941  0.01523911  0.00317856  0.02071369  0.02336666  0.01497138\n",
      "   0.00946809  0.01015603  0.00505552  0.02586574  0.00026467  0.02485683\n",
      "   0.02131044  0.00730507  0.01590435  0.00051983  0.00567272  0.0228308\n",
      "   0.00150932  0.00965814  0.00703675  0.00438405  0.02399832  0.01287023\n",
      "   0.01462232  0.01891931  0.02022701  0.00982961  0.00027328  0.01490118\n",
      "   0.02207692  0.00972182]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]]\n",
      "2.69212179517\n",
      "W2 [[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.01120941  0.01523911  0.00317856  0.02071369  0.02336665  0.01497138\n",
      "   0.00946809  0.01015603  0.00505552  0.02586574  0.00026467  0.02485682\n",
      "   0.02131044  0.00730507  0.01590435  0.00051983  0.00567272  0.0228308\n",
      "   0.00150932  0.00965814  0.00703675  0.00438405  0.02399832  0.01287022\n",
      "   0.01462232  0.01891931  0.02022701  0.00982961  0.00027328  0.01490117\n",
      "   0.02207692  0.00972182]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]]\n",
      "2.69212\n",
      "W3 [[ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.01120941  0.01523911  0.00317856  0.02071369  0.02336666  0.01497138\n",
      "   0.00946809  0.01015603  0.00505552  0.02586574  0.00026467  0.02485683\n",
      "   0.02131044  0.00730507  0.01590435  0.00051983  0.00567272  0.0228308\n",
      "   0.00150932  0.00965814  0.00703675  0.00438405  0.02399832  0.01287023\n",
      "   0.01462232  0.01891931  0.02022701  0.00982961  0.00027328  0.01490118\n",
      "   0.02207692  0.00972182]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.          0.          0.          0.\n",
      "   0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph) as sess:\n",
    "    with tf.device(\"cpu:0\"):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "        _s = np.random.randint(0, 16)\n",
    "        _a = np.random.randint(0, 4)\n",
    "        _r = 3.2\n",
    "        _maxQs1 = 2.3\n",
    "        _lr = 0.5\n",
    "        _qsa = 0.434\n",
    "\n",
    "        L = 0\n",
    "\n",
    "        W0 = sess.run(ws)\n",
    "        WW = W0[L]\n",
    "\n",
    "        print WW\n",
    "\n",
    "        reset = lambda: sess.run([ tf.assign(w, dw) for w, dw in zip(ws, W0) ])\n",
    "\n",
    "        _error, _ = sess.run([error[0], update], feed_dict={s: [_s], a: [_a], r: [_r], maxQs1: [_maxQs1], lr: _lr, QSA: [_qsa]})\n",
    "\n",
    "        W1 = sess.run(ws)[L]\n",
    "        print _error\n",
    "        print \"W1\", W1 - WW\n",
    "\n",
    "\n",
    "        reset()\n",
    "\n",
    "        [_qs, _gradients] = sess.run([Qs, gradients], {s: [_s], a: [_a]})\n",
    "        d = _lr * (_r + y * _maxQs1 - _qs[0,_a])\n",
    "        _dws = [ d * dw for dw in _gradients ]\n",
    "\n",
    "        sess.run(update2, feed_dict={\n",
    "            dw: _dw for dw, _dw in zip(dws, _dws)\n",
    "        })\n",
    "\n",
    "        W2 = sess.run(ws)[L]\n",
    "\n",
    "    #     sess.run(update2, feed_dict={s: [0], a: [1], r: [3.2], maxQs1: [2.3], lr: 0.5, QSA: [0.434]})\n",
    "        print d\n",
    "        print \"W2\", W2 - WW\n",
    "\n",
    "        reset()\n",
    "\n",
    "        _error, _ = sess.run([error[0], update3], feed_dict={s: [_s], a: [_a], r: [_r], maxQs1: [_maxQs1], lr: _lr, QSA: [_qsa]})\n",
    "\n",
    "        W3 = sess.run(ws)[L]\n",
    "        print _error\n",
    "        print \"W3\", W3 - WW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 of 500 , lr: 0.2\n",
      "3.0 of 500 , lr: 0.16\n",
      "0.0 of 500 , lr: 0.133333333333\n",
      "0.0 of 500 , lr: 0.114285714286\n",
      "0.0 of 500 , lr: 0.1\n",
      "0.0 of 500 , lr: 0.0888888888889\n",
      "0.0 of 500 , lr: 0.08\n",
      "0.0 of 500 , lr: 0.0727272727273\n",
      "11.0 of 500 , lr: 0.0666666666667\n",
      "9.0 of 500 , lr: 0.0615384615385\n",
      "23.0 of 500 , lr: 0.0571428571429\n",
      "14.0 of 500 , lr: 0.0533333333333\n",
      "16.0 of 500 , lr: 0.05\n",
      "11.0 of 500 , lr: 0.0470588235294\n",
      "15.0 of 500 , lr: 0.0444444444444\n",
      "16.0 of 500 , lr: 0.0421052631579\n",
      "8.0 of 500 , lr: 0.04\n",
      "20.0 of 500 , lr: 0.0380952380952\n",
      "23.0 of 500 , lr: 0.0363636363636\n",
      "22.0 of 500 , lr: 0.0347826086957\n",
      "29.0 of 500 , lr: 0.0333333333333\n",
      "24.0 of 500 , lr: 0.032\n",
      "26.0 of 500 , lr: 0.0307692307692\n",
      "26.0 of 500 , lr: 0.0296296296296\n",
      "20.0 of 500 , lr: 0.0285714285714\n",
      "17.0 of 500 , lr: 0.0275862068966\n",
      "21.0 of 500 , lr: 0.0266666666667\n",
      "27.0 of 500 , lr: 0.0258064516129\n",
      "25.0 of 500 , lr: 0.025\n",
      "34.0 of 500 , lr: 0.0242424242424\n",
      "36.0 of 500 , lr: 0.0235294117647\n",
      "37.0 of 500 , lr: 0.0228571428571\n",
      "45.0 of 500 , lr: 0.0222222222222\n",
      "45.0 of 500 , lr: 0.0216216216216\n",
      "58.0 of 500 , lr: 0.0210526315789\n",
      "54.0 of 500 , lr: 0.0205128205128\n",
      "64.0 of 500 , lr: 0.02\n",
      "66.0 of 500 , lr: 0.019512195122\n",
      "83.0 of 500 , lr: 0.0190476190476\n",
      "132.0 of 500 , lr: 0.0186046511628\n",
      "165.0 of 500 , lr: 0.0181818181818\n",
      "144.0 of 500 , lr: 0.0177777777778\n",
      "175.0 of 500 , lr: 0.0173913043478\n",
      "147.0 of 500 , lr: 0.0170212765957\n",
      "166.0 of 500 , lr: 0.0166666666667\n",
      "189.0 of 500 , lr: 0.0163265306122\n",
      "202.0 of 500 , lr: 0.016\n",
      "186.0 of 500 , lr: 0.0156862745098\n",
      "204.0 of 500 , lr: 0.0153846153846\n",
      "207.0 of 500 , lr: 0.0150943396226\n",
      "191.0 of 500 , lr: 0.0148148148148\n",
      "168.0 of 500 , lr: 0.0145454545455\n",
      "180.0 of 500 , lr: 0.0142857142857\n",
      "195.0 of 500 , lr: 0.0140350877193\n",
      "188.0 of 500 , lr: 0.0137931034483\n",
      "189.0 of 500 , lr: 0.0135593220339\n",
      "188.0 of 500 , lr: 0.0133333333333\n",
      "183.0 of 500 , lr: 0.0131147540984\n",
      "168.0 of 500 , lr: 0.0129032258065\n",
      "205.0 of 500 , lr: 0.0126984126984\n",
      "176.0 of 500 , lr: 0.0125\n",
      "215.0 of 500 , lr: 0.0123076923077\n",
      "207.0 of 500 , lr: 0.0121212121212\n",
      "178.0 of 500 , lr: 0.0119402985075\n",
      "204.0 of 500 , lr: 0.0117647058824\n",
      "205.0 of 500 , lr: 0.0115942028986\n",
      "206.0 of 500 , lr: 0.0114285714286\n",
      "175.0 of 500 , lr: 0.0112676056338\n",
      "201.0 of 500 , lr: 0.0111111111111\n",
      "207.0 of 500 , lr: 0.0109589041096\n",
      "192.0 of 500 , lr: 0.0108108108108\n",
      "213.0 of 500 , lr: 0.0106666666667\n",
      "177.0 of 500 , lr: 0.0105263157895\n",
      "159.0 of 500 , lr: 0.0103896103896\n",
      "203.0 of 500 , lr: 0.0102564102564\n",
      "201.0 of 500 , lr: 0.0101265822785\n",
      "195.0 of 500 , lr: 0.01\n",
      "198.0 of 500 , lr: 0.00987654320988\n",
      "192.0 of 500 , lr: 0.00975609756098\n",
      "203.0 of 500 , lr: 0.00963855421687\n",
      "206.0 of 500 , lr: 0.00952380952381\n",
      "205.0 of 500 , lr: 0.00941176470588\n",
      "196.0 of 500 , lr: 0.0093023255814\n",
      "219.0 of 500 , lr: 0.00919540229885\n",
      "169.0 of 500 , lr: 0.00909090909091\n",
      "188.0 of 500 , lr: 0.00898876404494\n",
      "215.0 of 500 , lr: 0.00888888888889\n",
      "181.0 of 500 , lr: 0.00879120879121\n",
      "200.0 of 500 , lr: 0.00869565217391\n",
      "193.0 of 500 , lr: 0.00860215053763\n",
      "216.0 of 500 , lr: 0.00851063829787\n",
      "185.0 of 500 , lr: 0.00842105263158\n",
      "192.0 of 500 , lr: 0.00833333333333\n",
      "182.0 of 500 , lr: 0.00824742268041\n",
      "208.0 of 500 , lr: 0.00816326530612\n",
      "183.0 of 500 , lr: 0.00808080808081\n",
      "215.0 of 500 , lr: 0.008\n",
      "205.0 of 500 , lr: 0.00792079207921\n",
      "216.0 of 500 , lr: 0.0078431372549\n",
      "184.0 of 500 , lr: 0.00776699029126\n",
      "209.0 of 500 , lr: 0.00769230769231\n",
      "194.0 of 500 , lr: 0.00761904761905\n",
      "199.0 of 500 , lr: 0.00754716981132\n",
      "199.0 of 500 , lr: 0.00747663551402\n",
      "181.0 of 500 , lr: 0.00740740740741\n",
      "180.0 of 500 , lr: 0.00733944954128\n",
      "197.0 of 500 , lr: 0.00727272727273\n",
      "197.0 of 500 , lr: 0.00720720720721\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-121-2a6860ad3ed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_r\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_maxQs1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0m_qs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0m_dws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m \u001b[0m_lr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_gradients\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m#                 train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    with tf.device(\"cpu:0\"):\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "    #     saver.restore(sess, model_path)\n",
    "\n",
    "        r_total = 0\n",
    "        k = 2000.0\n",
    "\n",
    "        for t in range(200000):\n",
    "            _lr = 0.2 * k / (k + t)\n",
    "    #         _lr = 0.5\n",
    "\n",
    "            _s = env.reset()\n",
    "            _qs = sess.run(Qs, feed_dict={s: [_s]})[0]\n",
    "\n",
    "            while True:\n",
    "    #             print _qs, _s\n",
    "    #             print \"\"\n",
    "\n",
    "                _a = next_action(_qs, 0.1)\n",
    "\n",
    "                #calculate gradients\n",
    "                _gradients = sess.run(gradients, {s: [_s], a: [_a]})\n",
    "\n",
    "                #take step\n",
    "                _s1, _r, done, info = env.step(_a)\n",
    "                r_total += _r\n",
    "\n",
    "                #calculate next Qs\n",
    "                [_maxQs1, _qs1] = sess.run([maxQs, Qs], feed_dict={s: [_s1]})\n",
    "\n",
    "                d = _r + y * _maxQs1 - _qs[_a]\n",
    "                _dws = [ _lr * d * dw for dw in _gradients ]\n",
    "\n",
    "#                 train\n",
    "#                 sess.run(update2, feed_dict={\n",
    "#                     dw: _dw for dw, _dw in zip(dws, _dws)\n",
    "#                 })\n",
    "                sess.run(update3, feed_dict={\n",
    "                    s: [_s], a: [_a], r: [_r], \n",
    "                    lr: _lr * 3.0,\n",
    "                    maxQs1: np.max(_qs1, 1),\n",
    "                    QSA: [_qs[_a]]\n",
    "                })\n",
    "\n",
    "                #update state\n",
    "                _s = _s1\n",
    "                _qs = _qs1[0]\n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "\n",
    "            if t % 500 == 0:\n",
    "                print r_total, \"of\", 500, \", lr:\", _lr\n",
    "                r_total = 0\n",
    "                saver.save(sess, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\n",
      "SF\u001b[41mF\u001b[0mF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Right)\n",
      "\n",
      "SFF\u001b[41mF\u001b[0m\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "\n",
      "SFF\u001b[41mF\u001b[0m\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "\n",
      "SFF\u001b[41mF\u001b[0m\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "\n",
      "SFFF\n",
      "FHF\u001b[41mH\u001b[0m\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "_s = env.reset()\n",
    "done = False\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, model_path)\n",
    "    \n",
    "    for i in range(100):\n",
    "        _qs = sess.run(Qs, feed_dict={s: [_s]})\n",
    "        _a = next_action(_qs, 0)\n",
    "        _s, _r, done, info = env.step(_a)\n",
    "        env.render()\n",
    "        print(\"\")\n",
    "\n",
    "        if done:\n",
    "            print(_r)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
