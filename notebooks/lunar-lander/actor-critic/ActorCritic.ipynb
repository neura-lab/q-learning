{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'module' object has no attribute '__module__'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from gym import wrappers\n",
    "from numpy.random import choice\n",
    "import random\n",
    "from phi.api import *\n",
    "import tensorflow as tf\n",
    "from tfinterface.reinforcement import DeepActorCritic, ExpandedStateEnv\n",
    "from tfinterface.interfaces import EnvironmentInterface\n",
    "from tfinterface.model_base import ModelBase\n",
    "from tensorflow.python import debug as tf_debug\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "import numbers\n",
    "\n",
    "\n",
    "def get_run():\n",
    "    try:\n",
    "        with open(\"run.txt\") as f:\n",
    "            run = int(f.read().split(\"/n\")[0])\n",
    "    except:\n",
    "        run = -1\n",
    "    \n",
    "    with open(\"run.txt\", 'w+') as f:\n",
    "        run += 1\n",
    "        \n",
    "        f.seek(0)\n",
    "        f.write(str(run))\n",
    "        f.truncate()\n",
    "        \n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LanderAC(DeepActorCritic):\n",
    "    \n",
    "    def define_actor_network(self, inputs, n_actions, n_states):\n",
    "        ops = dict(\n",
    "            trainable=True,\n",
    "            kernel_initializer=tf.random_uniform_initializer(minval=0.0, maxval=0.01),\n",
    "            use_bias=False,\n",
    "            bias_initializer=None\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            inputs.s\n",
    "            |> tf.layers.dense$(?, 128, activation=tf.nn.relu, name='relu_layer', **ops)\n",
    "            |> tf.nn.dropout$(?, inputs.keep_prob)\n",
    "            |> tf.layers.dense$(?, n_actions, activation=tf.nn.softmax, name='softmax_layer', **ops)\n",
    "        )\n",
    "\n",
    "\n",
    "    def define_critic_network(self, inputs, n_actions, n_states):\n",
    "        ops = dict(\n",
    "            trainable=True,\n",
    "            kernel_initializer=tf.random_uniform_initializer(minval=0.0, maxval=0.01),\n",
    "            use_bias=False,\n",
    "            bias_initializer=None\n",
    "        )\n",
    "\n",
    "        return (\n",
    "            inputs.s\n",
    "            |> tf.layers.dense$(?, 128, activation=tf.nn.relu, name='relu_layer', **ops)\n",
    "            |> tf.layers.dense$(?, 1, name='linear_layer', **ops)\n",
    "            |> (lambda t: t[:, 0])\n",
    "        )\n",
    "    \n",
    "    def fit(self, env, keep_prob=0.5, e=0., learning_rate=0.01, print_step=10, update_target=1, episodes=100000, max_episode_length=float('inf'), batch_size=32):\n",
    "        r_total = 0.\n",
    "\n",
    "        for episode in range(episodes):\n",
    "            done = False\n",
    "            ep_step = 0\n",
    "            s = env.reset()\n",
    "            episode_length = 0\n",
    "            ep_reward = 0.\n",
    "\n",
    "\n",
    "            while not done and ep_step <= max_episode_length:\n",
    "                self.global_step += 1\n",
    "                episode_length += 1\n",
    "                ep_step += 1\n",
    "\n",
    "                _learning_rate = learning_rate(self.global_step) if hasattr(learning_rate, '__call__') else learning_rate\n",
    "                _e = e(self.global_step) if hasattr(e, '__call__') else e\n",
    "\n",
    "                a = self.choose_action(s, keep_prob, e=_e)\n",
    "                s1, r, done, info = env.step(a)\n",
    "                r_total += r\n",
    "                ep_reward += r\n",
    "\n",
    "                self.replay_buffer.append((s, a, r, s1, float(done)))\n",
    "\n",
    "                S, A, R, S1, Done = self.replay_buffer.random_batch(batch_size).unzip()\n",
    "                V1 = self.sess.run(self.target_critic.V, feed_dict={self.inputs.s: S1, self.inputs.keep_prob: 1.0})\n",
    "\n",
    "                feed_dict = self.fit_feed(S, A, R, V1, Done, _learning_rate, True)\n",
    "\n",
    "                \n",
    "                _, summaries = self.sess.run([self.update, self.summaries], feed_dict=feed_dict)\n",
    "                self.writer.add_summary(summaries)\n",
    "\n",
    "                if self.global_step % update_target == 0:\n",
    "                    self.sess.run(self.update_target)\n",
    "\n",
    "                s = s1\n",
    "\n",
    "\n",
    "\n",
    "            episode_length_summary = self.sess.run(self.episode_length_summary,\n",
    "                                                   feed_dict={self.inputs.episode_length: episode_length})\n",
    "            self.writer.add_summary(episode_length_summary)\n",
    "\n",
    "\n",
    "            if ep_reward >= self.global_max:\n",
    "                print(\"[MAX] Episode: {}, Length: {}, Reward: {}, buffer_len: {}\".format(episode, episode_length, ep_reward, len(self.replay_buffer)))\n",
    "                self.save(model_path = self.model_path + \".max\")\n",
    "                self.global_max = ep_reward\n",
    "\n",
    "\n",
    "            if episode % print_step == 0 and episode > 0:\n",
    "                avg_r = r_total / print_step\n",
    "                actor_loss = self.sess.run(self.actor.loss, feed_dict=feed_dict)\n",
    "                print(\"[NOR] Episode: {}, Length: {}, e: {}, Avg Reward: {}, Learning Rate: {}, buffer_len: {}\".format(episode, episode_length, _e, avg_r, _learning_rate, len(self.replay_buffer)))\n",
    "                print(\"Loss: {}\".format(actor_loss))\n",
    "                self.save()\n",
    "                r_total = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-04 19:11:13,215] Making new env: LunarLander-v2\n",
      "[2017-03-04 19:11:13,219] DEPRECATION WARNING: env.spec.timestep_limit has been deprecated. Replace your call to `env.spec.timestep_limit` with `env.spec.tags.get('wrapper_config.TimeLimit.max_episode_steps')`. This change was made 12/28/2016 and is included in version 0.7.0\n",
      "[2017-03-04 19:11:13,219] Creating monitor directory tmp/monitor36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Discrete(4)\n",
      "Run: 36\n"
     ]
    }
   ],
   "source": [
    "run = get_run()\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "env = wrappers.Monitor(env, \"tmp/monitor{}\".format(run))\n",
    "env = ExpandedStateEnv(env, 3)\n",
    "print(env.action_space)\n",
    "n_actions = env.action_space.n\n",
    "n_states = env.observation_space.shape[0] * 3\n",
    "model_path = os.getcwd() + \"/actor-critic.model\"\n",
    "logs_path = \"logs/run{}\".format(run)\n",
    "\n",
    "print(\"Run: {}\".format(run))\n",
    "\n",
    "model = LanderAC(\n",
    "    n_actions, n_states, y=0.9999, \n",
    "    buffer_length=500000, pi=0.1,\n",
    "    model_path = model_path,\n",
    "    logs_path = logs_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NOR] Episode: 10, Length: 539, e: 0.05, Avg Reward: 170.422883141, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.81865692139\n",
      "[NOR] Episode: 20, Length: 457, e: 0.05, Avg Reward: 169.049271384, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.38664150238\n",
      "[NOR] Episode: 30, Length: 1012, e: 0.05, Avg Reward: 183.728628327, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.17222738266\n",
      "[NOR] Episode: 40, Length: 923, e: 0.05, Avg Reward: 166.677190079, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.46756410599\n",
      "[NOR] Episode: 50, Length: 373, e: 0.05, Avg Reward: 162.844334165, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.492980957\n",
      "[NOR] Episode: 60, Length: 600, e: 0.05, Avg Reward: 152.84946325, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.68625426292\n",
      "[NOR] Episode: 70, Length: 558, e: 0.05, Avg Reward: 178.068605347, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.323403120041\n",
      "[NOR] Episode: 80, Length: 632, e: 0.05, Avg Reward: 160.787147928, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.22890424728\n",
      "[NOR] Episode: 90, Length: 270, e: 0.05, Avg Reward: 155.776764159, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.30136823654\n",
      "[NOR] Episode: 100, Length: 280, e: 0.05, Avg Reward: 190.466136633, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.10143661499\n",
      "[NOR] Episode: 110, Length: 696, e: 0.05, Avg Reward: 175.860325267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.49580049515\n",
      "[NOR] Episode: 120, Length: 348, e: 0.05, Avg Reward: 159.990646833, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.42579364777\n",
      "[NOR] Episode: 130, Length: 228, e: 0.05, Avg Reward: 186.077158037, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.60403680801\n",
      "[NOR] Episode: 140, Length: 540, e: 0.05, Avg Reward: 134.058406291, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.921636343\n",
      "[NOR] Episode: 150, Length: 785, e: 0.05, Avg Reward: 158.064776386, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.00164222717\n",
      "[NOR] Episode: 160, Length: 194, e: 0.05, Avg Reward: 183.341507367, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.65427064896\n",
      "[MAX] Episode: 168, Length: 257, Reward: 258.66339238, buffer_len: 500000\n",
      "[NOR] Episode: 170, Length: 97, e: 0.05, Avg Reward: 179.682487741, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.98816084862\n",
      "[NOR] Episode: 180, Length: 210, e: 0.05, Avg Reward: 63.5068404316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.90067780018\n",
      "[NOR] Episode: 190, Length: 558, e: 0.05, Avg Reward: 5.78252607943, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.4175542593\n",
      "[NOR] Episode: 200, Length: 353, e: 0.05, Avg Reward: 110.140087933, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.96483039856\n",
      "[NOR] Episode: 210, Length: 493, e: 0.05, Avg Reward: 117.944214313, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.30016219616\n",
      "[NOR] Episode: 220, Length: 574, e: 0.05, Avg Reward: 148.595419032, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.5944237709\n",
      "[MAX] Episode: 230, Length: 411, Reward: 260.011913266, buffer_len: 500000\n",
      "[NOR] Episode: 230, Length: 411, e: 0.05, Avg Reward: 195.33550607, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.53757071495\n",
      "[NOR] Episode: 240, Length: 400, e: 0.05, Avg Reward: 195.011478974, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.90714216232\n",
      "[NOR] Episode: 250, Length: 475, e: 0.05, Avg Reward: 134.651985241, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.15954017639\n",
      "[MAX] Episode: 257, Length: 368, Reward: 266.394446101, buffer_len: 500000\n",
      "[NOR] Episode: 260, Length: 359, e: 0.05, Avg Reward: 201.635247998, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.25081253052\n",
      "[NOR] Episode: 270, Length: 127, e: 0.05, Avg Reward: 177.273038154, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.44309139252\n",
      "[NOR] Episode: 280, Length: 313, e: 0.05, Avg Reward: 73.7325271409, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.17588043213\n",
      "[NOR] Episode: 290, Length: 167, e: 0.05, Avg Reward: 154.817095581, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.59592103958\n",
      "[MAX] Episode: 299, Length: 368, Reward: 271.67200059, buffer_len: 500000\n",
      "[NOR] Episode: 300, Length: 99, e: 0.05, Avg Reward: 138.682689815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.04038047791\n",
      "[NOR] Episode: 310, Length: 426, e: 0.05, Avg Reward: 159.779572247, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.12588071823\n",
      "[NOR] Episode: 320, Length: 500, e: 0.05, Avg Reward: 196.58850981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0611384510994\n",
      "[NOR] Episode: 330, Length: 358, e: 0.05, Avg Reward: 195.331363732, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.48169803619\n",
      "[NOR] Episode: 340, Length: 384, e: 0.05, Avg Reward: 178.665152265, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.67285084724\n",
      "[NOR] Episode: 350, Length: 392, e: 0.05, Avg Reward: 189.090593122, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.29311025143\n",
      "[NOR] Episode: 360, Length: 285, e: 0.05, Avg Reward: 200.66531784, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.68202877045\n",
      "[NOR] Episode: 370, Length: 468, e: 0.05, Avg Reward: 141.51087276, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.132876753807\n",
      "[NOR] Episode: 380, Length: 507, e: 0.05, Avg Reward: 139.952884745, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.59766626358\n",
      "[NOR] Episode: 390, Length: 567, e: 0.05, Avg Reward: 200.140916347, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.07691526413\n",
      "[NOR] Episode: 400, Length: 213, e: 0.05, Avg Reward: 138.829924027, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.93275690079\n",
      "[NOR] Episode: 410, Length: 292, e: 0.05, Avg Reward: 202.258104277, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.22749400139\n",
      "[NOR] Episode: 420, Length: 472, e: 0.05, Avg Reward: 159.134086214, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.33159255981\n",
      "[NOR] Episode: 430, Length: 507, e: 0.05, Avg Reward: 70.0393390689, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.79792976379\n",
      "[NOR] Episode: 440, Length: 468, e: 0.05, Avg Reward: 190.602039073, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.726581096649\n",
      "[NOR] Episode: 450, Length: 312, e: 0.05, Avg Reward: 170.579076138, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.71197199821\n",
      "[NOR] Episode: 460, Length: 220, e: 0.05, Avg Reward: 106.152214395, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.57789993286\n",
      "[NOR] Episode: 470, Length: 396, e: 0.05, Avg Reward: 151.595325516, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.48010492325\n",
      "[NOR] Episode: 480, Length: 182, e: 0.05, Avg Reward: 97.6492943685, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.00801157951\n",
      "[NOR] Episode: 490, Length: 144, e: 0.05, Avg Reward: 165.200617962, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.3257598877\n",
      "[NOR] Episode: 500, Length: 403, e: 0.05, Avg Reward: 116.523079964, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.41501379013\n",
      "[NOR] Episode: 510, Length: 483, e: 0.05, Avg Reward: 192.674645881, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.62049651146\n",
      "[NOR] Episode: 520, Length: 176, e: 0.05, Avg Reward: 130.12087531, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.26729822159\n",
      "[NOR] Episode: 530, Length: 428, e: 0.05, Avg Reward: 60.9591575665, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.94879579544\n",
      "[NOR] Episode: 540, Length: 402, e: 0.05, Avg Reward: 87.4490487421, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.853840827942\n",
      "[NOR] Episode: 550, Length: 295, e: 0.05, Avg Reward: 198.308384465, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.34209060669\n",
      "[NOR] Episode: 560, Length: 257, e: 0.05, Avg Reward: 169.557281443, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.961465001106\n",
      "[NOR] Episode: 570, Length: 375, e: 0.05, Avg Reward: 136.762917148, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.88282012939\n",
      "[NOR] Episode: 580, Length: 63, e: 0.05, Avg Reward: 98.6704977086, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.20031034946\n",
      "[NOR] Episode: 590, Length: 4088, e: 0.05, Avg Reward: 116.257482461, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.4303715229\n",
      "[NOR] Episode: 600, Length: 446, e: 0.05, Avg Reward: 183.487826931, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.16256904602\n",
      "[NOR] Episode: 610, Length: 507, e: 0.05, Avg Reward: 149.840991355, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.76670694351\n",
      "[NOR] Episode: 620, Length: 448, e: 0.05, Avg Reward: 178.492916303, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.6921710968\n",
      "[NOR] Episode: 630, Length: 332, e: 0.05, Avg Reward: 207.063942073, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.67896080017\n",
      "[NOR] Episode: 640, Length: 61, e: 0.05, Avg Reward: 49.1356223125, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.75828051567\n",
      "[NOR] Episode: 650, Length: 467, e: 0.05, Avg Reward: 158.788657295, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.72108244896\n",
      "[NOR] Episode: 660, Length: 353, e: 0.05, Avg Reward: 171.972228458, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.73769855499\n",
      "[NOR] Episode: 670, Length: 447, e: 0.05, Avg Reward: 192.668293179, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.81989133358\n",
      "[NOR] Episode: 680, Length: 794, e: 0.05, Avg Reward: 142.959309181, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.351876020432\n",
      "[NOR] Episode: 690, Length: 86, e: 0.05, Avg Reward: 137.178224007, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.66217017174\n",
      "[NOR] Episode: 700, Length: 343, e: 0.05, Avg Reward: 87.6944936687, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.78143000603\n",
      "[NOR] Episode: 710, Length: 334, e: 0.05, Avg Reward: 40.7115635004, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.92118024826\n",
      "[NOR] Episode: 720, Length: 313, e: 0.05, Avg Reward: 207.449020151, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.67281389236\n",
      "[NOR] Episode: 730, Length: 246, e: 0.05, Avg Reward: 133.886292504, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.58440768719\n",
      "[NOR] Episode: 740, Length: 337, e: 0.05, Avg Reward: 135.327610209, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.82615041733\n",
      "[NOR] Episode: 750, Length: 276, e: 0.05, Avg Reward: 132.38415084, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.73732089996\n",
      "[NOR] Episode: 760, Length: 387, e: 0.05, Avg Reward: 175.550781971, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.47131824493\n",
      "[NOR] Episode: 770, Length: 350, e: 0.05, Avg Reward: 158.210311018, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.92699241638\n",
      "[NOR] Episode: 780, Length: 513, e: 0.05, Avg Reward: 186.349604469, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.52543354034\n",
      "[NOR] Episode: 790, Length: 338, e: 0.05, Avg Reward: 127.604720206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.63860714436\n",
      "[NOR] Episode: 800, Length: 482, e: 0.05, Avg Reward: 181.205298834, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.8761882782\n",
      "[NOR] Episode: 810, Length: 462, e: 0.05, Avg Reward: 109.744299811, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0107815265656\n",
      "[NOR] Episode: 820, Length: 390, e: 0.05, Avg Reward: 61.3777112831, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.207397222519\n",
      "[NOR] Episode: 830, Length: 587, e: 0.05, Avg Reward: 97.7483803826, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.48709464073\n",
      "[NOR] Episode: 840, Length: 343, e: 0.05, Avg Reward: 144.824585646, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.867660880089\n",
      "[NOR] Episode: 850, Length: 382, e: 0.05, Avg Reward: 130.043025393, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.59582614899\n",
      "[NOR] Episode: 860, Length: 705, e: 0.05, Avg Reward: 164.422993514, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.93219637871\n",
      "[NOR] Episode: 870, Length: 403, e: 0.05, Avg Reward: 204.232174206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.08467769623\n",
      "[NOR] Episode: 880, Length: 399, e: 0.05, Avg Reward: 115.861813922, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.08353805542\n",
      "[NOR] Episode: 890, Length: 362, e: 0.05, Avg Reward: 151.631835489, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.99011898041\n",
      "[NOR] Episode: 900, Length: 345, e: 0.05, Avg Reward: 138.86143684, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.26130974293\n",
      "[NOR] Episode: 910, Length: 585, e: 0.05, Avg Reward: 154.982634973, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.90405416489\n",
      "[NOR] Episode: 920, Length: 545, e: 0.05, Avg Reward: 115.521881581, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.50775337219\n",
      "[NOR] Episode: 930, Length: 424, e: 0.05, Avg Reward: 157.6202893, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.48688864708\n",
      "[NOR] Episode: 940, Length: 548, e: 0.05, Avg Reward: 162.438708222, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.83402991295\n",
      "[NOR] Episode: 950, Length: 348, e: 0.05, Avg Reward: 125.725684493, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.28797531128\n",
      "[NOR] Episode: 960, Length: 527, e: 0.05, Avg Reward: 149.497198981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.357641220093\n",
      "[NOR] Episode: 970, Length: 478, e: 0.05, Avg Reward: 130.44498751, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.38563871384\n",
      "[NOR] Episode: 980, Length: 563, e: 0.05, Avg Reward: 197.705262834, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.111259281635\n",
      "[NOR] Episode: 990, Length: 501, e: 0.05, Avg Reward: 196.090546937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.72526359558\n",
      "[NOR] Episode: 1000, Length: 451, e: 0.05, Avg Reward: 169.506784206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.42162942886\n",
      "[NOR] Episode: 1010, Length: 641, e: 0.05, Avg Reward: 178.537148863, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.92981076241\n",
      "[NOR] Episode: 1020, Length: 575, e: 0.05, Avg Reward: 163.219145395, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.90556144714\n",
      "[NOR] Episode: 1030, Length: 395, e: 0.05, Avg Reward: 197.741344109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.5445318222\n",
      "[NOR] Episode: 1040, Length: 415, e: 0.05, Avg Reward: 187.018839554, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.499466001987\n",
      "[NOR] Episode: 1050, Length: 454, e: 0.05, Avg Reward: 197.786628992, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0353066325188\n",
      "[NOR] Episode: 1060, Length: 418, e: 0.05, Avg Reward: 192.060267879, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.71033096313\n",
      "[NOR] Episode: 1070, Length: 669, e: 0.05, Avg Reward: 163.005314103, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.25336694717\n",
      "[NOR] Episode: 1080, Length: 496, e: 0.05, Avg Reward: 180.557726962, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.87320566177\n",
      "[NOR] Episode: 1090, Length: 543, e: 0.05, Avg Reward: 167.762282894, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0369081199169\n",
      "[NOR] Episode: 1100, Length: 378, e: 0.05, Avg Reward: 161.385229481, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.55382156372\n",
      "[NOR] Episode: 1110, Length: 359, e: 0.05, Avg Reward: 60.7348449139, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.670383989811\n",
      "[NOR] Episode: 1120, Length: 459, e: 0.05, Avg Reward: 21.6877069897, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.63196372986\n",
      "[NOR] Episode: 1130, Length: 391, e: 0.05, Avg Reward: -13.8307509259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.776148080826\n",
      "[NOR] Episode: 1140, Length: 170, e: 0.05, Avg Reward: 35.1411877924, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.1856675148\n",
      "[NOR] Episode: 1150, Length: 224, e: 0.05, Avg Reward: 75.1837058611, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.36096310616\n",
      "[NOR] Episode: 1160, Length: 544, e: 0.05, Avg Reward: 107.040144229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.45013523102\n",
      "[NOR] Episode: 1170, Length: 522, e: 0.05, Avg Reward: 33.3868634321, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.08333826065\n",
      "[NOR] Episode: 1180, Length: 389, e: 0.05, Avg Reward: 94.4571769089, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.82896029949\n",
      "[NOR] Episode: 1190, Length: 430, e: 0.05, Avg Reward: 130.739564617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.96945858002\n",
      "[NOR] Episode: 1200, Length: 121, e: 0.05, Avg Reward: 122.356335111, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.20959377289\n",
      "[NOR] Episode: 1210, Length: 437, e: 0.05, Avg Reward: 168.20120945, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.381178498268\n",
      "[NOR] Episode: 1220, Length: 403, e: 0.05, Avg Reward: 130.283148383, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.21208143234\n",
      "[NOR] Episode: 1230, Length: 376, e: 0.05, Avg Reward: 201.910519197, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.432857990265\n",
      "[NOR] Episode: 1240, Length: 350, e: 0.05, Avg Reward: 139.871641077, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.89235258102\n",
      "[NOR] Episode: 1250, Length: 490, e: 0.05, Avg Reward: 169.781710556, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.677709341049\n",
      "[NOR] Episode: 1260, Length: 529, e: 0.05, Avg Reward: 202.982530165, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.442951023579\n",
      "[NOR] Episode: 1270, Length: 1082, e: 0.05, Avg Reward: 145.498589405, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.61003875732\n",
      "[NOR] Episode: 1280, Length: 320, e: 0.05, Avg Reward: 174.156968765, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.25005483627\n",
      "[NOR] Episode: 1290, Length: 725, e: 0.05, Avg Reward: 118.394635663, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.47304391861\n",
      "[NOR] Episode: 1300, Length: 619, e: 0.05, Avg Reward: 166.564241724, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.22764158249\n",
      "[NOR] Episode: 1310, Length: 283, e: 0.05, Avg Reward: 191.732091819, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.89891672134\n",
      "[NOR] Episode: 1320, Length: 427, e: 0.05, Avg Reward: 153.799373134, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.6871162653\n",
      "[NOR] Episode: 1330, Length: 395, e: 0.05, Avg Reward: 175.972829867, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.31175288558\n",
      "[NOR] Episode: 1340, Length: 374, e: 0.05, Avg Reward: 120.250311928, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.56895685196\n",
      "[NOR] Episode: 1350, Length: 431, e: 0.05, Avg Reward: 107.613774194, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.07665348053\n",
      "[NOR] Episode: 1360, Length: 452, e: 0.05, Avg Reward: 184.215172167, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.23341941833\n",
      "[NOR] Episode: 1370, Length: 551, e: 0.05, Avg Reward: 170.976853943, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.82836413383\n",
      "[NOR] Episode: 1380, Length: 517, e: 0.05, Avg Reward: 138.981211254, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.16714453697\n",
      "[NOR] Episode: 1390, Length: 456, e: 0.05, Avg Reward: 185.495284069, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.57840132713\n",
      "[NOR] Episode: 1400, Length: 517, e: 0.05, Avg Reward: 205.059198988, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.74786782265\n",
      "[NOR] Episode: 1410, Length: 221, e: 0.05, Avg Reward: 196.617660737, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.82050967216\n",
      "[NOR] Episode: 1420, Length: 354, e: 0.05, Avg Reward: 139.562297868, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.40794062614\n",
      "[NOR] Episode: 1430, Length: 125, e: 0.05, Avg Reward: 82.8556647388, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.43646407127\n",
      "[NOR] Episode: 1440, Length: 1955, e: 0.05, Avg Reward: 173.757734897, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.445810437202\n",
      "[NOR] Episode: 1450, Length: 377, e: 0.05, Avg Reward: 178.636865009, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.16831862926\n",
      "[NOR] Episode: 1460, Length: 345, e: 0.05, Avg Reward: 193.765598641, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.888896167278\n",
      "[NOR] Episode: 1470, Length: 384, e: 0.05, Avg Reward: 124.44491818, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.50986731052\n",
      "[NOR] Episode: 1480, Length: 520, e: 0.05, Avg Reward: 132.048853124, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.43127393723\n",
      "[NOR] Episode: 1490, Length: 395, e: 0.05, Avg Reward: 155.890419267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.07287120819\n",
      "[NOR] Episode: 1500, Length: 140, e: 0.05, Avg Reward: 128.965764596, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.371174633503\n",
      "[NOR] Episode: 1510, Length: 399, e: 0.05, Avg Reward: 32.9768284763, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.31124961376\n",
      "[NOR] Episode: 1520, Length: 357, e: 0.05, Avg Reward: 160.8086511, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.74548196793\n",
      "[NOR] Episode: 1530, Length: 263, e: 0.05, Avg Reward: 132.88248613, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.75997829437\n",
      "[NOR] Episode: 1540, Length: 420, e: 0.05, Avg Reward: 162.1638175, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.6656460762\n",
      "[NOR] Episode: 1550, Length: 1573, e: 0.05, Avg Reward: -12.7959158804, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.71432244778\n",
      "[NOR] Episode: 1560, Length: 127, e: 0.05, Avg Reward: 77.162655213, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.0542297363\n",
      "[NOR] Episode: 1570, Length: 150, e: 0.05, Avg Reward: -15.6717181947, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.35585546494\n",
      "[NOR] Episode: 1580, Length: 133, e: 0.05, Avg Reward: -5.95275340259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.057751894\n",
      "[NOR] Episode: 1590, Length: 325, e: 0.05, Avg Reward: 39.3841665657, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.86672544479\n",
      "[NOR] Episode: 1600, Length: 412, e: 0.05, Avg Reward: 130.531517172, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.22617864609\n",
      "[NOR] Episode: 1610, Length: 795, e: 0.05, Avg Reward: 129.324636503, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.74725747108\n",
      "[MAX] Episode: 1618, Length: 285, Reward: 275.784938462, buffer_len: 500000\n",
      "[NOR] Episode: 1620, Length: 1129, e: 0.05, Avg Reward: 170.504751724, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.00325274467\n",
      "[NOR] Episode: 1630, Length: 244, e: 0.05, Avg Reward: 169.407902019, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.79759001732\n",
      "[NOR] Episode: 1640, Length: 252, e: 0.05, Avg Reward: 166.3371087, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.22135663033\n",
      "[NOR] Episode: 1650, Length: 295, e: 0.05, Avg Reward: 185.095671644, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.02403640747\n",
      "[NOR] Episode: 1660, Length: 349, e: 0.05, Avg Reward: 131.814574366, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.38399648666\n",
      "[NOR] Episode: 1670, Length: 303, e: 0.05, Avg Reward: 143.025891647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.67992019653\n",
      "[NOR] Episode: 1680, Length: 430, e: 0.05, Avg Reward: 131.964021607, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.809676170349\n",
      "[NOR] Episode: 1690, Length: 259, e: 0.05, Avg Reward: 147.111909417, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.37708759308\n",
      "[NOR] Episode: 1700, Length: 264, e: 0.05, Avg Reward: 149.116560922, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.4760532379\n",
      "[NOR] Episode: 1710, Length: 342, e: 0.05, Avg Reward: 184.671848765, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.489770770073\n",
      "[NOR] Episode: 1720, Length: 1169, e: 0.05, Avg Reward: 170.016184216, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.47444581985\n",
      "[NOR] Episode: 1730, Length: 644, e: 0.05, Avg Reward: 182.265063805, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.07121038437\n",
      "[NOR] Episode: 1740, Length: 132, e: 0.05, Avg Reward: 186.834997232, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.66166353226\n",
      "[NOR] Episode: 1750, Length: 259, e: 0.05, Avg Reward: 173.356895542, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.14008903503\n",
      "[NOR] Episode: 1760, Length: 111, e: 0.05, Avg Reward: 92.0755315038, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.48774456978\n",
      "[NOR] Episode: 1770, Length: 111, e: 0.05, Avg Reward: 47.8263804216, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.42663741112\n",
      "[NOR] Episode: 1780, Length: 248, e: 0.05, Avg Reward: 8.05242321467, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.38644433022\n",
      "[NOR] Episode: 1790, Length: 83, e: 0.05, Avg Reward: 11.5770597595, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.662314534187\n",
      "[NOR] Episode: 1800, Length: 64, e: 0.05, Avg Reward: -23.7716201746, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.737912416458\n",
      "[NOR] Episode: 1810, Length: 56, e: 0.05, Avg Reward: -70.2296287428, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.748247385025\n",
      "[NOR] Episode: 1820, Length: 113, e: 0.05, Avg Reward: -82.0391967495, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.75760650635\n",
      "[NOR] Episode: 1830, Length: 282, e: 0.05, Avg Reward: 97.2611750857, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.24541401863\n",
      "[NOR] Episode: 1840, Length: 359, e: 0.05, Avg Reward: 215.142516693, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.161561250687\n",
      "[NOR] Episode: 1850, Length: 431, e: 0.05, Avg Reward: 201.088693235, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.53725028038\n",
      "[NOR] Episode: 1860, Length: 512, e: 0.05, Avg Reward: 183.84629647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.00205248594284\n",
      "[NOR] Episode: 1870, Length: 165, e: 0.05, Avg Reward: 171.844143229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.90861153603\n",
      "[NOR] Episode: 1880, Length: 1335, e: 0.05, Avg Reward: 139.693888658, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.67111730576\n",
      "[NOR] Episode: 1890, Length: 420, e: 0.05, Avg Reward: 209.76234194, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.68193697929\n",
      "[NOR] Episode: 1900, Length: 471, e: 0.05, Avg Reward: 169.210573915, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.184262424707\n",
      "[NOR] Episode: 1910, Length: 348, e: 0.05, Avg Reward: 207.799774613, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.7870028019\n",
      "[NOR] Episode: 1920, Length: 354, e: 0.05, Avg Reward: 190.417060061, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.91993808746\n",
      "[NOR] Episode: 1930, Length: 782, e: 0.05, Avg Reward: 180.133510929, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.691505670547\n",
      "[NOR] Episode: 1940, Length: 396, e: 0.05, Avg Reward: 155.83685595, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.4530229568\n",
      "[NOR] Episode: 1950, Length: 1157, e: 0.05, Avg Reward: 100.716604627, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.57527589798\n",
      "[NOR] Episode: 1960, Length: 10001, e: 0.05, Avg Reward: 33.8599178784, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.42119979858\n",
      "[NOR] Episode: 1970, Length: 10001, e: 0.05, Avg Reward: -47.1699501131, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.608332753181\n",
      "[NOR] Episode: 1980, Length: 932, e: 0.05, Avg Reward: -134.22808524, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.66345310211\n",
      "[NOR] Episode: 1990, Length: 330, e: 0.05, Avg Reward: -4.99887304242, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.30443382263\n",
      "[NOR] Episode: 2000, Length: 10001, e: 0.05, Avg Reward: -90.6770045517, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.782939314842\n",
      "[NOR] Episode: 2010, Length: 673, e: 0.05, Avg Reward: 26.4465292697, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.489560365677\n",
      "[NOR] Episode: 2020, Length: 379, e: 0.05, Avg Reward: 44.4296070566, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.43717503548\n",
      "[NOR] Episode: 2030, Length: 276, e: 0.05, Avg Reward: -17.7264279583, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.17512774467\n",
      "[NOR] Episode: 2040, Length: 1973, e: 0.05, Avg Reward: -71.4968277148, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.919431686401\n",
      "[NOR] Episode: 2050, Length: 10001, e: 0.05, Avg Reward: -223.578959934, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.18370723724\n",
      "[NOR] Episode: 2060, Length: 1439, e: 0.05, Avg Reward: -450.943719828, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0104353427887\n",
      "[NOR] Episode: 2070, Length: 247, e: 0.05, Avg Reward: -15.0825343543, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.95444345474\n",
      "[NOR] Episode: 2080, Length: 211, e: 0.05, Avg Reward: -92.3724751193, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.5983009338\n",
      "[NOR] Episode: 2090, Length: 1460, e: 0.05, Avg Reward: -48.9054619785, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.837281286716\n",
      "[NOR] Episode: 2100, Length: 236, e: 0.05, Avg Reward: -119.991876601, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.88244581223\n",
      "[NOR] Episode: 2110, Length: 126, e: 0.05, Avg Reward: -241.168209611, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.8686084747\n",
      "[NOR] Episode: 2120, Length: 372, e: 0.05, Avg Reward: -28.3035448, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.5985088348\n",
      "[NOR] Episode: 2130, Length: 118, e: 0.05, Avg Reward: -87.3253982514, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -62.729675293\n",
      "[NOR] Episode: 2140, Length: 154, e: 0.05, Avg Reward: -130.318217901, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -38.8248062134\n",
      "[NOR] Episode: 2150, Length: 96, e: 0.05, Avg Reward: -132.789716982, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.7788600922\n",
      "[NOR] Episode: 2160, Length: 148, e: 0.05, Avg Reward: -78.6021962526, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.81452059746\n",
      "[NOR] Episode: 2170, Length: 174, e: 0.05, Avg Reward: -124.011514919, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -64.9639587402\n",
      "[NOR] Episode: 2180, Length: 150, e: 0.05, Avg Reward: -123.183025425, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.00992870331\n",
      "[NOR] Episode: 2190, Length: 181, e: 0.05, Avg Reward: -136.984226479, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.461025238\n",
      "[NOR] Episode: 2200, Length: 312, e: 0.05, Avg Reward: -166.23329857, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -86.1828765869\n",
      "[NOR] Episode: 2210, Length: 144, e: 0.05, Avg Reward: -91.5260305432, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.3313560486\n",
      "[NOR] Episode: 2220, Length: 129, e: 0.05, Avg Reward: -145.097639371, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.02629089355\n",
      "[NOR] Episode: 2230, Length: 137, e: 0.05, Avg Reward: -60.9863319109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -84.3459396362\n",
      "[NOR] Episode: 2240, Length: 121, e: 0.05, Avg Reward: -81.245805079, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -46.8568191528\n",
      "[NOR] Episode: 2250, Length: 158, e: 0.05, Avg Reward: -71.9258496026, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -46.8412742615\n",
      "[NOR] Episode: 2260, Length: 317, e: 0.05, Avg Reward: -126.258503354, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.2009468079\n",
      "[NOR] Episode: 2270, Length: 178, e: 0.05, Avg Reward: -173.92133034, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.0708179474\n",
      "[NOR] Episode: 2280, Length: 107, e: 0.05, Avg Reward: -185.541490149, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.4822368622\n",
      "[NOR] Episode: 2290, Length: 110, e: 0.05, Avg Reward: -182.981124438, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.72305488586\n",
      "[NOR] Episode: 2300, Length: 201, e: 0.05, Avg Reward: -256.245438862, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.0637283325\n",
      "[NOR] Episode: 2310, Length: 210, e: 0.05, Avg Reward: -265.249958262, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 108.77696228\n",
      "[NOR] Episode: 2320, Length: 104, e: 0.05, Avg Reward: -234.992948971, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.3533840179\n",
      "[NOR] Episode: 2330, Length: 111, e: 0.05, Avg Reward: -220.652549513, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.0149822235\n",
      "[NOR] Episode: 2340, Length: 173, e: 0.05, Avg Reward: -231.402588274, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -137.523544312\n",
      "[NOR] Episode: 2350, Length: 295, e: 0.05, Avg Reward: -204.45701848, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.34627723694\n",
      "[NOR] Episode: 2360, Length: 118, e: 0.05, Avg Reward: -195.464771483, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.4349822998\n",
      "[NOR] Episode: 2370, Length: 128, e: 0.05, Avg Reward: -153.519085266, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 75.5444793701\n",
      "[NOR] Episode: 2380, Length: 114, e: 0.05, Avg Reward: -152.159980738, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -57.0538482666\n",
      "[NOR] Episode: 2390, Length: 130, e: 0.05, Avg Reward: -210.740253844, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.6511154175\n",
      "[NOR] Episode: 2400, Length: 215, e: 0.05, Avg Reward: -173.720004217, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.2192611694\n",
      "[NOR] Episode: 2410, Length: 166, e: 0.05, Avg Reward: -211.365018365, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.4901351929\n",
      "[NOR] Episode: 2420, Length: 159, e: 0.05, Avg Reward: -222.849363136, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.8990631104\n",
      "[NOR] Episode: 2430, Length: 169, e: 0.05, Avg Reward: -284.132797099, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -84.2917938232\n",
      "[NOR] Episode: 2440, Length: 147, e: 0.05, Avg Reward: -276.428885709, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -191.85710144\n",
      "[NOR] Episode: 2450, Length: 118, e: 0.05, Avg Reward: -237.498070589, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -158.706481934\n",
      "[NOR] Episode: 2460, Length: 91, e: 0.05, Avg Reward: -277.165427871, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.0390453339\n",
      "[NOR] Episode: 2470, Length: 100, e: 0.05, Avg Reward: -259.445753423, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 50.5449905396\n",
      "[NOR] Episode: 2480, Length: 110, e: 0.05, Avg Reward: -248.159094957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.6432228088\n",
      "[NOR] Episode: 2490, Length: 166, e: 0.05, Avg Reward: -233.915832896, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.2669334412\n",
      "[NOR] Episode: 2500, Length: 92, e: 0.05, Avg Reward: -304.770185111, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 89.1918640137\n",
      "[NOR] Episode: 2510, Length: 185, e: 0.05, Avg Reward: -303.380018198, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 27.9623413086\n",
      "[NOR] Episode: 2520, Length: 190, e: 0.05, Avg Reward: -348.025118924, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.7215499878\n",
      "[NOR] Episode: 2530, Length: 58, e: 0.05, Avg Reward: -236.500397453, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.7408828735\n",
      "[NOR] Episode: 2540, Length: 87, e: 0.05, Avg Reward: -238.059707232, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 34.51978302\n",
      "[NOR] Episode: 2550, Length: 155, e: 0.05, Avg Reward: -278.946185561, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 73.6784667969\n",
      "[NOR] Episode: 2560, Length: 106, e: 0.05, Avg Reward: -251.113624321, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 87.975402832\n",
      "[NOR] Episode: 2570, Length: 178, e: 0.05, Avg Reward: -292.214292331, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.2243766785\n",
      "[NOR] Episode: 2580, Length: 123, e: 0.05, Avg Reward: -300.418201095, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -68.0434112549\n",
      "[NOR] Episode: 2590, Length: 156, e: 0.05, Avg Reward: -250.713984766, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -74.3875274658\n",
      "[NOR] Episode: 2600, Length: 176, e: 0.05, Avg Reward: -288.400513991, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -83.9066314697\n",
      "[NOR] Episode: 2610, Length: 140, e: 0.05, Avg Reward: -261.397346008, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 56.1680831909\n",
      "[NOR] Episode: 2620, Length: 99, e: 0.05, Avg Reward: -296.784737626, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -347.175476074\n",
      "[NOR] Episode: 2630, Length: 129, e: 0.05, Avg Reward: -373.326718569, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -120.687774658\n",
      "[NOR] Episode: 2640, Length: 98, e: 0.05, Avg Reward: -295.154788601, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 27.6123886108\n",
      "[NOR] Episode: 2650, Length: 88, e: 0.05, Avg Reward: -271.490392797, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -200.653884888\n",
      "[NOR] Episode: 2660, Length: 96, e: 0.05, Avg Reward: -185.404270984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.05216026306\n",
      "[NOR] Episode: 2670, Length: 69, e: 0.05, Avg Reward: -255.329949028, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -80.1759338379\n",
      "[NOR] Episode: 2680, Length: 119, e: 0.05, Avg Reward: -230.541676482, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.8495292664\n",
      "[NOR] Episode: 2690, Length: 128, e: 0.05, Avg Reward: -205.682300406, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -144.189346313\n",
      "[NOR] Episode: 2700, Length: 97, e: 0.05, Avg Reward: -321.251527044, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -46.0941543579\n",
      "[NOR] Episode: 2710, Length: 179, e: 0.05, Avg Reward: -291.215754589, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 288.309753418\n",
      "[NOR] Episode: 2720, Length: 144, e: 0.05, Avg Reward: -213.807728256, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.3230781555\n",
      "[NOR] Episode: 2730, Length: 102, e: 0.05, Avg Reward: -402.401152814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 94.8801269531\n",
      "[NOR] Episode: 2740, Length: 152, e: 0.05, Avg Reward: -343.951734237, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -121.155754089\n",
      "[NOR] Episode: 2750, Length: 119, e: 0.05, Avg Reward: -317.371764747, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -92.2864074707\n",
      "[NOR] Episode: 2760, Length: 107, e: 0.05, Avg Reward: -325.635472766, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.6405830383\n",
      "[NOR] Episode: 2770, Length: 79, e: 0.05, Avg Reward: -292.14222125, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -48.87059021\n",
      "[NOR] Episode: 2780, Length: 151, e: 0.05, Avg Reward: -340.445939745, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -96.8983154297\n",
      "[NOR] Episode: 2790, Length: 116, e: 0.05, Avg Reward: -408.912043932, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -117.03780365\n",
      "[NOR] Episode: 2800, Length: 112, e: 0.05, Avg Reward: -492.877193434, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 72.6202087402\n",
      "[NOR] Episode: 2810, Length: 161, e: 0.05, Avg Reward: -423.646188343, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -61.1248664856\n",
      "[NOR] Episode: 2820, Length: 128, e: 0.05, Avg Reward: -546.390390889, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -100.343009949\n",
      "[NOR] Episode: 2830, Length: 113, e: 0.05, Avg Reward: -525.567617616, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.3623504639\n",
      "[NOR] Episode: 2840, Length: 146, e: 0.05, Avg Reward: -524.4657937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -81.1651153564\n",
      "[NOR] Episode: 2850, Length: 87, e: 0.05, Avg Reward: -566.79000283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.1758928299\n",
      "[NOR] Episode: 2860, Length: 104, e: 0.05, Avg Reward: -417.946766885, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 42.049118042\n",
      "[NOR] Episode: 2870, Length: 150, e: 0.05, Avg Reward: -439.215126347, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.6944313049\n",
      "[NOR] Episode: 2880, Length: 138, e: 0.05, Avg Reward: -405.998555042, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -72.2266159058\n",
      "[NOR] Episode: 2890, Length: 151, e: 0.05, Avg Reward: -381.240215193, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 37.1974487305\n",
      "[NOR] Episode: 2900, Length: 115, e: 0.05, Avg Reward: -406.848200308, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.6768493652\n",
      "[NOR] Episode: 2910, Length: 144, e: 0.05, Avg Reward: -369.643851273, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.8398895264\n",
      "[NOR] Episode: 2920, Length: 167, e: 0.05, Avg Reward: -357.627237121, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -156.970214844\n",
      "[NOR] Episode: 2930, Length: 131, e: 0.05, Avg Reward: -312.245758326, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.8676834106\n",
      "[NOR] Episode: 2940, Length: 142, e: 0.05, Avg Reward: -310.357486208, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.7616157532\n",
      "[NOR] Episode: 2950, Length: 190, e: 0.05, Avg Reward: -382.988912182, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.7677192688\n",
      "[NOR] Episode: 2960, Length: 76, e: 0.05, Avg Reward: -420.167001658, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -75.7179718018\n",
      "[NOR] Episode: 2970, Length: 79, e: 0.05, Avg Reward: -447.302661914, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -103.385444641\n",
      "[NOR] Episode: 2980, Length: 208, e: 0.05, Avg Reward: -271.437478174, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.3694915771\n",
      "[NOR] Episode: 2990, Length: 88, e: 0.05, Avg Reward: -285.198198487, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.55239868164\n",
      "[NOR] Episode: 3000, Length: 86, e: 0.05, Avg Reward: -302.522071109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.1993427277\n",
      "[NOR] Episode: 3010, Length: 172, e: 0.05, Avg Reward: -326.422148336, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.9852600098\n",
      "[NOR] Episode: 3020, Length: 207, e: 0.05, Avg Reward: -269.102781856, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -195.822860718\n",
      "[NOR] Episode: 3030, Length: 184, e: 0.05, Avg Reward: -301.970151236, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.42606544495\n",
      "[NOR] Episode: 3040, Length: 138, e: 0.05, Avg Reward: -219.94917148, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -77.8185653687\n",
      "[NOR] Episode: 3050, Length: 89, e: 0.05, Avg Reward: -190.78443467, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 85.1939697266\n",
      "[NOR] Episode: 3060, Length: 98, e: 0.05, Avg Reward: -211.710487162, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.4641418457\n",
      "[NOR] Episode: 3070, Length: 189, e: 0.05, Avg Reward: -196.256437251, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -182.932235718\n",
      "[NOR] Episode: 3080, Length: 83, e: 0.05, Avg Reward: -215.409295802, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -144.406585693\n",
      "[NOR] Episode: 3090, Length: 111, e: 0.05, Avg Reward: -272.983914117, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.69769477844\n",
      "[NOR] Episode: 3100, Length: 98, e: 0.05, Avg Reward: -225.085050225, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 252.164245605\n",
      "[NOR] Episode: 3110, Length: 265, e: 0.05, Avg Reward: -372.031801723, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.26077079773\n",
      "[NOR] Episode: 3120, Length: 153, e: 0.05, Avg Reward: -250.240904351, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -46.6881408691\n",
      "[NOR] Episode: 3130, Length: 100, e: 0.05, Avg Reward: -299.547912599, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -109.411682129\n",
      "[NOR] Episode: 3140, Length: 88, e: 0.05, Avg Reward: -302.65390656, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.8995246887\n",
      "[NOR] Episode: 3150, Length: 84, e: 0.05, Avg Reward: -292.637054752, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -117.790290833\n",
      "[NOR] Episode: 3160, Length: 288, e: 0.05, Avg Reward: -295.278969708, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.9596481323\n",
      "[NOR] Episode: 3170, Length: 233, e: 0.05, Avg Reward: -323.436966069, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.5045967102\n",
      "[NOR] Episode: 3180, Length: 65, e: 0.05, Avg Reward: -261.161829006, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.4211273193\n",
      "[NOR] Episode: 3190, Length: 62, e: 0.05, Avg Reward: -304.390938255, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 77.1838531494\n",
      "[NOR] Episode: 3200, Length: 116, e: 0.05, Avg Reward: -293.884511315, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.958530426\n",
      "[NOR] Episode: 3210, Length: 111, e: 0.05, Avg Reward: -202.401733351, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -66.7073440552\n",
      "[NOR] Episode: 3220, Length: 232, e: 0.05, Avg Reward: -240.428812237, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 207.249084473\n",
      "[NOR] Episode: 3230, Length: 104, e: 0.05, Avg Reward: -230.685430513, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 50.5460548401\n",
      "[NOR] Episode: 3240, Length: 113, e: 0.05, Avg Reward: -222.361698855, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.873849868774\n",
      "[NOR] Episode: 3250, Length: 68, e: 0.05, Avg Reward: -167.692147763, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 103.06829834\n",
      "[NOR] Episode: 3260, Length: 75, e: 0.05, Avg Reward: -168.568430706, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.89521026611\n",
      "[NOR] Episode: 3270, Length: 213, e: 0.05, Avg Reward: -274.082162749, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -102.653259277\n",
      "[NOR] Episode: 3280, Length: 72, e: 0.05, Avg Reward: -264.363596517, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 812.270690918\n",
      "[NOR] Episode: 3290, Length: 180, e: 0.05, Avg Reward: -237.993132783, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.6852035522\n",
      "[NOR] Episode: 3300, Length: 147, e: 0.05, Avg Reward: -213.065544594, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -172.70223999\n",
      "[NOR] Episode: 3310, Length: 94, e: 0.05, Avg Reward: -171.266276702, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -216.502838135\n",
      "[NOR] Episode: 3320, Length: 235, e: 0.05, Avg Reward: -200.403841475, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.96475219727\n",
      "[NOR] Episode: 3330, Length: 224, e: 0.05, Avg Reward: -189.282479229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -166.456924438\n",
      "[NOR] Episode: 3340, Length: 87, e: 0.05, Avg Reward: -222.763904112, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.4483070374\n",
      "[NOR] Episode: 3350, Length: 80, e: 0.05, Avg Reward: -217.447258387, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.6946144104\n",
      "[NOR] Episode: 3360, Length: 172, e: 0.05, Avg Reward: -165.531159462, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -119.073013306\n",
      "[NOR] Episode: 3370, Length: 94, e: 0.05, Avg Reward: -251.720933187, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.2115135193\n",
      "[NOR] Episode: 3380, Length: 354, e: 0.05, Avg Reward: -179.596399524, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -68.8275756836\n",
      "[NOR] Episode: 3390, Length: 92, e: 0.05, Avg Reward: -215.975719931, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.1341400146\n",
      "[NOR] Episode: 3400, Length: 95, e: 0.05, Avg Reward: -207.355667797, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -80.8706588745\n",
      "[NOR] Episode: 3410, Length: 97, e: 0.05, Avg Reward: -183.204703724, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -472.071716309\n",
      "[NOR] Episode: 3420, Length: 98, e: 0.05, Avg Reward: -237.011059159, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.6252307892\n",
      "[NOR] Episode: 3430, Length: 134, e: 0.05, Avg Reward: -342.454919643, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.5331859589\n",
      "[NOR] Episode: 3440, Length: 193, e: 0.05, Avg Reward: -395.290908027, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -147.001831055\n",
      "[NOR] Episode: 3450, Length: 225, e: 0.05, Avg Reward: -293.21217389, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -346.664550781\n",
      "[NOR] Episode: 3460, Length: 119, e: 0.05, Avg Reward: -278.112284651, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -142.349029541\n",
      "[NOR] Episode: 3470, Length: 99, e: 0.05, Avg Reward: -359.741579947, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -193.535339355\n",
      "[NOR] Episode: 3480, Length: 70, e: 0.05, Avg Reward: -374.99048746, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -95.0576019287\n",
      "[NOR] Episode: 3490, Length: 229, e: 0.05, Avg Reward: -345.143476811, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -169.614547729\n",
      "[NOR] Episode: 3500, Length: 129, e: 0.05, Avg Reward: -288.710416326, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -397.104675293\n",
      "[NOR] Episode: 3510, Length: 132, e: 0.05, Avg Reward: -287.440963221, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -203.673110962\n",
      "[NOR] Episode: 3520, Length: 82, e: 0.05, Avg Reward: -266.898055521, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.9094161987\n",
      "[NOR] Episode: 3530, Length: 80, e: 0.05, Avg Reward: -233.327499185, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -275.033813477\n",
      "[NOR] Episode: 3540, Length: 60, e: 0.05, Avg Reward: -222.573923302, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.6214008331\n",
      "[NOR] Episode: 3550, Length: 79, e: 0.05, Avg Reward: -248.59154726, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 34.9251174927\n",
      "[NOR] Episode: 3560, Length: 86, e: 0.05, Avg Reward: -234.246803947, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.11685943604\n",
      "[NOR] Episode: 3570, Length: 105, e: 0.05, Avg Reward: -260.719622145, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -368.406158447\n",
      "[NOR] Episode: 3580, Length: 89, e: 0.05, Avg Reward: -240.76067144, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.70508384705\n",
      "[NOR] Episode: 3590, Length: 90, e: 0.05, Avg Reward: -301.679869635, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 71.2725753784\n",
      "[NOR] Episode: 3600, Length: 98, e: 0.05, Avg Reward: -358.052213234, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.7785425186\n",
      "[NOR] Episode: 3610, Length: 151, e: 0.05, Avg Reward: -340.20952995, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -150.681060791\n",
      "[NOR] Episode: 3620, Length: 126, e: 0.05, Avg Reward: -267.225990577, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -53.8584594727\n",
      "[NOR] Episode: 3630, Length: 120, e: 0.05, Avg Reward: -234.58908702, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.6278915405\n",
      "[NOR] Episode: 3640, Length: 97, e: 0.05, Avg Reward: -313.888431294, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 80.7515411377\n",
      "[NOR] Episode: 3650, Length: 116, e: 0.05, Avg Reward: -327.236585792, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 100.754013062\n",
      "[NOR] Episode: 3660, Length: 193, e: 0.05, Avg Reward: -358.432633538, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -345.371673584\n",
      "[NOR] Episode: 3670, Length: 143, e: 0.05, Avg Reward: -350.02887211, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -133.337509155\n",
      "[NOR] Episode: 3680, Length: 110, e: 0.05, Avg Reward: -384.882784997, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.2758026123\n",
      "[NOR] Episode: 3690, Length: 81, e: 0.05, Avg Reward: -445.978451812, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 305.348083496\n",
      "[NOR] Episode: 3700, Length: 161, e: 0.05, Avg Reward: -445.694337897, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 45.3082580566\n",
      "[NOR] Episode: 3710, Length: 177, e: 0.05, Avg Reward: -380.471734651, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.9573612213\n",
      "[NOR] Episode: 3720, Length: 159, e: 0.05, Avg Reward: -510.959416505, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 47.3572387695\n",
      "[NOR] Episode: 3730, Length: 69, e: 0.05, Avg Reward: -448.594630566, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -217.15486145\n",
      "[NOR] Episode: 3740, Length: 115, e: 0.05, Avg Reward: -573.682647324, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -72.5985412598\n",
      "[NOR] Episode: 3750, Length: 125, e: 0.05, Avg Reward: -613.230814682, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.2289924622\n",
      "[NOR] Episode: 3760, Length: 79, e: 0.05, Avg Reward: -610.747111936, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 472.557891846\n",
      "[NOR] Episode: 3770, Length: 65, e: 0.05, Avg Reward: -597.410300818, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.1482982635\n",
      "[NOR] Episode: 3780, Length: 128, e: 0.05, Avg Reward: -556.402496172, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -99.0068588257\n",
      "[NOR] Episode: 3790, Length: 97, e: 0.05, Avg Reward: -573.472786831, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -511.556152344\n",
      "[NOR] Episode: 3800, Length: 76, e: 0.05, Avg Reward: -525.320909606, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 70.3650588989\n",
      "[NOR] Episode: 3810, Length: 130, e: 0.05, Avg Reward: -478.364204053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -40.0830841064\n",
      "[NOR] Episode: 3820, Length: 88, e: 0.05, Avg Reward: -496.346739377, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -51.7748146057\n",
      "[NOR] Episode: 3830, Length: 100, e: 0.05, Avg Reward: -651.362525126, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -45.4843635559\n",
      "[NOR] Episode: 3840, Length: 78, e: 0.05, Avg Reward: -600.768944764, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 83.7186279297\n",
      "[NOR] Episode: 3850, Length: 62, e: 0.05, Avg Reward: -609.833996597, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.930606842\n",
      "[NOR] Episode: 3860, Length: 120, e: 0.05, Avg Reward: -615.106398089, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.3894882202\n",
      "[NOR] Episode: 3870, Length: 78, e: 0.05, Avg Reward: -546.634056302, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.884963512421\n",
      "[NOR] Episode: 3880, Length: 75, e: 0.05, Avg Reward: -604.343479281, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 51.6854782104\n",
      "[NOR] Episode: 3890, Length: 66, e: 0.05, Avg Reward: -555.954459486, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -134.669998169\n",
      "[NOR] Episode: 3900, Length: 75, e: 0.05, Avg Reward: -575.126995848, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -64.8130340576\n",
      "[NOR] Episode: 3910, Length: 84, e: 0.05, Avg Reward: -630.704988946, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.8618240356\n",
      "[NOR] Episode: 3920, Length: 196, e: 0.05, Avg Reward: -609.685734209, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.8249015808\n",
      "[NOR] Episode: 3930, Length: 195, e: 0.05, Avg Reward: -522.889339631, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -51.9442138672\n",
      "[NOR] Episode: 3940, Length: 150, e: 0.05, Avg Reward: -458.212913121, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -320.345184326\n",
      "[NOR] Episode: 3950, Length: 74, e: 0.05, Avg Reward: -531.675656394, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -333.60546875\n",
      "[NOR] Episode: 3960, Length: 64, e: 0.05, Avg Reward: -550.742600006, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.1585960388\n",
      "[NOR] Episode: 3970, Length: 82, e: 0.05, Avg Reward: -595.897471117, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.5149688721\n",
      "[NOR] Episode: 3980, Length: 123, e: 0.05, Avg Reward: -590.283936477, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 54.0014038086\n",
      "[NOR] Episode: 3990, Length: 174, e: 0.05, Avg Reward: -569.399910469, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -101.881835938\n",
      "[NOR] Episode: 4000, Length: 67, e: 0.05, Avg Reward: -585.060025698, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -300.388336182\n",
      "[NOR] Episode: 4010, Length: 62, e: 0.05, Avg Reward: -584.790891433, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 38.0456542969\n",
      "[NOR] Episode: 4020, Length: 67, e: 0.05, Avg Reward: -643.165999653, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -123.0414505\n",
      "[NOR] Episode: 4030, Length: 92, e: 0.05, Avg Reward: -586.350386078, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -161.141662598\n",
      "[NOR] Episode: 4040, Length: 97, e: 0.05, Avg Reward: -637.546671672, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -128.454772949\n",
      "[NOR] Episode: 4050, Length: 66, e: 0.05, Avg Reward: -606.65461605, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 213.791107178\n",
      "[NOR] Episode: 4060, Length: 144, e: 0.05, Avg Reward: -672.185668662, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.191318512\n",
      "[NOR] Episode: 4070, Length: 82, e: 0.05, Avg Reward: -613.461447687, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 305.041168213\n",
      "[NOR] Episode: 4080, Length: 90, e: 0.05, Avg Reward: -604.642324518, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.3627243042\n",
      "[NOR] Episode: 4090, Length: 57, e: 0.05, Avg Reward: -612.515942479, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -48.1569786072\n",
      "[NOR] Episode: 4100, Length: 75, e: 0.05, Avg Reward: -861.548963758, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 82.1270751953\n",
      "[NOR] Episode: 4110, Length: 50, e: 0.05, Avg Reward: -601.858669485, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -120.378494263\n",
      "[NOR] Episode: 4120, Length: 70, e: 0.05, Avg Reward: -682.835495715, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 140.147476196\n",
      "[NOR] Episode: 4130, Length: 68, e: 0.05, Avg Reward: -528.803422462, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.97864151\n",
      "[NOR] Episode: 4140, Length: 67, e: 0.05, Avg Reward: -578.864739857, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -124.129112244\n",
      "[NOR] Episode: 4150, Length: 79, e: 0.05, Avg Reward: -582.3057782, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -115.44228363\n",
      "[NOR] Episode: 4160, Length: 207, e: 0.05, Avg Reward: -566.05612268, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.92380905151\n",
      "[NOR] Episode: 4170, Length: 66, e: 0.05, Avg Reward: -544.430452441, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -67.3129425049\n",
      "[NOR] Episode: 4180, Length: 63, e: 0.05, Avg Reward: -545.207730312, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 141.20552063\n",
      "[NOR] Episode: 4190, Length: 68, e: 0.05, Avg Reward: -516.701997093, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -308.89276123\n",
      "[NOR] Episode: 4200, Length: 234, e: 0.05, Avg Reward: -545.165219381, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.43940734863\n",
      "[NOR] Episode: 4210, Length: 115, e: 0.05, Avg Reward: -653.079031706, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -78.8678588867\n",
      "[NOR] Episode: 4220, Length: 62, e: 0.05, Avg Reward: -685.883172275, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -78.4175109863\n",
      "[NOR] Episode: 4230, Length: 188, e: 0.05, Avg Reward: -650.098304125, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 85.4007568359\n",
      "[NOR] Episode: 4240, Length: 63, e: 0.05, Avg Reward: -655.295885689, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -139.029800415\n",
      "[NOR] Episode: 4250, Length: 72, e: 0.05, Avg Reward: -685.960421553, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -109.876434326\n",
      "[NOR] Episode: 4260, Length: 74, e: 0.05, Avg Reward: -603.578075272, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -87.2613220215\n",
      "[NOR] Episode: 4270, Length: 55, e: 0.05, Avg Reward: -569.499885615, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 163.363937378\n",
      "[NOR] Episode: 4280, Length: 77, e: 0.05, Avg Reward: -657.005652205, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.3435287476\n",
      "[NOR] Episode: 4290, Length: 122, e: 0.05, Avg Reward: -556.552463018, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.69063186646\n",
      "[NOR] Episode: 4300, Length: 128, e: 0.05, Avg Reward: -607.852330088, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 156.81539917\n",
      "[NOR] Episode: 4310, Length: 80, e: 0.05, Avg Reward: -610.105967575, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -278.644744873\n",
      "[NOR] Episode: 4320, Length: 52, e: 0.05, Avg Reward: -570.904653719, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -162.723220825\n",
      "[NOR] Episode: 4330, Length: 106, e: 0.05, Avg Reward: -484.513248473, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.23305130005\n",
      "[NOR] Episode: 4340, Length: 62, e: 0.05, Avg Reward: -604.461153235, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.5903358459\n",
      "[NOR] Episode: 4350, Length: 85, e: 0.05, Avg Reward: -612.527677998, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 54.6231231689\n",
      "[NOR] Episode: 4360, Length: 183, e: 0.05, Avg Reward: -608.514938165, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -73.2113494873\n",
      "[NOR] Episode: 4370, Length: 66, e: 0.05, Avg Reward: -717.575391544, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -319.008026123\n",
      "[NOR] Episode: 4380, Length: 66, e: 0.05, Avg Reward: -583.144953379, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.7320652008\n",
      "[NOR] Episode: 4390, Length: 83, e: 0.05, Avg Reward: -641.717740416, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -138.449798584\n",
      "[NOR] Episode: 4400, Length: 144, e: 0.05, Avg Reward: -690.862141112, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 200.484085083\n",
      "[NOR] Episode: 4410, Length: 168, e: 0.05, Avg Reward: -726.728117667, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.7247848511\n",
      "[NOR] Episode: 4420, Length: 186, e: 0.05, Avg Reward: -616.276597438, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 136.432510376\n",
      "[NOR] Episode: 4430, Length: 53, e: 0.05, Avg Reward: -603.573742014, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 216.777557373\n",
      "[NOR] Episode: 4440, Length: 105, e: 0.05, Avg Reward: -407.91087469, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.8701839447\n",
      "[NOR] Episode: 4450, Length: 119, e: 0.05, Avg Reward: -528.710960189, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -106.260246277\n",
      "[NOR] Episode: 4460, Length: 79, e: 0.05, Avg Reward: -611.628493839, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.233543396\n",
      "[NOR] Episode: 4470, Length: 191, e: 0.05, Avg Reward: -560.632750382, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -265.887023926\n",
      "[NOR] Episode: 4480, Length: 84, e: 0.05, Avg Reward: -426.632564115, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 40.1910667419\n",
      "[NOR] Episode: 4490, Length: 154, e: 0.05, Avg Reward: -552.674135662, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 119.185890198\n",
      "[NOR] Episode: 4500, Length: 62, e: 0.05, Avg Reward: -585.483461888, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 135.827789307\n",
      "[NOR] Episode: 4510, Length: 64, e: 0.05, Avg Reward: -564.573930718, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -53.0863418579\n",
      "[NOR] Episode: 4520, Length: 155, e: 0.05, Avg Reward: -512.206624389, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -142.300170898\n",
      "[NOR] Episode: 4530, Length: 61, e: 0.05, Avg Reward: -501.636605342, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 118.010437012\n",
      "[NOR] Episode: 4540, Length: 113, e: 0.05, Avg Reward: -521.095257285, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.671295166\n",
      "[NOR] Episode: 4550, Length: 59, e: 0.05, Avg Reward: -585.507225192, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.7456741333\n",
      "[NOR] Episode: 4560, Length: 116, e: 0.05, Avg Reward: -545.16056971, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.79720306396\n",
      "[NOR] Episode: 4570, Length: 89, e: 0.05, Avg Reward: -536.086238059, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 32.3015365601\n",
      "[NOR] Episode: 4580, Length: 165, e: 0.05, Avg Reward: -561.709043741, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.1743545532\n",
      "[NOR] Episode: 4590, Length: 70, e: 0.05, Avg Reward: -641.483447424, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 103.56036377\n",
      "[NOR] Episode: 4600, Length: 103, e: 0.05, Avg Reward: -502.348710468, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 61.7571144104\n",
      "[NOR] Episode: 4610, Length: 88, e: 0.05, Avg Reward: -589.583988263, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 97.4890975952\n",
      "[NOR] Episode: 4620, Length: 92, e: 0.05, Avg Reward: -629.944930124, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -75.1190719604\n",
      "[NOR] Episode: 4630, Length: 56, e: 0.05, Avg Reward: -701.420295181, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.0929222107\n",
      "[NOR] Episode: 4640, Length: 173, e: 0.05, Avg Reward: -677.905071451, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -112.341751099\n",
      "[NOR] Episode: 4650, Length: 87, e: 0.05, Avg Reward: -643.916456908, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.5361442566\n",
      "[NOR] Episode: 4660, Length: 70, e: 0.05, Avg Reward: -566.661063152, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -345.479492188\n",
      "[NOR] Episode: 4670, Length: 137, e: 0.05, Avg Reward: -434.715633725, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.4903411865\n",
      "[NOR] Episode: 4680, Length: 69, e: 0.05, Avg Reward: -743.435321812, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.9687461853\n",
      "[NOR] Episode: 4690, Length: 71, e: 0.05, Avg Reward: -648.587270143, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -60.5591125488\n",
      "[NOR] Episode: 4700, Length: 69, e: 0.05, Avg Reward: -576.190796552, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -70.7617950439\n",
      "[NOR] Episode: 4710, Length: 58, e: 0.05, Avg Reward: -598.776230161, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -44.6327781677\n",
      "[NOR] Episode: 4720, Length: 227, e: 0.05, Avg Reward: -626.762887556, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -491.360961914\n",
      "[NOR] Episode: 4730, Length: 98, e: 0.05, Avg Reward: -609.653514688, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -420.242523193\n",
      "[NOR] Episode: 4740, Length: 68, e: 0.05, Avg Reward: -611.797047452, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.2281646729\n",
      "[NOR] Episode: 4750, Length: 91, e: 0.05, Avg Reward: -570.744551942, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 103.906364441\n",
      "[NOR] Episode: 4760, Length: 66, e: 0.05, Avg Reward: -622.216676025, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 38.8509368896\n",
      "[NOR] Episode: 4770, Length: 65, e: 0.05, Avg Reward: -667.277124426, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 43.1071662903\n",
      "[NOR] Episode: 4780, Length: 88, e: 0.05, Avg Reward: -533.397461345, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.6088018417\n",
      "[NOR] Episode: 4790, Length: 66, e: 0.05, Avg Reward: -591.254462726, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.5096321106\n",
      "[NOR] Episode: 4800, Length: 77, e: 0.05, Avg Reward: -584.839374292, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.15350341797\n",
      "[NOR] Episode: 4810, Length: 74, e: 0.05, Avg Reward: -605.842523145, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -68.3467102051\n",
      "[NOR] Episode: 4820, Length: 98, e: 0.05, Avg Reward: -618.119157197, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 101.559623718\n",
      "[NOR] Episode: 4830, Length: 71, e: 0.05, Avg Reward: -518.252648911, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 100.038787842\n",
      "[NOR] Episode: 4840, Length: 87, e: 0.05, Avg Reward: -573.101144307, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 120.435638428\n",
      "[NOR] Episode: 4850, Length: 106, e: 0.05, Avg Reward: -613.515959285, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -51.7425765991\n",
      "[NOR] Episode: 4860, Length: 83, e: 0.05, Avg Reward: -529.570833053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 118.944908142\n",
      "[NOR] Episode: 4870, Length: 110, e: 0.05, Avg Reward: -532.752602804, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -196.264312744\n",
      "[NOR] Episode: 4880, Length: 99, e: 0.05, Avg Reward: -663.470926746, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 103.343818665\n",
      "[NOR] Episode: 4890, Length: 59, e: 0.05, Avg Reward: -595.132300266, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 45.7135848999\n",
      "[NOR] Episode: 4900, Length: 72, e: 0.05, Avg Reward: -537.385651256, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.8262023926\n",
      "[NOR] Episode: 4910, Length: 86, e: 0.05, Avg Reward: -501.875283711, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 54.6344642639\n",
      "[NOR] Episode: 4920, Length: 141, e: 0.05, Avg Reward: -472.528007269, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.8539791107\n",
      "[NOR] Episode: 4930, Length: 96, e: 0.05, Avg Reward: -562.653204624, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 78.9884490967\n",
      "[NOR] Episode: 4940, Length: 64, e: 0.05, Avg Reward: -625.006527413, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -38.9998626709\n",
      "[NOR] Episode: 4950, Length: 71, e: 0.05, Avg Reward: -611.549871798, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.437084198\n",
      "[NOR] Episode: 4960, Length: 122, e: 0.05, Avg Reward: -543.570352178, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -193.595672607\n",
      "[NOR] Episode: 4970, Length: 103, e: 0.05, Avg Reward: -486.560499099, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.7945556641\n",
      "[NOR] Episode: 4980, Length: 69, e: 0.05, Avg Reward: -520.992990603, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -133.874160767\n",
      "[NOR] Episode: 4990, Length: 83, e: 0.05, Avg Reward: -532.087904178, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 189.288208008\n",
      "[NOR] Episode: 5000, Length: 73, e: 0.05, Avg Reward: -541.655227337, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.0094909668\n",
      "[NOR] Episode: 5010, Length: 57, e: 0.05, Avg Reward: -637.951407492, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 71.3843841553\n",
      "[NOR] Episode: 5020, Length: 67, e: 0.05, Avg Reward: -587.194060023, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 478.77722168\n",
      "[NOR] Episode: 5030, Length: 58, e: 0.05, Avg Reward: -615.126776221, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 40.456905365\n",
      "[NOR] Episode: 5040, Length: 79, e: 0.05, Avg Reward: -571.020480414, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -96.8163146973\n",
      "[NOR] Episode: 5050, Length: 73, e: 0.05, Avg Reward: -523.600346598, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -117.555953979\n",
      "[NOR] Episode: 5060, Length: 107, e: 0.05, Avg Reward: -524.916269913, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -236.458648682\n",
      "[NOR] Episode: 5070, Length: 60, e: 0.05, Avg Reward: -495.85067278, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 63.587802887\n",
      "[NOR] Episode: 5080, Length: 75, e: 0.05, Avg Reward: -520.077461454, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -164.00201416\n",
      "[NOR] Episode: 5090, Length: 95, e: 0.05, Avg Reward: -571.301247591, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -139.62512207\n",
      "[NOR] Episode: 5100, Length: 66, e: 0.05, Avg Reward: -668.237045456, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.80427932739\n",
      "[NOR] Episode: 5110, Length: 105, e: 0.05, Avg Reward: -588.786445333, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -74.4816818237\n",
      "[NOR] Episode: 5120, Length: 61, e: 0.05, Avg Reward: -603.628527562, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -363.381286621\n",
      "[NOR] Episode: 5130, Length: 102, e: 0.05, Avg Reward: -591.821903684, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -64.8685455322\n",
      "[NOR] Episode: 5140, Length: 103, e: 0.05, Avg Reward: -608.692018304, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 66.1230926514\n",
      "[NOR] Episode: 5150, Length: 65, e: 0.05, Avg Reward: -547.350598148, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 79.9097595215\n",
      "[NOR] Episode: 5160, Length: 91, e: 0.05, Avg Reward: -642.516584671, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.9307498932\n",
      "[NOR] Episode: 5170, Length: 81, e: 0.05, Avg Reward: -577.270533241, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 118.097625732\n",
      "[NOR] Episode: 5180, Length: 80, e: 0.05, Avg Reward: -571.763380607, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 52.8857803345\n",
      "[NOR] Episode: 5190, Length: 65, e: 0.05, Avg Reward: -574.796334313, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -104.144218445\n",
      "[NOR] Episode: 5200, Length: 78, e: 0.05, Avg Reward: -631.489938292, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -178.960998535\n",
      "[NOR] Episode: 5210, Length: 69, e: 0.05, Avg Reward: -575.766213088, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -171.990631104\n",
      "[NOR] Episode: 5220, Length: 126, e: 0.05, Avg Reward: -582.228786488, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -105.729469299\n",
      "[NOR] Episode: 5230, Length: 61, e: 0.05, Avg Reward: -509.727778905, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.2414703369\n",
      "[NOR] Episode: 5240, Length: 91, e: 0.05, Avg Reward: -513.418842443, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -201.984069824\n",
      "[NOR] Episode: 5250, Length: 62, e: 0.05, Avg Reward: -633.043399916, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -83.6949157715\n",
      "[NOR] Episode: 5260, Length: 80, e: 0.05, Avg Reward: -574.868350724, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -70.9842681885\n",
      "[NOR] Episode: 5270, Length: 73, e: 0.05, Avg Reward: -483.763527191, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.8979873657\n",
      "[NOR] Episode: 5280, Length: 100, e: 0.05, Avg Reward: -615.998740966, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.65122699738\n",
      "[NOR] Episode: 5290, Length: 104, e: 0.05, Avg Reward: -539.316071475, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 178.812713623\n",
      "[NOR] Episode: 5300, Length: 74, e: 0.05, Avg Reward: -468.067534661, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -230.201629639\n",
      "[NOR] Episode: 5310, Length: 101, e: 0.05, Avg Reward: -570.356588141, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 46.7559204102\n",
      "[NOR] Episode: 5320, Length: 140, e: 0.05, Avg Reward: -522.602679678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.066160202\n",
      "[NOR] Episode: 5330, Length: 84, e: 0.05, Avg Reward: -491.570474447, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -74.9072647095\n",
      "[NOR] Episode: 5340, Length: 60, e: 0.05, Avg Reward: -556.719572906, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 46.6123924255\n",
      "[NOR] Episode: 5350, Length: 116, e: 0.05, Avg Reward: -598.245844266, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 41.1090774536\n",
      "[NOR] Episode: 5360, Length: 68, e: 0.05, Avg Reward: -613.663628892, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -91.172668457\n",
      "[NOR] Episode: 5370, Length: 76, e: 0.05, Avg Reward: -575.855172957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.0094909668\n",
      "[NOR] Episode: 5380, Length: 100, e: 0.05, Avg Reward: -554.105365004, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 62.7465171814\n",
      "[NOR] Episode: 5390, Length: 60, e: 0.05, Avg Reward: -621.380836172, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.5006866455\n",
      "[NOR] Episode: 5400, Length: 80, e: 0.05, Avg Reward: -510.900082223, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.6059837341\n",
      "[NOR] Episode: 5410, Length: 123, e: 0.05, Avg Reward: -499.06555193, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.74819374084\n",
      "[NOR] Episode: 5420, Length: 59, e: 0.05, Avg Reward: -563.726713885, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.28485298157\n",
      "[NOR] Episode: 5430, Length: 87, e: 0.05, Avg Reward: -496.702879772, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.9704723358\n",
      "[NOR] Episode: 5440, Length: 82, e: 0.05, Avg Reward: -592.05621267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 57.8212547302\n",
      "[NOR] Episode: 5450, Length: 98, e: 0.05, Avg Reward: -597.458197588, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.38566970825\n",
      "[NOR] Episode: 5460, Length: 131, e: 0.05, Avg Reward: -605.153264328, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -112.752029419\n",
      "[NOR] Episode: 5470, Length: 64, e: 0.05, Avg Reward: -613.466488895, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.4292373657\n",
      "[NOR] Episode: 5480, Length: 98, e: 0.05, Avg Reward: -503.724010455, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.73892140388\n",
      "[NOR] Episode: 5490, Length: 111, e: 0.05, Avg Reward: -510.642986028, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 171.030044556\n",
      "[NOR] Episode: 5500, Length: 83, e: 0.05, Avg Reward: -534.565281983, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.6042060852\n",
      "[NOR] Episode: 5510, Length: 104, e: 0.05, Avg Reward: -501.155046397, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 174.086395264\n",
      "[NOR] Episode: 5520, Length: 91, e: 0.05, Avg Reward: -535.047718153, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 28.5365543365\n",
      "[NOR] Episode: 5530, Length: 83, e: 0.05, Avg Reward: -515.730571837, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -190.05039978\n",
      "[NOR] Episode: 5540, Length: 82, e: 0.05, Avg Reward: -547.42933961, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 43.1704521179\n",
      "[NOR] Episode: 5550, Length: 80, e: 0.05, Avg Reward: -541.081463012, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -132.819534302\n",
      "[NOR] Episode: 5560, Length: 158, e: 0.05, Avg Reward: -477.37127446, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 44.5489845276\n",
      "[NOR] Episode: 5570, Length: 116, e: 0.05, Avg Reward: -464.93122093, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -155.062408447\n",
      "[NOR] Episode: 5580, Length: 88, e: 0.05, Avg Reward: -527.223155463, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 116.974960327\n",
      "[NOR] Episode: 5590, Length: 120, e: 0.05, Avg Reward: -475.094714257, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 62.2082138062\n",
      "[NOR] Episode: 5600, Length: 119, e: 0.05, Avg Reward: -489.451271683, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -51.3751220703\n",
      "[NOR] Episode: 5610, Length: 103, e: 0.05, Avg Reward: -469.804241399, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.0765151978\n",
      "[NOR] Episode: 5620, Length: 74, e: 0.05, Avg Reward: -473.696383671, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -105.444503784\n",
      "[NOR] Episode: 5630, Length: 90, e: 0.05, Avg Reward: -491.410458814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 70.5429077148\n",
      "[NOR] Episode: 5640, Length: 81, e: 0.05, Avg Reward: -482.390865265, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 89.5669555664\n",
      "[NOR] Episode: 5650, Length: 71, e: 0.05, Avg Reward: -484.281937416, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -44.3126182556\n",
      "[NOR] Episode: 5660, Length: 67, e: 0.05, Avg Reward: -512.776492775, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 64.2980575562\n",
      "[NOR] Episode: 5670, Length: 87, e: 0.05, Avg Reward: -487.534432977, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -76.5636825562\n",
      "[NOR] Episode: 5680, Length: 114, e: 0.05, Avg Reward: -540.607080312, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.3297958374\n",
      "[NOR] Episode: 5690, Length: 96, e: 0.05, Avg Reward: -541.18775117, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.91920232773\n",
      "[NOR] Episode: 5700, Length: 79, e: 0.05, Avg Reward: -476.154817536, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -454.871063232\n",
      "[NOR] Episode: 5710, Length: 99, e: 0.05, Avg Reward: -500.291478709, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 134.083175659\n",
      "[NOR] Episode: 5720, Length: 81, e: 0.05, Avg Reward: -464.174507753, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.52161598206\n",
      "[NOR] Episode: 5730, Length: 135, e: 0.05, Avg Reward: -456.306425314, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 114.795532227\n",
      "[NOR] Episode: 5740, Length: 142, e: 0.05, Avg Reward: -502.823137489, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.7416181564\n",
      "[NOR] Episode: 5750, Length: 247, e: 0.05, Avg Reward: -479.044035855, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 170.887191772\n",
      "[NOR] Episode: 5760, Length: 125, e: 0.05, Avg Reward: -418.88112172, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 66.4817047119\n",
      "[NOR] Episode: 5770, Length: 108, e: 0.05, Avg Reward: -443.869802764, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 35.0062561035\n",
      "[NOR] Episode: 5780, Length: 87, e: 0.05, Avg Reward: -375.561919557, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 46.0843315125\n",
      "[NOR] Episode: 5790, Length: 139, e: 0.05, Avg Reward: -483.125015937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 75.8364562988\n",
      "[NOR] Episode: 5800, Length: 280, e: 0.05, Avg Reward: -443.224989888, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.6294288635\n",
      "[NOR] Episode: 5810, Length: 122, e: 0.05, Avg Reward: -476.928995441, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.4450759888\n",
      "[NOR] Episode: 5820, Length: 110, e: 0.05, Avg Reward: -471.73209889, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -74.193069458\n",
      "[NOR] Episode: 5830, Length: 131, e: 0.05, Avg Reward: -445.372156035, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 65.165397644\n",
      "[NOR] Episode: 5840, Length: 85, e: 0.05, Avg Reward: -480.046535482, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.8829135895\n",
      "[NOR] Episode: 5850, Length: 84, e: 0.05, Avg Reward: -491.55461633, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -86.7469482422\n",
      "[NOR] Episode: 5860, Length: 143, e: 0.05, Avg Reward: -452.258462464, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 167.750671387\n",
      "[NOR] Episode: 5870, Length: 126, e: 0.05, Avg Reward: -379.707446648, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 45.267791748\n",
      "[NOR] Episode: 5880, Length: 150, e: 0.05, Avg Reward: -444.119326392, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 44.8899002075\n",
      "[NOR] Episode: 5890, Length: 70, e: 0.05, Avg Reward: -428.924828233, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.528377533\n",
      "[NOR] Episode: 5900, Length: 78, e: 0.05, Avg Reward: -445.36296684, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 98.758392334\n",
      "[NOR] Episode: 5910, Length: 80, e: 0.05, Avg Reward: -431.179311299, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 64.1625213623\n",
      "[NOR] Episode: 5920, Length: 122, e: 0.05, Avg Reward: -419.774327071, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.0249948502\n",
      "[NOR] Episode: 5930, Length: 73, e: 0.05, Avg Reward: -382.748844025, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -44.8854484558\n",
      "[NOR] Episode: 5940, Length: 100, e: 0.05, Avg Reward: -476.043778217, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -105.973716736\n",
      "[NOR] Episode: 5950, Length: 166, e: 0.05, Avg Reward: -421.796147337, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 54.8751678467\n",
      "[NOR] Episode: 5960, Length: 83, e: 0.05, Avg Reward: -491.976888337, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -129.460784912\n",
      "[NOR] Episode: 5970, Length: 131, e: 0.05, Avg Reward: -440.34152951, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -339.743255615\n",
      "[NOR] Episode: 5980, Length: 92, e: 0.05, Avg Reward: -437.06163926, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.5464420319\n",
      "[NOR] Episode: 5990, Length: 317, e: 0.05, Avg Reward: -465.954720197, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -83.908744812\n",
      "[NOR] Episode: 6000, Length: 131, e: 0.05, Avg Reward: -442.923327086, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -57.8035812378\n",
      "[NOR] Episode: 6010, Length: 182, e: 0.05, Avg Reward: -428.376069109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -88.5308609009\n",
      "[NOR] Episode: 6020, Length: 72, e: 0.05, Avg Reward: -456.326148944, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 119.139831543\n",
      "[NOR] Episode: 6030, Length: 80, e: 0.05, Avg Reward: -453.100532325, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 100.210945129\n",
      "[NOR] Episode: 6040, Length: 95, e: 0.05, Avg Reward: -435.011841731, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.247505188\n",
      "[NOR] Episode: 6050, Length: 101, e: 0.05, Avg Reward: -515.210570239, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -96.9423522949\n",
      "[NOR] Episode: 6060, Length: 168, e: 0.05, Avg Reward: -476.699435703, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.2037124634\n",
      "[NOR] Episode: 6070, Length: 82, e: 0.05, Avg Reward: -472.459602912, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.21238708496\n",
      "[NOR] Episode: 6080, Length: 257, e: 0.05, Avg Reward: -440.327996361, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 319.556732178\n",
      "[NOR] Episode: 6090, Length: 84, e: 0.05, Avg Reward: -442.060561283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.4213638306\n",
      "[NOR] Episode: 6100, Length: 75, e: 0.05, Avg Reward: -458.594393025, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -74.8476638794\n",
      "[NOR] Episode: 6110, Length: 330, e: 0.05, Avg Reward: -478.071584548, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.14022827148\n",
      "[NOR] Episode: 6120, Length: 93, e: 0.05, Avg Reward: -428.225266465, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -83.8720092773\n",
      "[NOR] Episode: 6130, Length: 113, e: 0.05, Avg Reward: -446.535540074, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -130.100845337\n",
      "[NOR] Episode: 6140, Length: 81, e: 0.05, Avg Reward: -477.224676044, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.8844413757\n",
      "[NOR] Episode: 6150, Length: 75, e: 0.05, Avg Reward: -441.672758237, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 58.09349823\n",
      "[NOR] Episode: 6160, Length: 154, e: 0.05, Avg Reward: -459.381507252, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 85.0600967407\n",
      "[NOR] Episode: 6170, Length: 102, e: 0.05, Avg Reward: -455.411298351, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 95.8725357056\n",
      "[NOR] Episode: 6180, Length: 75, e: 0.05, Avg Reward: -425.529979479, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.6231079102\n",
      "[NOR] Episode: 6190, Length: 113, e: 0.05, Avg Reward: -433.172841768, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.08568573\n",
      "[NOR] Episode: 6200, Length: 115, e: 0.05, Avg Reward: -467.371672432, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.63084220886\n",
      "[NOR] Episode: 6210, Length: 188, e: 0.05, Avg Reward: -408.805923274, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 131.576278687\n",
      "[NOR] Episode: 6220, Length: 120, e: 0.05, Avg Reward: -418.164336254, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.2039642334\n",
      "[NOR] Episode: 6230, Length: 93, e: 0.05, Avg Reward: -405.625007437, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 68.0484619141\n",
      "[NOR] Episode: 6240, Length: 84, e: 0.05, Avg Reward: -423.962046812, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.661239624\n",
      "[NOR] Episode: 6250, Length: 128, e: 0.05, Avg Reward: -426.948411517, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.5174598694\n",
      "[NOR] Episode: 6260, Length: 86, e: 0.05, Avg Reward: -417.919271431, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.7685966492\n",
      "[NOR] Episode: 6270, Length: 132, e: 0.05, Avg Reward: -396.901239405, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 170.09777832\n",
      "[NOR] Episode: 6280, Length: 132, e: 0.05, Avg Reward: -405.977987749, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -304.53125\n",
      "[NOR] Episode: 6290, Length: 92, e: 0.05, Avg Reward: -366.364088547, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -139.803833008\n",
      "[NOR] Episode: 6300, Length: 135, e: 0.05, Avg Reward: -411.708145525, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.2280960083\n",
      "[NOR] Episode: 6310, Length: 85, e: 0.05, Avg Reward: -365.716715861, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.6162719727\n",
      "[NOR] Episode: 6320, Length: 82, e: 0.05, Avg Reward: -373.351443217, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -76.306892395\n",
      "[NOR] Episode: 6330, Length: 317, e: 0.05, Avg Reward: -420.358175506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.3241767883\n",
      "[NOR] Episode: 6340, Length: 131, e: 0.05, Avg Reward: -373.257423284, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 163.625076294\n",
      "[NOR] Episode: 6350, Length: 107, e: 0.05, Avg Reward: -397.73107774, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.72568893433\n",
      "[NOR] Episode: 6360, Length: 86, e: 0.05, Avg Reward: -387.13758989, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.47362709045\n",
      "[NOR] Episode: 6370, Length: 86, e: 0.05, Avg Reward: -379.834715947, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.9624919891\n",
      "[NOR] Episode: 6380, Length: 96, e: 0.05, Avg Reward: -433.386278561, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 39.4619789124\n",
      "[NOR] Episode: 6390, Length: 162, e: 0.05, Avg Reward: -398.723365023, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.1773414612\n",
      "[NOR] Episode: 6400, Length: 105, e: 0.05, Avg Reward: -418.778432634, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 318.999481201\n",
      "[NOR] Episode: 6410, Length: 287, e: 0.05, Avg Reward: -411.657807057, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 152.215896606\n",
      "[NOR] Episode: 6420, Length: 136, e: 0.05, Avg Reward: -397.129376769, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -81.1547393799\n",
      "[NOR] Episode: 6430, Length: 161, e: 0.05, Avg Reward: -363.100619818, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 112.416122437\n",
      "[NOR] Episode: 6440, Length: 85, e: 0.05, Avg Reward: -393.763648766, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 55.2276077271\n",
      "[NOR] Episode: 6450, Length: 93, e: 0.05, Avg Reward: -378.762308055, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 64.0772476196\n",
      "[NOR] Episode: 6460, Length: 106, e: 0.05, Avg Reward: -355.548078779, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 80.3423233032\n",
      "[NOR] Episode: 6470, Length: 87, e: 0.05, Avg Reward: -428.775005857, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.351184845\n",
      "[NOR] Episode: 6480, Length: 126, e: 0.05, Avg Reward: -331.701104674, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.9958534241\n",
      "[NOR] Episode: 6490, Length: 232, e: 0.05, Avg Reward: -384.55149972, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.16504669189\n",
      "[NOR] Episode: 6500, Length: 184, e: 0.05, Avg Reward: -360.883950472, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.68359375\n",
      "[NOR] Episode: 6510, Length: 81, e: 0.05, Avg Reward: -361.156077395, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 27.9769496918\n",
      "[NOR] Episode: 6520, Length: 283, e: 0.05, Avg Reward: -402.532415358, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 123.357559204\n",
      "[NOR] Episode: 6530, Length: 105, e: 0.05, Avg Reward: -363.662690622, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 44.6085853577\n",
      "[NOR] Episode: 6540, Length: 108, e: 0.05, Avg Reward: -373.357928548, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.4297523499\n",
      "[NOR] Episode: 6550, Length: 109, e: 0.05, Avg Reward: -345.589035863, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.9455947876\n",
      "[NOR] Episode: 6560, Length: 213, e: 0.05, Avg Reward: -352.260209024, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 41.3047904968\n",
      "[NOR] Episode: 6570, Length: 140, e: 0.05, Avg Reward: -375.801561146, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.2832870483\n",
      "[NOR] Episode: 6580, Length: 187, e: 0.05, Avg Reward: -406.740770524, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -45.2679748535\n",
      "[NOR] Episode: 6590, Length: 100, e: 0.05, Avg Reward: -388.393295493, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -94.4655914307\n",
      "[NOR] Episode: 6600, Length: 265, e: 0.05, Avg Reward: -381.953661525, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.1620063782\n",
      "[NOR] Episode: 6610, Length: 118, e: 0.05, Avg Reward: -360.867717582, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -112.510848999\n",
      "[NOR] Episode: 6620, Length: 153, e: 0.05, Avg Reward: -368.35881184, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.9903125763\n",
      "[NOR] Episode: 6630, Length: 152, e: 0.05, Avg Reward: -395.327615742, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.56694316864\n",
      "[NOR] Episode: 6640, Length: 81, e: 0.05, Avg Reward: -352.121359816, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -413.216644287\n",
      "[NOR] Episode: 6650, Length: 71, e: 0.05, Avg Reward: -390.79242466, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 79.2466583252\n",
      "[NOR] Episode: 6660, Length: 81, e: 0.05, Avg Reward: -386.570770053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.5852661133\n",
      "[NOR] Episode: 6670, Length: 93, e: 0.05, Avg Reward: -390.944386257, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.22995090485\n",
      "[NOR] Episode: 6680, Length: 138, e: 0.05, Avg Reward: -380.96241638, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -56.3210945129\n",
      "[NOR] Episode: 6690, Length: 135, e: 0.05, Avg Reward: -400.710606097, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 54.6430473328\n",
      "[NOR] Episode: 6700, Length: 115, e: 0.05, Avg Reward: -374.611898283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.618976593\n",
      "[NOR] Episode: 6710, Length: 120, e: 0.05, Avg Reward: -371.675049692, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -155.270095825\n",
      "[NOR] Episode: 6720, Length: 99, e: 0.05, Avg Reward: -351.614245814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -72.4546585083\n",
      "[NOR] Episode: 6730, Length: 89, e: 0.05, Avg Reward: -338.069130845, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.3130197525\n",
      "[NOR] Episode: 6740, Length: 107, e: 0.05, Avg Reward: -310.571248094, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.9068832397\n",
      "[NOR] Episode: 6750, Length: 82, e: 0.05, Avg Reward: -357.136755287, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 48.3215789795\n",
      "[NOR] Episode: 6760, Length: 121, e: 0.05, Avg Reward: -335.742068642, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 48.4760322571\n",
      "[NOR] Episode: 6770, Length: 156, e: 0.05, Avg Reward: -326.966594988, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -64.0213699341\n",
      "[NOR] Episode: 6780, Length: 158, e: 0.05, Avg Reward: -371.106429178, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 91.8373260498\n",
      "[NOR] Episode: 6790, Length: 196, e: 0.05, Avg Reward: -327.418628277, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 114.241233826\n",
      "[NOR] Episode: 6800, Length: 106, e: 0.05, Avg Reward: -382.973608935, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 119.804985046\n",
      "[NOR] Episode: 6810, Length: 80, e: 0.05, Avg Reward: -332.211622273, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 50.7791786194\n",
      "[NOR] Episode: 6820, Length: 100, e: 0.05, Avg Reward: -358.408679192, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.9823493958\n",
      "[NOR] Episode: 6830, Length: 96, e: 0.05, Avg Reward: -364.287620356, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.2323493958\n",
      "[NOR] Episode: 6840, Length: 88, e: 0.05, Avg Reward: -336.094650045, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -105.442672729\n",
      "[NOR] Episode: 6850, Length: 190, e: 0.05, Avg Reward: -347.789019987, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -82.3807144165\n",
      "[NOR] Episode: 6860, Length: 83, e: 0.05, Avg Reward: -350.852236672, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.78827095032\n",
      "[NOR] Episode: 6870, Length: 116, e: 0.05, Avg Reward: -382.164960398, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -62.0725631714\n",
      "[NOR] Episode: 6880, Length: 134, e: 0.05, Avg Reward: -327.299216548, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 140.031707764\n",
      "[NOR] Episode: 6890, Length: 100, e: 0.05, Avg Reward: -356.912378193, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.6988334656\n",
      "[NOR] Episode: 6900, Length: 87, e: 0.05, Avg Reward: -345.830549161, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.4529056549\n",
      "[NOR] Episode: 6910, Length: 103, e: 0.05, Avg Reward: -315.038842127, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 65.2053375244\n",
      "[NOR] Episode: 6920, Length: 90, e: 0.05, Avg Reward: -379.010581943, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -78.9940490723\n",
      "[NOR] Episode: 6930, Length: 170, e: 0.05, Avg Reward: -331.164769393, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 437.112945557\n",
      "[NOR] Episode: 6940, Length: 170, e: 0.05, Avg Reward: -274.60532896, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.6537017822\n",
      "[NOR] Episode: 6950, Length: 324, e: 0.05, Avg Reward: -338.873074627, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -208.134658813\n",
      "[NOR] Episode: 6960, Length: 110, e: 0.05, Avg Reward: -253.659439391, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.5235824585\n",
      "[NOR] Episode: 6970, Length: 284, e: 0.05, Avg Reward: -322.765759528, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.5045108795\n",
      "[NOR] Episode: 6980, Length: 148, e: 0.05, Avg Reward: -320.923636069, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -170.253112793\n",
      "[NOR] Episode: 6990, Length: 106, e: 0.05, Avg Reward: -305.224655969, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.3568115234\n",
      "[NOR] Episode: 7000, Length: 213, e: 0.05, Avg Reward: -295.027211608, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.5572776794\n",
      "[NOR] Episode: 7010, Length: 123, e: 0.05, Avg Reward: -373.025015108, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 136.284698486\n",
      "[NOR] Episode: 7020, Length: 85, e: 0.05, Avg Reward: -314.316113853, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 411.695068359\n",
      "[NOR] Episode: 7030, Length: 260, e: 0.05, Avg Reward: -321.724618031, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 204.898498535\n",
      "[NOR] Episode: 7040, Length: 106, e: 0.05, Avg Reward: -355.968046059, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -46.2652435303\n",
      "[NOR] Episode: 7050, Length: 117, e: 0.05, Avg Reward: -349.768731423, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.5110473633\n",
      "[NOR] Episode: 7060, Length: 129, e: 0.05, Avg Reward: -311.026055059, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.5072021484\n",
      "[NOR] Episode: 7070, Length: 77, e: 0.05, Avg Reward: -319.378613233, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 118.137405396\n",
      "[NOR] Episode: 7080, Length: 115, e: 0.05, Avg Reward: -355.986779124, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -54.7742156982\n",
      "[NOR] Episode: 7090, Length: 148, e: 0.05, Avg Reward: -356.105851803, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.3233795166\n",
      "[NOR] Episode: 7100, Length: 94, e: 0.05, Avg Reward: -307.976790582, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -111.173713684\n",
      "[NOR] Episode: 7110, Length: 152, e: 0.05, Avg Reward: -235.264579444, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 27.1083202362\n",
      "[NOR] Episode: 7120, Length: 384, e: 0.05, Avg Reward: -309.291019096, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -60.0961532593\n",
      "[NOR] Episode: 7130, Length: 92, e: 0.05, Avg Reward: -317.185904158, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 62.6508255005\n",
      "[NOR] Episode: 7140, Length: 113, e: 0.05, Avg Reward: -340.285964429, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.575756073\n",
      "[NOR] Episode: 7150, Length: 110, e: 0.05, Avg Reward: -339.523682054, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.447909355164\n",
      "[NOR] Episode: 7160, Length: 77, e: 0.05, Avg Reward: -357.787628883, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 91.9022140503\n",
      "[NOR] Episode: 7170, Length: 82, e: 0.05, Avg Reward: -325.679103875, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -129.957397461\n",
      "[NOR] Episode: 7180, Length: 127, e: 0.05, Avg Reward: -370.094037414, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -66.9495544434\n",
      "[NOR] Episode: 7190, Length: 92, e: 0.05, Avg Reward: -361.673992312, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.6999053955\n",
      "[NOR] Episode: 7200, Length: 85, e: 0.05, Avg Reward: -394.749097267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.56583023071\n",
      "[NOR] Episode: 7210, Length: 170, e: 0.05, Avg Reward: -343.564564745, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -136.224975586\n",
      "[NOR] Episode: 7220, Length: 110, e: 0.05, Avg Reward: -393.705137457, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.6202468872\n",
      "[NOR] Episode: 7230, Length: 85, e: 0.05, Avg Reward: -344.815475885, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.4741516113\n",
      "[NOR] Episode: 7240, Length: 99, e: 0.05, Avg Reward: -321.354666546, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 54.1792526245\n",
      "[NOR] Episode: 7250, Length: 99, e: 0.05, Avg Reward: -367.501858189, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.9375114441\n",
      "[NOR] Episode: 7260, Length: 88, e: 0.05, Avg Reward: -362.962045634, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -279.486938477\n",
      "[NOR] Episode: 7270, Length: 101, e: 0.05, Avg Reward: -318.642346061, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.1274719238\n",
      "[NOR] Episode: 7280, Length: 122, e: 0.05, Avg Reward: -366.771472628, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 49.7342605591\n",
      "[NOR] Episode: 7290, Length: 99, e: 0.05, Avg Reward: -306.812335915, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -142.303863525\n",
      "[NOR] Episode: 7300, Length: 94, e: 0.05, Avg Reward: -426.586756617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -38.5357208252\n",
      "[NOR] Episode: 7310, Length: 76, e: 0.05, Avg Reward: -358.496856579, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -103.782714844\n",
      "[NOR] Episode: 7320, Length: 98, e: 0.05, Avg Reward: -324.182166014, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.760389328\n",
      "[NOR] Episode: 7330, Length: 157, e: 0.05, Avg Reward: -371.14331383, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -90.8887863159\n",
      "[NOR] Episode: 7340, Length: 83, e: 0.05, Avg Reward: -293.977106979, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.85002803802\n",
      "[NOR] Episode: 7350, Length: 275, e: 0.05, Avg Reward: -362.806253688, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.7814092636\n",
      "[NOR] Episode: 7360, Length: 81, e: 0.05, Avg Reward: -298.551081523, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.73416757584\n",
      "[NOR] Episode: 7370, Length: 100, e: 0.05, Avg Reward: -332.000851582, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.7103652954\n",
      "[NOR] Episode: 7380, Length: 93, e: 0.05, Avg Reward: -355.527370275, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.953830719\n",
      "[NOR] Episode: 7390, Length: 104, e: 0.05, Avg Reward: -280.382188375, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -125.417060852\n",
      "[NOR] Episode: 7400, Length: 78, e: 0.05, Avg Reward: -366.527873901, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.186466217\n",
      "[NOR] Episode: 7410, Length: 210, e: 0.05, Avg Reward: -422.204412225, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.3740501404\n",
      "[NOR] Episode: 7420, Length: 126, e: 0.05, Avg Reward: -374.410954746, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.2258815765\n",
      "[NOR] Episode: 7430, Length: 83, e: 0.05, Avg Reward: -356.203908408, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 66.1607971191\n",
      "[NOR] Episode: 7440, Length: 99, e: 0.05, Avg Reward: -320.685046849, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -44.0056610107\n",
      "[NOR] Episode: 7450, Length: 125, e: 0.05, Avg Reward: -324.525344391, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 77.8166732788\n",
      "[NOR] Episode: 7460, Length: 84, e: 0.05, Avg Reward: -359.587351302, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.5847702026\n",
      "[NOR] Episode: 7470, Length: 102, e: 0.05, Avg Reward: -398.119499824, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 44.0970840454\n",
      "[NOR] Episode: 7480, Length: 135, e: 0.05, Avg Reward: -268.974873905, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 28.9321479797\n",
      "[NOR] Episode: 7490, Length: 81, e: 0.05, Avg Reward: -342.609457071, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 276.995239258\n",
      "[NOR] Episode: 7500, Length: 76, e: 0.05, Avg Reward: -337.314079058, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.6328601837\n",
      "[NOR] Episode: 7510, Length: 109, e: 0.05, Avg Reward: -335.260999053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.0245914459\n",
      "[NOR] Episode: 7520, Length: 115, e: 0.05, Avg Reward: -382.895002699, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -126.833763123\n",
      "[NOR] Episode: 7530, Length: 88, e: 0.05, Avg Reward: -398.940492275, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -174.068191528\n",
      "[NOR] Episode: 7540, Length: 148, e: 0.05, Avg Reward: -347.857091314, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 100.46471405\n",
      "[NOR] Episode: 7550, Length: 114, e: 0.05, Avg Reward: -337.454399565, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -81.8592529297\n",
      "[NOR] Episode: 7560, Length: 92, e: 0.05, Avg Reward: -410.899724294, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.37842559814\n",
      "[NOR] Episode: 7570, Length: 207, e: 0.05, Avg Reward: -395.579386995, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.32348632812\n",
      "[NOR] Episode: 7580, Length: 161, e: 0.05, Avg Reward: -389.932172925, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.7080421448\n",
      "[NOR] Episode: 7590, Length: 112, e: 0.05, Avg Reward: -470.693098374, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -50.2688217163\n",
      "[NOR] Episode: 7600, Length: 96, e: 0.05, Avg Reward: -415.322391745, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 102.303993225\n",
      "[NOR] Episode: 7610, Length: 85, e: 0.05, Avg Reward: -406.54832016, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.0904331207\n",
      "[NOR] Episode: 7620, Length: 75, e: 0.05, Avg Reward: -315.655438545, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 51.0685882568\n",
      "[NOR] Episode: 7630, Length: 108, e: 0.05, Avg Reward: -376.949868787, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.4919090271\n",
      "[NOR] Episode: 7640, Length: 104, e: 0.05, Avg Reward: -310.358949357, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.75653505325\n",
      "[NOR] Episode: 7650, Length: 98, e: 0.05, Avg Reward: -352.197337679, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.53827810287\n",
      "[NOR] Episode: 7660, Length: 208, e: 0.05, Avg Reward: -336.076675403, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.0250663757\n",
      "[NOR] Episode: 7670, Length: 82, e: 0.05, Avg Reward: -354.847089917, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 35.0310020447\n",
      "[NOR] Episode: 7680, Length: 92, e: 0.05, Avg Reward: -393.622406832, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -254.617675781\n",
      "[NOR] Episode: 7690, Length: 148, e: 0.05, Avg Reward: -343.290578302, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -153.693756104\n",
      "[NOR] Episode: 7700, Length: 84, e: 0.05, Avg Reward: -369.693862322, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.7870998383\n",
      "[NOR] Episode: 7710, Length: 109, e: 0.05, Avg Reward: -348.712506619, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.4012069702\n",
      "[NOR] Episode: 7720, Length: 243, e: 0.05, Avg Reward: -345.436689848, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 77.3688201904\n",
      "[NOR] Episode: 7730, Length: 100, e: 0.05, Avg Reward: -328.525752344, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.0403995514\n",
      "[NOR] Episode: 7740, Length: 117, e: 0.05, Avg Reward: -396.819790787, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 163.656311035\n",
      "[NOR] Episode: 7750, Length: 93, e: 0.05, Avg Reward: -335.641351654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -68.0000991821\n",
      "[NOR] Episode: 7760, Length: 73, e: 0.05, Avg Reward: -432.580376017, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.9644546509\n",
      "[NOR] Episode: 7770, Length: 116, e: 0.05, Avg Reward: -378.902093428, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 41.8454055786\n",
      "[NOR] Episode: 7780, Length: 83, e: 0.05, Avg Reward: -374.38374121, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.2660903931\n",
      "[NOR] Episode: 7790, Length: 149, e: 0.05, Avg Reward: -553.141950862, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.0410194397\n",
      "[NOR] Episode: 7800, Length: 227, e: 0.05, Avg Reward: -371.941762367, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -52.5335426331\n",
      "[NOR] Episode: 7810, Length: 79, e: 0.05, Avg Reward: -379.639850661, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -147.703872681\n",
      "[NOR] Episode: 7820, Length: 103, e: 0.05, Avg Reward: -505.811428861, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.6218318939\n",
      "[NOR] Episode: 7830, Length: 123, e: 0.05, Avg Reward: -448.855496244, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -87.9686050415\n",
      "[NOR] Episode: 7840, Length: 82, e: 0.05, Avg Reward: -428.038437648, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.54914665222\n",
      "[NOR] Episode: 7850, Length: 97, e: 0.05, Avg Reward: -384.310478723, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.1147012711\n",
      "[NOR] Episode: 7860, Length: 101, e: 0.05, Avg Reward: -391.104108676, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.2731132507\n",
      "[NOR] Episode: 7870, Length: 71, e: 0.05, Avg Reward: -461.229568578, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -149.238800049\n",
      "[NOR] Episode: 7880, Length: 223, e: 0.05, Avg Reward: -445.249531669, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.66836595535\n",
      "[NOR] Episode: 7890, Length: 232, e: 0.05, Avg Reward: -459.740925881, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -70.4197616577\n",
      "[NOR] Episode: 7900, Length: 97, e: 0.05, Avg Reward: -412.849338573, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 48.1213264465\n",
      "[NOR] Episode: 7910, Length: 105, e: 0.05, Avg Reward: -371.680751781, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.9599990845\n",
      "[NOR] Episode: 7920, Length: 99, e: 0.05, Avg Reward: -391.657120257, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.0121421814\n",
      "[NOR] Episode: 7930, Length: 206, e: 0.05, Avg Reward: -445.785589639, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -67.268081665\n",
      "[NOR] Episode: 7940, Length: 93, e: 0.05, Avg Reward: -403.085189446, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -89.7854690552\n",
      "[NOR] Episode: 7950, Length: 104, e: 0.05, Avg Reward: -474.023175029, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.35468101501\n",
      "[NOR] Episode: 7960, Length: 101, e: 0.05, Avg Reward: -404.626036426, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.61065673828\n",
      "[NOR] Episode: 7970, Length: 78, e: 0.05, Avg Reward: -414.948047017, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.6604156494\n",
      "[NOR] Episode: 7980, Length: 125, e: 0.05, Avg Reward: -523.791458289, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -58.0773391724\n",
      "[NOR] Episode: 7990, Length: 101, e: 0.05, Avg Reward: -396.239734467, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.700504303\n",
      "[NOR] Episode: 8000, Length: 94, e: 0.05, Avg Reward: -432.217448437, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 35.0908737183\n",
      "[NOR] Episode: 8010, Length: 83, e: 0.05, Avg Reward: -424.513859358, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.6407165527\n",
      "[NOR] Episode: 8020, Length: 167, e: 0.05, Avg Reward: -360.619917379, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -65.8434066772\n",
      "[NOR] Episode: 8030, Length: 87, e: 0.05, Avg Reward: -439.442862476, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.581861496\n",
      "[NOR] Episode: 8040, Length: 154, e: 0.05, Avg Reward: -457.302992638, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 38.521194458\n",
      "[NOR] Episode: 8050, Length: 179, e: 0.05, Avg Reward: -426.516525181, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.6356544495\n",
      "[NOR] Episode: 8060, Length: 117, e: 0.05, Avg Reward: -363.674776487, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 111.756332397\n",
      "[NOR] Episode: 8070, Length: 120, e: 0.05, Avg Reward: -352.986449655, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 52.199420929\n",
      "[NOR] Episode: 8080, Length: 134, e: 0.05, Avg Reward: -342.933886387, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.51794147491\n",
      "[NOR] Episode: 8090, Length: 79, e: 0.05, Avg Reward: -393.381581593, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 86.3655700684\n",
      "[NOR] Episode: 8100, Length: 124, e: 0.05, Avg Reward: -406.331022707, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -38.2606163025\n",
      "[NOR] Episode: 8110, Length: 288, e: 0.05, Avg Reward: -408.16839008, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -68.8687362671\n",
      "[NOR] Episode: 8120, Length: 98, e: 0.05, Avg Reward: -402.267668826, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.7181854248\n",
      "[NOR] Episode: 8130, Length: 93, e: 0.05, Avg Reward: -347.447544067, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.9109954834\n",
      "[NOR] Episode: 8140, Length: 88, e: 0.05, Avg Reward: -470.643050313, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.39749526978\n",
      "[NOR] Episode: 8150, Length: 229, e: 0.05, Avg Reward: -429.724943677, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.1991157532\n",
      "[NOR] Episode: 8160, Length: 84, e: 0.05, Avg Reward: -391.159751979, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -72.3335876465\n",
      "[NOR] Episode: 8170, Length: 114, e: 0.05, Avg Reward: -389.951090926, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.8572311401\n",
      "[NOR] Episode: 8180, Length: 370, e: 0.05, Avg Reward: -365.202118598, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.1451148987\n",
      "[NOR] Episode: 8190, Length: 103, e: 0.05, Avg Reward: -484.626436277, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.2225723267\n",
      "[NOR] Episode: 8200, Length: 88, e: 0.05, Avg Reward: -389.327997884, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.3602142334\n",
      "[NOR] Episode: 8210, Length: 284, e: 0.05, Avg Reward: -367.071027084, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.9512672424\n",
      "[NOR] Episode: 8220, Length: 114, e: 0.05, Avg Reward: -486.28503471, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.9939537048\n",
      "[NOR] Episode: 8230, Length: 98, e: 0.05, Avg Reward: -403.101428362, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.9773101807\n",
      "[NOR] Episode: 8240, Length: 120, e: 0.05, Avg Reward: -413.399894128, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.97727584839\n",
      "[NOR] Episode: 8250, Length: 135, e: 0.05, Avg Reward: -412.919894156, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -56.2646789551\n",
      "[NOR] Episode: 8260, Length: 136, e: 0.05, Avg Reward: -416.642590567, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 62.6561470032\n",
      "[NOR] Episode: 8270, Length: 136, e: 0.05, Avg Reward: -388.679547504, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.4369301796\n",
      "[NOR] Episode: 8280, Length: 102, e: 0.05, Avg Reward: -402.910902816, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.9378509521\n",
      "[NOR] Episode: 8290, Length: 89, e: 0.05, Avg Reward: -477.513195183, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.8373069763\n",
      "[NOR] Episode: 8300, Length: 85, e: 0.05, Avg Reward: -377.468979566, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -70.8755493164\n",
      "[NOR] Episode: 8310, Length: 106, e: 0.05, Avg Reward: -387.16656133, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -55.9546089172\n",
      "[NOR] Episode: 8320, Length: 167, e: 0.05, Avg Reward: -430.874590329, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -46.1417045593\n",
      "[NOR] Episode: 8330, Length: 150, e: 0.05, Avg Reward: -359.068413518, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.50502586365\n",
      "[NOR] Episode: 8340, Length: 258, e: 0.05, Avg Reward: -353.848607923, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.41799449921\n",
      "[NOR] Episode: 8350, Length: 103, e: 0.05, Avg Reward: -394.838236779, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.79915189743\n",
      "[NOR] Episode: 8360, Length: 169, e: 0.05, Avg Reward: -416.47278947, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -58.7049636841\n",
      "[NOR] Episode: 8370, Length: 130, e: 0.05, Avg Reward: -375.392282292, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.2967643738\n",
      "[NOR] Episode: 8380, Length: 130, e: 0.05, Avg Reward: -408.680602539, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -62.0178909302\n",
      "[NOR] Episode: 8390, Length: 186, e: 0.05, Avg Reward: -420.005745284, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 50.8868370056\n",
      "[NOR] Episode: 8400, Length: 97, e: 0.05, Avg Reward: -382.127534521, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.4492607117\n",
      "[NOR] Episode: 8410, Length: 119, e: 0.05, Avg Reward: -445.926732222, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.0060005188\n",
      "[NOR] Episode: 8420, Length: 121, e: 0.05, Avg Reward: -398.665178248, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -46.8256607056\n",
      "[NOR] Episode: 8430, Length: 130, e: 0.05, Avg Reward: -318.838773259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.2611436844\n",
      "[NOR] Episode: 8440, Length: 138, e: 0.05, Avg Reward: -411.994075689, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -51.8546524048\n",
      "[NOR] Episode: 8450, Length: 88, e: 0.05, Avg Reward: -408.715742352, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -48.1699028015\n",
      "[NOR] Episode: 8460, Length: 80, e: 0.05, Avg Reward: -399.938965957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.011174202\n",
      "[NOR] Episode: 8470, Length: 144, e: 0.05, Avg Reward: -416.945624331, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.5532741547\n",
      "[NOR] Episode: 8480, Length: 90, e: 0.05, Avg Reward: -442.925297103, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.7799377441\n",
      "[NOR] Episode: 8490, Length: 163, e: 0.05, Avg Reward: -424.206023576, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.0158996582\n",
      "[NOR] Episode: 8500, Length: 112, e: 0.05, Avg Reward: -392.868216576, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.1044692993\n",
      "[NOR] Episode: 8510, Length: 82, e: 0.05, Avg Reward: -435.446771417, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.3950443268\n",
      "[NOR] Episode: 8520, Length: 151, e: 0.05, Avg Reward: -445.300873195, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.7579956055\n",
      "[NOR] Episode: 8530, Length: 102, e: 0.05, Avg Reward: -433.866512988, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -58.6519889832\n",
      "[NOR] Episode: 8540, Length: 72, e: 0.05, Avg Reward: -429.68234696, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.73985862732\n",
      "[NOR] Episode: 8550, Length: 88, e: 0.05, Avg Reward: -390.288846635, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.5697288513\n",
      "[NOR] Episode: 8560, Length: 116, e: 0.05, Avg Reward: -421.075006697, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -66.7483978271\n",
      "[NOR] Episode: 8570, Length: 108, e: 0.05, Avg Reward: -407.837077318, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -40.0354118347\n",
      "[NOR] Episode: 8580, Length: 238, e: 0.05, Avg Reward: -481.046933675, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.5167732239\n",
      "[NOR] Episode: 8590, Length: 156, e: 0.05, Avg Reward: -491.465270747, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.26281738281\n",
      "[NOR] Episode: 8600, Length: 102, e: 0.05, Avg Reward: -426.651024414, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.05620002747\n",
      "[NOR] Episode: 8610, Length: 139, e: 0.05, Avg Reward: -461.643300053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 83.5557861328\n",
      "[NOR] Episode: 8620, Length: 206, e: 0.05, Avg Reward: -417.947314885, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.29120874405\n",
      "[NOR] Episode: 8630, Length: 124, e: 0.05, Avg Reward: -433.711159355, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.0339813232\n",
      "[NOR] Episode: 8640, Length: 154, e: 0.05, Avg Reward: -427.509090298, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.9868602753\n",
      "[NOR] Episode: 8650, Length: 176, e: 0.05, Avg Reward: -328.282468956, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.2823858261\n",
      "[NOR] Episode: 8660, Length: 130, e: 0.05, Avg Reward: -428.245940968, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.478435516357\n",
      "[NOR] Episode: 8670, Length: 89, e: 0.05, Avg Reward: -425.054648616, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.4718780518\n",
      "[NOR] Episode: 8680, Length: 163, e: 0.05, Avg Reward: -481.75841343, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 27.3066596985\n",
      "[NOR] Episode: 8690, Length: 354, e: 0.05, Avg Reward: -509.902399722, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.37952542305\n",
      "[NOR] Episode: 8700, Length: 94, e: 0.05, Avg Reward: -468.665338905, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.2460174561\n",
      "[NOR] Episode: 8710, Length: 90, e: 0.05, Avg Reward: -377.643941555, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.92346477509\n",
      "[NOR] Episode: 8720, Length: 84, e: 0.05, Avg Reward: -385.588288845, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.4866333008\n",
      "[NOR] Episode: 8730, Length: 96, e: 0.05, Avg Reward: -358.400036656, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.2941093445\n",
      "[NOR] Episode: 8740, Length: 114, e: 0.05, Avg Reward: -404.889917127, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.6433830261\n",
      "[NOR] Episode: 8750, Length: 113, e: 0.05, Avg Reward: -397.449293522, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -52.6713256836\n",
      "[NOR] Episode: 8760, Length: 365, e: 0.05, Avg Reward: -428.800034812, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.7516822815\n",
      "[NOR] Episode: 8770, Length: 97, e: 0.05, Avg Reward: -426.122455799, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.83036804199\n",
      "[NOR] Episode: 8780, Length: 120, e: 0.05, Avg Reward: -355.039655859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.2739372253\n",
      "[NOR] Episode: 8790, Length: 167, e: 0.05, Avg Reward: -364.680685623, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 57.9391975403\n",
      "[NOR] Episode: 8800, Length: 110, e: 0.05, Avg Reward: -407.993751177, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.4322662354\n",
      "[NOR] Episode: 8810, Length: 88, e: 0.05, Avg Reward: -485.795039989, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.70616149902\n",
      "[NOR] Episode: 8820, Length: 239, e: 0.05, Avg Reward: -509.80593221, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.5857925415\n",
      "[NOR] Episode: 8830, Length: 112, e: 0.05, Avg Reward: -443.692232618, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.7837963104\n",
      "[NOR] Episode: 8840, Length: 137, e: 0.05, Avg Reward: -373.679949072, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -44.7365455627\n",
      "[NOR] Episode: 8850, Length: 176, e: 0.05, Avg Reward: -449.093257971, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.5928554535\n",
      "[NOR] Episode: 8860, Length: 94, e: 0.05, Avg Reward: -478.495203247, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 59.9895248413\n",
      "[NOR] Episode: 8870, Length: 104, e: 0.05, Avg Reward: -455.765105773, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.20703554153\n",
      "[NOR] Episode: 8880, Length: 211, e: 0.05, Avg Reward: -379.65962851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 35.3776779175\n",
      "[NOR] Episode: 8890, Length: 105, e: 0.05, Avg Reward: -522.456719377, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -127.71245575\n",
      "[NOR] Episode: 8900, Length: 133, e: 0.05, Avg Reward: -423.208502706, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.3319149017\n",
      "[NOR] Episode: 8910, Length: 218, e: 0.05, Avg Reward: -408.216496654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -40.410949707\n",
      "[NOR] Episode: 8920, Length: 144, e: 0.05, Avg Reward: -369.584379818, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.3907585144\n",
      "[NOR] Episode: 8930, Length: 156, e: 0.05, Avg Reward: -462.680655592, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.84794998169\n",
      "[NOR] Episode: 8940, Length: 124, e: 0.05, Avg Reward: -415.239167353, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.2760238647\n",
      "[NOR] Episode: 8950, Length: 77, e: 0.05, Avg Reward: -420.514809493, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 74.1088409424\n",
      "[NOR] Episode: 8960, Length: 125, e: 0.05, Avg Reward: -416.007107372, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -71.4769515991\n",
      "[NOR] Episode: 8970, Length: 110, e: 0.05, Avg Reward: -368.398658361, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.48224830627\n",
      "[NOR] Episode: 8980, Length: 121, e: 0.05, Avg Reward: -400.584155171, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.80037689209\n",
      "[NOR] Episode: 8990, Length: 106, e: 0.05, Avg Reward: -395.739881738, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.125202179\n",
      "[NOR] Episode: 9000, Length: 133, e: 0.05, Avg Reward: -342.922156645, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.1251792908\n",
      "[NOR] Episode: 9010, Length: 163, e: 0.05, Avg Reward: -477.495257901, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -40.5673675537\n",
      "[NOR] Episode: 9020, Length: 120, e: 0.05, Avg Reward: -342.614411392, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.7202911377\n",
      "[NOR] Episode: 9030, Length: 87, e: 0.05, Avg Reward: -424.181544981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 126.306335449\n",
      "[NOR] Episode: 9040, Length: 97, e: 0.05, Avg Reward: -433.589914344, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.6295995712\n",
      "[NOR] Episode: 9050, Length: 82, e: 0.05, Avg Reward: -464.239119571, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -65.2228012085\n",
      "[NOR] Episode: 9060, Length: 107, e: 0.05, Avg Reward: -396.035974181, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.9488487244\n",
      "[NOR] Episode: 9070, Length: 122, e: 0.05, Avg Reward: -544.030583169, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.0732803345\n",
      "[NOR] Episode: 9080, Length: 105, e: 0.05, Avg Reward: -482.672524139, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.24733352661\n",
      "[NOR] Episode: 9090, Length: 277, e: 0.05, Avg Reward: -423.308454779, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.3688812256\n",
      "[NOR] Episode: 9100, Length: 215, e: 0.05, Avg Reward: -451.189438191, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.4086265564\n",
      "[NOR] Episode: 9110, Length: 85, e: 0.05, Avg Reward: -530.137189287, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 60.0452575684\n",
      "[NOR] Episode: 9120, Length: 74, e: 0.05, Avg Reward: -463.826687809, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.7995710373\n",
      "[NOR] Episode: 9130, Length: 76, e: 0.05, Avg Reward: -430.987763248, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.4882717133\n",
      "[NOR] Episode: 9140, Length: 159, e: 0.05, Avg Reward: -555.610551778, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -104.911506653\n",
      "[NOR] Episode: 9150, Length: 133, e: 0.05, Avg Reward: -445.207990174, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.42506980896\n",
      "[NOR] Episode: 9160, Length: 99, e: 0.05, Avg Reward: -520.43129148, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.9358291626\n",
      "[NOR] Episode: 9170, Length: 76, e: 0.05, Avg Reward: -380.958532386, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.8881225586\n",
      "[NOR] Episode: 9180, Length: 163, e: 0.05, Avg Reward: -343.170614885, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -48.8452072144\n",
      "[NOR] Episode: 9190, Length: 83, e: 0.05, Avg Reward: -395.280269367, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.0645027161\n",
      "[NOR] Episode: 9200, Length: 144, e: 0.05, Avg Reward: -350.547034173, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.9931845665\n",
      "[NOR] Episode: 9210, Length: 120, e: 0.05, Avg Reward: -425.996715188, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -46.8767089844\n",
      "[NOR] Episode: 9220, Length: 211, e: 0.05, Avg Reward: -394.368637913, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.82015705109\n",
      "[NOR] Episode: 9230, Length: 95, e: 0.05, Avg Reward: -353.863512267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 75.7487945557\n",
      "[NOR] Episode: 9240, Length: 124, e: 0.05, Avg Reward: -422.022926026, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.0532922745\n",
      "[NOR] Episode: 9250, Length: 78, e: 0.05, Avg Reward: -410.640123173, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 139.221572876\n",
      "[NOR] Episode: 9260, Length: 86, e: 0.05, Avg Reward: -433.945438183, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -52.3139038086\n",
      "[NOR] Episode: 9270, Length: 116, e: 0.05, Avg Reward: -364.908328246, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.373796463013\n",
      "[NOR] Episode: 9280, Length: 87, e: 0.05, Avg Reward: -371.664042397, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.4799346924\n",
      "[NOR] Episode: 9290, Length: 78, e: 0.05, Avg Reward: -431.27772341, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.6300373077\n",
      "[NOR] Episode: 9300, Length: 94, e: 0.05, Avg Reward: -373.226964943, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.6559638977\n",
      "[NOR] Episode: 9310, Length: 95, e: 0.05, Avg Reward: -456.670800765, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.5169639587\n",
      "[NOR] Episode: 9320, Length: 113, e: 0.05, Avg Reward: -397.396802949, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.76502799988\n",
      "[NOR] Episode: 9330, Length: 89, e: 0.05, Avg Reward: -367.51962706, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.8416957855\n",
      "[NOR] Episode: 9340, Length: 93, e: 0.05, Avg Reward: -427.247102623, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.30608177185\n",
      "[NOR] Episode: 9350, Length: 72, e: 0.05, Avg Reward: -333.153596552, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -82.6707763672\n",
      "[NOR] Episode: 9360, Length: 88, e: 0.05, Avg Reward: -316.510054086, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.854429245\n",
      "[NOR] Episode: 9370, Length: 95, e: 0.05, Avg Reward: -433.995303641, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.80223417282\n",
      "[NOR] Episode: 9380, Length: 81, e: 0.05, Avg Reward: -382.122389859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.37092494965\n",
      "[NOR] Episode: 9390, Length: 117, e: 0.05, Avg Reward: -340.667054531, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.5367679596\n",
      "[NOR] Episode: 9400, Length: 105, e: 0.05, Avg Reward: -378.939284681, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.57674455643\n",
      "[NOR] Episode: 9410, Length: 110, e: 0.05, Avg Reward: -377.031973085, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.421836853\n",
      "[NOR] Episode: 9420, Length: 119, e: 0.05, Avg Reward: -378.988387637, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.2793159485\n",
      "[NOR] Episode: 9430, Length: 118, e: 0.05, Avg Reward: -414.722088329, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -56.1304397583\n",
      "[NOR] Episode: 9440, Length: 102, e: 0.05, Avg Reward: -411.068368339, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.336933136\n",
      "[NOR] Episode: 9450, Length: 82, e: 0.05, Avg Reward: -316.805231678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.7076797485\n",
      "[NOR] Episode: 9460, Length: 280, e: 0.05, Avg Reward: -391.06940134, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 64.9056472778\n",
      "[NOR] Episode: 9470, Length: 92, e: 0.05, Avg Reward: -359.697604823, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 61.8660087585\n",
      "[NOR] Episode: 9480, Length: 78, e: 0.05, Avg Reward: -267.691436142, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.3612556458\n",
      "[NOR] Episode: 9490, Length: 264, e: 0.05, Avg Reward: -356.99938152, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.8436393738\n",
      "[NOR] Episode: 9500, Length: 109, e: 0.05, Avg Reward: -360.966386781, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.6515464783\n",
      "[NOR] Episode: 9510, Length: 125, e: 0.05, Avg Reward: -402.173924952, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.92398405075\n",
      "[NOR] Episode: 9520, Length: 118, e: 0.05, Avg Reward: -350.931420258, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.7828979492\n",
      "[NOR] Episode: 9530, Length: 113, e: 0.05, Avg Reward: -291.590370159, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.8086013794\n",
      "[NOR] Episode: 9540, Length: 165, e: 0.05, Avg Reward: -363.76323998, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 158.48600769\n",
      "[NOR] Episode: 9550, Length: 90, e: 0.05, Avg Reward: -329.728874412, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.6195936203\n",
      "[NOR] Episode: 9560, Length: 97, e: 0.05, Avg Reward: -257.838152108, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -86.1242828369\n",
      "[NOR] Episode: 9570, Length: 94, e: 0.05, Avg Reward: -315.213966923, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.2425727844\n",
      "[NOR] Episode: 9580, Length: 133, e: 0.05, Avg Reward: -355.502996776, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.13819885254\n",
      "[NOR] Episode: 9590, Length: 80, e: 0.05, Avg Reward: -225.741497846, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.56882286072\n",
      "[NOR] Episode: 9600, Length: 111, e: 0.05, Avg Reward: -274.828291153, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -40.9535140991\n",
      "[NOR] Episode: 9610, Length: 103, e: 0.05, Avg Reward: -334.855334036, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.0559883118\n",
      "[NOR] Episode: 9620, Length: 155, e: 0.05, Avg Reward: -345.200372585, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -40.7650299072\n",
      "[NOR] Episode: 9630, Length: 127, e: 0.05, Avg Reward: -305.450559678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -45.8081970215\n",
      "[NOR] Episode: 9640, Length: 160, e: 0.05, Avg Reward: -198.856976911, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.702129364\n",
      "[NOR] Episode: 9650, Length: 91, e: 0.05, Avg Reward: -263.611858901, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 151.838439941\n",
      "[NOR] Episode: 9660, Length: 404, e: 0.05, Avg Reward: -246.517177092, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.768863678\n",
      "[NOR] Episode: 9670, Length: 116, e: 0.05, Avg Reward: -264.655749092, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 65.5862045288\n",
      "[NOR] Episode: 9680, Length: 183, e: 0.05, Avg Reward: -328.988521697, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.1594581604\n",
      "[NOR] Episode: 9690, Length: 144, e: 0.05, Avg Reward: -236.049183896, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.1962833405\n",
      "[NOR] Episode: 9700, Length: 224, e: 0.05, Avg Reward: -301.559716853, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -53.9887962341\n",
      "[NOR] Episode: 9710, Length: 137, e: 0.05, Avg Reward: -255.730363263, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -38.2926712036\n",
      "[NOR] Episode: 9720, Length: 101, e: 0.05, Avg Reward: -236.795516986, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 58.4448242188\n",
      "[NOR] Episode: 9730, Length: 112, e: 0.05, Avg Reward: -299.040140902, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -65.0600662231\n",
      "[NOR] Episode: 9740, Length: 74, e: 0.05, Avg Reward: -291.762326166, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.5439338684\n",
      "[NOR] Episode: 9750, Length: 77, e: 0.05, Avg Reward: -255.583678398, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.3863248825\n",
      "[NOR] Episode: 9760, Length: 72, e: 0.05, Avg Reward: -193.298204031, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -56.0945739746\n",
      "[NOR] Episode: 9770, Length: 84, e: 0.05, Avg Reward: -313.178659117, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.5527648926\n",
      "[NOR] Episode: 9780, Length: 122, e: 0.05, Avg Reward: -305.635276704, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.4036331177\n",
      "[NOR] Episode: 9790, Length: 78, e: 0.05, Avg Reward: -227.762451194, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.50823497772\n",
      "[NOR] Episode: 9800, Length: 92, e: 0.05, Avg Reward: -226.015269533, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.6348571777\n",
      "[NOR] Episode: 9810, Length: 109, e: 0.05, Avg Reward: -209.449750504, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.7696857452\n",
      "[NOR] Episode: 9820, Length: 106, e: 0.05, Avg Reward: -341.255860337, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.3652648926\n",
      "[NOR] Episode: 9830, Length: 57, e: 0.05, Avg Reward: -256.869987296, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.447807312\n",
      "[NOR] Episode: 9840, Length: 142, e: 0.05, Avg Reward: -276.297827897, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -57.5442848206\n",
      "[NOR] Episode: 9850, Length: 98, e: 0.05, Avg Reward: -283.511077762, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.46702575684\n",
      "[NOR] Episode: 9860, Length: 80, e: 0.05, Avg Reward: -273.886668578, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.0791006088\n",
      "[NOR] Episode: 9870, Length: 117, e: 0.05, Avg Reward: -300.839735317, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.8156833649\n",
      "[NOR] Episode: 9880, Length: 114, e: 0.05, Avg Reward: -314.833167529, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.4176101685\n",
      "[NOR] Episode: 9890, Length: 93, e: 0.05, Avg Reward: -241.933369315, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.19836139679\n",
      "[NOR] Episode: 9900, Length: 80, e: 0.05, Avg Reward: -237.787639536, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.9040489197\n",
      "[NOR] Episode: 9910, Length: 85, e: 0.05, Avg Reward: -295.1248562, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.2310667038\n",
      "[NOR] Episode: 9920, Length: 80, e: 0.05, Avg Reward: -312.902002654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.8250350952\n",
      "[NOR] Episode: 9930, Length: 101, e: 0.05, Avg Reward: -266.624599309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -76.4289855957\n",
      "[NOR] Episode: 9940, Length: 99, e: 0.05, Avg Reward: -222.880881486, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.1759529114\n",
      "[NOR] Episode: 9950, Length: 89, e: 0.05, Avg Reward: -231.984538123, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 93.5951690674\n",
      "[NOR] Episode: 9960, Length: 110, e: 0.05, Avg Reward: -280.602638261, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.0434188843\n",
      "[NOR] Episode: 9970, Length: 185, e: 0.05, Avg Reward: -287.959969617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.54199934006\n",
      "[NOR] Episode: 9980, Length: 144, e: 0.05, Avg Reward: -271.518041742, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.1678256989\n",
      "[NOR] Episode: 9990, Length: 55, e: 0.05, Avg Reward: -137.479061099, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.1519622803\n",
      "[NOR] Episode: 10000, Length: 87, e: 0.05, Avg Reward: -231.032744261, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.094417572\n",
      "[NOR] Episode: 10010, Length: 139, e: 0.05, Avg Reward: -243.004820941, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.4233703613\n",
      "[NOR] Episode: 10020, Length: 145, e: 0.05, Avg Reward: -322.61429635, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.026597023\n",
      "[NOR] Episode: 10030, Length: 107, e: 0.05, Avg Reward: -282.693420731, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.36523246765\n",
      "[NOR] Episode: 10040, Length: 78, e: 0.05, Avg Reward: -294.984710785, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.5965671539\n",
      "[NOR] Episode: 10050, Length: 108, e: 0.05, Avg Reward: -321.008532008, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.8924703598\n",
      "[NOR] Episode: 10060, Length: 83, e: 0.05, Avg Reward: -272.147805635, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.5961284637\n",
      "[NOR] Episode: 10070, Length: 105, e: 0.05, Avg Reward: -270.286547912, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.8126602173\n",
      "[NOR] Episode: 10080, Length: 110, e: 0.05, Avg Reward: -226.473141934, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.308157444\n",
      "[NOR] Episode: 10090, Length: 117, e: 0.05, Avg Reward: -365.697698653, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.5640487671\n",
      "[NOR] Episode: 10100, Length: 68, e: 0.05, Avg Reward: -195.716013655, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.3312454224\n",
      "[NOR] Episode: 10110, Length: 77, e: 0.05, Avg Reward: -235.299527552, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.0515832901\n",
      "[NOR] Episode: 10120, Length: 113, e: 0.05, Avg Reward: -273.519856195, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -80.7536773682\n",
      "[NOR] Episode: 10130, Length: 141, e: 0.05, Avg Reward: -247.137336305, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 54.1694869995\n",
      "[NOR] Episode: 10140, Length: 82, e: 0.05, Avg Reward: -308.630269065, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.7980575562\n",
      "[NOR] Episode: 10150, Length: 116, e: 0.05, Avg Reward: -247.70099229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.86331939697\n",
      "[NOR] Episode: 10160, Length: 160, e: 0.05, Avg Reward: -325.902397148, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -40.4790153503\n",
      "[NOR] Episode: 10170, Length: 93, e: 0.05, Avg Reward: -255.72546411, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.17607593536\n",
      "[NOR] Episode: 10180, Length: 108, e: 0.05, Avg Reward: -293.567140596, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.2829437256\n",
      "[NOR] Episode: 10190, Length: 75, e: 0.05, Avg Reward: -270.546722984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.3632526398\n",
      "[NOR] Episode: 10200, Length: 86, e: 0.05, Avg Reward: -313.794603851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.29715824127\n",
      "[NOR] Episode: 10210, Length: 94, e: 0.05, Avg Reward: -239.107892382, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.80822181702\n",
      "[NOR] Episode: 10220, Length: 96, e: 0.05, Avg Reward: -302.841057627, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.7492713928\n",
      "[NOR] Episode: 10230, Length: 88, e: 0.05, Avg Reward: -303.383587058, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -52.9725570679\n",
      "[NOR] Episode: 10240, Length: 86, e: 0.05, Avg Reward: -207.033822197, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.850944519\n",
      "[NOR] Episode: 10250, Length: 99, e: 0.05, Avg Reward: -235.713076513, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.9410514832\n",
      "[NOR] Episode: 10260, Length: 107, e: 0.05, Avg Reward: -237.707302254, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.7412872314\n",
      "[NOR] Episode: 10270, Length: 63, e: 0.05, Avg Reward: -298.205247006, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -68.3667221069\n",
      "[NOR] Episode: 10280, Length: 90, e: 0.05, Avg Reward: -262.246764051, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.9589586258\n",
      "[NOR] Episode: 10290, Length: 156, e: 0.05, Avg Reward: -206.647223106, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.7139263153\n",
      "[NOR] Episode: 10300, Length: 90, e: 0.05, Avg Reward: -226.690558736, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.734834671\n",
      "[NOR] Episode: 10310, Length: 125, e: 0.05, Avg Reward: -276.227088013, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.1627807617\n",
      "[NOR] Episode: 10320, Length: 186, e: 0.05, Avg Reward: -230.358703576, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.16340065002\n",
      "[NOR] Episode: 10330, Length: 73, e: 0.05, Avg Reward: -255.961824753, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.5794448853\n",
      "[NOR] Episode: 10340, Length: 73, e: 0.05, Avg Reward: -220.98597094, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.186132192612\n",
      "[NOR] Episode: 10350, Length: 72, e: 0.05, Avg Reward: -231.58484248, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.65807628632\n",
      "[NOR] Episode: 10360, Length: 299, e: 0.05, Avg Reward: -222.696947099, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.5364151001\n",
      "[NOR] Episode: 10370, Length: 93, e: 0.05, Avg Reward: -244.51246798, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.7952804565\n",
      "[NOR] Episode: 10380, Length: 166, e: 0.05, Avg Reward: -290.646821836, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.594952106476\n",
      "[NOR] Episode: 10390, Length: 79, e: 0.05, Avg Reward: -248.536324309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.2220611572\n",
      "[NOR] Episode: 10400, Length: 210, e: 0.05, Avg Reward: -309.297324595, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -45.04271698\n",
      "[NOR] Episode: 10410, Length: 162, e: 0.05, Avg Reward: -241.106784468, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 83.715171814\n",
      "[NOR] Episode: 10420, Length: 109, e: 0.05, Avg Reward: -224.579320484, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.021812439\n",
      "[NOR] Episode: 10430, Length: 93, e: 0.05, Avg Reward: -209.140505248, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -57.9645652771\n",
      "[NOR] Episode: 10440, Length: 84, e: 0.05, Avg Reward: -270.603615989, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.9625244141\n",
      "[NOR] Episode: 10450, Length: 105, e: 0.05, Avg Reward: -293.530273985, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -51.0582542419\n",
      "[NOR] Episode: 10460, Length: 95, e: 0.05, Avg Reward: -163.705672505, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -52.5659065247\n",
      "[NOR] Episode: 10470, Length: 84, e: 0.05, Avg Reward: -237.662780862, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.9942398071\n",
      "[NOR] Episode: 10480, Length: 91, e: 0.05, Avg Reward: -202.325636153, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.23849344254\n",
      "[NOR] Episode: 10490, Length: 86, e: 0.05, Avg Reward: -142.099078105, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.61108779907\n",
      "[NOR] Episode: 10500, Length: 157, e: 0.05, Avg Reward: -246.690755762, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 38.8082923889\n",
      "[NOR] Episode: 10510, Length: 99, e: 0.05, Avg Reward: -295.658709952, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.904586792\n",
      "[NOR] Episode: 10520, Length: 133, e: 0.05, Avg Reward: -274.012438368, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -70.4178085327\n",
      "[NOR] Episode: 10530, Length: 92, e: 0.05, Avg Reward: -240.781518999, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.6753101349\n",
      "[NOR] Episode: 10540, Length: 79, e: 0.05, Avg Reward: -284.69826112, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.7226486206\n",
      "[NOR] Episode: 10550, Length: 102, e: 0.05, Avg Reward: -214.880174978, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -81.2636871338\n",
      "[NOR] Episode: 10560, Length: 73, e: 0.05, Avg Reward: -225.320408629, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.2318611145\n",
      "[NOR] Episode: 10570, Length: 88, e: 0.05, Avg Reward: -220.419667945, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.9937210083\n",
      "[NOR] Episode: 10580, Length: 109, e: 0.05, Avg Reward: -284.449707032, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.190536499\n",
      "[NOR] Episode: 10590, Length: 105, e: 0.05, Avg Reward: -223.165539079, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.3347511292\n",
      "[NOR] Episode: 10600, Length: 168, e: 0.05, Avg Reward: -252.76710199, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.7485656738\n",
      "[NOR] Episode: 10610, Length: 228, e: 0.05, Avg Reward: -201.795927093, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -114.864723206\n",
      "[NOR] Episode: 10620, Length: 137, e: 0.05, Avg Reward: -226.447556872, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.36897468567\n",
      "[NOR] Episode: 10630, Length: 116, e: 0.05, Avg Reward: -210.009805588, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.08796405792\n",
      "[NOR] Episode: 10640, Length: 123, e: 0.05, Avg Reward: -229.846601001, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.78546237946\n",
      "[NOR] Episode: 10650, Length: 98, e: 0.05, Avg Reward: -250.36236794, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -58.0832176208\n",
      "[NOR] Episode: 10660, Length: 100, e: 0.05, Avg Reward: -227.91437116, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.8552379608\n",
      "[NOR] Episode: 10670, Length: 84, e: 0.05, Avg Reward: -250.883221106, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.4939117432\n",
      "[NOR] Episode: 10680, Length: 92, e: 0.05, Avg Reward: -239.973038502, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.9144973755\n",
      "[NOR] Episode: 10690, Length: 96, e: 0.05, Avg Reward: -238.441106084, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.92929077148\n",
      "[NOR] Episode: 10700, Length: 96, e: 0.05, Avg Reward: -243.730039316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 60.3777770996\n",
      "[NOR] Episode: 10710, Length: 85, e: 0.05, Avg Reward: -254.990852961, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.83901000023\n",
      "[NOR] Episode: 10720, Length: 94, e: 0.05, Avg Reward: -271.468617534, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.238690376282\n",
      "[NOR] Episode: 10730, Length: 91, e: 0.05, Avg Reward: -267.026554775, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -56.7346038818\n",
      "[NOR] Episode: 10740, Length: 127, e: 0.05, Avg Reward: -270.805051943, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -93.4777374268\n",
      "[NOR] Episode: 10750, Length: 170, e: 0.05, Avg Reward: -319.395785105, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.4352912903\n",
      "[NOR] Episode: 10760, Length: 82, e: 0.05, Avg Reward: -272.574462307, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -51.6686248779\n",
      "[NOR] Episode: 10770, Length: 209, e: 0.05, Avg Reward: -268.345710224, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.6057987213\n",
      "[NOR] Episode: 10780, Length: 146, e: 0.05, Avg Reward: -266.978733566, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.2108154297\n",
      "[NOR] Episode: 10790, Length: 122, e: 0.05, Avg Reward: -299.7910079, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.526873350143\n",
      "[NOR] Episode: 10800, Length: 100, e: 0.05, Avg Reward: -277.373717175, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.6321716309\n",
      "[NOR] Episode: 10810, Length: 159, e: 0.05, Avg Reward: -192.679504958, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.5784645081\n",
      "[NOR] Episode: 10820, Length: 189, e: 0.05, Avg Reward: -229.297783045, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.93680953979\n",
      "[NOR] Episode: 10830, Length: 166, e: 0.05, Avg Reward: -254.947313908, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.9513835907\n",
      "[NOR] Episode: 10840, Length: 95, e: 0.05, Avg Reward: -246.821068366, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.423456192\n",
      "[NOR] Episode: 10850, Length: 73, e: 0.05, Avg Reward: -224.058915257, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.3682289124\n",
      "[NOR] Episode: 10860, Length: 83, e: 0.05, Avg Reward: -219.968207469, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 55.5472335815\n",
      "[NOR] Episode: 10870, Length: 224, e: 0.05, Avg Reward: -242.856978737, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -40.4566345215\n",
      "[NOR] Episode: 10880, Length: 132, e: 0.05, Avg Reward: -238.514014872, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -44.0002670288\n",
      "[NOR] Episode: 10890, Length: 216, e: 0.05, Avg Reward: -260.890635618, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.6620197296\n",
      "[NOR] Episode: 10900, Length: 88, e: 0.05, Avg Reward: -222.395499434, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.9427223206\n",
      "[NOR] Episode: 10910, Length: 82, e: 0.05, Avg Reward: -228.322926815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.2186641693\n",
      "[NOR] Episode: 10920, Length: 133, e: 0.05, Avg Reward: -254.479875452, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.7174758911\n",
      "[NOR] Episode: 10930, Length: 251, e: 0.05, Avg Reward: -280.955759582, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.91357040405\n",
      "[NOR] Episode: 10940, Length: 134, e: 0.05, Avg Reward: -254.743344258, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -102.545135498\n",
      "[NOR] Episode: 10950, Length: 103, e: 0.05, Avg Reward: -345.772331618, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 98.9315795898\n",
      "[NOR] Episode: 10960, Length: 304, e: 0.05, Avg Reward: -210.343461834, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.7318973541\n",
      "[NOR] Episode: 10970, Length: 81, e: 0.05, Avg Reward: -276.897997316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.33817911148\n",
      "[NOR] Episode: 10980, Length: 269, e: 0.05, Avg Reward: -216.11642707, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.85347080231\n",
      "[NOR] Episode: 10990, Length: 86, e: 0.05, Avg Reward: -378.531040179, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.0613021851\n",
      "[NOR] Episode: 11000, Length: 88, e: 0.05, Avg Reward: -291.174248813, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.20571708679\n",
      "[NOR] Episode: 11010, Length: 139, e: 0.05, Avg Reward: -308.273089088, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.73311138153\n",
      "[NOR] Episode: 11020, Length: 152, e: 0.05, Avg Reward: -331.923669047, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -61.0308456421\n",
      "[NOR] Episode: 11030, Length: 105, e: 0.05, Avg Reward: -386.492385201, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -48.264755249\n",
      "[NOR] Episode: 11040, Length: 152, e: 0.05, Avg Reward: -288.370570553, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.9891014099\n",
      "[NOR] Episode: 11050, Length: 87, e: 0.05, Avg Reward: -341.401746937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 58.1881752014\n",
      "[NOR] Episode: 11060, Length: 311, e: 0.05, Avg Reward: -333.196290757, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.4214258194\n",
      "[NOR] Episode: 11070, Length: 290, e: 0.05, Avg Reward: -311.023819919, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.446603775\n",
      "[NOR] Episode: 11080, Length: 123, e: 0.05, Avg Reward: -326.757466057, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.6823806763\n",
      "[NOR] Episode: 11090, Length: 111, e: 0.05, Avg Reward: -259.868586088, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 171.373565674\n",
      "[NOR] Episode: 11100, Length: 123, e: 0.05, Avg Reward: -306.113157523, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.48996162415\n",
      "[NOR] Episode: 11110, Length: 112, e: 0.05, Avg Reward: -298.962514742, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -68.2722244263\n",
      "[NOR] Episode: 11120, Length: 99, e: 0.05, Avg Reward: -289.315510805, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.3640890121\n",
      "[NOR] Episode: 11130, Length: 143, e: 0.05, Avg Reward: -237.116308074, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -74.7920227051\n",
      "[NOR] Episode: 11140, Length: 146, e: 0.05, Avg Reward: -226.086037222, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.8440093994\n",
      "[NOR] Episode: 11150, Length: 327, e: 0.05, Avg Reward: -245.754995152, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.8641433716\n",
      "[NOR] Episode: 11160, Length: 97, e: 0.05, Avg Reward: -150.79431484, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -52.2173461914\n",
      "[NOR] Episode: 11170, Length: 83, e: 0.05, Avg Reward: -230.943474538, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -95.2629013062\n",
      "[NOR] Episode: 11180, Length: 220, e: 0.05, Avg Reward: -262.287958798, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -44.1106567383\n",
      "[NOR] Episode: 11190, Length: 136, e: 0.05, Avg Reward: -285.23787268, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.6670684814\n",
      "[NOR] Episode: 11200, Length: 298, e: 0.05, Avg Reward: -204.965180454, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.2928161621\n",
      "[NOR] Episode: 11210, Length: 97, e: 0.05, Avg Reward: -157.307270747, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -101.702964783\n",
      "[NOR] Episode: 11220, Length: 110, e: 0.05, Avg Reward: -285.402220486, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.59365975857\n",
      "[NOR] Episode: 11230, Length: 112, e: 0.05, Avg Reward: -208.68724932, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -149.253265381\n",
      "[NOR] Episode: 11240, Length: 155, e: 0.05, Avg Reward: -269.91844024, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 93.7312164307\n",
      "[NOR] Episode: 11250, Length: 116, e: 0.05, Avg Reward: -170.869270556, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.75318670273\n",
      "[NOR] Episode: 11260, Length: 116, e: 0.05, Avg Reward: -224.680540525, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 34.5033798218\n",
      "[NOR] Episode: 11270, Length: 103, e: 0.05, Avg Reward: -254.637241997, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.3974151611\n",
      "[NOR] Episode: 11280, Length: 112, e: 0.05, Avg Reward: -257.424385895, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.81880617142\n",
      "[NOR] Episode: 11290, Length: 81, e: 0.05, Avg Reward: -274.366085606, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -112.171730042\n",
      "[NOR] Episode: 11300, Length: 110, e: 0.05, Avg Reward: -273.476051425, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.3162975311\n",
      "[NOR] Episode: 11310, Length: 91, e: 0.05, Avg Reward: -239.154166384, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.6903800964\n",
      "[NOR] Episode: 11320, Length: 112, e: 0.05, Avg Reward: -264.448199898, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.33238935471\n",
      "[NOR] Episode: 11330, Length: 161, e: 0.05, Avg Reward: -256.733029211, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.8115367889\n",
      "[NOR] Episode: 11340, Length: 101, e: 0.05, Avg Reward: -220.366686487, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.540512085\n",
      "[NOR] Episode: 11350, Length: 164, e: 0.05, Avg Reward: -282.616319851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 37.4435653687\n",
      "[NOR] Episode: 11360, Length: 77, e: 0.05, Avg Reward: -222.596406899, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.9839172363\n",
      "[NOR] Episode: 11370, Length: 91, e: 0.05, Avg Reward: -300.47643964, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.3900794983\n",
      "[NOR] Episode: 11380, Length: 77, e: 0.05, Avg Reward: -230.470922627, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.85647964478\n",
      "[NOR] Episode: 11390, Length: 123, e: 0.05, Avg Reward: -193.011065655, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.2347297668\n",
      "[NOR] Episode: 11400, Length: 81, e: 0.05, Avg Reward: -228.449055226, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.8523139954\n",
      "[NOR] Episode: 11410, Length: 101, e: 0.05, Avg Reward: -238.208344632, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.91583490372\n",
      "[NOR] Episode: 11420, Length: 163, e: 0.05, Avg Reward: -280.971788101, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.33495616913\n",
      "[NOR] Episode: 11430, Length: 118, e: 0.05, Avg Reward: -270.197363851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.35492420197\n",
      "[NOR] Episode: 11440, Length: 158, e: 0.05, Avg Reward: -282.715590658, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.4741334915\n",
      "[NOR] Episode: 11450, Length: 211, e: 0.05, Avg Reward: -286.216468152, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 102.385673523\n",
      "[NOR] Episode: 11460, Length: 167, e: 0.05, Avg Reward: -270.796761123, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 39.2393722534\n",
      "[NOR] Episode: 11470, Length: 77, e: 0.05, Avg Reward: -281.033639689, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -56.9029083252\n",
      "[NOR] Episode: 11480, Length: 86, e: 0.05, Avg Reward: -195.764365682, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -40.9688339233\n",
      "[NOR] Episode: 11490, Length: 153, e: 0.05, Avg Reward: -234.001323607, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -150.974197388\n",
      "[NOR] Episode: 11500, Length: 340, e: 0.05, Avg Reward: -185.789002163, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.6848201752\n",
      "[NOR] Episode: 11510, Length: 279, e: 0.05, Avg Reward: -213.626643158, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.6203994751\n",
      "[NOR] Episode: 11520, Length: 187, e: 0.05, Avg Reward: -231.399112402, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.65382289886\n",
      "[NOR] Episode: 11530, Length: 85, e: 0.05, Avg Reward: -212.394057809, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.54306602478\n",
      "[NOR] Episode: 11540, Length: 371, e: 0.05, Avg Reward: -214.986156328, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.3228874207\n",
      "[NOR] Episode: 11550, Length: 83, e: 0.05, Avg Reward: -255.924083543, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -60.27917099\n",
      "[NOR] Episode: 11560, Length: 85, e: 0.05, Avg Reward: -213.154483475, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.7253465652\n",
      "[NOR] Episode: 11570, Length: 115, e: 0.05, Avg Reward: -226.504596044, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.6815090179\n",
      "[NOR] Episode: 11580, Length: 122, e: 0.05, Avg Reward: -193.185806241, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.1986694336\n",
      "[NOR] Episode: 11590, Length: 68, e: 0.05, Avg Reward: -224.859641957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.46194934845\n",
      "[NOR] Episode: 11600, Length: 69, e: 0.05, Avg Reward: -220.852517248, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.5047359467\n",
      "[NOR] Episode: 11610, Length: 54, e: 0.05, Avg Reward: -188.153558347, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.39349365234\n",
      "[NOR] Episode: 11620, Length: 69, e: 0.05, Avg Reward: -174.530660382, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.8524017334\n",
      "[NOR] Episode: 11630, Length: 105, e: 0.05, Avg Reward: -177.268091444, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 32.158531189\n",
      "[NOR] Episode: 11640, Length: 98, e: 0.05, Avg Reward: -267.108638825, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.29680538177\n",
      "[NOR] Episode: 11650, Length: 90, e: 0.05, Avg Reward: -148.724486421, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -73.9813537598\n",
      "[NOR] Episode: 11660, Length: 534, e: 0.05, Avg Reward: -282.163529531, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.5525016785\n",
      "[NOR] Episode: 11670, Length: 93, e: 0.05, Avg Reward: -256.607002785, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.8015727997\n",
      "[NOR] Episode: 11680, Length: 89, e: 0.05, Avg Reward: -165.457281348, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -86.49168396\n",
      "[NOR] Episode: 11690, Length: 89, e: 0.05, Avg Reward: -203.559373444, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.0413398743\n",
      "[NOR] Episode: 11700, Length: 98, e: 0.05, Avg Reward: -150.953363393, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.18270349503\n",
      "[NOR] Episode: 11710, Length: 130, e: 0.05, Avg Reward: -132.538125097, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.68778800964\n",
      "[NOR] Episode: 11720, Length: 125, e: 0.05, Avg Reward: -154.462482162, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.8837432861\n",
      "[NOR] Episode: 11730, Length: 259, e: 0.05, Avg Reward: -195.51687406, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.1505298615\n",
      "[NOR] Episode: 11740, Length: 99, e: 0.05, Avg Reward: -152.238193351, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -111.981216431\n",
      "[NOR] Episode: 11750, Length: 228, e: 0.05, Avg Reward: -282.062698581, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.5391712189\n",
      "[NOR] Episode: 11760, Length: 69, e: 0.05, Avg Reward: -221.811088655, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.5724601746\n",
      "[NOR] Episode: 11770, Length: 116, e: 0.05, Avg Reward: -241.44188812, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.8935756683\n",
      "[NOR] Episode: 11780, Length: 230, e: 0.05, Avg Reward: -238.924622788, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.6981039047\n",
      "[NOR] Episode: 11790, Length: 62, e: 0.05, Avg Reward: -216.693688013, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.8223171234\n",
      "[NOR] Episode: 11800, Length: 111, e: 0.05, Avg Reward: -125.412233459, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 76.2629394531\n",
      "[NOR] Episode: 11810, Length: 219, e: 0.05, Avg Reward: -270.390279654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -61.4982833862\n",
      "[NOR] Episode: 11820, Length: 124, e: 0.05, Avg Reward: -179.789243636, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.0623245239\n",
      "[NOR] Episode: 11830, Length: 101, e: 0.05, Avg Reward: -211.2224131, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.780418396\n",
      "[NOR] Episode: 11840, Length: 69, e: 0.05, Avg Reward: -162.289828596, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -119.044059753\n",
      "[NOR] Episode: 11850, Length: 106, e: 0.05, Avg Reward: -153.844698394, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.7150764465\n",
      "[NOR] Episode: 11860, Length: 240, e: 0.05, Avg Reward: -155.716196676, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -64.8207778931\n",
      "[NOR] Episode: 11870, Length: 216, e: 0.05, Avg Reward: -187.901775017, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.6513175964\n",
      "[NOR] Episode: 11880, Length: 196, e: 0.05, Avg Reward: -172.448115043, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.98311901093\n",
      "[NOR] Episode: 11890, Length: 83, e: 0.05, Avg Reward: -192.214219856, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -56.7113113403\n",
      "[NOR] Episode: 11900, Length: 210, e: 0.05, Avg Reward: -141.014392057, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.76585817337\n",
      "[NOR] Episode: 11910, Length: 80, e: 0.05, Avg Reward: -150.617369233, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.9503631592\n",
      "[NOR] Episode: 11920, Length: 63, e: 0.05, Avg Reward: -154.031715876, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 70.1796188354\n",
      "[NOR] Episode: 11930, Length: 89, e: 0.05, Avg Reward: -130.939125766, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -118.437049866\n",
      "[NOR] Episode: 11940, Length: 93, e: 0.05, Avg Reward: -136.501563639, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.4107379913\n",
      "[NOR] Episode: 11950, Length: 93, e: 0.05, Avg Reward: -73.9949529786, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.2826805115\n",
      "[NOR] Episode: 11960, Length: 108, e: 0.05, Avg Reward: -169.283433934, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.9815711975\n",
      "[NOR] Episode: 11970, Length: 93, e: 0.05, Avg Reward: -197.057728906, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -56.5645675659\n",
      "[NOR] Episode: 11980, Length: 325, e: 0.05, Avg Reward: -111.451210366, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -56.0688858032\n",
      "[NOR] Episode: 11990, Length: 81, e: 0.05, Avg Reward: -103.908906187, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.0819854736\n",
      "[NOR] Episode: 12000, Length: 103, e: 0.05, Avg Reward: -183.807642678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.3182830811\n",
      "[NOR] Episode: 12010, Length: 52, e: 0.05, Avg Reward: -128.528248853, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.5378322601\n",
      "[NOR] Episode: 12020, Length: 78, e: 0.05, Avg Reward: -148.632735972, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.1805858612\n",
      "[NOR] Episode: 12030, Length: 61, e: 0.05, Avg Reward: -108.710638258, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.1334209442\n",
      "[NOR] Episode: 12040, Length: 53, e: 0.05, Avg Reward: -122.239510915, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 48.3609313965\n",
      "[NOR] Episode: 12050, Length: 60, e: 0.05, Avg Reward: -173.317756187, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.0664958954\n",
      "[NOR] Episode: 12060, Length: 110, e: 0.05, Avg Reward: -136.921327838, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -62.1807937622\n",
      "[NOR] Episode: 12070, Length: 121, e: 0.05, Avg Reward: -120.444847042, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.81556034088\n",
      "[NOR] Episode: 12080, Length: 76, e: 0.05, Avg Reward: -105.401398485, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.0396385193\n",
      "[NOR] Episode: 12090, Length: 87, e: 0.05, Avg Reward: -176.387116829, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.0778827667\n",
      "[NOR] Episode: 12100, Length: 75, e: 0.05, Avg Reward: -103.998757678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.6109390259\n",
      "[NOR] Episode: 12110, Length: 156, e: 0.05, Avg Reward: -107.293800021, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.8013162613\n",
      "[NOR] Episode: 12120, Length: 86, e: 0.05, Avg Reward: -92.8442757092, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.7545089722\n",
      "[NOR] Episode: 12130, Length: 100, e: 0.05, Avg Reward: -139.198019636, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.71235084534\n",
      "[NOR] Episode: 12140, Length: 112, e: 0.05, Avg Reward: -98.2719867801, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.2511482239\n",
      "[NOR] Episode: 12150, Length: 162, e: 0.05, Avg Reward: -211.122254545, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -38.9824104309\n",
      "[NOR] Episode: 12160, Length: 110, e: 0.05, Avg Reward: -94.4660123116, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.15116262436\n",
      "[NOR] Episode: 12170, Length: 71, e: 0.05, Avg Reward: -144.942051615, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.9550361633\n",
      "[NOR] Episode: 12180, Length: 115, e: 0.05, Avg Reward: -160.263163371, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.70623970032\n",
      "[NOR] Episode: 12190, Length: 109, e: 0.05, Avg Reward: -62.9223565829, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.58058261871\n",
      "[NOR] Episode: 12200, Length: 79, e: 0.05, Avg Reward: -95.7923202741, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.55581188202\n",
      "[NOR] Episode: 12210, Length: 69, e: 0.05, Avg Reward: -110.282933939, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.2942581177\n",
      "[NOR] Episode: 12220, Length: 77, e: 0.05, Avg Reward: -77.6447415246, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.4442329407\n",
      "[NOR] Episode: 12230, Length: 74, e: 0.05, Avg Reward: -145.671330742, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.0022315979\n",
      "[NOR] Episode: 12240, Length: 100, e: 0.05, Avg Reward: -122.187245178, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.5229568481\n",
      "[NOR] Episode: 12250, Length: 107, e: 0.05, Avg Reward: -72.5382391592, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.59689617157\n",
      "[NOR] Episode: 12260, Length: 93, e: 0.05, Avg Reward: -154.423692476, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.5620098114\n",
      "[NOR] Episode: 12270, Length: 88, e: 0.05, Avg Reward: -67.4663489224, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.1799430847\n",
      "[NOR] Episode: 12280, Length: 93, e: 0.05, Avg Reward: -128.759902809, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.7926225662\n",
      "[NOR] Episode: 12290, Length: 59, e: 0.05, Avg Reward: -138.276742478, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.522277832\n",
      "[NOR] Episode: 12300, Length: 95, e: 0.05, Avg Reward: -86.3402239975, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.74069404602\n",
      "[NOR] Episode: 12310, Length: 90, e: 0.05, Avg Reward: -105.72191891, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.3219184875\n",
      "[NOR] Episode: 12320, Length: 106, e: 0.05, Avg Reward: -105.351559143, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.501449585\n",
      "[NOR] Episode: 12330, Length: 82, e: 0.05, Avg Reward: -94.4259816005, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.3975448608\n",
      "[NOR] Episode: 12340, Length: 84, e: 0.05, Avg Reward: -120.011815995, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.9644203186\n",
      "[NOR] Episode: 12350, Length: 59, e: 0.05, Avg Reward: -96.4259428917, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -86.8328094482\n",
      "[NOR] Episode: 12360, Length: 91, e: 0.05, Avg Reward: -94.3643305584, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -45.465385437\n",
      "[NOR] Episode: 12370, Length: 100, e: 0.05, Avg Reward: -95.3125915035, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 48.4360313416\n",
      "[NOR] Episode: 12380, Length: 81, e: 0.05, Avg Reward: -53.8731551043, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 165.608459473\n",
      "[NOR] Episode: 12390, Length: 59, e: 0.05, Avg Reward: -159.044038807, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.8071937561\n",
      "[NOR] Episode: 12400, Length: 72, e: 0.05, Avg Reward: -178.856126591, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 234.406738281\n",
      "[NOR] Episode: 12410, Length: 88, e: 0.05, Avg Reward: -128.232917433, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.92170906067\n",
      "[NOR] Episode: 12420, Length: 77, e: 0.05, Avg Reward: -62.9874953257, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.7048034668\n",
      "[NOR] Episode: 12430, Length: 86, e: 0.05, Avg Reward: -110.097571877, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.3704299927\n",
      "[NOR] Episode: 12440, Length: 79, e: 0.05, Avg Reward: -83.2478727452, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.6154127121\n",
      "[NOR] Episode: 12450, Length: 86, e: 0.05, Avg Reward: -164.067480603, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.6731262207\n",
      "[NOR] Episode: 12460, Length: 406, e: 0.05, Avg Reward: -133.542023951, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.05470085144\n",
      "[NOR] Episode: 12470, Length: 99, e: 0.05, Avg Reward: -115.699028271, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.7296504974\n",
      "[NOR] Episode: 12480, Length: 84, e: 0.05, Avg Reward: -100.769922561, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.48807144165\n",
      "[NOR] Episode: 12490, Length: 104, e: 0.05, Avg Reward: -149.384362354, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.8088607788\n",
      "[NOR] Episode: 12500, Length: 1059, e: 0.05, Avg Reward: -93.0695645972, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.3096160889\n",
      "[NOR] Episode: 12510, Length: 61, e: 0.05, Avg Reward: -136.151912474, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.7234344482\n",
      "[NOR] Episode: 12520, Length: 218, e: 0.05, Avg Reward: -80.4509626796, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -84.2215194702\n",
      "[NOR] Episode: 12530, Length: 501, e: 0.05, Avg Reward: -120.608779617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.17279958725\n",
      "[NOR] Episode: 12540, Length: 225, e: 0.05, Avg Reward: -139.725664128, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.0831050873\n",
      "[NOR] Episode: 12550, Length: 219, e: 0.05, Avg Reward: -89.2175413851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.2167701721\n",
      "[NOR] Episode: 12560, Length: 78, e: 0.05, Avg Reward: -128.583099334, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -67.5237350464\n",
      "[NOR] Episode: 12570, Length: 370, e: 0.05, Avg Reward: -87.6815965353, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.168510437\n",
      "[NOR] Episode: 12580, Length: 55, e: 0.05, Avg Reward: -153.686680598, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.720434188843\n",
      "[NOR] Episode: 12590, Length: 235, e: 0.05, Avg Reward: -169.47970245, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 80.2554016113\n",
      "[NOR] Episode: 12600, Length: 67, e: 0.05, Avg Reward: -215.233752173, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.2057228088\n",
      "[NOR] Episode: 12610, Length: 73, e: 0.05, Avg Reward: -130.903017568, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.3863487244\n",
      "[NOR] Episode: 12620, Length: 52, e: 0.05, Avg Reward: -78.9708389482, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.90805625916\n",
      "[NOR] Episode: 12630, Length: 485, e: 0.05, Avg Reward: -127.520669902, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.8204364777\n",
      "[NOR] Episode: 12640, Length: 98, e: 0.05, Avg Reward: -151.664460139, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.099861145\n",
      "[NOR] Episode: 12650, Length: 329, e: 0.05, Avg Reward: -199.239109205, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -76.9868621826\n",
      "[NOR] Episode: 12660, Length: 73, e: 0.05, Avg Reward: -125.287477645, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.77964019775\n",
      "[NOR] Episode: 12670, Length: 248, e: 0.05, Avg Reward: -179.254826819, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.3268527985\n",
      "[NOR] Episode: 12680, Length: 58, e: 0.05, Avg Reward: -141.75032541, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.2016239166\n",
      "[NOR] Episode: 12690, Length: 64, e: 0.05, Avg Reward: -120.061001608, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.8219337463\n",
      "[NOR] Episode: 12700, Length: 79, e: 0.05, Avg Reward: -168.922466522, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.4169540405\n",
      "[NOR] Episode: 12710, Length: 54, e: 0.05, Avg Reward: -142.112791782, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.46090888977\n",
      "[NOR] Episode: 12720, Length: 168, e: 0.05, Avg Reward: -99.9975562476, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.38274765015\n",
      "[NOR] Episode: 12730, Length: 228, e: 0.05, Avg Reward: -176.29502941, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.4655017853\n",
      "[NOR] Episode: 12740, Length: 81, e: 0.05, Avg Reward: -145.973784709, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.0330314636\n",
      "[NOR] Episode: 12750, Length: 68, e: 0.05, Avg Reward: -161.825084666, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.9286794662\n",
      "[NOR] Episode: 12760, Length: 85, e: 0.05, Avg Reward: -153.524008273, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.37631416321\n",
      "[NOR] Episode: 12770, Length: 276, e: 0.05, Avg Reward: -146.743038812, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.1335144043\n",
      "[NOR] Episode: 12780, Length: 63, e: 0.05, Avg Reward: -162.741989788, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.9153957367\n",
      "[NOR] Episode: 12790, Length: 190, e: 0.05, Avg Reward: -115.507300171, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.13389539719\n",
      "[NOR] Episode: 12800, Length: 120, e: 0.05, Avg Reward: -118.229036493, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.6786594391\n",
      "[NOR] Episode: 12810, Length: 78, e: 0.05, Avg Reward: -171.801184715, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -58.9546928406\n",
      "[NOR] Episode: 12820, Length: 56, e: 0.05, Avg Reward: -118.784313155, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.657901763916\n",
      "[NOR] Episode: 12830, Length: 87, e: 0.05, Avg Reward: -120.611271938, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.7155990601\n",
      "[NOR] Episode: 12840, Length: 108, e: 0.05, Avg Reward: -149.435103084, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.3496551514\n",
      "[NOR] Episode: 12850, Length: 250, e: 0.05, Avg Reward: -125.702764017, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.23879337311\n",
      "[NOR] Episode: 12860, Length: 184, e: 0.05, Avg Reward: -134.651222116, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -64.4345550537\n",
      "[NOR] Episode: 12870, Length: 79, e: 0.05, Avg Reward: -179.173111728, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.42642593384\n",
      "[NOR] Episode: 12880, Length: 59, e: 0.05, Avg Reward: -120.718794984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.2275085449\n",
      "[NOR] Episode: 12890, Length: 58, e: 0.05, Avg Reward: -164.066037901, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.02827072144\n",
      "[NOR] Episode: 12900, Length: 87, e: 0.05, Avg Reward: -128.689324563, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.9262924194\n",
      "[NOR] Episode: 12910, Length: 71, e: 0.05, Avg Reward: -127.86261755, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.74232530594\n",
      "[NOR] Episode: 12920, Length: 99, e: 0.05, Avg Reward: -113.786066607, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 107.945358276\n",
      "[NOR] Episode: 12930, Length: 229, e: 0.05, Avg Reward: -93.6976491307, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 60.6058425903\n",
      "[NOR] Episode: 12940, Length: 86, e: 0.05, Avg Reward: -135.773036462, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.6243972778\n",
      "[NOR] Episode: 12950, Length: 74, e: 0.05, Avg Reward: -173.952924355, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.83367347717\n",
      "[NOR] Episode: 12960, Length: 149, e: 0.05, Avg Reward: -112.07198642, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.6837501526\n",
      "[NOR] Episode: 12970, Length: 171, e: 0.05, Avg Reward: -147.352546546, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -81.9539337158\n",
      "[NOR] Episode: 12980, Length: 71, e: 0.05, Avg Reward: -148.869988257, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.3186264038\n",
      "[NOR] Episode: 12990, Length: 62, e: 0.05, Avg Reward: -89.9746850483, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.0566644669\n",
      "[NOR] Episode: 13000, Length: 98, e: 0.05, Avg Reward: -144.239327481, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.8355979919\n",
      "[NOR] Episode: 13010, Length: 82, e: 0.05, Avg Reward: -149.597366679, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.22990131378\n",
      "[NOR] Episode: 13020, Length: 317, e: 0.05, Avg Reward: -69.5064872468, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 42.0816040039\n",
      "[NOR] Episode: 13030, Length: 86, e: 0.05, Avg Reward: -161.060702453, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.0069675446\n",
      "[NOR] Episode: 13040, Length: 80, e: 0.05, Avg Reward: -182.250402661, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.1168365479\n",
      "[NOR] Episode: 13050, Length: 82, e: 0.05, Avg Reward: -169.667919051, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.24172210693\n",
      "[NOR] Episode: 13060, Length: 84, e: 0.05, Avg Reward: -141.267861325, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 98.0497894287\n",
      "[NOR] Episode: 13070, Length: 56, e: 0.05, Avg Reward: -160.864902174, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.6186752319\n",
      "[NOR] Episode: 13080, Length: 70, e: 0.05, Avg Reward: -137.03848371, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.3400688171\n",
      "[NOR] Episode: 13090, Length: 87, e: 0.05, Avg Reward: -135.326047818, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.00268936157\n",
      "[NOR] Episode: 13100, Length: 95, e: 0.05, Avg Reward: -122.37635008, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.9453315735\n",
      "[NOR] Episode: 13110, Length: 112, e: 0.05, Avg Reward: -188.653807612, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.862953186\n",
      "[NOR] Episode: 13120, Length: 56, e: 0.05, Avg Reward: -144.510894087, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.96330928802\n",
      "[NOR] Episode: 13130, Length: 121, e: 0.05, Avg Reward: -167.419492347, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.0499401093\n",
      "[NOR] Episode: 13140, Length: 470, e: 0.05, Avg Reward: -121.954320483, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.3825817108\n",
      "[NOR] Episode: 13150, Length: 131, e: 0.05, Avg Reward: -190.304809472, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.952878952\n",
      "[NOR] Episode: 13160, Length: 91, e: 0.05, Avg Reward: -213.371641664, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 68.0341033936\n",
      "[NOR] Episode: 13170, Length: 107, e: 0.05, Avg Reward: -169.686587291, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.7671661377\n",
      "[NOR] Episode: 13180, Length: 91, e: 0.05, Avg Reward: -212.61799624, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.1463623047\n",
      "[NOR] Episode: 13190, Length: 55, e: 0.05, Avg Reward: -184.29221317, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.5238342285\n",
      "[NOR] Episode: 13200, Length: 71, e: 0.05, Avg Reward: -179.82927362, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.9390830994\n",
      "[NOR] Episode: 13210, Length: 93, e: 0.05, Avg Reward: -124.922010882, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -38.0780715942\n",
      "[NOR] Episode: 13220, Length: 204, e: 0.05, Avg Reward: -173.008191694, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.57669830322\n",
      "[NOR] Episode: 13230, Length: 69, e: 0.05, Avg Reward: -109.514201088, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.427570343\n",
      "[NOR] Episode: 13240, Length: 106, e: 0.05, Avg Reward: -158.037826224, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 88.1050872803\n",
      "[NOR] Episode: 13250, Length: 58, e: 0.05, Avg Reward: -176.351635381, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.69195365906\n",
      "[NOR] Episode: 13260, Length: 215, e: 0.05, Avg Reward: -125.419568895, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -93.1560440063\n",
      "[NOR] Episode: 13270, Length: 72, e: 0.05, Avg Reward: -188.068542621, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.0037269592\n",
      "[NOR] Episode: 13280, Length: 168, e: 0.05, Avg Reward: -217.788096773, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.0549945831\n",
      "[NOR] Episode: 13290, Length: 102, e: 0.05, Avg Reward: -204.255650516, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 39.8690757751\n",
      "[NOR] Episode: 13300, Length: 169, e: 0.05, Avg Reward: -255.281882412, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -50.0727729797\n",
      "[NOR] Episode: 13310, Length: 294, e: 0.05, Avg Reward: -149.773085532, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.9026622772\n",
      "[NOR] Episode: 13320, Length: 58, e: 0.05, Avg Reward: -139.79699778, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.7755670547\n",
      "[NOR] Episode: 13330, Length: 96, e: 0.05, Avg Reward: -207.810576642, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.28160095215\n",
      "[NOR] Episode: 13340, Length: 91, e: 0.05, Avg Reward: -204.858845193, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.8263092041\n",
      "[NOR] Episode: 13350, Length: 133, e: 0.05, Avg Reward: -208.914415845, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.89740943909\n",
      "[NOR] Episode: 13360, Length: 89, e: 0.05, Avg Reward: -115.140435942, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.3346366882\n",
      "[NOR] Episode: 13370, Length: 91, e: 0.05, Avg Reward: -211.920724117, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 45.7167282104\n",
      "[NOR] Episode: 13380, Length: 83, e: 0.05, Avg Reward: -207.028773655, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.54567337036\n",
      "[NOR] Episode: 13390, Length: 85, e: 0.05, Avg Reward: -200.777148919, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.9778347015\n",
      "[NOR] Episode: 13400, Length: 90, e: 0.05, Avg Reward: -172.47297893, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.7951622009\n",
      "[NOR] Episode: 13410, Length: 242, e: 0.05, Avg Reward: -164.212621807, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.0340900421\n",
      "[NOR] Episode: 13420, Length: 61, e: 0.05, Avg Reward: -210.026968961, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.0035057068\n",
      "[NOR] Episode: 13430, Length: 144, e: 0.05, Avg Reward: -209.340861026, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.9127616882\n",
      "[NOR] Episode: 13440, Length: 93, e: 0.05, Avg Reward: -202.51052515, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.16742420197\n",
      "[NOR] Episode: 13450, Length: 80, e: 0.05, Avg Reward: -210.468843463, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.2046461105\n",
      "[NOR] Episode: 13460, Length: 95, e: 0.05, Avg Reward: -199.411663167, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -63.6091766357\n",
      "[NOR] Episode: 13470, Length: 54, e: 0.05, Avg Reward: -184.765930124, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.9503822327\n",
      "[NOR] Episode: 13480, Length: 90, e: 0.05, Avg Reward: -139.948388568, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.5935287476\n",
      "[NOR] Episode: 13490, Length: 52, e: 0.05, Avg Reward: -205.518126825, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.6310329437\n",
      "[NOR] Episode: 13500, Length: 90, e: 0.05, Avg Reward: -209.094421921, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.5951766968\n",
      "[NOR] Episode: 13510, Length: 61, e: 0.05, Avg Reward: -130.999416669, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.158416748\n",
      "[NOR] Episode: 13520, Length: 64, e: 0.05, Avg Reward: -127.957855552, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.375134468079\n",
      "[NOR] Episode: 13530, Length: 81, e: 0.05, Avg Reward: -200.58163579, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.25191688538\n",
      "[NOR] Episode: 13540, Length: 121, e: 0.05, Avg Reward: -170.646797881, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 109.536834717\n",
      "[NOR] Episode: 13550, Length: 218, e: 0.05, Avg Reward: -171.656953981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.9665765762\n",
      "[NOR] Episode: 13560, Length: 58, e: 0.05, Avg Reward: -233.048518804, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.8545913696\n",
      "[NOR] Episode: 13570, Length: 139, e: 0.05, Avg Reward: -173.98947863, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.6069755554\n",
      "[NOR] Episode: 13580, Length: 111, e: 0.05, Avg Reward: -187.16844047, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.50693798065\n",
      "[NOR] Episode: 13590, Length: 66, e: 0.05, Avg Reward: -164.01135397, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.6404752731\n",
      "[NOR] Episode: 13600, Length: 85, e: 0.05, Avg Reward: -211.380296137, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -46.9085121155\n",
      "[NOR] Episode: 13610, Length: 79, e: 0.05, Avg Reward: -189.475542033, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.445854187\n",
      "[NOR] Episode: 13620, Length: 62, e: 0.05, Avg Reward: -171.372682204, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.8800830841\n",
      "[NOR] Episode: 13630, Length: 86, e: 0.05, Avg Reward: -163.720812885, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.9832515717\n",
      "[NOR] Episode: 13640, Length: 72, e: 0.05, Avg Reward: -242.290624487, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.0631523132\n",
      "[NOR] Episode: 13650, Length: 305, e: 0.05, Avg Reward: -150.870555115, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.72830224037\n",
      "[NOR] Episode: 13660, Length: 371, e: 0.05, Avg Reward: -204.175186417, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.58754754066\n",
      "[NOR] Episode: 13670, Length: 174, e: 0.05, Avg Reward: -214.636362551, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.554151535\n",
      "[NOR] Episode: 13680, Length: 86, e: 0.05, Avg Reward: -157.701080241, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.33426117897\n",
      "[NOR] Episode: 13690, Length: 92, e: 0.05, Avg Reward: -223.445473664, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 98.3339309692\n",
      "[NOR] Episode: 13700, Length: 61, e: 0.05, Avg Reward: -176.094843699, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -253.033355713\n",
      "[NOR] Episode: 13710, Length: 90, e: 0.05, Avg Reward: -223.199687077, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -321.383270264\n",
      "[NOR] Episode: 13720, Length: 77, e: 0.05, Avg Reward: -149.049059942, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.2647209167\n",
      "[NOR] Episode: 13730, Length: 250, e: 0.05, Avg Reward: -234.171193867, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.4059019089\n",
      "[NOR] Episode: 13740, Length: 84, e: 0.05, Avg Reward: -221.083300043, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -93.5992889404\n",
      "[NOR] Episode: 13750, Length: 89, e: 0.05, Avg Reward: -155.466762419, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.03798675537\n",
      "[NOR] Episode: 13760, Length: 73, e: 0.05, Avg Reward: -183.707086814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.3045196533\n",
      "[NOR] Episode: 13770, Length: 110, e: 0.05, Avg Reward: -266.960569218, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.9699516296\n",
      "[NOR] Episode: 13780, Length: 82, e: 0.05, Avg Reward: -316.182221253, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.3133773804\n",
      "[NOR] Episode: 13790, Length: 96, e: 0.05, Avg Reward: -259.072634269, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.0569019318\n",
      "[NOR] Episode: 13800, Length: 124, e: 0.05, Avg Reward: -259.084948359, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.8918418884\n",
      "[NOR] Episode: 13810, Length: 83, e: 0.05, Avg Reward: -217.415280781, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.734790802\n",
      "[NOR] Episode: 13820, Length: 61, e: 0.05, Avg Reward: -219.19119958, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.7597064972\n",
      "[NOR] Episode: 13830, Length: 158, e: 0.05, Avg Reward: -220.446975715, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.0621643066\n",
      "[NOR] Episode: 13840, Length: 72, e: 0.05, Avg Reward: -219.54679222, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.26117753983\n",
      "[NOR] Episode: 13850, Length: 74, e: 0.05, Avg Reward: -192.920124692, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.0667572021\n",
      "[NOR] Episode: 13860, Length: 270, e: 0.05, Avg Reward: -230.387317952, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.09405136108\n",
      "[NOR] Episode: 13870, Length: 101, e: 0.05, Avg Reward: -223.922263417, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -81.031211853\n",
      "[NOR] Episode: 13880, Length: 95, e: 0.05, Avg Reward: -223.274245806, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.86477375031\n",
      "[NOR] Episode: 13890, Length: 103, e: 0.05, Avg Reward: -175.61425055, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.81788897514\n",
      "[NOR] Episode: 13900, Length: 251, e: 0.05, Avg Reward: -144.763729651, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.4497184753\n",
      "[NOR] Episode: 13910, Length: 80, e: 0.05, Avg Reward: -203.063177522, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.7969875336\n",
      "[NOR] Episode: 13920, Length: 107, e: 0.05, Avg Reward: -257.455909828, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.5005702972\n",
      "[NOR] Episode: 13930, Length: 64, e: 0.05, Avg Reward: -219.376644955, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -59.0245323181\n",
      "[NOR] Episode: 13940, Length: 92, e: 0.05, Avg Reward: -96.3177960445, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.4429988861\n",
      "[NOR] Episode: 13950, Length: 109, e: 0.05, Avg Reward: -205.13500231, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.1569194794\n",
      "[NOR] Episode: 13960, Length: 93, e: 0.05, Avg Reward: -211.148342503, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -108.164848328\n",
      "[NOR] Episode: 13970, Length: 111, e: 0.05, Avg Reward: -181.414813456, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.2525444031\n",
      "[NOR] Episode: 13980, Length: 78, e: 0.05, Avg Reward: -238.874290202, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -175.605895996\n",
      "[NOR] Episode: 13990, Length: 119, e: 0.05, Avg Reward: -251.510168563, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.9258842468\n",
      "[NOR] Episode: 14000, Length: 140, e: 0.05, Avg Reward: -183.559158353, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.454165697098\n",
      "[NOR] Episode: 14010, Length: 60, e: 0.05, Avg Reward: -213.620492786, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.44548416138\n",
      "[NOR] Episode: 14020, Length: 149, e: 0.05, Avg Reward: -192.785783897, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.44667434692\n",
      "[NOR] Episode: 14030, Length: 59, e: 0.05, Avg Reward: -197.743416256, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.84513092041\n",
      "[NOR] Episode: 14040, Length: 72, e: 0.05, Avg Reward: -212.782892471, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.52206468582\n",
      "[NOR] Episode: 14050, Length: 51, e: 0.05, Avg Reward: -214.487747308, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.66817379\n",
      "[NOR] Episode: 14060, Length: 123, e: 0.05, Avg Reward: -189.37845444, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 67.4941253662\n",
      "[NOR] Episode: 14070, Length: 54, e: 0.05, Avg Reward: -146.253817733, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 138.601165771\n",
      "[NOR] Episode: 14080, Length: 75, e: 0.05, Avg Reward: -181.006270204, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.188317298889\n",
      "[NOR] Episode: 14090, Length: 71, e: 0.05, Avg Reward: -132.624788837, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.5633335114\n",
      "[NOR] Episode: 14100, Length: 60, e: 0.05, Avg Reward: -166.916819433, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.3298158646\n",
      "[NOR] Episode: 14110, Length: 98, e: 0.05, Avg Reward: -182.423365692, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -59.6934280396\n",
      "[NOR] Episode: 14120, Length: 97, e: 0.05, Avg Reward: -194.726314436, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.57235145569\n",
      "[NOR] Episode: 14130, Length: 63, e: 0.05, Avg Reward: -155.024414812, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.4390296936\n",
      "[NOR] Episode: 14140, Length: 75, e: 0.05, Avg Reward: -207.336881093, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.0676136017\n",
      "[NOR] Episode: 14150, Length: 59, e: 0.05, Avg Reward: -205.850870602, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.860118866\n",
      "[NOR] Episode: 14160, Length: 66, e: 0.05, Avg Reward: -156.022032411, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.31575298309\n",
      "[NOR] Episode: 14170, Length: 69, e: 0.05, Avg Reward: -156.332318881, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.8551568985\n",
      "[NOR] Episode: 14180, Length: 198, e: 0.05, Avg Reward: -177.672803884, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.7458114624\n",
      "[NOR] Episode: 14190, Length: 71, e: 0.05, Avg Reward: -140.835720296, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.3961639404\n",
      "[NOR] Episode: 14200, Length: 99, e: 0.05, Avg Reward: -238.223830759, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.7254276276\n",
      "[NOR] Episode: 14210, Length: 85, e: 0.05, Avg Reward: -214.787500442, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 64.7557067871\n",
      "[NOR] Episode: 14220, Length: 344, e: 0.05, Avg Reward: -215.105501915, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 53.4630622864\n",
      "[NOR] Episode: 14230, Length: 75, e: 0.05, Avg Reward: -208.522606223, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.4565973282\n",
      "[NOR] Episode: 14240, Length: 92, e: 0.05, Avg Reward: -170.990583021, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.0937347412\n",
      "[NOR] Episode: 14250, Length: 85, e: 0.05, Avg Reward: -191.611343343, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 52.2495727539\n",
      "[NOR] Episode: 14260, Length: 95, e: 0.05, Avg Reward: -155.496964258, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.6572761536\n",
      "[NOR] Episode: 14270, Length: 115, e: 0.05, Avg Reward: -153.850973409, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 52.7842636108\n",
      "[NOR] Episode: 14280, Length: 153, e: 0.05, Avg Reward: -209.331371651, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.96025562286\n",
      "[NOR] Episode: 14290, Length: 135, e: 0.05, Avg Reward: -213.093922613, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.0015296936\n",
      "[NOR] Episode: 14300, Length: 48, e: 0.05, Avg Reward: -179.152387181, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.5291442871\n",
      "[NOR] Episode: 14310, Length: 79, e: 0.05, Avg Reward: -224.720074579, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.7023906708\n",
      "[NOR] Episode: 14320, Length: 64, e: 0.05, Avg Reward: -177.48355142, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -63.5280380249\n",
      "[NOR] Episode: 14330, Length: 186, e: 0.05, Avg Reward: -210.261275014, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.5534267426\n",
      "[NOR] Episode: 14340, Length: 61, e: 0.05, Avg Reward: -196.605263354, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.9840641022\n",
      "[NOR] Episode: 14350, Length: 78, e: 0.05, Avg Reward: -168.647309348, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.4685821533\n",
      "[NOR] Episode: 14360, Length: 102, e: 0.05, Avg Reward: -169.289129398, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 157.0652771\n",
      "[NOR] Episode: 14370, Length: 91, e: 0.05, Avg Reward: -193.458302287, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.28659629822\n",
      "[NOR] Episode: 14380, Length: 158, e: 0.05, Avg Reward: -227.101719191, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.9660978317\n",
      "[NOR] Episode: 14390, Length: 69, e: 0.05, Avg Reward: -165.194574582, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 47.8132743835\n",
      "[NOR] Episode: 14400, Length: 106, e: 0.05, Avg Reward: -255.770553587, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.0784797668\n",
      "[NOR] Episode: 14410, Length: 213, e: 0.05, Avg Reward: -182.95781303, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -173.496170044\n",
      "[NOR] Episode: 14420, Length: 138, e: 0.05, Avg Reward: -220.769199999, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.9891109467\n",
      "[NOR] Episode: 14430, Length: 124, e: 0.05, Avg Reward: -232.230800632, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.136882782\n",
      "[NOR] Episode: 14440, Length: 91, e: 0.05, Avg Reward: -178.062861341, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 34.4681854248\n",
      "[NOR] Episode: 14450, Length: 59, e: 0.05, Avg Reward: -230.266325285, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -40.0977554321\n",
      "[NOR] Episode: 14460, Length: 129, e: 0.05, Avg Reward: -172.691532853, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.118979454\n",
      "[NOR] Episode: 14470, Length: 89, e: 0.05, Avg Reward: -218.60072196, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.9375915527\n",
      "[NOR] Episode: 14480, Length: 82, e: 0.05, Avg Reward: -186.095868058, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.4353408813\n",
      "[NOR] Episode: 14490, Length: 104, e: 0.05, Avg Reward: -163.538279828, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.6701660156\n",
      "[NOR] Episode: 14500, Length: 152, e: 0.05, Avg Reward: -114.312089945, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.2251167297\n",
      "[NOR] Episode: 14510, Length: 495, e: 0.05, Avg Reward: -212.232374312, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 108.836868286\n",
      "[NOR] Episode: 14520, Length: 90, e: 0.05, Avg Reward: -181.058146761, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.8694915771\n",
      "[NOR] Episode: 14530, Length: 93, e: 0.05, Avg Reward: -172.782847574, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.37976264954\n",
      "[NOR] Episode: 14540, Length: 81, e: 0.05, Avg Reward: -281.072183574, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.7222976685\n",
      "[NOR] Episode: 14550, Length: 84, e: 0.05, Avg Reward: -189.988320908, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.7868595123\n",
      "[NOR] Episode: 14560, Length: 88, e: 0.05, Avg Reward: -193.872540351, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.4710006714\n",
      "[NOR] Episode: 14570, Length: 72, e: 0.05, Avg Reward: -190.974313154, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.6267662048\n",
      "[NOR] Episode: 14580, Length: 164, e: 0.05, Avg Reward: -171.037373749, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.676410675\n",
      "[NOR] Episode: 14590, Length: 72, e: 0.05, Avg Reward: -148.297076953, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.4451084137\n",
      "[NOR] Episode: 14600, Length: 309, e: 0.05, Avg Reward: -167.413355086, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -173.197235107\n",
      "[NOR] Episode: 14610, Length: 105, e: 0.05, Avg Reward: -125.489096884, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.3865509033\n",
      "[NOR] Episode: 14620, Length: 87, e: 0.05, Avg Reward: -152.566021238, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 68.5111999512\n",
      "[NOR] Episode: 14630, Length: 58, e: 0.05, Avg Reward: -184.712330978, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.7896766663\n",
      "[NOR] Episode: 14640, Length: 63, e: 0.05, Avg Reward: -186.724159648, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -54.3569946289\n",
      "[NOR] Episode: 14650, Length: 107, e: 0.05, Avg Reward: -176.181753465, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.4359836578\n",
      "[NOR] Episode: 14660, Length: 57, e: 0.05, Avg Reward: -145.43628659, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -57.9012641907\n",
      "[NOR] Episode: 14670, Length: 172, e: 0.05, Avg Reward: -176.668989039, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.32732772827\n",
      "[NOR] Episode: 14680, Length: 74, e: 0.05, Avg Reward: -147.613244705, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.33020401\n",
      "[NOR] Episode: 14690, Length: 66, e: 0.05, Avg Reward: -123.36085676, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.18987464905\n",
      "[NOR] Episode: 14700, Length: 78, e: 0.05, Avg Reward: -217.281452381, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.8259859085\n",
      "[NOR] Episode: 14710, Length: 100, e: 0.05, Avg Reward: -228.481415533, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.41266059875\n",
      "[NOR] Episode: 14720, Length: 133, e: 0.05, Avg Reward: -153.453837325, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.3646278381\n",
      "[NOR] Episode: 14730, Length: 190, e: 0.05, Avg Reward: -208.745769066, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.428943634\n",
      "[NOR] Episode: 14740, Length: 86, e: 0.05, Avg Reward: -213.584846984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 141.957092285\n",
      "[NOR] Episode: 14750, Length: 58, e: 0.05, Avg Reward: -285.407502533, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.997297287\n",
      "[NOR] Episode: 14760, Length: 101, e: 0.05, Avg Reward: -191.260505206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.0291805267\n",
      "[NOR] Episode: 14770, Length: 90, e: 0.05, Avg Reward: -266.234206797, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.9029693604\n",
      "[NOR] Episode: 14780, Length: 65, e: 0.05, Avg Reward: -191.3903347, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 27.993970871\n",
      "[NOR] Episode: 14790, Length: 90, e: 0.05, Avg Reward: -222.105515725, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.84229469299\n",
      "[NOR] Episode: 14800, Length: 91, e: 0.05, Avg Reward: -321.009721076, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.4277610779\n",
      "[NOR] Episode: 14810, Length: 130, e: 0.05, Avg Reward: -327.272651403, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.88016653061\n",
      "[NOR] Episode: 14820, Length: 315, e: 0.05, Avg Reward: -233.680950023, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.47074317932\n",
      "[NOR] Episode: 14830, Length: 97, e: 0.05, Avg Reward: -230.870191605, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.700920105\n",
      "[NOR] Episode: 14840, Length: 100, e: 0.05, Avg Reward: -202.34140697, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.2591209412\n",
      "[NOR] Episode: 14850, Length: 51, e: 0.05, Avg Reward: -203.009286664, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -98.2358169556\n",
      "[NOR] Episode: 14860, Length: 135, e: 0.05, Avg Reward: -201.978181848, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.7999000549\n",
      "[NOR] Episode: 14870, Length: 82, e: 0.05, Avg Reward: -209.166573297, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.9559307098\n",
      "[NOR] Episode: 14880, Length: 144, e: 0.05, Avg Reward: -224.594212913, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.0709466934\n",
      "[NOR] Episode: 14890, Length: 91, e: 0.05, Avg Reward: -319.264196735, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.8798484802\n",
      "[NOR] Episode: 14900, Length: 90, e: 0.05, Avg Reward: -289.313361124, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.15840339661\n",
      "[NOR] Episode: 14910, Length: 83, e: 0.05, Avg Reward: -299.879212157, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.32876157761\n",
      "[NOR] Episode: 14920, Length: 59, e: 0.05, Avg Reward: -274.440375268, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.1231193542\n",
      "[NOR] Episode: 14930, Length: 65, e: 0.05, Avg Reward: -253.302519413, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 39.0952758789\n",
      "[NOR] Episode: 14940, Length: 10001, e: 0.05, Avg Reward: -266.146471178, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.0159950256\n",
      "[NOR] Episode: 14950, Length: 267, e: 0.05, Avg Reward: -212.581583194, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.60557556152\n",
      "[NOR] Episode: 14960, Length: 92, e: 0.05, Avg Reward: -279.160237267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.1052646637\n",
      "[NOR] Episode: 14970, Length: 72, e: 0.05, Avg Reward: -285.811113438, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.7091350555\n",
      "[NOR] Episode: 14980, Length: 183, e: 0.05, Avg Reward: -225.233588015, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.123125076294\n",
      "[NOR] Episode: 14990, Length: 90, e: 0.05, Avg Reward: -231.538604331, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.67961120605\n",
      "[NOR] Episode: 15000, Length: 79, e: 0.05, Avg Reward: -341.721444635, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.99267292023\n",
      "[NOR] Episode: 15010, Length: 234, e: 0.05, Avg Reward: -285.232471072, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.4916810989\n",
      "[NOR] Episode: 15020, Length: 98, e: 0.05, Avg Reward: -273.870743011, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.8157491684\n",
      "[NOR] Episode: 15030, Length: 103, e: 0.05, Avg Reward: -349.538217669, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 47.4295120239\n",
      "[NOR] Episode: 15040, Length: 194, e: 0.05, Avg Reward: -273.825086199, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.10383653641\n",
      "[NOR] Episode: 15050, Length: 208, e: 0.05, Avg Reward: -268.401447222, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 35.9777030945\n",
      "[NOR] Episode: 15060, Length: 307, e: 0.05, Avg Reward: -340.329765462, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.28917217255\n",
      "[NOR] Episode: 15070, Length: 219, e: 0.05, Avg Reward: -325.201482449, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.659342765808\n",
      "[NOR] Episode: 15080, Length: 175, e: 0.05, Avg Reward: -318.941661982, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.95554828644\n",
      "[NOR] Episode: 15090, Length: 63, e: 0.05, Avg Reward: -323.837130839, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.83478164673\n",
      "[NOR] Episode: 15100, Length: 162, e: 0.05, Avg Reward: -419.60486219, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.18936920166\n",
      "[NOR] Episode: 15110, Length: 301, e: 0.05, Avg Reward: -349.088658552, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.5288658142\n",
      "[NOR] Episode: 15120, Length: 97, e: 0.05, Avg Reward: -329.890863142, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -89.78881073\n",
      "[NOR] Episode: 15130, Length: 139, e: 0.05, Avg Reward: -387.752482975, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 44.800163269\n",
      "[NOR] Episode: 15140, Length: 113, e: 0.05, Avg Reward: -307.599560879, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.100479126\n",
      "[NOR] Episode: 15150, Length: 63, e: 0.05, Avg Reward: -423.712589705, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.2652664185\n",
      "[NOR] Episode: 15160, Length: 94, e: 0.05, Avg Reward: -408.499780664, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.5594577789\n",
      "[NOR] Episode: 15170, Length: 70, e: 0.05, Avg Reward: -453.734095938, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.54817247391\n",
      "[NOR] Episode: 15180, Length: 211, e: 0.05, Avg Reward: -364.961193432, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.6836738586\n",
      "[NOR] Episode: 15190, Length: 95, e: 0.05, Avg Reward: -334.847407039, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.95508265495\n",
      "[NOR] Episode: 15200, Length: 60, e: 0.05, Avg Reward: -431.270800814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.1619300842\n",
      "[NOR] Episode: 15210, Length: 77, e: 0.05, Avg Reward: -336.807073434, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.84078407288\n",
      "[NOR] Episode: 15220, Length: 62, e: 0.05, Avg Reward: -458.727786077, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.91150283813\n",
      "[NOR] Episode: 15230, Length: 64, e: 0.05, Avg Reward: -359.748513325, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.6551704407\n",
      "[NOR] Episode: 15240, Length: 61, e: 0.05, Avg Reward: -411.766968067, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.77636814117\n",
      "[NOR] Episode: 15250, Length: 233, e: 0.05, Avg Reward: -426.934018049, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.1641368866\n",
      "[NOR] Episode: 15260, Length: 85, e: 0.05, Avg Reward: -473.476260097, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.2379961014\n",
      "[NOR] Episode: 15270, Length: 244, e: 0.05, Avg Reward: -422.664234642, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.1490821838\n",
      "[NOR] Episode: 15280, Length: 79, e: 0.05, Avg Reward: -425.238959252, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.7253723145\n",
      "[NOR] Episode: 15290, Length: 54, e: 0.05, Avg Reward: -395.273632953, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.7186107635\n",
      "[NOR] Episode: 15300, Length: 324, e: 0.05, Avg Reward: -473.921083175, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.1446208954\n",
      "[NOR] Episode: 15310, Length: 69, e: 0.05, Avg Reward: -500.999571878, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -50.7638626099\n",
      "[NOR] Episode: 15320, Length: 100, e: 0.05, Avg Reward: -530.077981975, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.30600070953\n",
      "[NOR] Episode: 15330, Length: 111, e: 0.05, Avg Reward: -476.037428281, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.8821258545\n",
      "[NOR] Episode: 15340, Length: 169, e: 0.05, Avg Reward: -617.241103217, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.32653188705\n",
      "[NOR] Episode: 15350, Length: 56, e: 0.05, Avg Reward: -402.676900734, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.6938686371\n",
      "[NOR] Episode: 15360, Length: 148, e: 0.05, Avg Reward: -490.045703381, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.7381629944\n",
      "[NOR] Episode: 15370, Length: 59, e: 0.05, Avg Reward: -449.26078448, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.9812583923\n",
      "[NOR] Episode: 15380, Length: 93, e: 0.05, Avg Reward: -452.348327316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 85.5880889893\n",
      "[NOR] Episode: 15390, Length: 55, e: 0.05, Avg Reward: -342.665163912, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -93.6600036621\n",
      "[NOR] Episode: 15400, Length: 86, e: 0.05, Avg Reward: -438.414500458, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.33419084549\n",
      "[NOR] Episode: 15410, Length: 289, e: 0.05, Avg Reward: -469.049271356, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.985706329346\n",
      "[NOR] Episode: 15420, Length: 89, e: 0.05, Avg Reward: -390.403477639, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.58985614777\n",
      "[NOR] Episode: 15430, Length: 79, e: 0.05, Avg Reward: -412.864327068, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.693712234497\n",
      "[NOR] Episode: 15440, Length: 111, e: 0.05, Avg Reward: -389.272395015, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.4063835144\n",
      "[NOR] Episode: 15450, Length: 109, e: 0.05, Avg Reward: -448.472061505, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 75.8315811157\n",
      "[NOR] Episode: 15460, Length: 311, e: 0.05, Avg Reward: -301.676356355, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.157743454\n",
      "[NOR] Episode: 15470, Length: 99, e: 0.05, Avg Reward: -354.763678335, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.9521770477\n",
      "[NOR] Episode: 15480, Length: 58, e: 0.05, Avg Reward: -384.305137641, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.3141727448\n",
      "[NOR] Episode: 15490, Length: 208, e: 0.05, Avg Reward: -322.49660957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.42490816116\n",
      "[NOR] Episode: 15500, Length: 72, e: 0.05, Avg Reward: -449.818476081, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -48.3518295288\n",
      "[NOR] Episode: 15510, Length: 91, e: 0.05, Avg Reward: -332.240916281, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.04830884933\n",
      "[NOR] Episode: 15520, Length: 77, e: 0.05, Avg Reward: -420.941486186, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.63206863403\n",
      "[NOR] Episode: 15530, Length: 107, e: 0.05, Avg Reward: -472.546632248, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.13898658752\n",
      "[NOR] Episode: 15540, Length: 74, e: 0.05, Avg Reward: -453.368666368, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.90893745422\n",
      "[NOR] Episode: 15550, Length: 78, e: 0.05, Avg Reward: -346.123707483, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.8567590714\n",
      "[NOR] Episode: 15560, Length: 68, e: 0.05, Avg Reward: -416.408048137, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -44.2781181335\n",
      "[NOR] Episode: 15570, Length: 77, e: 0.05, Avg Reward: -387.995934396, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.7207727432\n",
      "[NOR] Episode: 15580, Length: 147, e: 0.05, Avg Reward: -300.858069463, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.51900196075\n",
      "[NOR] Episode: 15590, Length: 168, e: 0.05, Avg Reward: -305.859842977, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.9255981445\n",
      "[NOR] Episode: 15600, Length: 75, e: 0.05, Avg Reward: -329.128875533, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.6834144592\n",
      "[NOR] Episode: 15610, Length: 100, e: 0.05, Avg Reward: -283.619306619, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.7236690521\n",
      "[NOR] Episode: 15620, Length: 90, e: 0.05, Avg Reward: -227.394310229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.4433860779\n",
      "[NOR] Episode: 15630, Length: 160, e: 0.05, Avg Reward: -413.897463786, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.66137933731\n",
      "[NOR] Episode: 15640, Length: 98, e: 0.05, Avg Reward: -318.274464654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 85.5406265259\n",
      "[NOR] Episode: 15650, Length: 69, e: 0.05, Avg Reward: -328.42871207, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.14427852631\n",
      "[NOR] Episode: 15660, Length: 62, e: 0.05, Avg Reward: -399.570577703, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.62063312531\n",
      "[NOR] Episode: 15670, Length: 97, e: 0.05, Avg Reward: -283.448098439, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.34221076965\n",
      "[NOR] Episode: 15680, Length: 82, e: 0.05, Avg Reward: -376.319572073, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.85091400146\n",
      "[NOR] Episode: 15690, Length: 74, e: 0.05, Avg Reward: -402.846908226, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -121.526824951\n",
      "[NOR] Episode: 15700, Length: 102, e: 0.05, Avg Reward: -387.903916359, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.9125976562\n",
      "[NOR] Episode: 15710, Length: 89, e: 0.05, Avg Reward: -369.896448973, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.5303344727\n",
      "[NOR] Episode: 15720, Length: 117, e: 0.05, Avg Reward: -318.514363187, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.2527923584\n",
      "[NOR] Episode: 15730, Length: 91, e: 0.05, Avg Reward: -331.41541165, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.033121109\n",
      "[NOR] Episode: 15740, Length: 91, e: 0.05, Avg Reward: -337.620308864, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 59.4566230774\n",
      "[NOR] Episode: 15750, Length: 102, e: 0.05, Avg Reward: -218.838621278, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.3531255722\n",
      "[NOR] Episode: 15760, Length: 100, e: 0.05, Avg Reward: -220.362514229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.1223945618\n",
      "[NOR] Episode: 15770, Length: 102, e: 0.05, Avg Reward: -285.979987706, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.02473163605\n",
      "[NOR] Episode: 15780, Length: 93, e: 0.05, Avg Reward: -242.213096307, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.4486160278\n",
      "[NOR] Episode: 15790, Length: 82, e: 0.05, Avg Reward: -289.225624124, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.3052215576\n",
      "[NOR] Episode: 15800, Length: 183, e: 0.05, Avg Reward: -213.362823323, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.37669181824\n",
      "[NOR] Episode: 15810, Length: 96, e: 0.05, Avg Reward: -257.249507782, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.3508815765\n",
      "[NOR] Episode: 15820, Length: 102, e: 0.05, Avg Reward: -242.905997131, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.0106391907\n",
      "[NOR] Episode: 15830, Length: 68, e: 0.05, Avg Reward: -284.73464077, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.89256095886\n",
      "[NOR] Episode: 15840, Length: 102, e: 0.05, Avg Reward: -259.061561984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -57.5369491577\n",
      "[NOR] Episode: 15850, Length: 115, e: 0.05, Avg Reward: -122.449337883, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.5064506531\n",
      "[NOR] Episode: 15860, Length: 75, e: 0.05, Avg Reward: -132.333799001, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.5289726257\n",
      "[NOR] Episode: 15870, Length: 77, e: 0.05, Avg Reward: -268.207421675, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 67.3265304565\n",
      "[NOR] Episode: 15880, Length: 70, e: 0.05, Avg Reward: -268.122290495, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -189.814300537\n",
      "[NOR] Episode: 15890, Length: 80, e: 0.05, Avg Reward: -99.3716166016, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.9374217987\n",
      "[NOR] Episode: 15900, Length: 71, e: 0.05, Avg Reward: -117.683731594, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.61283731461\n",
      "[NOR] Episode: 15910, Length: 71, e: 0.05, Avg Reward: -158.44899381, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.14044952393\n",
      "[NOR] Episode: 15920, Length: 95, e: 0.05, Avg Reward: -84.3034822423, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 47.6539993286\n",
      "[NOR] Episode: 15930, Length: 85, e: 0.05, Avg Reward: -257.154350252, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.87788105011\n",
      "[NOR] Episode: 15940, Length: 60, e: 0.05, Avg Reward: -127.805485755, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.46018218994\n",
      "[NOR] Episode: 15950, Length: 83, e: 0.05, Avg Reward: -90.9930302643, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.2704086304\n",
      "[NOR] Episode: 15960, Length: 89, e: 0.05, Avg Reward: -145.800985063, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.6520423889\n",
      "[NOR] Episode: 15970, Length: 64, e: 0.05, Avg Reward: -154.296055107, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.7065200806\n",
      "[NOR] Episode: 15980, Length: 79, e: 0.05, Avg Reward: -137.090597273, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.7891464233\n",
      "[NOR] Episode: 15990, Length: 63, e: 0.05, Avg Reward: -120.576755668, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.5094871521\n",
      "[NOR] Episode: 16000, Length: 58, e: 0.05, Avg Reward: -170.479552276, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.4414329529\n",
      "[NOR] Episode: 16010, Length: 59, e: 0.05, Avg Reward: -135.05612209, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.9162521362\n",
      "[NOR] Episode: 16020, Length: 65, e: 0.05, Avg Reward: -102.023169678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.5655956268\n",
      "[NOR] Episode: 16030, Length: 90, e: 0.05, Avg Reward: -141.85183893, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.3804359436\n",
      "[NOR] Episode: 16040, Length: 76, e: 0.05, Avg Reward: -143.51817659, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.42802906036\n",
      "[NOR] Episode: 16050, Length: 90, e: 0.05, Avg Reward: -145.719042291, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.8823308945\n",
      "[NOR] Episode: 16060, Length: 75, e: 0.05, Avg Reward: -146.582637913, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.7518787384\n",
      "[NOR] Episode: 16070, Length: 73, e: 0.05, Avg Reward: -100.796001283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.0089569092\n",
      "[NOR] Episode: 16080, Length: 64, e: 0.05, Avg Reward: -146.332184956, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.98649692535\n",
      "[NOR] Episode: 16090, Length: 62, e: 0.05, Avg Reward: -121.018419943, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.2145729065\n",
      "[NOR] Episode: 16100, Length: 61, e: 0.05, Avg Reward: -129.364555575, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.40457487106\n",
      "[NOR] Episode: 16110, Length: 84, e: 0.05, Avg Reward: -124.630374393, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -65.6200256348\n",
      "[NOR] Episode: 16120, Length: 67, e: 0.05, Avg Reward: -129.897802245, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.34273719788\n",
      "[NOR] Episode: 16130, Length: 97, e: 0.05, Avg Reward: -146.659303554, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.7175941467\n",
      "[NOR] Episode: 16140, Length: 62, e: 0.05, Avg Reward: -163.330255263, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.568956375122\n",
      "[NOR] Episode: 16150, Length: 59, e: 0.05, Avg Reward: -148.071394562, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.35183858871\n",
      "[NOR] Episode: 16160, Length: 88, e: 0.05, Avg Reward: -141.850936062, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.0557518005\n",
      "[NOR] Episode: 16170, Length: 67, e: 0.05, Avg Reward: -103.490738441, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.9976243973\n",
      "[NOR] Episode: 16180, Length: 89, e: 0.05, Avg Reward: -163.550437187, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.76223444939\n",
      "[NOR] Episode: 16190, Length: 73, e: 0.05, Avg Reward: -120.810902833, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.2776985168\n",
      "[NOR] Episode: 16200, Length: 86, e: 0.05, Avg Reward: -119.800652556, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.02819538116\n",
      "[NOR] Episode: 16210, Length: 81, e: 0.05, Avg Reward: -145.235518067, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.8941373825\n",
      "[NOR] Episode: 16220, Length: 85, e: 0.05, Avg Reward: -129.067661085, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.3462791443\n",
      "[NOR] Episode: 16230, Length: 61, e: 0.05, Avg Reward: -113.845380089, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.6475257874\n",
      "[NOR] Episode: 16240, Length: 76, e: 0.05, Avg Reward: -120.758699158, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.38643312454\n",
      "[NOR] Episode: 16250, Length: 58, e: 0.05, Avg Reward: -119.510115901, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.79099082947\n",
      "[NOR] Episode: 16260, Length: 87, e: 0.05, Avg Reward: -112.985692786, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.9131813049\n",
      "[NOR] Episode: 16270, Length: 84, e: 0.05, Avg Reward: -142.464405537, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.84139919281\n",
      "[NOR] Episode: 16280, Length: 64, e: 0.05, Avg Reward: -142.581198772, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -115.770233154\n",
      "[NOR] Episode: 16290, Length: 90, e: 0.05, Avg Reward: -137.625317167, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.708667755127\n",
      "[NOR] Episode: 16300, Length: 60, e: 0.05, Avg Reward: -154.312346798, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.53697967529\n",
      "[NOR] Episode: 16310, Length: 81, e: 0.05, Avg Reward: -127.804783308, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.18338298798\n",
      "[NOR] Episode: 16320, Length: 63, e: 0.05, Avg Reward: -114.273313751, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.4227390289\n",
      "[NOR] Episode: 16330, Length: 83, e: 0.05, Avg Reward: -137.276444072, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.5684337616\n",
      "[NOR] Episode: 16340, Length: 89, e: 0.05, Avg Reward: -183.726000202, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.2910242081\n",
      "[NOR] Episode: 16350, Length: 53, e: 0.05, Avg Reward: -163.893698343, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.57395887375\n",
      "[NOR] Episode: 16360, Length: 81, e: 0.05, Avg Reward: -195.659964422, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 54.5531005859\n",
      "[NOR] Episode: 16370, Length: 64, e: 0.05, Avg Reward: -212.036838099, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 74.2231216431\n",
      "[NOR] Episode: 16380, Length: 59, e: 0.05, Avg Reward: -201.493220739, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.0615386963\n",
      "[NOR] Episode: 16390, Length: 71, e: 0.05, Avg Reward: -191.506634185, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.74194908142\n",
      "[NOR] Episode: 16400, Length: 50, e: 0.05, Avg Reward: -174.238285606, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.8496074677\n",
      "[NOR] Episode: 16410, Length: 65, e: 0.05, Avg Reward: -134.621094299, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.6912126541\n",
      "[NOR] Episode: 16420, Length: 77, e: 0.05, Avg Reward: -184.520309624, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.6736087799\n",
      "[NOR] Episode: 16430, Length: 89, e: 0.05, Avg Reward: -176.249419076, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 43.6919746399\n",
      "[NOR] Episode: 16440, Length: 84, e: 0.05, Avg Reward: -156.121875789, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.8658599854\n",
      "[NOR] Episode: 16450, Length: 79, e: 0.05, Avg Reward: -219.891593556, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.25956583023\n",
      "[NOR] Episode: 16460, Length: 77, e: 0.05, Avg Reward: -142.399217675, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.2522201538\n",
      "[NOR] Episode: 16470, Length: 67, e: 0.05, Avg Reward: -152.181651176, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 48.2410507202\n",
      "[NOR] Episode: 16480, Length: 56, e: 0.05, Avg Reward: -131.211548498, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.64248085022\n",
      "[NOR] Episode: 16490, Length: 65, e: 0.05, Avg Reward: -149.860275565, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.22548484802\n",
      "[NOR] Episode: 16500, Length: 72, e: 0.05, Avg Reward: -133.921719537, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.99571657181\n",
      "[NOR] Episode: 16510, Length: 95, e: 0.05, Avg Reward: -164.894304322, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.2943305969\n",
      "[NOR] Episode: 16520, Length: 96, e: 0.05, Avg Reward: -205.531109401, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.16517591476\n",
      "[NOR] Episode: 16530, Length: 94, e: 0.05, Avg Reward: -177.56323379, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.772983551\n",
      "[NOR] Episode: 16540, Length: 66, e: 0.05, Avg Reward: -179.802222846, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.32455730438\n",
      "[NOR] Episode: 16550, Length: 97, e: 0.05, Avg Reward: -258.710226877, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.80098438263\n",
      "[NOR] Episode: 16560, Length: 84, e: 0.05, Avg Reward: -166.981107436, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -165.500473022\n",
      "[NOR] Episode: 16570, Length: 64, e: 0.05, Avg Reward: -187.87744563, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -44.4202041626\n",
      "[NOR] Episode: 16580, Length: 55, e: 0.05, Avg Reward: -200.87948057, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 59.0024223328\n",
      "[NOR] Episode: 16590, Length: 99, e: 0.05, Avg Reward: -120.702903228, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.6053161621\n",
      "[NOR] Episode: 16600, Length: 73, e: 0.05, Avg Reward: -209.477637562, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.80541992188\n",
      "[NOR] Episode: 16610, Length: 59, e: 0.05, Avg Reward: -129.676819557, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.150384903\n",
      "[NOR] Episode: 16620, Length: 75, e: 0.05, Avg Reward: -150.928452109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.12407207489\n",
      "[NOR] Episode: 16630, Length: 84, e: 0.05, Avg Reward: -180.895079364, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.6687908173\n",
      "[NOR] Episode: 16640, Length: 60, e: 0.05, Avg Reward: -172.052024079, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.427274704\n",
      "[NOR] Episode: 16650, Length: 83, e: 0.05, Avg Reward: -169.441805155, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -75.2978515625\n",
      "[NOR] Episode: 16660, Length: 91, e: 0.05, Avg Reward: -186.628987745, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.2230348587\n",
      "[NOR] Episode: 16670, Length: 97, e: 0.05, Avg Reward: -146.288914593, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.191865921\n",
      "[NOR] Episode: 16680, Length: 54, e: 0.05, Avg Reward: -177.902060504, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 43.907749176\n",
      "[NOR] Episode: 16690, Length: 60, e: 0.05, Avg Reward: -174.685241996, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.5297775269\n",
      "[NOR] Episode: 16700, Length: 53, e: 0.05, Avg Reward: -127.873595898, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.88072085381\n",
      "[NOR] Episode: 16710, Length: 67, e: 0.05, Avg Reward: -139.259967181, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.1695556641\n",
      "[NOR] Episode: 16720, Length: 94, e: 0.05, Avg Reward: -179.758952419, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.93355739117\n",
      "[NOR] Episode: 16730, Length: 59, e: 0.05, Avg Reward: -105.364309668, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.63005685806\n",
      "[NOR] Episode: 16740, Length: 71, e: 0.05, Avg Reward: -184.739307015, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.5394821167\n",
      "[NOR] Episode: 16750, Length: 60, e: 0.05, Avg Reward: -151.821354016, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.0844535828\n",
      "[NOR] Episode: 16760, Length: 74, e: 0.05, Avg Reward: -210.698653537, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.7269477844\n",
      "[NOR] Episode: 16770, Length: 81, e: 0.05, Avg Reward: -128.530481785, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.2540016174\n",
      "[NOR] Episode: 16780, Length: 72, e: 0.05, Avg Reward: -129.529038435, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.6904144287\n",
      "[NOR] Episode: 16790, Length: 66, e: 0.05, Avg Reward: -105.584120816, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.60598397255\n",
      "[NOR] Episode: 16800, Length: 70, e: 0.05, Avg Reward: -168.63809973, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.7634677887\n",
      "[NOR] Episode: 16810, Length: 91, e: 0.05, Avg Reward: -114.148908977, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -83.7804794312\n",
      "[NOR] Episode: 16820, Length: 70, e: 0.05, Avg Reward: -138.192690475, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.2956466675\n",
      "[NOR] Episode: 16830, Length: 88, e: 0.05, Avg Reward: -127.249660477, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -54.333568573\n",
      "[NOR] Episode: 16840, Length: 76, e: 0.05, Avg Reward: -148.888525177, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.92285919189\n",
      "[NOR] Episode: 16850, Length: 83, e: 0.05, Avg Reward: -161.008272764, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.37074756622\n",
      "[NOR] Episode: 16860, Length: 55, e: 0.05, Avg Reward: -169.877563718, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.8827705383\n",
      "[NOR] Episode: 16870, Length: 65, e: 0.05, Avg Reward: -118.689702211, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.0388565063\n",
      "[NOR] Episode: 16880, Length: 80, e: 0.05, Avg Reward: -140.687844957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.408741951\n",
      "[NOR] Episode: 16890, Length: 76, e: 0.05, Avg Reward: -159.582903859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.0132255554\n",
      "[NOR] Episode: 16900, Length: 77, e: 0.05, Avg Reward: -144.185846221, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.1386547089\n",
      "[NOR] Episode: 16910, Length: 103, e: 0.05, Avg Reward: -144.593726637, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.3858737946\n",
      "[NOR] Episode: 16920, Length: 73, e: 0.05, Avg Reward: -127.440094392, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.57478523254\n",
      "[NOR] Episode: 16930, Length: 78, e: 0.05, Avg Reward: -137.561068981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.1254224777\n",
      "[NOR] Episode: 16940, Length: 90, e: 0.05, Avg Reward: -156.258412182, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.27678251266\n",
      "[NOR] Episode: 16950, Length: 54, e: 0.05, Avg Reward: -152.386211316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.74150466919\n",
      "[NOR] Episode: 16960, Length: 86, e: 0.05, Avg Reward: -163.737074457, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.5195999146\n",
      "[NOR] Episode: 16970, Length: 69, e: 0.05, Avg Reward: -174.184277917, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.8021697998\n",
      "[NOR] Episode: 16980, Length: 71, e: 0.05, Avg Reward: -130.419063537, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.45953369141\n",
      "[NOR] Episode: 16990, Length: 103, e: 0.05, Avg Reward: -78.2574394396, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.69741725922\n",
      "[NOR] Episode: 17000, Length: 86, e: 0.05, Avg Reward: -124.322051601, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.89797258377\n",
      "[NOR] Episode: 17010, Length: 76, e: 0.05, Avg Reward: -129.745132275, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.83211326599\n",
      "[NOR] Episode: 17020, Length: 71, e: 0.05, Avg Reward: -114.886247134, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.66039657593\n",
      "[NOR] Episode: 17030, Length: 61, e: 0.05, Avg Reward: -158.614614871, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.01079463959\n",
      "[NOR] Episode: 17040, Length: 102, e: 0.05, Avg Reward: -105.037221662, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.4501419067\n",
      "[NOR] Episode: 17050, Length: 86, e: 0.05, Avg Reward: -110.881308958, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.9132184982\n",
      "[NOR] Episode: 17060, Length: 66, e: 0.05, Avg Reward: -124.398417433, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.17563486099\n",
      "[NOR] Episode: 17070, Length: 82, e: 0.05, Avg Reward: -125.727503062, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.1910552979\n",
      "[NOR] Episode: 17080, Length: 69, e: 0.05, Avg Reward: -118.175041163, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.5915126801\n",
      "[NOR] Episode: 17090, Length: 64, e: 0.05, Avg Reward: -178.185567972, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.4668073654\n",
      "[NOR] Episode: 17100, Length: 81, e: 0.05, Avg Reward: -144.051799715, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.3036422729\n",
      "[NOR] Episode: 17110, Length: 59, e: 0.05, Avg Reward: -119.988755139, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.1217079163\n",
      "[NOR] Episode: 17120, Length: 67, e: 0.05, Avg Reward: -131.311903815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.075758934\n",
      "[NOR] Episode: 17130, Length: 71, e: 0.05, Avg Reward: -148.597475103, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -75.1968765259\n",
      "[NOR] Episode: 17140, Length: 94, e: 0.05, Avg Reward: -162.909435908, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.77529335022\n",
      "[NOR] Episode: 17150, Length: 61, e: 0.05, Avg Reward: -121.077551505, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.223934173584\n",
      "[NOR] Episode: 17160, Length: 79, e: 0.05, Avg Reward: -132.487436665, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 34.6158905029\n",
      "[NOR] Episode: 17170, Length: 99, e: 0.05, Avg Reward: -139.305088858, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.10932350159\n",
      "[NOR] Episode: 17180, Length: 103, e: 0.05, Avg Reward: -142.551578675, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.9009838104\n",
      "[NOR] Episode: 17190, Length: 87, e: 0.05, Avg Reward: -154.625813765, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.9726715088\n",
      "[NOR] Episode: 17200, Length: 87, e: 0.05, Avg Reward: -174.734594396, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.6543159485\n",
      "[NOR] Episode: 17210, Length: 69, e: 0.05, Avg Reward: -159.04469071, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.10344409943\n",
      "[NOR] Episode: 17220, Length: 67, e: 0.05, Avg Reward: -72.8385154513, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.1669273376\n",
      "[NOR] Episode: 17230, Length: 72, e: 0.05, Avg Reward: -114.591942053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.610956192\n",
      "[NOR] Episode: 17240, Length: 60, e: 0.05, Avg Reward: -148.267389458, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.5488243103\n",
      "[NOR] Episode: 17250, Length: 71, e: 0.05, Avg Reward: -133.348852425, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.1252174377\n",
      "[NOR] Episode: 17260, Length: 68, e: 0.05, Avg Reward: -156.637563176, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.2681446075\n",
      "[NOR] Episode: 17270, Length: 84, e: 0.05, Avg Reward: -121.99021659, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.3669204712\n",
      "[NOR] Episode: 17280, Length: 113, e: 0.05, Avg Reward: -151.969059477, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.9432449341\n",
      "[NOR] Episode: 17290, Length: 98, e: 0.05, Avg Reward: -152.432705864, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.2986125946\n",
      "[NOR] Episode: 17300, Length: 86, e: 0.05, Avg Reward: -106.654910121, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.38647937775\n",
      "[NOR] Episode: 17310, Length: 68, e: 0.05, Avg Reward: -135.899604685, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.2363624573\n",
      "[NOR] Episode: 17320, Length: 94, e: 0.05, Avg Reward: -172.123298226, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.6663818359\n",
      "[NOR] Episode: 17330, Length: 80, e: 0.05, Avg Reward: -126.442463137, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.3049249649\n",
      "[NOR] Episode: 17340, Length: 78, e: 0.05, Avg Reward: -133.941805102, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.78949356079\n",
      "[NOR] Episode: 17350, Length: 99, e: 0.05, Avg Reward: -140.289782616, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 68.3557434082\n",
      "[NOR] Episode: 17360, Length: 87, e: 0.05, Avg Reward: -170.176972713, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.1012325287\n",
      "[NOR] Episode: 17370, Length: 64, e: 0.05, Avg Reward: -120.797936354, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.6977405548\n",
      "[NOR] Episode: 17380, Length: 72, e: 0.05, Avg Reward: -168.613992745, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.8472118378\n",
      "[NOR] Episode: 17390, Length: 90, e: 0.05, Avg Reward: -153.086863067, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.6274299622\n",
      "[NOR] Episode: 17400, Length: 75, e: 0.05, Avg Reward: -147.102234304, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -63.1926879883\n",
      "[NOR] Episode: 17410, Length: 73, e: 0.05, Avg Reward: -151.232558, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.5855979919\n",
      "[NOR] Episode: 17420, Length: 71, e: 0.05, Avg Reward: -172.384447328, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.829713821411\n",
      "[NOR] Episode: 17430, Length: 59, e: 0.05, Avg Reward: -130.900729953, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.498260498\n",
      "[NOR] Episode: 17440, Length: 60, e: 0.05, Avg Reward: -161.019060306, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.69913196564\n",
      "[NOR] Episode: 17450, Length: 68, e: 0.05, Avg Reward: -109.285118829, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.5497398376\n",
      "[NOR] Episode: 17460, Length: 61, e: 0.05, Avg Reward: -128.328043273, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.834851980209\n",
      "[NOR] Episode: 17470, Length: 94, e: 0.05, Avg Reward: -156.340425006, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.2381744385\n",
      "[NOR] Episode: 17480, Length: 72, e: 0.05, Avg Reward: -161.102875586, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 64.8975524902\n",
      "[NOR] Episode: 17490, Length: 69, e: 0.05, Avg Reward: -126.46118099, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.45186686516\n",
      "[NOR] Episode: 17500, Length: 73, e: 0.05, Avg Reward: -133.489682912, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.5101995468\n",
      "[NOR] Episode: 17510, Length: 93, e: 0.05, Avg Reward: -163.447318668, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.48380756378\n",
      "[NOR] Episode: 17520, Length: 79, e: 0.05, Avg Reward: -177.865538393, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.05365467072\n",
      "[NOR] Episode: 17530, Length: 76, e: 0.05, Avg Reward: -188.346985468, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.27634644508\n",
      "[NOR] Episode: 17540, Length: 92, e: 0.05, Avg Reward: -138.211556713, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.8051795959\n",
      "[NOR] Episode: 17550, Length: 62, e: 0.05, Avg Reward: -132.059244856, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.83903121948\n",
      "[NOR] Episode: 17560, Length: 67, e: 0.05, Avg Reward: -126.731083114, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.2157363892\n",
      "[NOR] Episode: 17570, Length: 50, e: 0.05, Avg Reward: -147.876618807, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.8254079819\n",
      "[NOR] Episode: 17580, Length: 63, e: 0.05, Avg Reward: -140.687094578, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.01194095612\n",
      "[NOR] Episode: 17590, Length: 68, e: 0.05, Avg Reward: -141.98399323, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.2545433044\n",
      "[NOR] Episode: 17600, Length: 55, e: 0.05, Avg Reward: -132.578845422, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.9781570435\n",
      "[NOR] Episode: 17610, Length: 69, e: 0.05, Avg Reward: -194.767063293, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.2490196228\n",
      "[NOR] Episode: 17620, Length: 69, e: 0.05, Avg Reward: -134.100981941, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.47366189957\n",
      "[NOR] Episode: 17630, Length: 79, e: 0.05, Avg Reward: -135.529358158, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.40123462677\n",
      "[NOR] Episode: 17640, Length: 74, e: 0.05, Avg Reward: -167.056264171, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.94932556152\n",
      "[NOR] Episode: 17650, Length: 73, e: 0.05, Avg Reward: -155.158638291, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.02754259109\n",
      "[NOR] Episode: 17660, Length: 82, e: 0.05, Avg Reward: -143.7977536, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.348449707\n",
      "[NOR] Episode: 17670, Length: 78, e: 0.05, Avg Reward: -142.353550739, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -51.9769363403\n",
      "[NOR] Episode: 17680, Length: 64, e: 0.05, Avg Reward: -134.083048063, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.4009666443\n",
      "[NOR] Episode: 17690, Length: 67, e: 0.05, Avg Reward: -146.32949731, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.1077365875\n",
      "[NOR] Episode: 17700, Length: 77, e: 0.05, Avg Reward: -144.777720301, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.69040584564\n",
      "[NOR] Episode: 17710, Length: 83, e: 0.05, Avg Reward: -133.105710913, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.8670368195\n",
      "[NOR] Episode: 17720, Length: 63, e: 0.05, Avg Reward: -127.872564464, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.4550895691\n",
      "[NOR] Episode: 17730, Length: 64, e: 0.05, Avg Reward: -127.396674696, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.41283988953\n",
      "[NOR] Episode: 17740, Length: 93, e: 0.05, Avg Reward: -85.9270604314, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.54388427734\n",
      "[NOR] Episode: 17750, Length: 62, e: 0.05, Avg Reward: -128.0129584, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.70257949829\n",
      "[NOR] Episode: 17760, Length: 97, e: 0.05, Avg Reward: -153.760585046, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.6614465714\n",
      "[NOR] Episode: 17770, Length: 70, e: 0.05, Avg Reward: -112.709226223, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.35101604462\n",
      "[NOR] Episode: 17780, Length: 88, e: 0.05, Avg Reward: -117.826410891, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.11545467377\n",
      "[NOR] Episode: 17790, Length: 60, e: 0.05, Avg Reward: -86.7952820566, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.49884223938\n",
      "[NOR] Episode: 17800, Length: 78, e: 0.05, Avg Reward: -116.13818645, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.90677714348\n",
      "[NOR] Episode: 17810, Length: 60, e: 0.05, Avg Reward: -197.711582414, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -63.2985877991\n",
      "[NOR] Episode: 17820, Length: 70, e: 0.05, Avg Reward: -152.636029865, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.9891357422\n",
      "[NOR] Episode: 17830, Length: 71, e: 0.05, Avg Reward: -145.192775229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.88261222839\n",
      "[NOR] Episode: 17840, Length: 84, e: 0.05, Avg Reward: -139.931080268, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.274477005\n",
      "[NOR] Episode: 17850, Length: 73, e: 0.05, Avg Reward: -111.553053481, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.7690200806\n",
      "[NOR] Episode: 17860, Length: 78, e: 0.05, Avg Reward: -154.90700004, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -209.525543213\n",
      "[NOR] Episode: 17870, Length: 85, e: 0.05, Avg Reward: -131.273852689, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.681119918823\n",
      "[NOR] Episode: 17880, Length: 93, e: 0.05, Avg Reward: -112.677819326, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.8328895569\n",
      "[NOR] Episode: 17890, Length: 102, e: 0.05, Avg Reward: -108.469852561, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.56287479401\n",
      "[NOR] Episode: 17900, Length: 95, e: 0.05, Avg Reward: -159.092801556, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -70.2734909058\n",
      "[NOR] Episode: 17910, Length: 67, e: 0.05, Avg Reward: -151.680077448, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.7705459595\n",
      "[NOR] Episode: 17920, Length: 75, e: 0.05, Avg Reward: -152.573709368, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.1851568222\n",
      "[NOR] Episode: 17930, Length: 90, e: 0.05, Avg Reward: -133.751775652, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.1631126404\n",
      "[NOR] Episode: 17940, Length: 66, e: 0.05, Avg Reward: -147.621521259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.5579996109\n",
      "[NOR] Episode: 17950, Length: 87, e: 0.05, Avg Reward: -147.487677301, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.59614276886\n",
      "[NOR] Episode: 17960, Length: 58, e: 0.05, Avg Reward: -159.661612959, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.2271852493\n",
      "[NOR] Episode: 17970, Length: 52, e: 0.05, Avg Reward: -161.875965072, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.6353721619\n",
      "[NOR] Episode: 17980, Length: 55, e: 0.05, Avg Reward: -151.375658838, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.0173950195\n",
      "[NOR] Episode: 17990, Length: 63, e: 0.05, Avg Reward: -130.273916065, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.70267868042\n",
      "[NOR] Episode: 18000, Length: 96, e: 0.05, Avg Reward: -164.047829421, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.6013088226\n",
      "[NOR] Episode: 18010, Length: 59, e: 0.05, Avg Reward: -147.568636026, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.8497262001\n",
      "[NOR] Episode: 18020, Length: 71, e: 0.05, Avg Reward: -150.615237605, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.87627601624\n",
      "[NOR] Episode: 18030, Length: 70, e: 0.05, Avg Reward: -171.854626141, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.3701095581\n",
      "[NOR] Episode: 18040, Length: 89, e: 0.05, Avg Reward: -151.204262186, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.75941133499\n",
      "[NOR] Episode: 18050, Length: 61, e: 0.05, Avg Reward: -139.318076384, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 112.483467102\n",
      "[NOR] Episode: 18060, Length: 68, e: 0.05, Avg Reward: -130.442239516, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.0043296814\n",
      "[NOR] Episode: 18070, Length: 65, e: 0.05, Avg Reward: -136.718151198, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.6538448334\n",
      "[NOR] Episode: 18080, Length: 71, e: 0.05, Avg Reward: -113.986500489, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.68882751465\n",
      "[NOR] Episode: 18090, Length: 58, e: 0.05, Avg Reward: -178.754944237, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.91638088226\n",
      "[NOR] Episode: 18100, Length: 80, e: 0.05, Avg Reward: -151.794392612, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 35.8090820312\n",
      "[NOR] Episode: 18110, Length: 71, e: 0.05, Avg Reward: -153.008365905, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.29672241211\n",
      "[NOR] Episode: 18120, Length: 59, e: 0.05, Avg Reward: -141.392688456, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.3281974792\n",
      "[NOR] Episode: 18130, Length: 62, e: 0.05, Avg Reward: -135.964552065, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.87627220154\n",
      "[NOR] Episode: 18140, Length: 75, e: 0.05, Avg Reward: -148.970916868, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.98736357689\n",
      "[NOR] Episode: 18150, Length: 60, e: 0.05, Avg Reward: -168.445800423, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.68427801132\n",
      "[NOR] Episode: 18160, Length: 90, e: 0.05, Avg Reward: -163.129550521, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.94800519943\n",
      "[NOR] Episode: 18170, Length: 72, e: 0.05, Avg Reward: -151.574578675, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.59351444244\n",
      "[NOR] Episode: 18180, Length: 56, e: 0.05, Avg Reward: -161.550129956, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 38.1630134583\n",
      "[NOR] Episode: 18190, Length: 61, e: 0.05, Avg Reward: -150.194584662, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.18941497803\n",
      "[NOR] Episode: 18200, Length: 52, e: 0.05, Avg Reward: -157.285518297, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.2362785339\n",
      "[NOR] Episode: 18210, Length: 74, e: 0.05, Avg Reward: -165.279186888, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.234834671\n",
      "[NOR] Episode: 18220, Length: 77, e: 0.05, Avg Reward: -151.43156403, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.7530384064\n",
      "[NOR] Episode: 18230, Length: 83, e: 0.05, Avg Reward: -137.64027882, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.06468296051\n",
      "[NOR] Episode: 18240, Length: 71, e: 0.05, Avg Reward: -178.02371921, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.4565505981\n",
      "[NOR] Episode: 18250, Length: 77, e: 0.05, Avg Reward: -135.035227409, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.3766078949\n",
      "[NOR] Episode: 18260, Length: 58, e: 0.05, Avg Reward: -163.285578031, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.66885232925\n",
      "[NOR] Episode: 18270, Length: 91, e: 0.05, Avg Reward: -166.919376126, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.85147953033\n",
      "[NOR] Episode: 18280, Length: 65, e: 0.05, Avg Reward: -150.306142641, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.8178977966\n",
      "[NOR] Episode: 18290, Length: 75, e: 0.05, Avg Reward: -128.696417291, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.13150691986\n",
      "[NOR] Episode: 18300, Length: 60, e: 0.05, Avg Reward: -130.53164772, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.2663726807\n",
      "[NOR] Episode: 18310, Length: 68, e: 0.05, Avg Reward: -145.166333588, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 44.082901001\n",
      "[NOR] Episode: 18320, Length: 85, e: 0.05, Avg Reward: -140.073989766, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.2076396942\n",
      "[NOR] Episode: 18330, Length: 83, e: 0.05, Avg Reward: -167.419166427, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.8124294281\n",
      "[NOR] Episode: 18340, Length: 67, e: 0.05, Avg Reward: -164.502455724, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.5415229797\n",
      "[NOR] Episode: 18350, Length: 56, e: 0.05, Avg Reward: -127.431029196, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.8037567139\n",
      "[NOR] Episode: 18360, Length: 92, e: 0.05, Avg Reward: -124.507689215, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 57.6931304932\n",
      "[NOR] Episode: 18370, Length: 74, e: 0.05, Avg Reward: -141.648438428, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.9633388519\n",
      "[NOR] Episode: 18380, Length: 90, e: 0.05, Avg Reward: -105.715876144, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.42294597626\n",
      "[NOR] Episode: 18390, Length: 93, e: 0.05, Avg Reward: -150.591600634, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.4477500916\n",
      "[NOR] Episode: 18400, Length: 91, e: 0.05, Avg Reward: -136.136776471, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.8777370453\n",
      "[NOR] Episode: 18410, Length: 69, e: 0.05, Avg Reward: -111.405124454, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.07180690765\n",
      "[NOR] Episode: 18420, Length: 67, e: 0.05, Avg Reward: -100.665757043, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -95.8518981934\n",
      "[NOR] Episode: 18430, Length: 79, e: 0.05, Avg Reward: -131.172767866, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.3225021362\n",
      "[NOR] Episode: 18440, Length: 78, e: 0.05, Avg Reward: -152.723847627, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.6357879639\n",
      "[NOR] Episode: 18450, Length: 55, e: 0.05, Avg Reward: -135.231244654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -38.1063079834\n",
      "[NOR] Episode: 18460, Length: 57, e: 0.05, Avg Reward: -142.289449175, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.4051856995\n",
      "[NOR] Episode: 18470, Length: 83, e: 0.05, Avg Reward: -142.529016997, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.7171983719\n",
      "[NOR] Episode: 18480, Length: 62, e: 0.05, Avg Reward: -143.190734423, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.333568573\n",
      "[NOR] Episode: 18490, Length: 56, e: 0.05, Avg Reward: -134.47306778, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.2533864975\n",
      "[NOR] Episode: 18500, Length: 62, e: 0.05, Avg Reward: -126.483184485, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.92091369629\n",
      "[NOR] Episode: 18510, Length: 67, e: 0.05, Avg Reward: -120.65073115, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.3511037827\n",
      "[NOR] Episode: 18520, Length: 88, e: 0.05, Avg Reward: -122.360836039, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.7771148682\n",
      "[NOR] Episode: 18530, Length: 52, e: 0.05, Avg Reward: -130.97751776, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.7459201813\n",
      "[NOR] Episode: 18540, Length: 69, e: 0.05, Avg Reward: -133.372680453, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.64804363251\n",
      "[NOR] Episode: 18550, Length: 56, e: 0.05, Avg Reward: -153.614755704, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.2946014404\n",
      "[NOR] Episode: 18560, Length: 66, e: 0.05, Avg Reward: -131.800934995, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.9674701691\n",
      "[NOR] Episode: 18570, Length: 71, e: 0.05, Avg Reward: -136.105447654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.5316047668\n",
      "[NOR] Episode: 18580, Length: 94, e: 0.05, Avg Reward: -152.935169267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.71720504761\n",
      "[NOR] Episode: 18590, Length: 64, e: 0.05, Avg Reward: -131.531003231, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.81467628479\n",
      "[NOR] Episode: 18600, Length: 67, e: 0.05, Avg Reward: -119.630853462, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.0188331604\n",
      "[NOR] Episode: 18610, Length: 67, e: 0.05, Avg Reward: -142.360316682, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.0560760498\n",
      "[NOR] Episode: 18620, Length: 88, e: 0.05, Avg Reward: -127.873800954, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.16139030457\n",
      "[NOR] Episode: 18630, Length: 90, e: 0.05, Avg Reward: -142.333461249, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.6599750519\n",
      "[NOR] Episode: 18640, Length: 54, e: 0.05, Avg Reward: -137.894023514, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -56.4745979309\n",
      "[NOR] Episode: 18650, Length: 66, e: 0.05, Avg Reward: -159.246847664, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.2313528061\n",
      "[NOR] Episode: 18660, Length: 67, e: 0.05, Avg Reward: -148.023114046, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 51.4493141174\n",
      "[NOR] Episode: 18670, Length: 60, e: 0.05, Avg Reward: -131.173216024, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.3756389618\n",
      "[NOR] Episode: 18680, Length: 57, e: 0.05, Avg Reward: -142.208784895, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.8015480042\n",
      "[NOR] Episode: 18690, Length: 67, e: 0.05, Avg Reward: -137.834055495, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.166220665\n",
      "[NOR] Episode: 18700, Length: 71, e: 0.05, Avg Reward: -169.365209661, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.4353141785\n",
      "[NOR] Episode: 18710, Length: 59, e: 0.05, Avg Reward: -134.639799867, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.6955413818\n",
      "[NOR] Episode: 18720, Length: 61, e: 0.05, Avg Reward: -129.282041359, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.0118932724\n",
      "[NOR] Episode: 18730, Length: 77, e: 0.05, Avg Reward: -168.385255703, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.399684906\n",
      "[NOR] Episode: 18740, Length: 69, e: 0.05, Avg Reward: -129.491107484, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.37320709229\n",
      "[NOR] Episode: 18750, Length: 64, e: 0.05, Avg Reward: -126.525124804, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.33584499359\n",
      "[NOR] Episode: 18760, Length: 86, e: 0.05, Avg Reward: -143.20850289, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.7971229553\n",
      "[NOR] Episode: 18770, Length: 84, e: 0.05, Avg Reward: -127.00064736, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.88733291626\n",
      "[NOR] Episode: 18780, Length: 62, e: 0.05, Avg Reward: -114.885070152, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.648762226105\n",
      "[NOR] Episode: 18790, Length: 92, e: 0.05, Avg Reward: -114.638317531, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.2678527832\n",
      "[NOR] Episode: 18800, Length: 75, e: 0.05, Avg Reward: -125.228255245, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.0382728577\n",
      "[NOR] Episode: 18810, Length: 59, e: 0.05, Avg Reward: -121.612830564, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.5393753052\n",
      "[NOR] Episode: 18820, Length: 86, e: 0.05, Avg Reward: -117.310832709, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.900172710419\n",
      "[NOR] Episode: 18830, Length: 65, e: 0.05, Avg Reward: -140.653499211, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 42.9992523193\n",
      "[NOR] Episode: 18840, Length: 84, e: 0.05, Avg Reward: -117.592535914, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.99888658524\n",
      "[NOR] Episode: 18850, Length: 73, e: 0.05, Avg Reward: -107.309202118, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 165.926605225\n",
      "[NOR] Episode: 18860, Length: 90, e: 0.05, Avg Reward: -138.061905788, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.348690033\n",
      "[NOR] Episode: 18870, Length: 69, e: 0.05, Avg Reward: -122.004473952, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.221578598\n",
      "[NOR] Episode: 18880, Length: 54, e: 0.05, Avg Reward: -131.483326692, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.0568037033\n",
      "[NOR] Episode: 18890, Length: 66, e: 0.05, Avg Reward: -121.600157241, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.60174965858\n",
      "[NOR] Episode: 18900, Length: 63, e: 0.05, Avg Reward: -110.868170563, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.6357536316\n",
      "[NOR] Episode: 18910, Length: 80, e: 0.05, Avg Reward: -93.4069117569, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.44641017914\n",
      "[NOR] Episode: 18920, Length: 69, e: 0.05, Avg Reward: -133.968869232, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 63.4913749695\n",
      "[NOR] Episode: 18930, Length: 74, e: 0.05, Avg Reward: -181.810060437, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 65.5919647217\n",
      "[NOR] Episode: 18940, Length: 76, e: 0.05, Avg Reward: -142.29723687, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.9811553955\n",
      "[NOR] Episode: 18950, Length: 93, e: 0.05, Avg Reward: -139.033483107, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.10101079941\n",
      "[NOR] Episode: 18960, Length: 59, e: 0.05, Avg Reward: -142.293731712, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.2591667175\n",
      "[NOR] Episode: 18970, Length: 55, e: 0.05, Avg Reward: -131.791238383, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.1648788452\n",
      "[NOR] Episode: 18980, Length: 68, e: 0.05, Avg Reward: -163.657006984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 232.025421143\n",
      "[NOR] Episode: 18990, Length: 67, e: 0.05, Avg Reward: -122.600994409, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.8691616058\n",
      "[NOR] Episode: 19000, Length: 78, e: 0.05, Avg Reward: -139.690545682, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.12644672394\n",
      "[NOR] Episode: 19010, Length: 62, e: 0.05, Avg Reward: -122.67111264, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.0199699402\n",
      "[NOR] Episode: 19020, Length: 88, e: 0.05, Avg Reward: -163.341483405, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.66478729248\n",
      "[NOR] Episode: 19030, Length: 56, e: 0.05, Avg Reward: -125.464827267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.3987622261\n",
      "[NOR] Episode: 19040, Length: 55, e: 0.05, Avg Reward: -113.871730124, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.15975952148\n",
      "[NOR] Episode: 19050, Length: 81, e: 0.05, Avg Reward: -147.949770159, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.6426963806\n",
      "[NOR] Episode: 19060, Length: 67, e: 0.05, Avg Reward: -119.597893987, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.510307312\n",
      "[NOR] Episode: 19070, Length: 86, e: 0.05, Avg Reward: -90.8683682685, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.31631755829\n",
      "[NOR] Episode: 19080, Length: 65, e: 0.05, Avg Reward: -93.6022450084, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -53.7225990295\n",
      "[NOR] Episode: 19090, Length: 90, e: 0.05, Avg Reward: -113.225392368, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.0872955322\n",
      "[NOR] Episode: 19100, Length: 91, e: 0.05, Avg Reward: -122.597531391, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.3185329437\n",
      "[NOR] Episode: 19110, Length: 61, e: 0.05, Avg Reward: -151.672536504, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.9088478088\n",
      "[NOR] Episode: 19120, Length: 104, e: 0.05, Avg Reward: -135.302342733, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.42039489746\n",
      "[NOR] Episode: 19130, Length: 61, e: 0.05, Avg Reward: -110.204109615, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 96.2552947998\n",
      "[NOR] Episode: 19140, Length: 68, e: 0.05, Avg Reward: -150.109214636, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.6308097839\n",
      "[NOR] Episode: 19150, Length: 53, e: 0.05, Avg Reward: -118.64755269, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.48743581772\n",
      "[NOR] Episode: 19160, Length: 79, e: 0.05, Avg Reward: -144.578721235, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.5860843658\n",
      "[NOR] Episode: 19170, Length: 65, e: 0.05, Avg Reward: -103.229428251, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.0190553665\n",
      "[NOR] Episode: 19180, Length: 62, e: 0.05, Avg Reward: -126.752905819, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.9498062134\n",
      "[NOR] Episode: 19190, Length: 79, e: 0.05, Avg Reward: -102.594055851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.61866140366\n",
      "[NOR] Episode: 19200, Length: 64, e: 0.05, Avg Reward: -128.335673544, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.96283864975\n",
      "[NOR] Episode: 19210, Length: 89, e: 0.05, Avg Reward: -99.1888809476, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.39409637451\n",
      "[NOR] Episode: 19220, Length: 78, e: 0.05, Avg Reward: -99.6889489594, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -38.1097259521\n",
      "[NOR] Episode: 19230, Length: 103, e: 0.05, Avg Reward: -133.873077059, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.1441612244\n",
      "[NOR] Episode: 19240, Length: 100, e: 0.05, Avg Reward: -95.4470547905, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.10611248016\n",
      "[NOR] Episode: 19250, Length: 70, e: 0.05, Avg Reward: -95.0232952272, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.160326004\n",
      "[NOR] Episode: 19260, Length: 62, e: 0.05, Avg Reward: -129.79442388, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.07423532009\n",
      "[NOR] Episode: 19270, Length: 75, e: 0.05, Avg Reward: -78.9069061106, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.600025177\n",
      "[NOR] Episode: 19280, Length: 52, e: 0.05, Avg Reward: -104.77643471, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.26708829403\n",
      "[NOR] Episode: 19290, Length: 66, e: 0.05, Avg Reward: -113.050683522, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.856048584\n",
      "[NOR] Episode: 19300, Length: 75, e: 0.05, Avg Reward: -105.205160632, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.44194507599\n",
      "[NOR] Episode: 19310, Length: 90, e: 0.05, Avg Reward: -171.490392546, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.13140201569\n",
      "[NOR] Episode: 19320, Length: 78, e: 0.05, Avg Reward: -81.3278654073, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.325590133667\n",
      "[NOR] Episode: 19330, Length: 76, e: 0.05, Avg Reward: -86.6057841387, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.62808990479\n",
      "[NOR] Episode: 19340, Length: 90, e: 0.05, Avg Reward: -98.7459990766, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.39761829376\n",
      "[NOR] Episode: 19350, Length: 64, e: 0.05, Avg Reward: -122.694444183, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.2191886902\n",
      "[NOR] Episode: 19360, Length: 53, e: 0.05, Avg Reward: -85.5053556699, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.0788955688\n",
      "[NOR] Episode: 19370, Length: 66, e: 0.05, Avg Reward: -120.316207373, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.2450237274\n",
      "[NOR] Episode: 19380, Length: 78, e: 0.05, Avg Reward: -125.075125076, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.1063489914\n",
      "[NOR] Episode: 19390, Length: 57, e: 0.05, Avg Reward: -182.208934733, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.6675834656\n",
      "[NOR] Episode: 19400, Length: 85, e: 0.05, Avg Reward: -115.094222466, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.61336231232\n",
      "[NOR] Episode: 19410, Length: 86, e: 0.05, Avg Reward: -90.8929837057, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -58.2211914062\n",
      "[NOR] Episode: 19420, Length: 87, e: 0.05, Avg Reward: -98.0708092178, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.3908367157\n",
      "[NOR] Episode: 19430, Length: 62, e: 0.05, Avg Reward: -131.876863841, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.07500982285\n",
      "[NOR] Episode: 19440, Length: 64, e: 0.05, Avg Reward: -104.772126321, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.49657058716\n",
      "[NOR] Episode: 19450, Length: 92, e: 0.05, Avg Reward: -139.507319751, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.34179258347\n",
      "[NOR] Episode: 19460, Length: 78, e: 0.05, Avg Reward: -116.979426219, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.2046356201\n",
      "[NOR] Episode: 19470, Length: 100, e: 0.05, Avg Reward: -117.740164807, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.8360977173\n",
      "[NOR] Episode: 19480, Length: 61, e: 0.05, Avg Reward: -138.235468164, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.8198604584\n",
      "[NOR] Episode: 19490, Length: 75, e: 0.05, Avg Reward: -115.045109649, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.12223672867\n",
      "[NOR] Episode: 19500, Length: 61, e: 0.05, Avg Reward: -114.060258497, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.809387207\n",
      "[NOR] Episode: 19510, Length: 63, e: 0.05, Avg Reward: -66.393799994, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.2678089142\n",
      "[NOR] Episode: 19520, Length: 73, e: 0.05, Avg Reward: -112.164361735, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.68410491943\n",
      "[NOR] Episode: 19530, Length: 58, e: 0.05, Avg Reward: -115.537328821, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.8997745514\n",
      "[NOR] Episode: 19540, Length: 83, e: 0.05, Avg Reward: -151.480226973, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.1021957397\n",
      "[NOR] Episode: 19550, Length: 70, e: 0.05, Avg Reward: -119.981636698, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.8998975754\n",
      "[NOR] Episode: 19560, Length: 83, e: 0.05, Avg Reward: -125.173096872, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.044626236\n",
      "[NOR] Episode: 19570, Length: 176, e: 0.05, Avg Reward: -80.0737587681, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.3110618591\n",
      "[NOR] Episode: 19580, Length: 94, e: 0.05, Avg Reward: -24.8066208246, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.452564239502\n",
      "[NOR] Episode: 19590, Length: 106, e: 0.05, Avg Reward: -85.9171245695, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.40824127197\n",
      "[NOR] Episode: 19600, Length: 68, e: 0.05, Avg Reward: -133.879642003, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.00038719177\n",
      "[NOR] Episode: 19610, Length: 87, e: 0.05, Avg Reward: -128.716278061, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.5227336884\n",
      "[NOR] Episode: 19620, Length: 79, e: 0.05, Avg Reward: -114.573053857, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.7887516022\n",
      "[NOR] Episode: 19630, Length: 62, e: 0.05, Avg Reward: -114.768836854, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.2313613892\n",
      "[NOR] Episode: 19640, Length: 89, e: 0.05, Avg Reward: -131.822151095, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.15043067932\n",
      "[NOR] Episode: 19650, Length: 88, e: 0.05, Avg Reward: -161.131495485, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.75614261627\n",
      "[NOR] Episode: 19660, Length: 77, e: 0.05, Avg Reward: -162.035410651, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -38.8893165588\n",
      "[NOR] Episode: 19670, Length: 72, e: 0.05, Avg Reward: -112.815686837, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.7102060318\n",
      "[NOR] Episode: 19680, Length: 73, e: 0.05, Avg Reward: -127.574740189, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.2110271454\n",
      "[NOR] Episode: 19690, Length: 114, e: 0.05, Avg Reward: -124.964431685, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.8659915924\n",
      "[NOR] Episode: 19700, Length: 72, e: 0.05, Avg Reward: -94.5773758372, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.77053260803\n",
      "[NOR] Episode: 19710, Length: 75, e: 0.05, Avg Reward: -108.057422833, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.1891345978\n",
      "[NOR] Episode: 19720, Length: 94, e: 0.05, Avg Reward: -151.31689491, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.85785293579\n",
      "[NOR] Episode: 19730, Length: 78, e: 0.05, Avg Reward: -110.02324586, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.37983989716\n",
      "[NOR] Episode: 19740, Length: 74, e: 0.05, Avg Reward: -99.2190348174, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.5744972229\n",
      "[NOR] Episode: 19750, Length: 69, e: 0.05, Avg Reward: -98.5615324967, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.8512115479\n",
      "[NOR] Episode: 19760, Length: 71, e: 0.05, Avg Reward: -99.8588412422, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.2046041489\n",
      "[NOR] Episode: 19770, Length: 65, e: 0.05, Avg Reward: -162.159607682, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.890291214\n",
      "[NOR] Episode: 19780, Length: 73, e: 0.05, Avg Reward: -135.444688396, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 54.2745285034\n",
      "[NOR] Episode: 19790, Length: 96, e: 0.05, Avg Reward: -127.579692146, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.63823604584\n",
      "[NOR] Episode: 19800, Length: 64, e: 0.05, Avg Reward: -126.981289118, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.5261726379\n",
      "[NOR] Episode: 19810, Length: 71, e: 0.05, Avg Reward: -131.031986866, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.82511305809\n",
      "[NOR] Episode: 19820, Length: 85, e: 0.05, Avg Reward: -125.536080506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.4468193054\n",
      "[NOR] Episode: 19830, Length: 82, e: 0.05, Avg Reward: -114.936600788, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.7391624451\n",
      "[NOR] Episode: 19840, Length: 83, e: 0.05, Avg Reward: -120.099858633, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.65784263611\n",
      "[NOR] Episode: 19850, Length: 94, e: 0.05, Avg Reward: -129.054609116, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.209274292\n",
      "[NOR] Episode: 19860, Length: 76, e: 0.05, Avg Reward: -135.874312817, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.384099960327\n",
      "[NOR] Episode: 19870, Length: 77, e: 0.05, Avg Reward: -123.659486837, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.29267954826\n",
      "[NOR] Episode: 19880, Length: 64, e: 0.05, Avg Reward: -127.733381373, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.5756607056\n",
      "[NOR] Episode: 19890, Length: 73, e: 0.05, Avg Reward: -129.790851523, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.7962818146\n",
      "[NOR] Episode: 19900, Length: 57, e: 0.05, Avg Reward: -104.313740936, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.60916376114\n",
      "[NOR] Episode: 19910, Length: 84, e: 0.05, Avg Reward: -131.601379435, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.70618200302\n",
      "[NOR] Episode: 19920, Length: 68, e: 0.05, Avg Reward: -135.371998283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 35.7214431763\n",
      "[NOR] Episode: 19930, Length: 89, e: 0.05, Avg Reward: -124.676102647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.2398204803\n",
      "[NOR] Episode: 19940, Length: 83, e: 0.05, Avg Reward: -136.2893218, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 60.1844825745\n",
      "[NOR] Episode: 19950, Length: 68, e: 0.05, Avg Reward: -145.807391207, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.9946537018\n",
      "[NOR] Episode: 19960, Length: 56, e: 0.05, Avg Reward: -130.209860052, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.8827819824\n",
      "[NOR] Episode: 19970, Length: 65, e: 0.05, Avg Reward: -154.860889804, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.045841217\n",
      "[NOR] Episode: 19980, Length: 71, e: 0.05, Avg Reward: -131.377045922, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.0722160339\n",
      "[NOR] Episode: 19990, Length: 58, e: 0.05, Avg Reward: -140.493928867, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.1789321899\n",
      "[NOR] Episode: 20000, Length: 75, e: 0.05, Avg Reward: -126.726504295, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.4824943542\n",
      "[NOR] Episode: 20010, Length: 62, e: 0.05, Avg Reward: -124.302864136, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.3726959229\n",
      "[NOR] Episode: 20020, Length: 85, e: 0.05, Avg Reward: -125.790929888, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.31770467758\n",
      "[NOR] Episode: 20030, Length: 66, e: 0.05, Avg Reward: -128.357395511, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.1118469238\n",
      "[NOR] Episode: 20040, Length: 78, e: 0.05, Avg Reward: -119.295814479, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.40172982216\n",
      "[NOR] Episode: 20050, Length: 58, e: 0.05, Avg Reward: -131.272442017, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.5541400909\n",
      "[NOR] Episode: 20060, Length: 73, e: 0.05, Avg Reward: -116.52330833, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.2155570984\n",
      "[NOR] Episode: 20070, Length: 67, e: 0.05, Avg Reward: -156.200424607, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.4976387024\n",
      "[NOR] Episode: 20080, Length: 91, e: 0.05, Avg Reward: -138.495013956, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.18713974953\n",
      "[NOR] Episode: 20090, Length: 99, e: 0.05, Avg Reward: -129.258334341, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.66504049301\n",
      "[NOR] Episode: 20100, Length: 55, e: 0.05, Avg Reward: -162.039728187, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.30964231491\n",
      "[NOR] Episode: 20110, Length: 81, e: 0.05, Avg Reward: -102.474780419, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.4875774384\n",
      "[NOR] Episode: 20120, Length: 64, e: 0.05, Avg Reward: -130.121697078, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.7308731079\n",
      "[NOR] Episode: 20130, Length: 76, e: 0.05, Avg Reward: -120.700364594, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.5902080536\n",
      "[NOR] Episode: 20140, Length: 59, e: 0.05, Avg Reward: -122.335696405, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.43090391159\n",
      "[NOR] Episode: 20150, Length: 86, e: 0.05, Avg Reward: -110.016265657, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 39.7978401184\n",
      "[NOR] Episode: 20160, Length: 93, e: 0.05, Avg Reward: -159.402044594, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.07083320618\n",
      "[NOR] Episode: 20170, Length: 66, e: 0.05, Avg Reward: -99.2603878326, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.72779512405\n",
      "[NOR] Episode: 20180, Length: 85, e: 0.05, Avg Reward: -121.666512869, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.6874771118\n",
      "[NOR] Episode: 20190, Length: 59, e: 0.05, Avg Reward: -125.740981396, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 86.299331665\n",
      "[NOR] Episode: 20200, Length: 87, e: 0.05, Avg Reward: -150.306706764, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.64617490768\n",
      "[NOR] Episode: 20210, Length: 85, e: 0.05, Avg Reward: -146.630411363, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.26415228844\n",
      "[NOR] Episode: 20220, Length: 54, e: 0.05, Avg Reward: -129.547699566, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.85706233978\n",
      "[NOR] Episode: 20230, Length: 53, e: 0.05, Avg Reward: -156.928105614, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.26937675476\n",
      "[NOR] Episode: 20240, Length: 51, e: 0.05, Avg Reward: -140.989438742, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.15241384506\n",
      "[NOR] Episode: 20250, Length: 62, e: 0.05, Avg Reward: -117.36656952, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.89974403381\n",
      "[NOR] Episode: 20260, Length: 61, e: 0.05, Avg Reward: -111.964960621, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 38.3801040649\n",
      "[NOR] Episode: 20270, Length: 74, e: 0.05, Avg Reward: -97.9418897338, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.3052444458\n",
      "[NOR] Episode: 20280, Length: 78, e: 0.05, Avg Reward: -141.172106245, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 27.3590888977\n",
      "[NOR] Episode: 20290, Length: 61, e: 0.05, Avg Reward: -131.813918641, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -68.273147583\n",
      "[NOR] Episode: 20300, Length: 68, e: 0.05, Avg Reward: -152.524368207, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.8193924427\n",
      "[NOR] Episode: 20310, Length: 84, e: 0.05, Avg Reward: -182.945609364, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.27801322937\n",
      "[NOR] Episode: 20320, Length: 59, e: 0.05, Avg Reward: -149.744754859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 160.862640381\n",
      "[NOR] Episode: 20330, Length: 64, e: 0.05, Avg Reward: -139.620746056, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.06159210205\n",
      "[NOR] Episode: 20340, Length: 88, e: 0.05, Avg Reward: -138.58359433, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.1509857178\n",
      "[NOR] Episode: 20350, Length: 58, e: 0.05, Avg Reward: -96.3897595144, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.5210227966\n",
      "[NOR] Episode: 20360, Length: 81, e: 0.05, Avg Reward: -121.881181485, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.73938703537\n",
      "[NOR] Episode: 20370, Length: 85, e: 0.05, Avg Reward: -90.6289142558, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 75.0972595215\n",
      "[NOR] Episode: 20380, Length: 56, e: 0.05, Avg Reward: -99.4327224415, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.91449093819\n",
      "[NOR] Episode: 20390, Length: 62, e: 0.05, Avg Reward: -77.4197670676, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.918012142181\n",
      "[NOR] Episode: 20400, Length: 91, e: 0.05, Avg Reward: -108.726948298, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.7429485321\n",
      "[NOR] Episode: 20410, Length: 69, e: 0.05, Avg Reward: -124.542423171, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.4939918518\n",
      "[NOR] Episode: 20420, Length: 59, e: 0.05, Avg Reward: -156.078749792, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.5050296783\n",
      "[NOR] Episode: 20430, Length: 86, e: 0.05, Avg Reward: -103.918478323, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.64360523224\n",
      "[NOR] Episode: 20440, Length: 64, e: 0.05, Avg Reward: -155.673220595, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.93757867813\n",
      "[NOR] Episode: 20450, Length: 62, e: 0.05, Avg Reward: -65.1633673712, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.95004749298\n",
      "[NOR] Episode: 20460, Length: 70, e: 0.05, Avg Reward: -137.990589048, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.5112628937\n",
      "[NOR] Episode: 20470, Length: 74, e: 0.05, Avg Reward: -109.494495263, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.7968959808\n",
      "[NOR] Episode: 20480, Length: 93, e: 0.05, Avg Reward: -124.792336719, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.6638460159\n",
      "[NOR] Episode: 20490, Length: 69, e: 0.05, Avg Reward: -158.737867252, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.6661605835\n",
      "[NOR] Episode: 20500, Length: 68, e: 0.05, Avg Reward: -105.958057056, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.686589241\n",
      "[NOR] Episode: 20510, Length: 88, e: 0.05, Avg Reward: -129.761101827, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.2628235817\n",
      "[NOR] Episode: 20520, Length: 85, e: 0.05, Avg Reward: -100.086384812, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 76.8671646118\n",
      "[NOR] Episode: 20530, Length: 63, e: 0.05, Avg Reward: -85.3917455516, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.5101661682\n",
      "[NOR] Episode: 20540, Length: 61, e: 0.05, Avg Reward: -110.492294106, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.5636348724\n",
      "[NOR] Episode: 20550, Length: 69, e: 0.05, Avg Reward: -118.297464122, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -85.2242050171\n",
      "[NOR] Episode: 20560, Length: 82, e: 0.05, Avg Reward: -105.01646148, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.4130382538\n",
      "[NOR] Episode: 20570, Length: 88, e: 0.05, Avg Reward: -157.490949505, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.68790006638\n",
      "[NOR] Episode: 20580, Length: 92, e: 0.05, Avg Reward: -84.9714133579, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.42499923706\n",
      "[NOR] Episode: 20590, Length: 88, e: 0.05, Avg Reward: -103.290762369, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.30905914307\n",
      "[NOR] Episode: 20600, Length: 58, e: 0.05, Avg Reward: -99.9150878967, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.020690918\n",
      "[NOR] Episode: 20610, Length: 98, e: 0.05, Avg Reward: -126.211731395, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.55859947205\n",
      "[NOR] Episode: 20620, Length: 61, e: 0.05, Avg Reward: -80.4019664082, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.76847648621\n",
      "[NOR] Episode: 20630, Length: 65, e: 0.05, Avg Reward: -119.364724843, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.6896209717\n",
      "[NOR] Episode: 20640, Length: 75, e: 0.05, Avg Reward: -171.709539529, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.446023941\n",
      "[NOR] Episode: 20650, Length: 84, e: 0.05, Avg Reward: -170.359166082, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.15188694\n",
      "[NOR] Episode: 20660, Length: 84, e: 0.05, Avg Reward: -112.339429337, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.0592498779\n",
      "[NOR] Episode: 20670, Length: 81, e: 0.05, Avg Reward: -165.88925145, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.1619434357\n",
      "[NOR] Episode: 20680, Length: 74, e: 0.05, Avg Reward: -111.1444079, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.7744941711\n",
      "[NOR] Episode: 20690, Length: 89, e: 0.05, Avg Reward: -168.195520295, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.4577217102\n",
      "[NOR] Episode: 20700, Length: 87, e: 0.05, Avg Reward: -157.612908769, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.8430366516\n",
      "[NOR] Episode: 20710, Length: 87, e: 0.05, Avg Reward: -154.594883326, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.0323104858\n",
      "[NOR] Episode: 20720, Length: 82, e: 0.05, Avg Reward: -175.347038391, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.2267665863\n",
      "[NOR] Episode: 20730, Length: 101, e: 0.05, Avg Reward: -174.34280669, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -118.133865356\n",
      "[NOR] Episode: 20740, Length: 58, e: 0.05, Avg Reward: -166.608989939, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 38.2298431396\n",
      "[NOR] Episode: 20750, Length: 67, e: 0.05, Avg Reward: -156.82940166, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.485445022583\n",
      "[NOR] Episode: 20760, Length: 73, e: 0.05, Avg Reward: -173.332717089, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.91833305359\n",
      "[NOR] Episode: 20770, Length: 71, e: 0.05, Avg Reward: -171.974033663, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.5412406921\n",
      "[NOR] Episode: 20780, Length: 87, e: 0.05, Avg Reward: -181.646351661, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.2930526733\n",
      "[NOR] Episode: 20790, Length: 59, e: 0.05, Avg Reward: -157.95562245, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.12918329239\n",
      "[NOR] Episode: 20800, Length: 82, e: 0.05, Avg Reward: -179.492321395, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.3158922195\n",
      "[NOR] Episode: 20810, Length: 76, e: 0.05, Avg Reward: -203.915651359, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.75621080399\n",
      "[NOR] Episode: 20820, Length: 77, e: 0.05, Avg Reward: -178.221223648, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.7775306702\n",
      "[NOR] Episode: 20830, Length: 88, e: 0.05, Avg Reward: -151.432718586, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.2580242157\n",
      "[NOR] Episode: 20840, Length: 78, e: 0.05, Avg Reward: -164.4471261, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.886390686\n",
      "[NOR] Episode: 20850, Length: 96, e: 0.05, Avg Reward: -153.565152568, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.0390791893\n",
      "[NOR] Episode: 20860, Length: 76, e: 0.05, Avg Reward: -172.800197612, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.2198638916\n",
      "[NOR] Episode: 20870, Length: 61, e: 0.05, Avg Reward: -141.913012397, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.664894104\n",
      "[NOR] Episode: 20880, Length: 65, e: 0.05, Avg Reward: -191.899556513, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.871089816093\n",
      "[NOR] Episode: 20890, Length: 83, e: 0.05, Avg Reward: -131.189931555, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.0095710754\n",
      "[NOR] Episode: 20900, Length: 95, e: 0.05, Avg Reward: -154.753620903, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.6858978271\n",
      "[NOR] Episode: 20910, Length: 65, e: 0.05, Avg Reward: -179.117802583, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.42865896225\n",
      "[NOR] Episode: 20920, Length: 50, e: 0.05, Avg Reward: -164.111383178, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.61001396179\n",
      "[NOR] Episode: 20930, Length: 86, e: 0.05, Avg Reward: -150.105177106, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.47000837326\n",
      "[NOR] Episode: 20940, Length: 111, e: 0.05, Avg Reward: -187.978699022, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.4117193222\n",
      "[NOR] Episode: 20950, Length: 70, e: 0.05, Avg Reward: -180.022918878, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.9191207886\n",
      "[NOR] Episode: 20960, Length: 94, e: 0.05, Avg Reward: -178.153901203, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -75.270904541\n",
      "[NOR] Episode: 20970, Length: 64, e: 0.05, Avg Reward: -143.800130014, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.8361434937\n",
      "[NOR] Episode: 20980, Length: 60, e: 0.05, Avg Reward: -137.712456064, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.1208744049\n",
      "[NOR] Episode: 20990, Length: 78, e: 0.05, Avg Reward: -182.725559678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.2681491375\n",
      "[NOR] Episode: 21000, Length: 65, e: 0.05, Avg Reward: -161.800002622, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.0959720612\n",
      "[NOR] Episode: 21010, Length: 53, e: 0.05, Avg Reward: -182.004568888, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.8324816227\n",
      "[NOR] Episode: 21020, Length: 85, e: 0.05, Avg Reward: -178.792429276, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.2996063232\n",
      "[NOR] Episode: 21030, Length: 57, e: 0.05, Avg Reward: -152.778188151, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.70676469803\n",
      "[NOR] Episode: 21040, Length: 52, e: 0.05, Avg Reward: -189.314234683, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.5458908081\n",
      "[NOR] Episode: 21050, Length: 84, e: 0.05, Avg Reward: -173.08168009, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.3632106781\n",
      "[NOR] Episode: 21060, Length: 90, e: 0.05, Avg Reward: -215.218219133, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.48580360413\n",
      "[NOR] Episode: 21070, Length: 76, e: 0.05, Avg Reward: -181.393335653, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.87903118134\n",
      "[NOR] Episode: 21080, Length: 84, e: 0.05, Avg Reward: -181.407135208, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.74141550064\n",
      "[NOR] Episode: 21090, Length: 72, e: 0.05, Avg Reward: -161.325118401, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.97699737549\n",
      "[NOR] Episode: 21100, Length: 70, e: 0.05, Avg Reward: -174.382764108, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.54057025909\n",
      "[NOR] Episode: 21110, Length: 53, e: 0.05, Avg Reward: -179.233107029, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.8156042099\n",
      "[NOR] Episode: 21120, Length: 73, e: 0.05, Avg Reward: -183.915215667, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.03679633141\n",
      "[NOR] Episode: 21130, Length: 76, e: 0.05, Avg Reward: -166.480426468, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.10718345642\n",
      "[NOR] Episode: 21140, Length: 87, e: 0.05, Avg Reward: -194.440397065, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.9503173828\n",
      "[NOR] Episode: 21150, Length: 76, e: 0.05, Avg Reward: -189.769620498, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.9432439804\n",
      "[NOR] Episode: 21160, Length: 63, e: 0.05, Avg Reward: -152.258174871, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.94326257706\n",
      "[NOR] Episode: 21170, Length: 52, e: 0.05, Avg Reward: -176.328491078, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.2373771667\n",
      "[NOR] Episode: 21180, Length: 69, e: 0.05, Avg Reward: -178.400738621, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.06201171875\n",
      "[NOR] Episode: 21190, Length: 62, e: 0.05, Avg Reward: -221.93672102, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.0672531128\n",
      "[NOR] Episode: 21200, Length: 59, e: 0.05, Avg Reward: -157.228735096, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.8099384308\n",
      "[NOR] Episode: 21210, Length: 89, e: 0.05, Avg Reward: -190.664890354, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.6918392181\n",
      "[NOR] Episode: 21220, Length: 75, e: 0.05, Avg Reward: -153.937096097, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.405349493027\n",
      "[NOR] Episode: 21230, Length: 51, e: 0.05, Avg Reward: -190.973332448, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.85250759125\n",
      "[NOR] Episode: 21240, Length: 60, e: 0.05, Avg Reward: -173.574432276, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.0487728119\n",
      "[NOR] Episode: 21250, Length: 64, e: 0.05, Avg Reward: -156.810110508, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.2137107849\n",
      "[NOR] Episode: 21260, Length: 60, e: 0.05, Avg Reward: -173.821156868, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.57584857941\n",
      "[NOR] Episode: 21270, Length: 84, e: 0.05, Avg Reward: -164.692425664, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.37737846375\n",
      "[NOR] Episode: 21280, Length: 61, e: 0.05, Avg Reward: -157.248221411, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.2721061707\n",
      "[NOR] Episode: 21290, Length: 67, e: 0.05, Avg Reward: -166.077727479, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.4958763123\n",
      "[NOR] Episode: 21300, Length: 80, e: 0.05, Avg Reward: -156.031252306, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.0046348572\n",
      "[NOR] Episode: 21310, Length: 61, e: 0.05, Avg Reward: -167.865421194, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.8639087677\n",
      "[NOR] Episode: 21320, Length: 65, e: 0.05, Avg Reward: -142.162861948, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.9263057709\n",
      "[NOR] Episode: 21330, Length: 77, e: 0.05, Avg Reward: -108.156557678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.3391418457\n",
      "[NOR] Episode: 21340, Length: 63, e: 0.05, Avg Reward: -160.926626755, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.57843494415\n",
      "[NOR] Episode: 21350, Length: 92, e: 0.05, Avg Reward: -92.9224380267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.5997600555\n",
      "[NOR] Episode: 21360, Length: 76, e: 0.05, Avg Reward: -160.885318051, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.19692611694\n",
      "[NOR] Episode: 21370, Length: 78, e: 0.05, Avg Reward: -216.369897677, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.5662336349\n",
      "[NOR] Episode: 21380, Length: 72, e: 0.05, Avg Reward: -147.801870258, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.9584741592\n",
      "[NOR] Episode: 21390, Length: 68, e: 0.05, Avg Reward: -117.450451473, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.27496623993\n",
      "[NOR] Episode: 21400, Length: 102, e: 0.05, Avg Reward: -169.316026224, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.3058719635\n",
      "[NOR] Episode: 21410, Length: 85, e: 0.05, Avg Reward: -151.03427248, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 46.3937301636\n",
      "[NOR] Episode: 21420, Length: 96, e: 0.05, Avg Reward: -126.186365134, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.7656936646\n",
      "[NOR] Episode: 21430, Length: 71, e: 0.05, Avg Reward: -172.076971295, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.1010532379\n",
      "[NOR] Episode: 21440, Length: 85, e: 0.05, Avg Reward: -145.644861245, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.2931442261\n",
      "[NOR] Episode: 21450, Length: 68, e: 0.05, Avg Reward: -208.797631572, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.6729679108\n",
      "[NOR] Episode: 21460, Length: 81, e: 0.05, Avg Reward: -184.440780574, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.50905895233\n",
      "[NOR] Episode: 21470, Length: 81, e: 0.05, Avg Reward: -160.597773764, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.2666683197\n",
      "[NOR] Episode: 21480, Length: 73, e: 0.05, Avg Reward: -176.619492666, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -36.6436157227\n",
      "[NOR] Episode: 21490, Length: 106, e: 0.05, Avg Reward: -187.962864354, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.27475357056\n",
      "[NOR] Episode: 21500, Length: 70, e: 0.05, Avg Reward: -186.507257983, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.8201351166\n",
      "[NOR] Episode: 21510, Length: 56, e: 0.05, Avg Reward: -181.102972696, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.1697921753\n",
      "[NOR] Episode: 21520, Length: 74, e: 0.05, Avg Reward: -225.718165998, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.6921195984\n",
      "[NOR] Episode: 21530, Length: 56, e: 0.05, Avg Reward: -209.771995259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.665245056152\n",
      "[NOR] Episode: 21540, Length: 62, e: 0.05, Avg Reward: -184.04533015, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.6373596191\n",
      "[NOR] Episode: 21550, Length: 53, e: 0.05, Avg Reward: -199.991016387, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.75523948669\n",
      "[NOR] Episode: 21560, Length: 95, e: 0.05, Avg Reward: -202.669845907, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.9851617813\n",
      "[NOR] Episode: 21570, Length: 71, e: 0.05, Avg Reward: -165.654339993, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.7697467804\n",
      "[NOR] Episode: 21580, Length: 64, e: 0.05, Avg Reward: -185.340546208, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 28.9447898865\n",
      "[NOR] Episode: 21590, Length: 69, e: 0.05, Avg Reward: -158.190826022, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.41215324402\n",
      "[NOR] Episode: 21600, Length: 66, e: 0.05, Avg Reward: -185.146116125, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -50.0238761902\n",
      "[NOR] Episode: 21610, Length: 74, e: 0.05, Avg Reward: -186.428547926, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.6621723175\n",
      "[NOR] Episode: 21620, Length: 76, e: 0.05, Avg Reward: -162.664161754, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.9730224609\n",
      "[NOR] Episode: 21630, Length: 68, e: 0.05, Avg Reward: -169.636390329, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.936267614365\n",
      "[NOR] Episode: 21640, Length: 66, e: 0.05, Avg Reward: -209.220785101, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.857566833496\n",
      "[NOR] Episode: 21650, Length: 76, e: 0.05, Avg Reward: -181.141300375, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.3989334106\n",
      "[NOR] Episode: 21660, Length: 62, e: 0.05, Avg Reward: -136.751519121, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 55.6684494019\n",
      "[NOR] Episode: 21670, Length: 77, e: 0.05, Avg Reward: -145.639939719, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.89568090439\n",
      "[NOR] Episode: 21680, Length: 70, e: 0.05, Avg Reward: -147.41671907, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.98287200928\n",
      "[NOR] Episode: 21690, Length: 88, e: 0.05, Avg Reward: -159.897662871, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -87.3073425293\n",
      "[NOR] Episode: 21700, Length: 55, e: 0.05, Avg Reward: -151.738866213, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.5027198792\n",
      "[NOR] Episode: 21710, Length: 92, e: 0.05, Avg Reward: -183.225309149, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.3259506226\n",
      "[NOR] Episode: 21720, Length: 65, e: 0.05, Avg Reward: -133.242841373, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.77154445648\n",
      "[NOR] Episode: 21730, Length: 74, e: 0.05, Avg Reward: -140.229447653, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.68920946121\n",
      "[NOR] Episode: 21740, Length: 71, e: 0.05, Avg Reward: -142.53454487, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -48.5150260925\n",
      "[NOR] Episode: 21750, Length: 64, e: 0.05, Avg Reward: -144.105887199, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 40.6092338562\n",
      "[NOR] Episode: 21760, Length: 82, e: 0.05, Avg Reward: -199.036595964, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.6888809204\n",
      "[NOR] Episode: 21770, Length: 60, e: 0.05, Avg Reward: -153.45790453, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.0658969879\n",
      "[NOR] Episode: 21780, Length: 64, e: 0.05, Avg Reward: -183.333730712, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.1705436707\n",
      "[NOR] Episode: 21790, Length: 83, e: 0.05, Avg Reward: -134.419669681, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 38.0145950317\n",
      "[NOR] Episode: 21800, Length: 73, e: 0.05, Avg Reward: -147.502393999, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.0132102966\n",
      "[NOR] Episode: 21810, Length: 74, e: 0.05, Avg Reward: -167.598428357, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.4741210938\n",
      "[NOR] Episode: 21820, Length: 66, e: 0.05, Avg Reward: -162.317599135, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.1334190369\n",
      "[NOR] Episode: 21830, Length: 68, e: 0.05, Avg Reward: -161.049191259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.9480705261\n",
      "[NOR] Episode: 21840, Length: 64, e: 0.05, Avg Reward: -153.413682546, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.59837198257\n",
      "[NOR] Episode: 21850, Length: 67, e: 0.05, Avg Reward: -117.507334379, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.1762809753\n",
      "[NOR] Episode: 21860, Length: 74, e: 0.05, Avg Reward: -138.321283499, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.95586299896\n",
      "[NOR] Episode: 21870, Length: 78, e: 0.05, Avg Reward: -138.01468693, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.6010446548\n",
      "[NOR] Episode: 21880, Length: 72, e: 0.05, Avg Reward: -157.686036444, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.9263896942\n",
      "[NOR] Episode: 21890, Length: 90, e: 0.05, Avg Reward: -123.119195815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.1421394348\n",
      "[NOR] Episode: 21900, Length: 88, e: 0.05, Avg Reward: -172.48027354, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -59.854598999\n",
      "[NOR] Episode: 21910, Length: 93, e: 0.05, Avg Reward: -148.523148589, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.45731735229\n",
      "[NOR] Episode: 21920, Length: 69, e: 0.05, Avg Reward: -110.99397677, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.6402592659\n",
      "[NOR] Episode: 21930, Length: 72, e: 0.05, Avg Reward: -139.684045245, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.84708786011\n",
      "[NOR] Episode: 21940, Length: 65, e: 0.05, Avg Reward: -143.138891545, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.1633481979\n",
      "[NOR] Episode: 21950, Length: 69, e: 0.05, Avg Reward: -153.917526334, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.8736877441\n",
      "[NOR] Episode: 21960, Length: 79, e: 0.05, Avg Reward: -139.226340508, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.9465141296\n",
      "[NOR] Episode: 21970, Length: 91, e: 0.05, Avg Reward: -136.841826686, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.79347848892\n",
      "[NOR] Episode: 21980, Length: 85, e: 0.05, Avg Reward: -138.435218255, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.9949636459\n",
      "[NOR] Episode: 21990, Length: 96, e: 0.05, Avg Reward: -117.205541257, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 32.6085739136\n",
      "[NOR] Episode: 22000, Length: 51, e: 0.05, Avg Reward: -172.748463802, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.6583194733\n",
      "[NOR] Episode: 22010, Length: 69, e: 0.05, Avg Reward: -128.443331359, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 32.3561706543\n",
      "[NOR] Episode: 22020, Length: 71, e: 0.05, Avg Reward: -143.362687558, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.3151464462\n",
      "[NOR] Episode: 22030, Length: 63, e: 0.05, Avg Reward: -120.717510152, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.85159873962\n",
      "[NOR] Episode: 22040, Length: 79, e: 0.05, Avg Reward: -131.645542547, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.17722225189\n",
      "[NOR] Episode: 22050, Length: 64, e: 0.05, Avg Reward: -153.675187252, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.04137611389\n",
      "[NOR] Episode: 22060, Length: 70, e: 0.05, Avg Reward: -193.10480697, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.70385169983\n",
      "[NOR] Episode: 22070, Length: 58, e: 0.05, Avg Reward: -179.86067092, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 28.6983795166\n",
      "[NOR] Episode: 22080, Length: 89, e: 0.05, Avg Reward: -147.353433109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.35666656494\n",
      "[NOR] Episode: 22090, Length: 84, e: 0.05, Avg Reward: -198.641106449, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -48.1473808289\n",
      "[NOR] Episode: 22100, Length: 96, e: 0.05, Avg Reward: -149.495004236, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 28.4411277771\n",
      "[NOR] Episode: 22110, Length: 60, e: 0.05, Avg Reward: -175.189635817, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.8402786255\n",
      "[NOR] Episode: 22120, Length: 57, e: 0.05, Avg Reward: -152.005348884, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.92574071884\n",
      "[NOR] Episode: 22130, Length: 73, e: 0.05, Avg Reward: -168.243901413, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.8720741272\n",
      "[NOR] Episode: 22140, Length: 86, e: 0.05, Avg Reward: -186.161006911, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.2428836823\n",
      "[NOR] Episode: 22150, Length: 64, e: 0.05, Avg Reward: -184.477608182, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.02752184868\n",
      "[NOR] Episode: 22160, Length: 70, e: 0.05, Avg Reward: -190.360458206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.006072998\n",
      "[NOR] Episode: 22170, Length: 79, e: 0.05, Avg Reward: -149.757239671, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.1775131226\n",
      "[NOR] Episode: 22180, Length: 88, e: 0.05, Avg Reward: -162.004612708, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.9601421356\n",
      "[NOR] Episode: 22190, Length: 60, e: 0.05, Avg Reward: -143.120432066, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.0188484192\n",
      "[NOR] Episode: 22200, Length: 85, e: 0.05, Avg Reward: -164.564921227, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.9088115692\n",
      "[NOR] Episode: 22210, Length: 57, e: 0.05, Avg Reward: -135.397000082, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.94940567017\n",
      "[NOR] Episode: 22220, Length: 84, e: 0.05, Avg Reward: -154.347654159, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.5585327148\n",
      "[NOR] Episode: 22230, Length: 62, e: 0.05, Avg Reward: -176.130477858, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.9196624756\n",
      "[NOR] Episode: 22240, Length: 69, e: 0.05, Avg Reward: -171.960181615, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 32.698638916\n",
      "[NOR] Episode: 22250, Length: 121, e: 0.05, Avg Reward: -188.614350335, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.32348632812\n",
      "[NOR] Episode: 22260, Length: 96, e: 0.05, Avg Reward: -160.330778827, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.6665248871\n",
      "[NOR] Episode: 22270, Length: 54, e: 0.05, Avg Reward: -164.055658646, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.8160762787\n",
      "[NOR] Episode: 22280, Length: 78, e: 0.05, Avg Reward: -149.465546586, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.0687084198\n",
      "[NOR] Episode: 22290, Length: 66, e: 0.05, Avg Reward: -150.193248604, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.91074943542\n",
      "[NOR] Episode: 22300, Length: 72, e: 0.05, Avg Reward: -170.938308501, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.2635564804\n",
      "[NOR] Episode: 22310, Length: 60, e: 0.05, Avg Reward: -167.174520421, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.69658613205\n",
      "[NOR] Episode: 22320, Length: 57, e: 0.05, Avg Reward: -163.915830055, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.1753635406\n",
      "[NOR] Episode: 22330, Length: 64, e: 0.05, Avg Reward: -130.274562861, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.98997974396\n",
      "[NOR] Episode: 22340, Length: 70, e: 0.05, Avg Reward: -170.195169119, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.902929306\n",
      "[NOR] Episode: 22350, Length: 66, e: 0.05, Avg Reward: -155.997158953, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.02686452866\n",
      "[NOR] Episode: 22360, Length: 55, e: 0.05, Avg Reward: -147.038988239, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.60381364822\n",
      "[NOR] Episode: 22370, Length: 64, e: 0.05, Avg Reward: -152.214970739, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.68914794922\n",
      "[NOR] Episode: 22380, Length: 57, e: 0.05, Avg Reward: -141.863914987, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.48864078522\n",
      "[NOR] Episode: 22390, Length: 68, e: 0.05, Avg Reward: -158.928674532, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.5780820847\n",
      "[NOR] Episode: 22400, Length: 95, e: 0.05, Avg Reward: -157.409705656, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.3723297119\n",
      "[NOR] Episode: 22410, Length: 77, e: 0.05, Avg Reward: -159.727680178, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.7726707458\n",
      "[NOR] Episode: 22420, Length: 62, e: 0.05, Avg Reward: -170.098637572, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.8781433105\n",
      "[NOR] Episode: 22430, Length: 80, e: 0.05, Avg Reward: -138.097643208, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.75277137756\n",
      "[NOR] Episode: 22440, Length: 88, e: 0.05, Avg Reward: -139.243138611, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.90652418137\n",
      "[NOR] Episode: 22450, Length: 82, e: 0.05, Avg Reward: -170.554632278, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.8994541168\n",
      "[NOR] Episode: 22460, Length: 75, e: 0.05, Avg Reward: -165.242675006, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.5784988403\n",
      "[NOR] Episode: 22470, Length: 95, e: 0.05, Avg Reward: -105.795938513, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.6352291107\n",
      "[NOR] Episode: 22480, Length: 63, e: 0.05, Avg Reward: -146.07641646, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.24273109436\n",
      "[NOR] Episode: 22490, Length: 87, e: 0.05, Avg Reward: -145.851990508, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.4901199341\n",
      "[NOR] Episode: 22500, Length: 76, e: 0.05, Avg Reward: -146.847533843, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.66503810883\n",
      "[NOR] Episode: 22510, Length: 53, e: 0.05, Avg Reward: -132.845967404, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.460239648819\n",
      "[NOR] Episode: 22520, Length: 70, e: 0.05, Avg Reward: -124.542330113, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -44.0540122986\n",
      "[NOR] Episode: 22530, Length: 63, e: 0.05, Avg Reward: -139.955572109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.2507953644\n",
      "[NOR] Episode: 22540, Length: 63, e: 0.05, Avg Reward: -158.353336679, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.7090301514\n",
      "[NOR] Episode: 22550, Length: 60, e: 0.05, Avg Reward: -156.597746871, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 35.8308258057\n",
      "[NOR] Episode: 22560, Length: 75, e: 0.05, Avg Reward: -142.982932976, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.121307373\n",
      "[NOR] Episode: 22570, Length: 89, e: 0.05, Avg Reward: -146.377687747, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.117767334\n",
      "[NOR] Episode: 22580, Length: 57, e: 0.05, Avg Reward: -154.520663308, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.7583026886\n",
      "[NOR] Episode: 22590, Length: 100, e: 0.05, Avg Reward: -135.455551586, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.93454813957\n",
      "[NOR] Episode: 22600, Length: 80, e: 0.05, Avg Reward: -141.03060985, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.88965415955\n",
      "[NOR] Episode: 22610, Length: 63, e: 0.05, Avg Reward: -138.829176233, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.65426826477\n",
      "[NOR] Episode: 22620, Length: 60, e: 0.05, Avg Reward: -145.437320774, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.3753261566\n",
      "[NOR] Episode: 22630, Length: 86, e: 0.05, Avg Reward: -102.45134489, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.9263553619\n",
      "[NOR] Episode: 22640, Length: 73, e: 0.05, Avg Reward: -107.660904287, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.1534881592\n",
      "[NOR] Episode: 22650, Length: 77, e: 0.05, Avg Reward: -155.351895602, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.29853439331\n",
      "[NOR] Episode: 22660, Length: 59, e: 0.05, Avg Reward: -132.537584445, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.0194149017\n",
      "[NOR] Episode: 22670, Length: 75, e: 0.05, Avg Reward: -130.331157965, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.5607185364\n",
      "[NOR] Episode: 22680, Length: 67, e: 0.05, Avg Reward: -140.870663149, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.5673761368\n",
      "[NOR] Episode: 22690, Length: 72, e: 0.05, Avg Reward: -153.691483681, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.351678967476\n",
      "[NOR] Episode: 22700, Length: 52, e: 0.05, Avg Reward: -132.347305096, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -78.8407287598\n",
      "[NOR] Episode: 22710, Length: 123, e: 0.05, Avg Reward: -113.697134969, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.7933521271\n",
      "[NOR] Episode: 22720, Length: 96, e: 0.05, Avg Reward: -119.644168522, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.05251693726\n",
      "[NOR] Episode: 22730, Length: 140, e: 0.05, Avg Reward: -149.847789024, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.86878919601\n",
      "[NOR] Episode: 22740, Length: 151, e: 0.05, Avg Reward: -85.7827235331, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.83731174469\n",
      "[NOR] Episode: 22750, Length: 85, e: 0.05, Avg Reward: -103.111764332, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.01715278625\n",
      "[NOR] Episode: 22760, Length: 72, e: 0.05, Avg Reward: -122.241849907, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.7068653107\n",
      "[NOR] Episode: 22770, Length: 93, e: 0.05, Avg Reward: -115.042850549, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.312809944153\n",
      "[NOR] Episode: 22780, Length: 81, e: 0.05, Avg Reward: -145.302374983, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.63830900192\n",
      "[NOR] Episode: 22790, Length: 120, e: 0.05, Avg Reward: -131.971119114, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.2564926147\n",
      "[NOR] Episode: 22800, Length: 56, e: 0.05, Avg Reward: -163.636437228, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.593596935272\n",
      "[NOR] Episode: 22810, Length: 86, e: 0.05, Avg Reward: -137.272101814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.56405544281\n",
      "[NOR] Episode: 22820, Length: 86, e: 0.05, Avg Reward: -105.264738139, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.92792797089\n",
      "[NOR] Episode: 22830, Length: 309, e: 0.05, Avg Reward: -88.8755072678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.14779281616\n",
      "[NOR] Episode: 22840, Length: 96, e: 0.05, Avg Reward: -88.0620764468, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.49880695343\n",
      "[NOR] Episode: 22850, Length: 451, e: 0.05, Avg Reward: -132.361302041, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.0190019608\n",
      "[NOR] Episode: 22860, Length: 302, e: 0.05, Avg Reward: -125.002202318, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.9308595657\n",
      "[NOR] Episode: 22870, Length: 143, e: 0.05, Avg Reward: -147.98967594, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.6030778885\n",
      "[NOR] Episode: 22880, Length: 183, e: 0.05, Avg Reward: -146.845010567, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.7147254944\n",
      "[NOR] Episode: 22890, Length: 179, e: 0.05, Avg Reward: -135.538785991, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.9058952332\n",
      "[NOR] Episode: 22900, Length: 246, e: 0.05, Avg Reward: -151.986135104, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.73734331131\n",
      "[NOR] Episode: 22910, Length: 71, e: 0.05, Avg Reward: -111.579547471, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.09097862244\n",
      "[NOR] Episode: 22920, Length: 69, e: 0.05, Avg Reward: -175.990479253, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.68085479736\n",
      "[NOR] Episode: 22930, Length: 68, e: 0.05, Avg Reward: -169.764574311, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.92657089233\n",
      "[NOR] Episode: 22940, Length: 143, e: 0.05, Avg Reward: -166.80611935, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.5968961716\n",
      "[NOR] Episode: 22950, Length: 128, e: 0.05, Avg Reward: -152.130280708, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 40.1647262573\n",
      "[NOR] Episode: 22960, Length: 221, e: 0.05, Avg Reward: -186.458600272, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.1437397003\n",
      "[NOR] Episode: 22970, Length: 60, e: 0.05, Avg Reward: -165.804958659, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.6050319672\n",
      "[NOR] Episode: 22980, Length: 197, e: 0.05, Avg Reward: -217.625883991, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.9066762924\n",
      "[NOR] Episode: 22990, Length: 82, e: 0.05, Avg Reward: -189.968965783, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.4998245239\n",
      "[NOR] Episode: 23000, Length: 64, e: 0.05, Avg Reward: -205.2120939, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.8872013092\n",
      "[NOR] Episode: 23010, Length: 87, e: 0.05, Avg Reward: -156.831999054, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.26032066345\n",
      "[NOR] Episode: 23020, Length: 91, e: 0.05, Avg Reward: -171.712990544, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.5025463104\n",
      "[NOR] Episode: 23030, Length: 51, e: 0.05, Avg Reward: -189.248572666, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.3330001831\n",
      "[NOR] Episode: 23040, Length: 101, e: 0.05, Avg Reward: -163.868581324, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.23478364944\n",
      "[NOR] Episode: 23050, Length: 220, e: 0.05, Avg Reward: -176.878483413, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.1759462357\n",
      "[NOR] Episode: 23060, Length: 122, e: 0.05, Avg Reward: -169.153106716, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.1943025589\n",
      "[NOR] Episode: 23070, Length: 137, e: 0.05, Avg Reward: -165.896628708, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.56383800507\n",
      "[NOR] Episode: 23080, Length: 137, e: 0.05, Avg Reward: -127.695483787, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.14211606979\n",
      "[NOR] Episode: 23090, Length: 90, e: 0.05, Avg Reward: -158.697587616, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.14602470398\n",
      "[NOR] Episode: 23100, Length: 111, e: 0.05, Avg Reward: -160.317584339, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.663983345\n",
      "[NOR] Episode: 23110, Length: 82, e: 0.05, Avg Reward: -173.524229336, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.5213060379\n",
      "[NOR] Episode: 23120, Length: 66, e: 0.05, Avg Reward: -169.175721723, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.5479755402\n",
      "[NOR] Episode: 23130, Length: 130, e: 0.05, Avg Reward: -127.719801242, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.8149032593\n",
      "[NOR] Episode: 23140, Length: 116, e: 0.05, Avg Reward: -110.470416704, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.9617023468\n",
      "[NOR] Episode: 23150, Length: 115, e: 0.05, Avg Reward: -144.20874502, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.47260951996\n",
      "[NOR] Episode: 23160, Length: 73, e: 0.05, Avg Reward: -167.471049539, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.91957950592\n",
      "[NOR] Episode: 23170, Length: 79, e: 0.05, Avg Reward: -148.775387636, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.25802326202\n",
      "[NOR] Episode: 23180, Length: 113, e: 0.05, Avg Reward: -161.175152014, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.98048782349\n",
      "[NOR] Episode: 23190, Length: 182, e: 0.05, Avg Reward: -171.439136838, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.10745239258\n",
      "[NOR] Episode: 23200, Length: 110, e: 0.05, Avg Reward: -163.476291696, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.18810606003\n",
      "[NOR] Episode: 23210, Length: 59, e: 0.05, Avg Reward: -145.216532753, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.13022995\n",
      "[NOR] Episode: 23220, Length: 129, e: 0.05, Avg Reward: -152.921742227, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.4926261902\n",
      "[NOR] Episode: 23230, Length: 115, e: 0.05, Avg Reward: -96.532642034, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.0417642593\n",
      "[NOR] Episode: 23240, Length: 69, e: 0.05, Avg Reward: -159.948954223, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 47.8765258789\n",
      "[NOR] Episode: 23250, Length: 83, e: 0.05, Avg Reward: -184.364337302, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.641416549683\n",
      "[NOR] Episode: 23260, Length: 144, e: 0.05, Avg Reward: -132.369870638, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.24161148071\n",
      "[NOR] Episode: 23270, Length: 119, e: 0.05, Avg Reward: -142.236528736, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.01249980927\n",
      "[NOR] Episode: 23280, Length: 55, e: 0.05, Avg Reward: -140.032685033, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.9858207703\n",
      "[NOR] Episode: 23290, Length: 423, e: 0.05, Avg Reward: -148.869968022, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.3556213379\n",
      "[NOR] Episode: 23300, Length: 112, e: 0.05, Avg Reward: -151.004174292, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.41226005554\n",
      "[NOR] Episode: 23310, Length: 282, e: 0.05, Avg Reward: -157.891987567, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.5305509567\n",
      "[NOR] Episode: 23320, Length: 98, e: 0.05, Avg Reward: -147.246254403, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.5923194885\n",
      "[NOR] Episode: 23330, Length: 57, e: 0.05, Avg Reward: -169.957882844, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.82415771484\n",
      "[NOR] Episode: 23340, Length: 125, e: 0.05, Avg Reward: -169.511941148, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.81057667732\n",
      "[NOR] Episode: 23350, Length: 58, e: 0.05, Avg Reward: -191.054751163, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.41891288757\n",
      "[NOR] Episode: 23360, Length: 79, e: 0.05, Avg Reward: -149.1477496, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.3902425766\n",
      "[NOR] Episode: 23370, Length: 136, e: 0.05, Avg Reward: -145.922874568, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.02472686768\n",
      "[NOR] Episode: 23380, Length: 83, e: 0.05, Avg Reward: -159.708950263, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.78577685356\n",
      "[NOR] Episode: 23390, Length: 150, e: 0.05, Avg Reward: -132.935734014, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 32.4517402649\n",
      "[NOR] Episode: 23400, Length: 190, e: 0.05, Avg Reward: -146.119444123, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.10573005676\n",
      "[NOR] Episode: 23410, Length: 154, e: 0.05, Avg Reward: -187.332936174, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.98575401306\n",
      "[NOR] Episode: 23420, Length: 63, e: 0.05, Avg Reward: -162.185805575, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.89327859879\n",
      "[NOR] Episode: 23430, Length: 153, e: 0.05, Avg Reward: -183.804970629, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.9905910492\n",
      "[NOR] Episode: 23440, Length: 88, e: 0.05, Avg Reward: -156.214635719, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.55558347702\n",
      "[NOR] Episode: 23450, Length: 57, e: 0.05, Avg Reward: -103.627907063, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.3665027618\n",
      "[NOR] Episode: 23460, Length: 160, e: 0.05, Avg Reward: -92.899563687, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.2255744934\n",
      "[NOR] Episode: 23470, Length: 122, e: 0.05, Avg Reward: -102.310052524, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.28556346893\n",
      "[NOR] Episode: 23480, Length: 113, e: 0.05, Avg Reward: -154.924326709, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.35168457031\n",
      "[NOR] Episode: 23490, Length: 88, e: 0.05, Avg Reward: -150.330737274, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.10949516296\n",
      "[NOR] Episode: 23500, Length: 109, e: 0.05, Avg Reward: -195.058659991, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.7944869995\n",
      "[NOR] Episode: 23510, Length: 219, e: 0.05, Avg Reward: -189.066853528, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.9516038895\n",
      "[NOR] Episode: 23520, Length: 222, e: 0.05, Avg Reward: -142.543272736, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.93339729309\n",
      "[NOR] Episode: 23530, Length: 75, e: 0.05, Avg Reward: -173.049835945, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.2951526642\n",
      "[NOR] Episode: 23540, Length: 77, e: 0.05, Avg Reward: -176.443544969, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.5575351715\n",
      "[NOR] Episode: 23550, Length: 98, e: 0.05, Avg Reward: -168.891885957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.26234054565\n",
      "[NOR] Episode: 23560, Length: 269, e: 0.05, Avg Reward: -183.837371311, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.766869902611\n",
      "[NOR] Episode: 23570, Length: 85, e: 0.05, Avg Reward: -175.643692281, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.2708091736\n",
      "[NOR] Episode: 23580, Length: 227, e: 0.05, Avg Reward: -140.236884434, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.57136249542\n",
      "[NOR] Episode: 23590, Length: 63, e: 0.05, Avg Reward: -163.927444384, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.1454181671\n",
      "[NOR] Episode: 23600, Length: 125, e: 0.05, Avg Reward: -184.538912909, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.0728902817\n",
      "[NOR] Episode: 23610, Length: 107, e: 0.05, Avg Reward: -168.64255142, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.0317249298\n",
      "[NOR] Episode: 23620, Length: 91, e: 0.05, Avg Reward: -126.551988305, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.8477363586\n",
      "[NOR] Episode: 23630, Length: 71, e: 0.05, Avg Reward: -169.50828164, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.37359237671\n",
      "[NOR] Episode: 23640, Length: 119, e: 0.05, Avg Reward: -145.244499832, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.8229322433\n",
      "[NOR] Episode: 23650, Length: 99, e: 0.05, Avg Reward: -158.611055798, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.00113630295\n",
      "[NOR] Episode: 23660, Length: 79, e: 0.05, Avg Reward: -130.112222624, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.687934041023\n",
      "[NOR] Episode: 23670, Length: 180, e: 0.05, Avg Reward: -115.777217902, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.5756530762\n",
      "[NOR] Episode: 23680, Length: 299, e: 0.05, Avg Reward: -61.9550145184, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.24235510826\n",
      "[NOR] Episode: 23690, Length: 71, e: 0.05, Avg Reward: -113.136000052, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.9510879517\n",
      "[NOR] Episode: 23700, Length: 124, e: 0.05, Avg Reward: -125.279641311, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.3582305908\n",
      "[NOR] Episode: 23710, Length: 89, e: 0.05, Avg Reward: -74.9303767129, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.5161056519\n",
      "[NOR] Episode: 23720, Length: 240, e: 0.05, Avg Reward: -111.246623829, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.9369058609\n",
      "[NOR] Episode: 23730, Length: 124, e: 0.05, Avg Reward: -91.6538758101, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.32177615166\n",
      "[NOR] Episode: 23740, Length: 115, e: 0.05, Avg Reward: -120.154424588, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.26186466217\n",
      "[NOR] Episode: 23750, Length: 115, e: 0.05, Avg Reward: -121.541476124, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.13660430908\n",
      "[NOR] Episode: 23760, Length: 166, e: 0.05, Avg Reward: -126.87056983, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.2097740173\n",
      "[NOR] Episode: 23770, Length: 230, e: 0.05, Avg Reward: -114.484812778, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.30388498306\n",
      "[NOR] Episode: 23780, Length: 145, e: 0.05, Avg Reward: -141.601639914, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 27.6964530945\n",
      "[NOR] Episode: 23790, Length: 69, e: 0.05, Avg Reward: -166.308724439, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.2761878967\n",
      "[NOR] Episode: 23800, Length: 108, e: 0.05, Avg Reward: -128.20376803, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.911529183388\n",
      "[NOR] Episode: 23810, Length: 93, e: 0.05, Avg Reward: -157.05706533, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.20781707764\n",
      "[NOR] Episode: 23820, Length: 206, e: 0.05, Avg Reward: -136.800281843, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.11940574646\n",
      "[NOR] Episode: 23830, Length: 603, e: 0.05, Avg Reward: -93.1790451849, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 46.4706954956\n",
      "[NOR] Episode: 23840, Length: 76, e: 0.05, Avg Reward: -114.894937051, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.370552063\n",
      "[NOR] Episode: 23850, Length: 90, e: 0.05, Avg Reward: -117.712750429, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.01558208466\n",
      "[NOR] Episode: 23860, Length: 209, e: 0.05, Avg Reward: -149.47919787, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.25962734222\n",
      "[NOR] Episode: 23870, Length: 129, e: 0.05, Avg Reward: -99.012751244, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.03821897507\n",
      "[NOR] Episode: 23880, Length: 78, e: 0.05, Avg Reward: -134.168936539, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.80543851852\n",
      "[NOR] Episode: 23890, Length: 135, e: 0.05, Avg Reward: -134.572521966, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.5930709839\n",
      "[NOR] Episode: 23900, Length: 85, e: 0.05, Avg Reward: -88.0615573695, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.11140394211\n",
      "[NOR] Episode: 23910, Length: 80, e: 0.05, Avg Reward: -137.370902436, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.11504936218\n",
      "[NOR] Episode: 23920, Length: 54, e: 0.05, Avg Reward: -121.486269544, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.809027910233\n",
      "[NOR] Episode: 23930, Length: 86, e: 0.05, Avg Reward: -91.9891699451, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.48101568222\n",
      "[NOR] Episode: 23940, Length: 281, e: 0.05, Avg Reward: -130.980566054, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.1006965637\n",
      "[NOR] Episode: 23950, Length: 117, e: 0.05, Avg Reward: -68.9315465143, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.5427455902\n",
      "[NOR] Episode: 23960, Length: 82, e: 0.05, Avg Reward: -136.415502246, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.30246400833\n",
      "[NOR] Episode: 23970, Length: 79, e: 0.05, Avg Reward: -72.2139258446, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.5265455246\n",
      "[NOR] Episode: 23980, Length: 112, e: 0.05, Avg Reward: -108.308105549, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.7596788406\n",
      "[NOR] Episode: 23990, Length: 88, e: 0.05, Avg Reward: -101.455615503, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.705860614777\n",
      "[NOR] Episode: 24000, Length: 126, e: 0.05, Avg Reward: -101.577026369, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.80269813538\n",
      "[NOR] Episode: 24010, Length: 209, e: 0.05, Avg Reward: -167.847034874, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.1648769379\n",
      "[NOR] Episode: 24020, Length: 305, e: 0.05, Avg Reward: -139.119545212, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.22260952\n",
      "[NOR] Episode: 24030, Length: 110, e: 0.05, Avg Reward: -165.068241092, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.9669761658\n",
      "[NOR] Episode: 24040, Length: 131, e: 0.05, Avg Reward: -150.64174811, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.0950889587\n",
      "[NOR] Episode: 24050, Length: 218, e: 0.05, Avg Reward: -112.448462533, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.28363609314\n",
      "[NOR] Episode: 24060, Length: 453, e: 0.05, Avg Reward: -120.951276361, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.13813400269\n",
      "[NOR] Episode: 24070, Length: 115, e: 0.05, Avg Reward: -205.423091857, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.8515605927\n",
      "[NOR] Episode: 24080, Length: 312, e: 0.05, Avg Reward: -146.677181907, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.1716499329\n",
      "[NOR] Episode: 24090, Length: 181, e: 0.05, Avg Reward: -128.275406102, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.33664655685\n",
      "[NOR] Episode: 24100, Length: 169, e: 0.05, Avg Reward: -69.791811671, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.25058317184\n",
      "[NOR] Episode: 24110, Length: 670, e: 0.05, Avg Reward: -132.142222315, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.03059530258\n",
      "[NOR] Episode: 24120, Length: 153, e: 0.05, Avg Reward: -159.962833369, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 34.7631607056\n",
      "[NOR] Episode: 24130, Length: 133, e: 0.05, Avg Reward: -174.174482654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.15338993073\n",
      "[NOR] Episode: 24140, Length: 109, e: 0.05, Avg Reward: -143.452890133, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.26493668556\n",
      "[NOR] Episode: 24150, Length: 85, e: 0.05, Avg Reward: -154.459977484, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 28.1832771301\n",
      "[NOR] Episode: 24160, Length: 167, e: 0.05, Avg Reward: -176.676330583, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.3210272789\n",
      "[NOR] Episode: 24170, Length: 125, e: 0.05, Avg Reward: -172.973608524, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.94362735748\n",
      "[NOR] Episode: 24180, Length: 238, e: 0.05, Avg Reward: -135.416369296, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.720489502\n",
      "[NOR] Episode: 24190, Length: 80, e: 0.05, Avg Reward: -135.000590065, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.7482833862\n",
      "[NOR] Episode: 24200, Length: 158, e: 0.05, Avg Reward: -180.310158829, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.32121229172\n",
      "[NOR] Episode: 24210, Length: 102, e: 0.05, Avg Reward: -142.820108795, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.0584487915\n",
      "[NOR] Episode: 24220, Length: 132, e: 0.05, Avg Reward: -146.661005312, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.8678760529\n",
      "[NOR] Episode: 24230, Length: 127, e: 0.05, Avg Reward: -132.343835009, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.38323116302\n",
      "[NOR] Episode: 24240, Length: 102, e: 0.05, Avg Reward: -115.219999849, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.7398805618\n",
      "[NOR] Episode: 24250, Length: 220, e: 0.05, Avg Reward: -131.019170787, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.02536201477\n",
      "[NOR] Episode: 24260, Length: 201, e: 0.05, Avg Reward: -132.351269974, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.53730332851\n",
      "[NOR] Episode: 24270, Length: 185, e: 0.05, Avg Reward: -109.53772112, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.08205223083\n",
      "[NOR] Episode: 24280, Length: 64, e: 0.05, Avg Reward: -123.485358454, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.61330795288\n",
      "[NOR] Episode: 24290, Length: 89, e: 0.05, Avg Reward: -101.693852881, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.7844963074\n",
      "[NOR] Episode: 24300, Length: 74, e: 0.05, Avg Reward: -168.930270931, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.60302209854\n",
      "[NOR] Episode: 24310, Length: 161, e: 0.05, Avg Reward: -154.988278769, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -55.1605491638\n",
      "[NOR] Episode: 24320, Length: 173, e: 0.05, Avg Reward: -173.138404852, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.43109798431\n",
      "[NOR] Episode: 24330, Length: 164, e: 0.05, Avg Reward: -117.707005617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.5223693848\n",
      "[NOR] Episode: 24340, Length: 151, e: 0.05, Avg Reward: -175.90728389, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.69263553619\n",
      "[NOR] Episode: 24350, Length: 115, e: 0.05, Avg Reward: -128.722845362, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.96489334106\n",
      "[NOR] Episode: 24360, Length: 206, e: 0.05, Avg Reward: -156.14437253, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.39569282532\n",
      "[NOR] Episode: 24370, Length: 143, e: 0.05, Avg Reward: -188.813686903, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.767619133\n",
      "[NOR] Episode: 24380, Length: 142, e: 0.05, Avg Reward: -166.596667309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.77561473846\n",
      "[NOR] Episode: 24390, Length: 265, e: 0.05, Avg Reward: -107.909156509, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.2136573792\n",
      "[NOR] Episode: 24400, Length: 116, e: 0.05, Avg Reward: -138.944245924, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.52767086029\n",
      "[NOR] Episode: 24410, Length: 142, e: 0.05, Avg Reward: -185.333892168, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.71720409393\n",
      "[NOR] Episode: 24420, Length: 143, e: 0.05, Avg Reward: -185.966309927, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.01909208298\n",
      "[NOR] Episode: 24430, Length: 193, e: 0.05, Avg Reward: -163.34490757, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.2251243591\n",
      "[NOR] Episode: 24440, Length: 110, e: 0.05, Avg Reward: -203.630192133, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.4049186707\n",
      "[NOR] Episode: 24450, Length: 101, e: 0.05, Avg Reward: -237.84568743, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.2285861969\n",
      "[NOR] Episode: 24460, Length: 88, e: 0.05, Avg Reward: -276.563100495, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.953245163\n",
      "[NOR] Episode: 24470, Length: 149, e: 0.05, Avg Reward: -188.079357119, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.27424669266\n",
      "[NOR] Episode: 24480, Length: 127, e: 0.05, Avg Reward: -261.735413386, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.40773963928\n",
      "[NOR] Episode: 24490, Length: 227, e: 0.05, Avg Reward: -248.900479927, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.41386413574\n",
      "[NOR] Episode: 24500, Length: 267, e: 0.05, Avg Reward: -271.938354755, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.60347557068\n",
      "[NOR] Episode: 24510, Length: 138, e: 0.05, Avg Reward: -152.965669791, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.541356444359\n",
      "[NOR] Episode: 24520, Length: 105, e: 0.05, Avg Reward: -264.42908978, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.3933134079\n",
      "[NOR] Episode: 24530, Length: 153, e: 0.05, Avg Reward: -174.560567237, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.7852630615\n",
      "[NOR] Episode: 24540, Length: 428, e: 0.05, Avg Reward: -235.587860216, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.5056772232\n",
      "[NOR] Episode: 24550, Length: 192, e: 0.05, Avg Reward: -263.959067006, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.03181266785\n",
      "[NOR] Episode: 24560, Length: 107, e: 0.05, Avg Reward: -196.257792574, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.50752353668\n",
      "[NOR] Episode: 24570, Length: 128, e: 0.05, Avg Reward: -307.579370603, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.030582428\n",
      "[NOR] Episode: 24580, Length: 357, e: 0.05, Avg Reward: -297.58091937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.1255168915\n",
      "[NOR] Episode: 24590, Length: 151, e: 0.05, Avg Reward: -304.144532757, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.77972626686\n",
      "[NOR] Episode: 24600, Length: 230, e: 0.05, Avg Reward: -237.188962957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.91367578506\n",
      "[NOR] Episode: 24610, Length: 256, e: 0.05, Avg Reward: -262.837595261, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.1023864746\n",
      "[NOR] Episode: 24620, Length: 194, e: 0.05, Avg Reward: -310.279363621, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 45.9602165222\n",
      "[NOR] Episode: 24630, Length: 232, e: 0.05, Avg Reward: -257.334617788, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.86090660095\n",
      "[NOR] Episode: 24640, Length: 182, e: 0.05, Avg Reward: -322.402198766, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.3642616272\n",
      "[NOR] Episode: 24650, Length: 189, e: 0.05, Avg Reward: -302.737693247, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.1127538681\n",
      "[NOR] Episode: 24660, Length: 332, e: 0.05, Avg Reward: -250.440935714, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.71991252899\n",
      "[NOR] Episode: 24670, Length: 173, e: 0.05, Avg Reward: -248.451407598, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.892159938812\n",
      "[NOR] Episode: 24680, Length: 315, e: 0.05, Avg Reward: -219.83200376, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.60197937489\n",
      "[NOR] Episode: 24690, Length: 85, e: 0.05, Avg Reward: -282.899283784, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.02014684677\n",
      "[NOR] Episode: 24700, Length: 114, e: 0.05, Avg Reward: -246.930959984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.7625980377\n",
      "[NOR] Episode: 24710, Length: 169, e: 0.05, Avg Reward: -247.287645834, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.90932416916\n",
      "[NOR] Episode: 24720, Length: 173, e: 0.05, Avg Reward: -222.94618892, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.688566446304\n",
      "[NOR] Episode: 24730, Length: 294, e: 0.05, Avg Reward: -221.982977825, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.6135368347\n",
      "[NOR] Episode: 24740, Length: 91, e: 0.05, Avg Reward: -195.477288084, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.94146156311\n",
      "[NOR] Episode: 24750, Length: 211, e: 0.05, Avg Reward: -222.943336686, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.67130279541\n",
      "[NOR] Episode: 24760, Length: 384, e: 0.05, Avg Reward: -205.610023997, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.6224708557\n",
      "[NOR] Episode: 24770, Length: 224, e: 0.05, Avg Reward: -207.653577869, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.81657409668\n",
      "[NOR] Episode: 24780, Length: 183, e: 0.05, Avg Reward: -205.635920827, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.15332841873\n",
      "[NOR] Episode: 24790, Length: 93, e: 0.05, Avg Reward: -282.394806918, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.55915474892\n",
      "[NOR] Episode: 24800, Length: 288, e: 0.05, Avg Reward: -248.705363211, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.18218612671\n",
      "[NOR] Episode: 24810, Length: 174, e: 0.05, Avg Reward: -245.085581088, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.2765293121\n",
      "[NOR] Episode: 24820, Length: 167, e: 0.05, Avg Reward: -309.874931763, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.4885940552\n",
      "[NOR] Episode: 24830, Length: 76, e: 0.05, Avg Reward: -270.685003981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.0464248657\n",
      "[NOR] Episode: 24840, Length: 156, e: 0.05, Avg Reward: -277.739031142, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.62930965424\n",
      "[NOR] Episode: 24850, Length: 172, e: 0.05, Avg Reward: -311.140579815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.9864377975\n",
      "[NOR] Episode: 24860, Length: 194, e: 0.05, Avg Reward: -278.146856793, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.43604850769\n",
      "[NOR] Episode: 24870, Length: 108, e: 0.05, Avg Reward: -207.879947179, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.9453735352\n",
      "[NOR] Episode: 24880, Length: 110, e: 0.05, Avg Reward: -238.443648089, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.1332683563\n",
      "[NOR] Episode: 24890, Length: 247, e: 0.05, Avg Reward: -247.071219343, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.13847064972\n",
      "[NOR] Episode: 24900, Length: 229, e: 0.05, Avg Reward: -263.460510509, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.143453598\n",
      "[NOR] Episode: 24910, Length: 194, e: 0.05, Avg Reward: -206.622587447, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.4561367035\n",
      "[NOR] Episode: 24920, Length: 340, e: 0.05, Avg Reward: -268.78826886, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.1256933212\n",
      "[NOR] Episode: 24930, Length: 287, e: 0.05, Avg Reward: -304.221261033, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.653019189835\n",
      "[NOR] Episode: 24940, Length: 232, e: 0.05, Avg Reward: -243.275741961, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.4914236069\n",
      "[NOR] Episode: 24950, Length: 195, e: 0.05, Avg Reward: -271.958524437, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.97449302673\n",
      "[NOR] Episode: 24960, Length: 284, e: 0.05, Avg Reward: -253.38284511, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.05626583099\n",
      "[NOR] Episode: 24970, Length: 236, e: 0.05, Avg Reward: -247.190790164, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.10580706596\n",
      "[NOR] Episode: 24980, Length: 112, e: 0.05, Avg Reward: -242.555421482, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.9539985657\n",
      "[NOR] Episode: 24990, Length: 135, e: 0.05, Avg Reward: -201.816082912, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.8310184479\n",
      "[NOR] Episode: 25000, Length: 166, e: 0.05, Avg Reward: -229.660047601, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.3998203278\n",
      "[NOR] Episode: 25010, Length: 121, e: 0.05, Avg Reward: -230.89851633, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.49686002731\n",
      "[NOR] Episode: 25020, Length: 127, e: 0.05, Avg Reward: -251.49290412, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.51974821091\n",
      "[NOR] Episode: 25030, Length: 202, e: 0.05, Avg Reward: -220.245054075, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.071144104\n",
      "[NOR] Episode: 25040, Length: 86, e: 0.05, Avg Reward: -223.807931817, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.4308490753\n",
      "[NOR] Episode: 25050, Length: 142, e: 0.05, Avg Reward: -266.538596551, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.6125164032\n",
      "[NOR] Episode: 25060, Length: 133, e: 0.05, Avg Reward: -213.560985348, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.39372682571\n",
      "[NOR] Episode: 25070, Length: 242, e: 0.05, Avg Reward: -236.559275652, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.53277254105\n",
      "[NOR] Episode: 25080, Length: 76, e: 0.05, Avg Reward: -267.597984025, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.38009119034\n",
      "[NOR] Episode: 25090, Length: 114, e: 0.05, Avg Reward: -216.790806973, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.78210449219\n",
      "[NOR] Episode: 25100, Length: 84, e: 0.05, Avg Reward: -212.426428148, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.38446235657\n",
      "[NOR] Episode: 25110, Length: 215, e: 0.05, Avg Reward: -163.313205142, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.31380271912\n",
      "[NOR] Episode: 25120, Length: 88, e: 0.05, Avg Reward: -151.095848698, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.04240489006\n",
      "[NOR] Episode: 25130, Length: 149, e: 0.05, Avg Reward: -126.806258369, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.163675904274\n",
      "[NOR] Episode: 25140, Length: 118, e: 0.05, Avg Reward: -130.56576612, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.96603870392\n",
      "[NOR] Episode: 25150, Length: 181, e: 0.05, Avg Reward: -104.191827386, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.18324184418\n",
      "[NOR] Episode: 25160, Length: 124, e: 0.05, Avg Reward: -154.613382977, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.23572182655\n",
      "[NOR] Episode: 25170, Length: 232, e: 0.05, Avg Reward: -135.332259001, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.40560770035\n",
      "[NOR] Episode: 25180, Length: 122, e: 0.05, Avg Reward: -158.020958299, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.78702640533\n",
      "[NOR] Episode: 25190, Length: 120, e: 0.05, Avg Reward: -145.037115505, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.24723052979\n",
      "[NOR] Episode: 25200, Length: 158, e: 0.05, Avg Reward: -153.819837451, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.6133823395\n",
      "[NOR] Episode: 25210, Length: 205, e: 0.05, Avg Reward: -114.276936753, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.28524589539\n",
      "[NOR] Episode: 25220, Length: 97, e: 0.05, Avg Reward: -160.064381811, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.45274448395\n",
      "[NOR] Episode: 25230, Length: 176, e: 0.05, Avg Reward: -100.730467127, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.50490283966\n",
      "[NOR] Episode: 25240, Length: 150, e: 0.05, Avg Reward: -103.92887321, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.254695355892\n",
      "[NOR] Episode: 25250, Length: 234, e: 0.05, Avg Reward: -132.741659339, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.6224422455\n",
      "[NOR] Episode: 25260, Length: 153, e: 0.05, Avg Reward: -122.515289842, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.51847553253\n",
      "[NOR] Episode: 25270, Length: 159, e: 0.05, Avg Reward: -131.149822335, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.3880186081\n",
      "[NOR] Episode: 25280, Length: 129, e: 0.05, Avg Reward: -95.8024361122, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.83643817902\n",
      "[NOR] Episode: 25290, Length: 94, e: 0.05, Avg Reward: -122.832769154, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.4708423615\n",
      "[NOR] Episode: 25300, Length: 116, e: 0.05, Avg Reward: -124.753213414, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.65995121002\n",
      "[NOR] Episode: 25310, Length: 120, e: 0.05, Avg Reward: -143.355492548, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.4505443573\n",
      "[NOR] Episode: 25320, Length: 186, e: 0.05, Avg Reward: -132.549387673, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.8425960541\n",
      "[NOR] Episode: 25330, Length: 157, e: 0.05, Avg Reward: -137.582420049, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.91031360626\n",
      "[NOR] Episode: 25340, Length: 200, e: 0.05, Avg Reward: -180.722312373, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.03111886978\n",
      "[NOR] Episode: 25350, Length: 154, e: 0.05, Avg Reward: -127.683805897, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.4009437561\n",
      "[NOR] Episode: 25360, Length: 525, e: 0.05, Avg Reward: -121.967998952, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.96713137627\n",
      "[NOR] Episode: 25370, Length: 184, e: 0.05, Avg Reward: -127.037923593, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.56036233902\n",
      "[NOR] Episode: 25380, Length: 80, e: 0.05, Avg Reward: -102.393734248, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.96131277084\n",
      "[NOR] Episode: 25390, Length: 87, e: 0.05, Avg Reward: -128.321442131, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.3943939209\n",
      "[NOR] Episode: 25400, Length: 153, e: 0.05, Avg Reward: -105.497578869, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.93331241608\n",
      "[NOR] Episode: 25410, Length: 85, e: 0.05, Avg Reward: -144.20077422, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.3689968586\n",
      "[NOR] Episode: 25420, Length: 86, e: 0.05, Avg Reward: -37.9417007067, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.7226066589\n",
      "[NOR] Episode: 25430, Length: 88, e: 0.05, Avg Reward: -105.937348337, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.3267555237\n",
      "[NOR] Episode: 25440, Length: 102, e: 0.05, Avg Reward: -127.194281277, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.64399576187\n",
      "[NOR] Episode: 25450, Length: 91, e: 0.05, Avg Reward: -135.758496028, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.166153281927\n",
      "[NOR] Episode: 25460, Length: 138, e: 0.05, Avg Reward: -16.5583166166, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.7179746628\n",
      "[NOR] Episode: 25470, Length: 142, e: 0.05, Avg Reward: -132.759768769, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.3927001953\n",
      "[NOR] Episode: 25480, Length: 166, e: 0.05, Avg Reward: -115.425583362, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.386721611\n",
      "[NOR] Episode: 25490, Length: 131, e: 0.05, Avg Reward: -97.4969824058, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.86628818512\n",
      "[NOR] Episode: 25500, Length: 127, e: 0.05, Avg Reward: -129.930462726, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.75319004059\n",
      "[NOR] Episode: 25510, Length: 201, e: 0.05, Avg Reward: -125.057678088, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.432352066\n",
      "[NOR] Episode: 25520, Length: 75, e: 0.05, Avg Reward: -127.727517931, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.74780845642\n",
      "[NOR] Episode: 25530, Length: 169, e: 0.05, Avg Reward: -101.758549396, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.99321317673\n",
      "[NOR] Episode: 25540, Length: 84, e: 0.05, Avg Reward: -132.075882938, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.5299377441\n",
      "[NOR] Episode: 25550, Length: 566, e: 0.05, Avg Reward: -104.811819602, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.5856990814\n",
      "[NOR] Episode: 25560, Length: 143, e: 0.05, Avg Reward: -167.568633077, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.65218400955\n",
      "[NOR] Episode: 25570, Length: 149, e: 0.05, Avg Reward: -161.002291856, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.383895874\n",
      "[NOR] Episode: 25580, Length: 180, e: 0.05, Avg Reward: -159.277944802, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.71202516556\n",
      "[NOR] Episode: 25590, Length: 255, e: 0.05, Avg Reward: -169.901897011, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.68753671646\n",
      "[NOR] Episode: 25600, Length: 79, e: 0.05, Avg Reward: -138.093516102, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.86615657806\n",
      "[NOR] Episode: 25610, Length: 136, e: 0.05, Avg Reward: -154.20256668, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.06478071213\n",
      "[NOR] Episode: 25620, Length: 162, e: 0.05, Avg Reward: -152.133944023, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.3941001892\n",
      "[NOR] Episode: 25630, Length: 107, e: 0.05, Avg Reward: -167.265470386, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.999577045441\n",
      "[NOR] Episode: 25640, Length: 268, e: 0.05, Avg Reward: -145.014185155, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.18055486679\n",
      "[NOR] Episode: 25650, Length: 106, e: 0.05, Avg Reward: -142.834853318, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.43930435181\n",
      "[NOR] Episode: 25660, Length: 170, e: 0.05, Avg Reward: -185.778054322, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.83398008347\n",
      "[NOR] Episode: 25670, Length: 172, e: 0.05, Avg Reward: -169.085758285, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.53201150894\n",
      "[NOR] Episode: 25680, Length: 115, e: 0.05, Avg Reward: -185.858916987, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.10363054276\n",
      "[NOR] Episode: 25690, Length: 272, e: 0.05, Avg Reward: -209.060245404, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.81847429276\n",
      "[NOR] Episode: 25700, Length: 166, e: 0.05, Avg Reward: -196.5205339, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.32688236237\n",
      "[NOR] Episode: 25710, Length: 217, e: 0.05, Avg Reward: -139.1329594, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.58305692673\n",
      "[NOR] Episode: 25720, Length: 92, e: 0.05, Avg Reward: -175.737639122, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.89491033554\n",
      "[NOR] Episode: 25730, Length: 101, e: 0.05, Avg Reward: -161.201309105, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.2573566437\n",
      "[NOR] Episode: 25740, Length: 492, e: 0.05, Avg Reward: -196.553111581, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.71437597275\n",
      "[NOR] Episode: 25750, Length: 127, e: 0.05, Avg Reward: -149.585918879, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.40619134903\n",
      "[NOR] Episode: 25760, Length: 133, e: 0.05, Avg Reward: -136.878989058, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.70886182785\n",
      "[NOR] Episode: 25770, Length: 144, e: 0.05, Avg Reward: -105.297540534, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -53.6112976074\n",
      "[NOR] Episode: 25780, Length: 75, e: 0.05, Avg Reward: -111.651970856, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.5141582489\n",
      "[NOR] Episode: 25790, Length: 92, e: 0.05, Avg Reward: -148.696887006, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.1206798553\n",
      "[NOR] Episode: 25800, Length: 225, e: 0.05, Avg Reward: -115.274116751, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0828648805618\n",
      "[NOR] Episode: 25810, Length: 108, e: 0.05, Avg Reward: -138.079377246, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.7088842392\n",
      "[NOR] Episode: 25820, Length: 185, e: 0.05, Avg Reward: -154.409607712, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.53108310699\n",
      "[NOR] Episode: 25830, Length: 106, e: 0.05, Avg Reward: -138.22312574, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.53255462646\n",
      "[NOR] Episode: 25840, Length: 78, e: 0.05, Avg Reward: -135.340617804, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.405169487\n",
      "[NOR] Episode: 25850, Length: 82, e: 0.05, Avg Reward: -107.366979924, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.6073217392\n",
      "[NOR] Episode: 25860, Length: 77, e: 0.05, Avg Reward: -101.970148022, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.89063739777\n",
      "[NOR] Episode: 25870, Length: 138, e: 0.05, Avg Reward: -180.418815206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.25831317902\n",
      "[NOR] Episode: 25880, Length: 103, e: 0.05, Avg Reward: -135.832390004, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.4028186798\n",
      "[NOR] Episode: 25890, Length: 102, e: 0.05, Avg Reward: -167.190305797, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.83807373047\n",
      "[NOR] Episode: 25900, Length: 252, e: 0.05, Avg Reward: -85.9921997499, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.2554931641\n",
      "[NOR] Episode: 25910, Length: 79, e: 0.05, Avg Reward: -220.643094273, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.37995815277\n",
      "[NOR] Episode: 25920, Length: 90, e: 0.05, Avg Reward: -92.3701285705, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.398818731308\n",
      "[NOR] Episode: 25930, Length: 149, e: 0.05, Avg Reward: -173.75449776, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.9492759705\n",
      "[NOR] Episode: 25940, Length: 107, e: 0.05, Avg Reward: -173.015596879, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.5702996254\n",
      "[NOR] Episode: 25950, Length: 159, e: 0.05, Avg Reward: -158.967547583, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.7351369858\n",
      "[NOR] Episode: 25960, Length: 97, e: 0.05, Avg Reward: -101.229303061, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.94417953491\n",
      "[NOR] Episode: 25970, Length: 137, e: 0.05, Avg Reward: -155.911555362, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.250619232655\n",
      "[NOR] Episode: 25980, Length: 193, e: 0.05, Avg Reward: -135.641633801, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.2179546356\n",
      "[NOR] Episode: 25990, Length: 76, e: 0.05, Avg Reward: -163.767052442, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.51880908012\n",
      "[NOR] Episode: 26000, Length: 75, e: 0.05, Avg Reward: -152.04674127, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.48955416679\n",
      "[NOR] Episode: 26010, Length: 93, e: 0.05, Avg Reward: -159.927818855, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.961230874062\n",
      "[NOR] Episode: 26020, Length: 90, e: 0.05, Avg Reward: -128.731212813, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.95643806458\n",
      "[NOR] Episode: 26030, Length: 79, e: 0.05, Avg Reward: -117.590310318, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.00478458405\n",
      "[NOR] Episode: 26040, Length: 85, e: 0.05, Avg Reward: -121.696579969, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.05541706085\n",
      "[NOR] Episode: 26050, Length: 73, e: 0.05, Avg Reward: -148.092143669, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.72466564178\n",
      "[NOR] Episode: 26060, Length: 100, e: 0.05, Avg Reward: -154.100175703, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.9024066925\n",
      "[NOR] Episode: 26070, Length: 102, e: 0.05, Avg Reward: -172.575023914, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.20010614395\n",
      "[NOR] Episode: 26080, Length: 107, e: 0.05, Avg Reward: -168.493548073, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.99612236023\n",
      "[NOR] Episode: 26090, Length: 96, e: 0.05, Avg Reward: -140.917017689, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.70313358307\n",
      "[NOR] Episode: 26100, Length: 75, e: 0.05, Avg Reward: -99.6346942997, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.66609764099\n",
      "[NOR] Episode: 26110, Length: 108, e: 0.05, Avg Reward: -91.5680044557, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.7580108643\n",
      "[NOR] Episode: 26120, Length: 94, e: 0.05, Avg Reward: -30.1544489015, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.2206120491\n",
      "[NOR] Episode: 26130, Length: 110, e: 0.05, Avg Reward: -131.543677797, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.80520820618\n",
      "[NOR] Episode: 26140, Length: 104, e: 0.05, Avg Reward: 0.017314127912, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.28521001339\n",
      "[NOR] Episode: 26150, Length: 75, e: 0.05, Avg Reward: -83.712283102, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.4329252243\n",
      "[NOR] Episode: 26160, Length: 103, e: 0.05, Avg Reward: -128.196702719, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.28996562958\n",
      "[NOR] Episode: 26170, Length: 136, e: 0.05, Avg Reward: -96.7238776418, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.7510147095\n",
      "[NOR] Episode: 26180, Length: 75, e: 0.05, Avg Reward: -82.2514969229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.11874365807\n",
      "[NOR] Episode: 26190, Length: 87, e: 0.05, Avg Reward: -22.6239625645, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.12738370895\n",
      "[NOR] Episode: 26200, Length: 129, e: 0.05, Avg Reward: -128.943168478, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.39472961426\n",
      "[NOR] Episode: 26210, Length: 143, e: 0.05, Avg Reward: -144.386644886, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.8124055862\n",
      "[NOR] Episode: 26220, Length: 80, e: 0.05, Avg Reward: -64.7812515053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.7089343071\n",
      "[NOR] Episode: 26230, Length: 128, e: 0.05, Avg Reward: -9.47545136521, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.46373987198\n",
      "[NOR] Episode: 26240, Length: 106, e: 0.05, Avg Reward: -112.012880708, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.36056661606\n",
      "[NOR] Episode: 26250, Length: 88, e: 0.05, Avg Reward: -78.7498301248, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.685732841492\n",
      "[NOR] Episode: 26260, Length: 89, e: 0.05, Avg Reward: -145.251134307, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -64.1596984863\n",
      "[NOR] Episode: 26270, Length: 186, e: 0.05, Avg Reward: -44.7119026249, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.69457435608\n",
      "[NOR] Episode: 26280, Length: 101, e: 0.05, Avg Reward: -106.117355799, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.05652046204\n",
      "[NOR] Episode: 26290, Length: 125, e: 0.05, Avg Reward: -85.8397427794, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.11317539215\n",
      "[NOR] Episode: 26300, Length: 62, e: 0.05, Avg Reward: -116.876727884, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.1448707581\n",
      "[NOR] Episode: 26310, Length: 299, e: 0.05, Avg Reward: -58.2573409877, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.41371822357\n",
      "[NOR] Episode: 26320, Length: 101, e: 0.05, Avg Reward: -137.175979627, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.6600418091\n",
      "[NOR] Episode: 26330, Length: 151, e: 0.05, Avg Reward: -128.840040237, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.9177532196\n",
      "[NOR] Episode: 26340, Length: 81, e: 0.05, Avg Reward: -129.299477598, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.2870397568\n",
      "[NOR] Episode: 26350, Length: 82, e: 0.05, Avg Reward: -108.4819535, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.99270343781\n",
      "[NOR] Episode: 26360, Length: 107, e: 0.05, Avg Reward: -82.2552105924, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.84069418907\n",
      "[NOR] Episode: 26370, Length: 95, e: 0.05, Avg Reward: -84.2522525807, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.35951042175\n",
      "[NOR] Episode: 26380, Length: 102, e: 0.05, Avg Reward: -80.5352270673, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.55227088928\n",
      "[NOR] Episode: 26390, Length: 76, e: 0.05, Avg Reward: -90.6251963101, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.823355078697\n",
      "[NOR] Episode: 26400, Length: 161, e: 0.05, Avg Reward: -134.706660596, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.15900230408\n",
      "[NOR] Episode: 26410, Length: 91, e: 0.05, Avg Reward: -129.20188322, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.8477768898\n",
      "[NOR] Episode: 26420, Length: 115, e: 0.05, Avg Reward: -165.999268356, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.25111794472\n",
      "[NOR] Episode: 26430, Length: 117, e: 0.05, Avg Reward: -112.501216726, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.46308326721\n",
      "[NOR] Episode: 26440, Length: 118, e: 0.05, Avg Reward: -116.000187692, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.47065734863\n",
      "[NOR] Episode: 26450, Length: 123, e: 0.05, Avg Reward: -127.797304651, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.54709076881\n",
      "[NOR] Episode: 26460, Length: 113, e: 0.05, Avg Reward: -124.227590042, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.181028962135\n",
      "[NOR] Episode: 26470, Length: 155, e: 0.05, Avg Reward: -118.915697535, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.7745018005\n",
      "[NOR] Episode: 26480, Length: 88, e: 0.05, Avg Reward: -113.068453043, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.37186145782\n",
      "[NOR] Episode: 26490, Length: 91, e: 0.05, Avg Reward: -135.21871375, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.0034675598\n",
      "[NOR] Episode: 26500, Length: 57, e: 0.05, Avg Reward: -145.264168923, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.87026035786\n",
      "[NOR] Episode: 26510, Length: 147, e: 0.05, Avg Reward: -82.0955145071, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.60556411743\n",
      "[NOR] Episode: 26520, Length: 116, e: 0.05, Avg Reward: -144.920509829, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.2054920197\n",
      "[NOR] Episode: 26530, Length: 268, e: 0.05, Avg Reward: -70.6871898054, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.55076503754\n",
      "[NOR] Episode: 26540, Length: 93, e: 0.05, Avg Reward: -80.2614702322, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.25487136841\n",
      "[NOR] Episode: 26550, Length: 111, e: 0.05, Avg Reward: -101.684523309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.92626142502\n",
      "[NOR] Episode: 26560, Length: 71, e: 0.05, Avg Reward: -108.183176939, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.75464439392\n",
      "[NOR] Episode: 26570, Length: 125, e: 0.05, Avg Reward: -132.420742834, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.4501914978\n",
      "[NOR] Episode: 26580, Length: 76, e: 0.05, Avg Reward: -101.360085481, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.0387468338\n",
      "[NOR] Episode: 26590, Length: 82, e: 0.05, Avg Reward: -118.880696253, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.55544662476\n",
      "[NOR] Episode: 26600, Length: 126, e: 0.05, Avg Reward: -135.334557452, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.75928497314\n",
      "[NOR] Episode: 26610, Length: 130, e: 0.05, Avg Reward: -113.303830906, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.4460372925\n",
      "[NOR] Episode: 26620, Length: 97, e: 0.05, Avg Reward: -83.269540278, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.36526298523\n",
      "[NOR] Episode: 26630, Length: 206, e: 0.05, Avg Reward: -117.53766441, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.2190914154\n",
      "[NOR] Episode: 26640, Length: 229, e: 0.05, Avg Reward: -89.003170419, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.92878937721\n",
      "[NOR] Episode: 26650, Length: 118, e: 0.05, Avg Reward: -107.312076954, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.17832422256\n",
      "[NOR] Episode: 26660, Length: 216, e: 0.05, Avg Reward: -112.747835568, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.7862319946\n",
      "[NOR] Episode: 26670, Length: 92, e: 0.05, Avg Reward: -105.839930321, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.05892562866\n",
      "[NOR] Episode: 26680, Length: 93, e: 0.05, Avg Reward: -152.798276078, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.29274225235\n",
      "[NOR] Episode: 26690, Length: 110, e: 0.05, Avg Reward: -113.742063853, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.66679477692\n",
      "[NOR] Episode: 26700, Length: 103, e: 0.05, Avg Reward: -145.128456866, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.13467025757\n",
      "[NOR] Episode: 26710, Length: 82, e: 0.05, Avg Reward: -140.545761271, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.2740573883\n",
      "[NOR] Episode: 26720, Length: 167, e: 0.05, Avg Reward: -80.60752763, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.88305950165\n",
      "[NOR] Episode: 26730, Length: 238, e: 0.05, Avg Reward: -88.9084500952, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.14215087891\n",
      "[NOR] Episode: 26740, Length: 77, e: 0.05, Avg Reward: -147.014591421, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.94727039337\n",
      "[NOR] Episode: 26750, Length: 212, e: 0.05, Avg Reward: -65.2387451829, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.2852535248\n",
      "[NOR] Episode: 26760, Length: 85, e: 0.05, Avg Reward: -124.833390672, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.2353363037\n",
      "[NOR] Episode: 26770, Length: 119, e: 0.05, Avg Reward: -128.778540241, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.3467254639\n",
      "[NOR] Episode: 26780, Length: 162, e: 0.05, Avg Reward: -210.339907795, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.676955938339\n",
      "[NOR] Episode: 26790, Length: 123, e: 0.05, Avg Reward: -109.225204749, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.7734203339\n",
      "[NOR] Episode: 26800, Length: 175, e: 0.05, Avg Reward: -136.975274143, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.08296489716\n",
      "[NOR] Episode: 26810, Length: 99, e: 0.05, Avg Reward: -174.999329226, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.710190773\n",
      "[NOR] Episode: 26820, Length: 157, e: 0.05, Avg Reward: -95.5482272655, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.3586563766\n",
      "[NOR] Episode: 26830, Length: 203, e: 0.05, Avg Reward: -115.766783416, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.02287125587\n",
      "[NOR] Episode: 26840, Length: 154, e: 0.05, Avg Reward: -90.2343136203, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.32047820091\n",
      "[NOR] Episode: 26850, Length: 278, e: 0.05, Avg Reward: -97.8929153415, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.94445323944\n",
      "[NOR] Episode: 26860, Length: 128, e: 0.05, Avg Reward: -146.557670034, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.84904503822\n",
      "[NOR] Episode: 26870, Length: 67, e: 0.05, Avg Reward: -128.462231828, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.93743133545\n",
      "[NOR] Episode: 26880, Length: 95, e: 0.05, Avg Reward: -154.196677308, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.1409454346\n",
      "[NOR] Episode: 26890, Length: 120, e: 0.05, Avg Reward: -89.7077551157, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.4735314846\n",
      "[NOR] Episode: 26900, Length: 118, e: 0.05, Avg Reward: -92.3665969647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.53485679626\n",
      "[NOR] Episode: 26910, Length: 132, e: 0.05, Avg Reward: -90.6074657506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.6300430298\n",
      "[NOR] Episode: 26920, Length: 164, e: 0.05, Avg Reward: -117.093632317, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.8236913681\n",
      "[NOR] Episode: 26930, Length: 83, e: 0.05, Avg Reward: -144.933139125, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.8197288513\n",
      "[NOR] Episode: 26940, Length: 75, e: 0.05, Avg Reward: -133.237285621, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -51.3361358643\n",
      "[NOR] Episode: 26950, Length: 100, e: 0.05, Avg Reward: -76.3603089464, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.24105119705\n",
      "[NOR] Episode: 26960, Length: 129, e: 0.05, Avg Reward: -158.548162847, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.648141861\n",
      "[NOR] Episode: 26970, Length: 144, e: 0.05, Avg Reward: -89.4949490131, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.21198749542\n",
      "[NOR] Episode: 26980, Length: 168, e: 0.05, Avg Reward: -119.978684557, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.4753656387\n",
      "[NOR] Episode: 26990, Length: 134, e: 0.05, Avg Reward: -102.695682898, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.13790655136\n",
      "[NOR] Episode: 27000, Length: 68, e: 0.05, Avg Reward: -121.740686619, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.155233979225\n",
      "[NOR] Episode: 27010, Length: 62, e: 0.05, Avg Reward: -126.543472831, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.16236972809\n",
      "[NOR] Episode: 27020, Length: 159, e: 0.05, Avg Reward: -74.0870276825, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.17854070663\n",
      "[NOR] Episode: 27030, Length: 101, e: 0.05, Avg Reward: -109.329463174, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.9689178467\n",
      "[NOR] Episode: 27040, Length: 88, e: 0.05, Avg Reward: -95.2560657356, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.30073451996\n",
      "[NOR] Episode: 27050, Length: 73, e: 0.05, Avg Reward: -84.6474152449, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.5674247742\n",
      "[NOR] Episode: 27060, Length: 76, e: 0.05, Avg Reward: -99.6831447854, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.04018855095\n",
      "[NOR] Episode: 27070, Length: 72, e: 0.05, Avg Reward: -103.01448223, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.8574180603\n",
      "[NOR] Episode: 27080, Length: 70, e: 0.05, Avg Reward: -138.321525268, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.63283371925\n",
      "[NOR] Episode: 27090, Length: 118, e: 0.05, Avg Reward: -85.2223533557, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.2074813843\n",
      "[NOR] Episode: 27100, Length: 116, e: 0.05, Avg Reward: -74.87047429, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.59036970139\n",
      "[NOR] Episode: 27110, Length: 66, e: 0.05, Avg Reward: -73.4349929318, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.70749902725\n",
      "[NOR] Episode: 27120, Length: 102, e: 0.05, Avg Reward: -122.505380412, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.726474762\n",
      "[NOR] Episode: 27130, Length: 60, e: 0.05, Avg Reward: -112.58410298, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.440355598927\n",
      "[NOR] Episode: 27140, Length: 77, e: 0.05, Avg Reward: -112.848074038, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.6416478157\n",
      "[NOR] Episode: 27150, Length: 112, e: 0.05, Avg Reward: -112.442827447, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.41040349007\n",
      "[NOR] Episode: 27160, Length: 59, e: 0.05, Avg Reward: -88.4743767834, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.22953820229\n",
      "[NOR] Episode: 27170, Length: 149, e: 0.05, Avg Reward: -71.2517066033, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 38.6640090942\n",
      "[NOR] Episode: 27180, Length: 156, e: 0.05, Avg Reward: -65.2672336411, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.778459549\n",
      "[NOR] Episode: 27190, Length: 224, e: 0.05, Avg Reward: -77.6980533052, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.3794898987\n",
      "[NOR] Episode: 27200, Length: 101, e: 0.05, Avg Reward: -133.759042617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.659626960754\n",
      "[NOR] Episode: 27210, Length: 88, e: 0.05, Avg Reward: -49.4676336534, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.68132781982\n",
      "[NOR] Episode: 27220, Length: 76, e: 0.05, Avg Reward: -159.902843101, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.87816047668\n",
      "[NOR] Episode: 27230, Length: 82, e: 0.05, Avg Reward: -89.3374770639, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 92.9736099243\n",
      "[NOR] Episode: 27240, Length: 82, e: 0.05, Avg Reward: -152.857546839, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.600219845772\n",
      "[NOR] Episode: 27250, Length: 57, e: 0.05, Avg Reward: -134.907055393, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.19032096863\n",
      "[NOR] Episode: 27260, Length: 146, e: 0.05, Avg Reward: -123.154087066, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.3220424652\n",
      "[NOR] Episode: 27270, Length: 127, e: 0.05, Avg Reward: -132.973895628, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.50626850128\n",
      "[NOR] Episode: 27280, Length: 99, e: 0.05, Avg Reward: -106.822048652, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.59729385376\n",
      "[NOR] Episode: 27290, Length: 117, e: 0.05, Avg Reward: -121.544370521, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.0211868286\n",
      "[NOR] Episode: 27300, Length: 62, e: 0.05, Avg Reward: -122.586239981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.397381782532\n",
      "[NOR] Episode: 27310, Length: 91, e: 0.05, Avg Reward: -136.786389075, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.220027923584\n",
      "[NOR] Episode: 27320, Length: 75, e: 0.05, Avg Reward: -156.795442676, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.94098854065\n",
      "[NOR] Episode: 27330, Length: 74, e: 0.05, Avg Reward: -127.226947712, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.7646808624\n",
      "[NOR] Episode: 27340, Length: 114, e: 0.05, Avg Reward: -122.512787458, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.13296079636\n",
      "[NOR] Episode: 27350, Length: 64, e: 0.05, Avg Reward: -102.393304109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.108548641205\n",
      "[NOR] Episode: 27360, Length: 94, e: 0.05, Avg Reward: -99.556897815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.4843482971\n",
      "[NOR] Episode: 27370, Length: 55, e: 0.05, Avg Reward: -75.3646202398, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.5217857361\n",
      "[NOR] Episode: 27380, Length: 67, e: 0.05, Avg Reward: -80.9779466287, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.90908956528\n",
      "[NOR] Episode: 27390, Length: 93, e: 0.05, Avg Reward: -98.0190365285, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.76993751526\n",
      "[NOR] Episode: 27400, Length: 86, e: 0.05, Avg Reward: -129.575243163, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.452715158463\n",
      "[NOR] Episode: 27410, Length: 74, e: 0.05, Avg Reward: -135.398670609, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.46597862244\n",
      "[NOR] Episode: 27420, Length: 73, e: 0.05, Avg Reward: -98.1155482536, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.29490184784\n",
      "[NOR] Episode: 27430, Length: 67, e: 0.05, Avg Reward: -104.798425786, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -55.0842285156\n",
      "[NOR] Episode: 27440, Length: 65, e: 0.05, Avg Reward: -70.9116877577, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.3512954712\n",
      "[NOR] Episode: 27450, Length: 268, e: 0.05, Avg Reward: -52.6846357751, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.24287319183\n",
      "[NOR] Episode: 27460, Length: 97, e: 0.05, Avg Reward: -34.6512567791, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.8565101624\n",
      "[NOR] Episode: 27470, Length: 97, e: 0.05, Avg Reward: -132.427239682, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.515648365021\n",
      "[NOR] Episode: 27480, Length: 218, e: 0.05, Avg Reward: -32.3714783517, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.92115736008\n",
      "[NOR] Episode: 27490, Length: 89, e: 0.05, Avg Reward: -75.4301392948, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.60113763809\n",
      "[NOR] Episode: 27500, Length: 58, e: 0.05, Avg Reward: -93.4664382821, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.75936460495\n",
      "[NOR] Episode: 27510, Length: 59, e: 0.05, Avg Reward: -117.35524554, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.31506252289\n",
      "[NOR] Episode: 27520, Length: 93, e: 0.05, Avg Reward: -154.427454237, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.37278914452\n",
      "[NOR] Episode: 27530, Length: 67, e: 0.05, Avg Reward: -84.3788545052, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.7514486313\n",
      "[NOR] Episode: 27540, Length: 84, e: 0.05, Avg Reward: -121.337066119, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.09652352333\n",
      "[NOR] Episode: 27550, Length: 145, e: 0.05, Avg Reward: -130.051253944, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 35.6169281006\n",
      "[NOR] Episode: 27560, Length: 89, e: 0.05, Avg Reward: -133.138214505, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.0040206909\n",
      "[NOR] Episode: 27570, Length: 61, e: 0.05, Avg Reward: -100.477559172, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.2011613846\n",
      "[NOR] Episode: 27580, Length: 220, e: 0.05, Avg Reward: -90.1609237762, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.93846893311\n",
      "[NOR] Episode: 27590, Length: 66, e: 0.05, Avg Reward: -51.9510271157, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.86828160286\n",
      "[NOR] Episode: 27600, Length: 84, e: 0.05, Avg Reward: -85.3052725558, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.86977243423\n",
      "[NOR] Episode: 27610, Length: 81, e: 0.05, Avg Reward: -98.2851239737, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.55824613571\n",
      "[NOR] Episode: 27620, Length: 235, e: 0.05, Avg Reward: -74.9040185241, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.2014541626\n",
      "[NOR] Episode: 27630, Length: 92, e: 0.05, Avg Reward: -118.25755991, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.8575191498\n",
      "[NOR] Episode: 27640, Length: 63, e: 0.05, Avg Reward: -91.495044564, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.64329051971\n",
      "[NOR] Episode: 27650, Length: 99, e: 0.05, Avg Reward: -113.552421015, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.8721389771\n",
      "[NOR] Episode: 27660, Length: 77, e: 0.05, Avg Reward: -102.559450604, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.13892698288\n",
      "[NOR] Episode: 27670, Length: 81, e: 0.05, Avg Reward: -132.31730367, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.47849273682\n",
      "[NOR] Episode: 27680, Length: 81, e: 0.05, Avg Reward: -124.231838369, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.423065185547\n",
      "[NOR] Episode: 27690, Length: 81, e: 0.05, Avg Reward: -89.646941681, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.2376976013\n",
      "[NOR] Episode: 27700, Length: 69, e: 0.05, Avg Reward: -88.4269504265, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.91956520081\n",
      "[NOR] Episode: 27710, Length: 73, e: 0.05, Avg Reward: -67.5507855903, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.318069458\n",
      "[NOR] Episode: 27720, Length: 68, e: 0.05, Avg Reward: -95.3832278615, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.46184253693\n",
      "[NOR] Episode: 27730, Length: 86, e: 0.05, Avg Reward: -123.529424326, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.97225856781\n",
      "[NOR] Episode: 27740, Length: 147, e: 0.05, Avg Reward: -116.827965636, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.51083803177\n",
      "[NOR] Episode: 27750, Length: 60, e: 0.05, Avg Reward: -112.106528496, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.72902488708\n",
      "[NOR] Episode: 27760, Length: 62, e: 0.05, Avg Reward: -130.278491436, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.79486942291\n",
      "[NOR] Episode: 27770, Length: 78, e: 0.05, Avg Reward: -82.1068812249, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.5651268959\n",
      "[NOR] Episode: 27780, Length: 92, e: 0.05, Avg Reward: -134.610343495, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.03374457359\n",
      "[NOR] Episode: 27790, Length: 117, e: 0.05, Avg Reward: -114.759125179, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.630532264709\n",
      "[NOR] Episode: 27800, Length: 66, e: 0.05, Avg Reward: -114.687465896, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.26575136185\n",
      "[NOR] Episode: 27810, Length: 77, e: 0.05, Avg Reward: -150.200329464, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.1474590302\n",
      "[NOR] Episode: 27820, Length: 61, e: 0.05, Avg Reward: -101.70347035, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.5311031342\n",
      "[NOR] Episode: 27830, Length: 57, e: 0.05, Avg Reward: -115.494003666, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.17271566391\n",
      "[NOR] Episode: 27840, Length: 212, e: 0.05, Avg Reward: -101.186485981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.8622200489\n",
      "[NOR] Episode: 27850, Length: 123, e: 0.05, Avg Reward: -73.2774814478, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.3739089966\n",
      "[NOR] Episode: 27860, Length: 90, e: 0.05, Avg Reward: -130.871290684, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.19502329826\n",
      "[NOR] Episode: 27870, Length: 68, e: 0.05, Avg Reward: -67.2331354588, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.25085306168\n",
      "[NOR] Episode: 27880, Length: 55, e: 0.05, Avg Reward: -134.726610067, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.950624585152\n",
      "[NOR] Episode: 27890, Length: 78, e: 0.05, Avg Reward: -113.386872077, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.78830766678\n",
      "[NOR] Episode: 27900, Length: 83, e: 0.05, Avg Reward: -128.684764194, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0832666158676\n",
      "[NOR] Episode: 27910, Length: 68, e: 0.05, Avg Reward: -93.8021500811, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.51599597931\n",
      "[NOR] Episode: 27920, Length: 55, e: 0.05, Avg Reward: -129.10013716, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.86236476898\n",
      "[NOR] Episode: 27930, Length: 66, e: 0.05, Avg Reward: -95.6879523539, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.28817558289\n",
      "[NOR] Episode: 27940, Length: 213, e: 0.05, Avg Reward: -97.4563987043, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.7129802704\n",
      "[NOR] Episode: 27950, Length: 99, e: 0.05, Avg Reward: -98.3568581756, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.216342926025\n",
      "[NOR] Episode: 27960, Length: 71, e: 0.05, Avg Reward: -85.2974295438, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.69528675079\n",
      "[NOR] Episode: 27970, Length: 67, e: 0.05, Avg Reward: -93.4268938367, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.73874378204\n",
      "[NOR] Episode: 27980, Length: 115, e: 0.05, Avg Reward: -67.5342554519, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.31054353714\n",
      "[NOR] Episode: 27990, Length: 74, e: 0.05, Avg Reward: -147.851631505, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.4598369598\n",
      "[NOR] Episode: 28000, Length: 79, e: 0.05, Avg Reward: -145.215799721, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.31604576111\n",
      "[NOR] Episode: 28010, Length: 85, e: 0.05, Avg Reward: -105.74594045, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.17830681801\n",
      "[NOR] Episode: 28020, Length: 69, e: 0.05, Avg Reward: -128.600084053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.6886825562\n",
      "[NOR] Episode: 28030, Length: 74, e: 0.05, Avg Reward: -108.593555314, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.4874649048\n",
      "[NOR] Episode: 28040, Length: 94, e: 0.05, Avg Reward: -98.1390394779, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.54283809662\n",
      "[NOR] Episode: 28050, Length: 335, e: 0.05, Avg Reward: -17.7897610516, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -34.2085533142\n",
      "[NOR] Episode: 28060, Length: 99, e: 0.05, Avg Reward: -117.897512295, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.49185371399\n",
      "[NOR] Episode: 28070, Length: 84, e: 0.05, Avg Reward: -107.084996217, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.91398763657\n",
      "[NOR] Episode: 28080, Length: 109, e: 0.05, Avg Reward: -119.598744896, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.6507091522\n",
      "[NOR] Episode: 28090, Length: 78, e: 0.05, Avg Reward: -96.2337072992, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.75764083862\n",
      "[NOR] Episode: 28100, Length: 80, e: 0.05, Avg Reward: -104.044960678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 35.265789032\n",
      "[NOR] Episode: 28110, Length: 125, e: 0.05, Avg Reward: -132.257236768, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.83119106293\n",
      "[NOR] Episode: 28120, Length: 90, e: 0.05, Avg Reward: -85.2364409741, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.564704895\n",
      "[NOR] Episode: 28130, Length: 71, e: 0.05, Avg Reward: -117.649729707, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.6173858643\n",
      "[NOR] Episode: 28140, Length: 164, e: 0.05, Avg Reward: -116.390940788, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.79366898537\n",
      "[NOR] Episode: 28150, Length: 69, e: 0.05, Avg Reward: -117.024768615, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.3498468399\n",
      "[NOR] Episode: 28160, Length: 82, e: 0.05, Avg Reward: -92.8370592498, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.11405181885\n",
      "[NOR] Episode: 28170, Length: 126, e: 0.05, Avg Reward: -127.955813657, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.15676259995\n",
      "[NOR] Episode: 28180, Length: 76, e: 0.05, Avg Reward: -14.4163383478, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.2379646301\n",
      "[NOR] Episode: 28190, Length: 226, e: 0.05, Avg Reward: -91.1098131201, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.6298732758\n",
      "[NOR] Episode: 28200, Length: 90, e: 0.05, Avg Reward: -61.1635696272, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.150478363037\n",
      "[NOR] Episode: 28210, Length: 106, e: 0.05, Avg Reward: -137.844122927, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.53429031372\n",
      "[NOR] Episode: 28220, Length: 61, e: 0.05, Avg Reward: -123.54578759, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.350367307663\n",
      "[NOR] Episode: 28230, Length: 119, e: 0.05, Avg Reward: -137.49531161, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.9609985352\n",
      "[NOR] Episode: 28240, Length: 49, e: 0.05, Avg Reward: -52.0413409568, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.58434963226\n",
      "[NOR] Episode: 28250, Length: 105, e: 0.05, Avg Reward: -45.5388199937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.66443443298\n",
      "[NOR] Episode: 28260, Length: 71, e: 0.05, Avg Reward: -112.951940919, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.39150047302\n",
      "[NOR] Episode: 28270, Length: 278, e: 0.05, Avg Reward: -97.090530951, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.7979660034\n",
      "[NOR] Episode: 28280, Length: 74, e: 0.05, Avg Reward: -101.667509277, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.74741745\n",
      "[NOR] Episode: 28290, Length: 80, e: 0.05, Avg Reward: -99.5573311474, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.9351606369\n",
      "[NOR] Episode: 28300, Length: 79, e: 0.05, Avg Reward: -136.796762061, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.27489376068\n",
      "[NOR] Episode: 28310, Length: 179, e: 0.05, Avg Reward: -95.8539479452, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.98411464691\n",
      "[NOR] Episode: 28320, Length: 96, e: 0.05, Avg Reward: -111.807566052, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.6234331131\n",
      "[NOR] Episode: 28330, Length: 117, e: 0.05, Avg Reward: -124.685760956, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.28233957291\n",
      "[NOR] Episode: 28340, Length: 180, e: 0.05, Avg Reward: -71.8962907953, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.3308067322\n",
      "[NOR] Episode: 28350, Length: 80, e: 0.05, Avg Reward: -94.2744126869, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.83571863174\n",
      "[NOR] Episode: 28360, Length: 71, e: 0.05, Avg Reward: -116.34683241, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.37983179092\n",
      "[NOR] Episode: 28370, Length: 132, e: 0.05, Avg Reward: -129.316406777, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -49.1649551392\n",
      "[NOR] Episode: 28380, Length: 265, e: 0.05, Avg Reward: -57.4390911919, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.97168731689\n",
      "[NOR] Episode: 28390, Length: 151, e: 0.05, Avg Reward: -99.4233833197, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.05889511108\n",
      "[NOR] Episode: 28400, Length: 76, e: 0.05, Avg Reward: -122.110187456, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.941707372665\n",
      "[NOR] Episode: 28410, Length: 72, e: 0.05, Avg Reward: -143.978470043, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.19771814346\n",
      "[NOR] Episode: 28420, Length: 54, e: 0.05, Avg Reward: -110.305501669, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.37066602707\n",
      "[NOR] Episode: 28430, Length: 106, e: 0.05, Avg Reward: -100.203223526, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.81088685989\n",
      "[NOR] Episode: 28440, Length: 68, e: 0.05, Avg Reward: -121.965983283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.94110202789\n",
      "[NOR] Episode: 28450, Length: 104, e: 0.05, Avg Reward: -144.179044071, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.87291622162\n",
      "[NOR] Episode: 28460, Length: 102, e: 0.05, Avg Reward: -111.959274258, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.1427154541\n",
      "[NOR] Episode: 28470, Length: 94, e: 0.05, Avg Reward: -96.4991285867, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.39060878754\n",
      "[NOR] Episode: 28480, Length: 60, e: 0.05, Avg Reward: -38.0255213139, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.0407333374\n",
      "[NOR] Episode: 28490, Length: 83, e: 0.05, Avg Reward: -140.905134838, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.1733026505\n",
      "[NOR] Episode: 28500, Length: 103, e: 0.05, Avg Reward: -110.932665053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.92688345909\n",
      "[NOR] Episode: 28510, Length: 108, e: 0.05, Avg Reward: -146.645294069, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.02404558659\n",
      "[NOR] Episode: 28520, Length: 81, e: 0.05, Avg Reward: -111.694884864, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.61736965179\n",
      "[NOR] Episode: 28530, Length: 237, e: 0.05, Avg Reward: -57.0226503585, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.9104552269\n",
      "[NOR] Episode: 28540, Length: 83, e: 0.05, Avg Reward: -131.759816588, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.32521390915\n",
      "[NOR] Episode: 28550, Length: 99, e: 0.05, Avg Reward: -85.0985710663, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.28878974915\n",
      "[NOR] Episode: 28560, Length: 106, e: 0.05, Avg Reward: -133.517728949, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.816009521484\n",
      "[NOR] Episode: 28570, Length: 82, e: 0.05, Avg Reward: -127.445660913, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.751101017\n",
      "[NOR] Episode: 28580, Length: 103, e: 0.05, Avg Reward: -88.4536932148, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.90696692467\n",
      "[NOR] Episode: 28590, Length: 65, e: 0.05, Avg Reward: -112.41354654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.9714107513\n",
      "[NOR] Episode: 28600, Length: 100, e: 0.05, Avg Reward: -122.042072122, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.27477478981\n",
      "[NOR] Episode: 28610, Length: 88, e: 0.05, Avg Reward: -126.967278806, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.37257909775\n",
      "[NOR] Episode: 28620, Length: 71, e: 0.05, Avg Reward: -52.5937401876, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.5085144043\n",
      "[NOR] Episode: 28630, Length: 89, e: 0.05, Avg Reward: -101.469260185, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.88564944267\n",
      "[NOR] Episode: 28640, Length: 90, e: 0.05, Avg Reward: -101.003471099, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.07779097557\n",
      "[NOR] Episode: 28650, Length: 105, e: 0.05, Avg Reward: -86.0073347846, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.7588920593\n",
      "[NOR] Episode: 28660, Length: 84, e: 0.05, Avg Reward: -87.3226516122, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.29464030266\n",
      "[NOR] Episode: 28670, Length: 69, e: 0.05, Avg Reward: -98.8024731156, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.01457881927\n",
      "[NOR] Episode: 28680, Length: 70, e: 0.05, Avg Reward: -90.7275578143, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.04393708706\n",
      "[NOR] Episode: 28690, Length: 87, e: 0.05, Avg Reward: -130.848340601, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.71807670593\n",
      "[NOR] Episode: 28700, Length: 123, e: 0.05, Avg Reward: -152.38990447, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.228328228\n",
      "[NOR] Episode: 28710, Length: 68, e: 0.05, Avg Reward: -58.0916760912, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.53884506226\n",
      "[NOR] Episode: 28720, Length: 73, e: 0.05, Avg Reward: -123.79502957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.900970459\n",
      "[NOR] Episode: 28730, Length: 66, e: 0.05, Avg Reward: -143.244188328, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.92780339718\n",
      "[NOR] Episode: 28740, Length: 81, e: 0.05, Avg Reward: -105.439016998, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.568684339523\n",
      "[NOR] Episode: 28750, Length: 128, e: 0.05, Avg Reward: -32.990886291, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.9239635468\n",
      "[NOR] Episode: 28760, Length: 116, e: 0.05, Avg Reward: -84.8975652794, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.29930591583\n",
      "[NOR] Episode: 28770, Length: 79, e: 0.05, Avg Reward: -83.2381062873, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.9134483337\n",
      "[NOR] Episode: 28780, Length: 96, e: 0.05, Avg Reward: -145.98214701, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 37.833770752\n",
      "[NOR] Episode: 28790, Length: 68, e: 0.05, Avg Reward: -116.249706847, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.16964292526\n",
      "[NOR] Episode: 28800, Length: 80, e: 0.05, Avg Reward: -132.095042077, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.58180427551\n",
      "[NOR] Episode: 28810, Length: 106, e: 0.05, Avg Reward: -114.017946795, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.31179046631\n",
      "[NOR] Episode: 28820, Length: 104, e: 0.05, Avg Reward: -111.38459923, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.8079013824\n",
      "[NOR] Episode: 28830, Length: 145, e: 0.05, Avg Reward: -125.339651114, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.58395195007\n",
      "[NOR] Episode: 28840, Length: 79, e: 0.05, Avg Reward: -101.213455618, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.88202571869\n",
      "[NOR] Episode: 28850, Length: 79, e: 0.05, Avg Reward: -122.809119015, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.31267738342\n",
      "[NOR] Episode: 28860, Length: 110, e: 0.05, Avg Reward: -127.69290705, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.520431518555\n",
      "[NOR] Episode: 28870, Length: 95, e: 0.05, Avg Reward: -99.9959132206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.20049142838\n",
      "[NOR] Episode: 28880, Length: 108, e: 0.05, Avg Reward: -128.363754592, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.30082941055\n",
      "[NOR] Episode: 28890, Length: 143, e: 0.05, Avg Reward: -96.2175625821, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.2044715881\n",
      "[NOR] Episode: 28900, Length: 65, e: 0.05, Avg Reward: -92.9952429283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.81362009048\n",
      "[NOR] Episode: 28910, Length: 97, e: 0.05, Avg Reward: -55.1417924163, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.32673120499\n",
      "[NOR] Episode: 28920, Length: 130, e: 0.05, Avg Reward: -120.995165346, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.1869306564\n",
      "[NOR] Episode: 28930, Length: 73, e: 0.05, Avg Reward: -35.1435935008, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.0815601349\n",
      "[NOR] Episode: 28940, Length: 81, e: 0.05, Avg Reward: -121.593302551, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.43374919891\n",
      "[NOR] Episode: 28950, Length: 89, e: 0.05, Avg Reward: -100.105418672, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.21129894257\n",
      "[NOR] Episode: 28960, Length: 56, e: 0.05, Avg Reward: -132.180514964, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.21900558472\n",
      "[NOR] Episode: 28970, Length: 58, e: 0.05, Avg Reward: -88.1727059555, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.94419288635\n",
      "[NOR] Episode: 28980, Length: 142, e: 0.05, Avg Reward: -70.15304619, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.3346633911\n",
      "[NOR] Episode: 28990, Length: 88, e: 0.05, Avg Reward: -87.5521460341, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.17744827271\n",
      "[NOR] Episode: 29000, Length: 92, e: 0.05, Avg Reward: -178.719984326, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.55916142464\n",
      "[NOR] Episode: 29010, Length: 65, e: 0.05, Avg Reward: -99.232118506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.931401968\n",
      "[NOR] Episode: 29020, Length: 178, e: 0.05, Avg Reward: -64.2590210182, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.71379470825\n",
      "[NOR] Episode: 29030, Length: 123, e: 0.05, Avg Reward: -75.4445585517, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.54442501068\n",
      "[NOR] Episode: 29040, Length: 134, e: 0.05, Avg Reward: -96.857253563, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.018212556839\n",
      "[NOR] Episode: 29050, Length: 95, e: 0.05, Avg Reward: -122.566017942, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.169277668\n",
      "[NOR] Episode: 29060, Length: 87, e: 0.05, Avg Reward: -78.427516364, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.85707712173\n",
      "[NOR] Episode: 29070, Length: 56, e: 0.05, Avg Reward: -138.710902817, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.8313512802\n",
      "[NOR] Episode: 29080, Length: 70, e: 0.05, Avg Reward: -105.911278195, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.15748786926\n",
      "[NOR] Episode: 29090, Length: 141, e: 0.05, Avg Reward: -96.4399853892, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.76521658897\n",
      "[NOR] Episode: 29100, Length: 63, e: 0.05, Avg Reward: -114.410079124, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.36452126503\n",
      "[NOR] Episode: 29110, Length: 89, e: 0.05, Avg Reward: -116.57432931, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.4036822319\n",
      "[NOR] Episode: 29120, Length: 133, e: 0.05, Avg Reward: -33.0602324016, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.39847183228\n",
      "[NOR] Episode: 29130, Length: 163, e: 0.05, Avg Reward: -130.186696704, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.1713638306\n",
      "[NOR] Episode: 29140, Length: 103, e: 0.05, Avg Reward: -137.839775996, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.84170818329\n",
      "[NOR] Episode: 29150, Length: 91, e: 0.05, Avg Reward: -173.592475629, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.90734529495\n",
      "[NOR] Episode: 29160, Length: 74, e: 0.05, Avg Reward: -87.240304633, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.8139972687\n",
      "[NOR] Episode: 29170, Length: 52, e: 0.05, Avg Reward: -54.0035741051, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.49788761139\n",
      "[NOR] Episode: 29180, Length: 71, e: 0.05, Avg Reward: -119.994464051, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.04548358917\n",
      "[NOR] Episode: 29190, Length: 172, e: 0.05, Avg Reward: -157.62727655, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.5341976881\n",
      "[NOR] Episode: 29200, Length: 55, e: 0.05, Avg Reward: -104.973205477, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.84702062607\n",
      "[NOR] Episode: 29210, Length: 61, e: 0.05, Avg Reward: -164.775090864, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.65693998337\n",
      "[NOR] Episode: 29220, Length: 109, e: 0.05, Avg Reward: -174.221049138, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.38134884834\n",
      "[NOR] Episode: 29230, Length: 69, e: 0.05, Avg Reward: -109.229313605, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.06066608429\n",
      "[NOR] Episode: 29240, Length: 81, e: 0.05, Avg Reward: -64.4558855152, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.2949771881\n",
      "[NOR] Episode: 29250, Length: 135, e: 0.05, Avg Reward: -125.058252017, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.8006858826\n",
      "[NOR] Episode: 29260, Length: 83, e: 0.05, Avg Reward: -141.533196778, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.89761734009\n",
      "[NOR] Episode: 29270, Length: 86, e: 0.05, Avg Reward: -82.913053378, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.4930019379\n",
      "[NOR] Episode: 29280, Length: 97, e: 0.05, Avg Reward: -90.891397387, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.8273897171\n",
      "[NOR] Episode: 29290, Length: 57, e: 0.05, Avg Reward: -92.3193365987, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.34523963928\n",
      "[NOR] Episode: 29300, Length: 99, e: 0.05, Avg Reward: -11.8535064619, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.46843504906\n",
      "[NOR] Episode: 29310, Length: 60, e: 0.05, Avg Reward: -150.81369812, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.59032249451\n",
      "[NOR] Episode: 29320, Length: 67, e: 0.05, Avg Reward: -131.044180777, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.48681974411\n",
      "[NOR] Episode: 29330, Length: 60, e: 0.05, Avg Reward: -72.255003274, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.0842323303\n",
      "[NOR] Episode: 29340, Length: 124, e: 0.05, Avg Reward: -69.7400340527, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.26496315\n",
      "[NOR] Episode: 29350, Length: 150, e: 0.05, Avg Reward: -96.9969566761, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.66829800606\n",
      "[NOR] Episode: 29360, Length: 183, e: 0.05, Avg Reward: -120.889789042, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.178012609482\n",
      "[NOR] Episode: 29370, Length: 96, e: 0.05, Avg Reward: -96.3616725404, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.5522689819\n",
      "[NOR] Episode: 29380, Length: 50, e: 0.05, Avg Reward: -117.727715693, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.3769435883\n",
      "[NOR] Episode: 29390, Length: 134, e: 0.05, Avg Reward: -45.5180176489, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.8903055191\n",
      "[NOR] Episode: 29400, Length: 123, e: 0.05, Avg Reward: -128.93805926, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.70174694061\n",
      "[NOR] Episode: 29410, Length: 69, e: 0.05, Avg Reward: -120.522047515, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.334836483\n",
      "[NOR] Episode: 29420, Length: 98, e: 0.05, Avg Reward: -120.645814651, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.9412937164\n",
      "[NOR] Episode: 29430, Length: 58, e: 0.05, Avg Reward: -110.511909107, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.8577747345\n",
      "[NOR] Episode: 29440, Length: 203, e: 0.05, Avg Reward: -79.3175315446, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.383395910263\n",
      "[NOR] Episode: 29450, Length: 207, e: 0.05, Avg Reward: -128.701495042, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.40956687927\n",
      "[NOR] Episode: 29460, Length: 99, e: 0.05, Avg Reward: -82.1238932341, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.63688659668\n",
      "[NOR] Episode: 29470, Length: 58, e: 0.05, Avg Reward: -129.728883695, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.27452945709\n",
      "[NOR] Episode: 29480, Length: 126, e: 0.05, Avg Reward: -99.293674106, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.67644762993\n",
      "[NOR] Episode: 29490, Length: 127, e: 0.05, Avg Reward: -71.2736485207, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.7082901001\n",
      "[NOR] Episode: 29500, Length: 247, e: 0.05, Avg Reward: -144.696546241, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.98508024216\n",
      "[NOR] Episode: 29510, Length: 151, e: 0.05, Avg Reward: -113.782460587, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.892583370209\n",
      "[NOR] Episode: 29520, Length: 189, e: 0.05, Avg Reward: -78.6790420936, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.39366316795\n",
      "[NOR] Episode: 29530, Length: 319, e: 0.05, Avg Reward: -44.5470800339, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.726066172123\n",
      "[NOR] Episode: 29540, Length: 200, e: 0.05, Avg Reward: -164.746646643, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.85170459747\n",
      "[NOR] Episode: 29550, Length: 74, e: 0.05, Avg Reward: -186.265919853, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.66552245617\n",
      "[NOR] Episode: 29560, Length: 76, e: 0.05, Avg Reward: -87.8985562018, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.678696632385\n",
      "[NOR] Episode: 29570, Length: 84, e: 0.05, Avg Reward: -111.016733911, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.76209354401\n",
      "[NOR] Episode: 29580, Length: 131, e: 0.05, Avg Reward: -146.353240813, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.304193794727\n",
      "[NOR] Episode: 29590, Length: 76, e: 0.05, Avg Reward: -161.344947638, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.25208473206\n",
      "[NOR] Episode: 29600, Length: 325, e: 0.05, Avg Reward: -84.5754666839, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.68451118469\n",
      "[NOR] Episode: 29610, Length: 212, e: 0.05, Avg Reward: -113.743336917, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.41441965103\n",
      "[NOR] Episode: 29620, Length: 75, e: 0.05, Avg Reward: -142.180757442, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.88515710831\n",
      "[NOR] Episode: 29630, Length: 73, e: 0.05, Avg Reward: -133.227093534, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.87901306152\n",
      "[NOR] Episode: 29640, Length: 196, e: 0.05, Avg Reward: -133.837203708, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.43223905563\n",
      "[NOR] Episode: 29650, Length: 177, e: 0.05, Avg Reward: -112.651655917, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.643624782562\n",
      "[NOR] Episode: 29660, Length: 118, e: 0.05, Avg Reward: -68.123716647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.992387235165\n",
      "[NOR] Episode: 29670, Length: 200, e: 0.05, Avg Reward: -126.508905297, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.19171309471\n",
      "[NOR] Episode: 29680, Length: 152, e: 0.05, Avg Reward: -135.163779316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.82269954681\n",
      "[NOR] Episode: 29690, Length: 75, e: 0.05, Avg Reward: -64.8946104948, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.5320529938\n",
      "[NOR] Episode: 29700, Length: 133, e: 0.05, Avg Reward: -166.040753752, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.23445892334\n",
      "[NOR] Episode: 29710, Length: 69, e: 0.05, Avg Reward: -156.073583747, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.80208396912\n",
      "[NOR] Episode: 29720, Length: 83, e: 0.05, Avg Reward: -111.175618244, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.18939614296\n",
      "[NOR] Episode: 29730, Length: 111, e: 0.05, Avg Reward: -135.906075351, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.16557788849\n",
      "[NOR] Episode: 29740, Length: 63, e: 0.05, Avg Reward: -134.443035273, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.62179756165\n",
      "[NOR] Episode: 29750, Length: 81, e: 0.05, Avg Reward: -109.340166011, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.75545334816\n",
      "[NOR] Episode: 29760, Length: 208, e: 0.05, Avg Reward: -70.5289638079, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.84937047958\n",
      "[NOR] Episode: 29770, Length: 100, e: 0.05, Avg Reward: -101.110332075, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.732397675514\n",
      "[NOR] Episode: 29780, Length: 343, e: 0.05, Avg Reward: -45.8245212086, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.92825365067\n",
      "[NOR] Episode: 29790, Length: 144, e: 0.05, Avg Reward: -80.2039254644, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.80120182037\n",
      "[NOR] Episode: 29800, Length: 89, e: 0.05, Avg Reward: -144.277787937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.59236717224\n",
      "[NOR] Episode: 29810, Length: 151, e: 0.05, Avg Reward: -194.755682188, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.49373912811\n",
      "[NOR] Episode: 29820, Length: 74, e: 0.05, Avg Reward: -167.292082549, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.25519490242\n",
      "[NOR] Episode: 29830, Length: 62, e: 0.05, Avg Reward: -154.260584631, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.00717258453\n",
      "[NOR] Episode: 29840, Length: 63, e: 0.05, Avg Reward: -75.7874752807, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.71021413803\n",
      "[NOR] Episode: 29850, Length: 60, e: 0.05, Avg Reward: -118.50105283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.6945705414\n",
      "[NOR] Episode: 29860, Length: 181, e: 0.05, Avg Reward: -98.5807233063, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.03443717957\n",
      "[NOR] Episode: 29870, Length: 191, e: 0.05, Avg Reward: -89.52616928, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.3352880478\n",
      "[NOR] Episode: 29880, Length: 89, e: 0.05, Avg Reward: -124.900583163, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.28008818626\n",
      "[NOR] Episode: 29890, Length: 122, e: 0.05, Avg Reward: -59.3135869205, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.71156358719\n",
      "[NOR] Episode: 29900, Length: 80, e: 0.05, Avg Reward: -117.387064153, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.27882289886\n",
      "[NOR] Episode: 29910, Length: 228, e: 0.05, Avg Reward: -133.610003745, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.123561859131\n",
      "[NOR] Episode: 29920, Length: 99, e: 0.05, Avg Reward: -129.036908916, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.99647045135\n",
      "[NOR] Episode: 29930, Length: 63, e: 0.05, Avg Reward: -176.082832606, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.73682785034\n",
      "[NOR] Episode: 29940, Length: 178, e: 0.05, Avg Reward: -110.55038295, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.73159599304\n",
      "[NOR] Episode: 29950, Length: 101, e: 0.05, Avg Reward: -118.990120691, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.53180003166\n",
      "[NOR] Episode: 29960, Length: 178, e: 0.05, Avg Reward: -126.400788404, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.9452724457\n",
      "[NOR] Episode: 29970, Length: 81, e: 0.05, Avg Reward: -201.972145989, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.04543280602\n",
      "[NOR] Episode: 29980, Length: 71, e: 0.05, Avg Reward: -150.561191636, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.890884876251\n",
      "[NOR] Episode: 29990, Length: 101, e: 0.05, Avg Reward: -185.795140586, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -48.1839981079\n",
      "[NOR] Episode: 30000, Length: 81, e: 0.05, Avg Reward: -106.304110278, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.3046684265\n",
      "[NOR] Episode: 30010, Length: 147, e: 0.05, Avg Reward: -75.2081493817, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.693151474\n",
      "[NOR] Episode: 30020, Length: 190, e: 0.05, Avg Reward: -85.3458053259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.5774993896\n",
      "[NOR] Episode: 30030, Length: 170, e: 0.05, Avg Reward: -139.681976673, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.00110435486\n",
      "[NOR] Episode: 30040, Length: 84, e: 0.05, Avg Reward: -169.921503663, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.7915115356\n",
      "[NOR] Episode: 30050, Length: 161, e: 0.05, Avg Reward: -96.1222230367, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0707902908325\n",
      "[NOR] Episode: 30060, Length: 142, e: 0.05, Avg Reward: -133.420845619, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.75096511841\n",
      "[NOR] Episode: 30070, Length: 105, e: 0.05, Avg Reward: -179.695554814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.31074500084\n",
      "[NOR] Episode: 30080, Length: 116, e: 0.05, Avg Reward: -141.47374945, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.53760385513\n",
      "[NOR] Episode: 30090, Length: 215, e: 0.05, Avg Reward: -147.423084883, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.17301368713\n",
      "[NOR] Episode: 30100, Length: 175, e: 0.05, Avg Reward: -205.883378206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.41295862198\n",
      "[NOR] Episode: 30110, Length: 167, e: 0.05, Avg Reward: -104.908456302, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.05046606064\n",
      "[NOR] Episode: 30120, Length: 86, e: 0.05, Avg Reward: -150.559352046, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.13586997986\n",
      "[NOR] Episode: 30130, Length: 94, e: 0.05, Avg Reward: -139.205306458, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.57830524445\n",
      "[NOR] Episode: 30140, Length: 164, e: 0.05, Avg Reward: -154.260398047, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.25645256042\n",
      "[NOR] Episode: 30150, Length: 75, e: 0.05, Avg Reward: -170.249640917, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.0746049881\n",
      "[NOR] Episode: 30160, Length: 104, e: 0.05, Avg Reward: -166.233145351, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.14299035072\n",
      "[NOR] Episode: 30170, Length: 70, e: 0.05, Avg Reward: -179.211909849, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.05285406113\n",
      "[NOR] Episode: 30180, Length: 213, e: 0.05, Avg Reward: -156.52703034, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -51.3939170837\n",
      "[NOR] Episode: 30190, Length: 81, e: 0.05, Avg Reward: -187.828297781, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.2833709717\n",
      "[NOR] Episode: 30200, Length: 219, e: 0.05, Avg Reward: -182.657347737, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.41345405579\n",
      "[NOR] Episode: 30210, Length: 246, e: 0.05, Avg Reward: -173.828684626, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.16441106796\n",
      "[NOR] Episode: 30220, Length: 74, e: 0.05, Avg Reward: -158.099938883, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.1823253632\n",
      "[NOR] Episode: 30230, Length: 174, e: 0.05, Avg Reward: -189.332636299, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.16708135605\n",
      "[NOR] Episode: 30240, Length: 218, e: 0.05, Avg Reward: -181.927205594, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.89833164215\n",
      "[NOR] Episode: 30250, Length: 270, e: 0.05, Avg Reward: -185.738941809, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.62170886993\n",
      "[NOR] Episode: 30260, Length: 212, e: 0.05, Avg Reward: -182.530417283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.92430067062\n",
      "[NOR] Episode: 30270, Length: 192, e: 0.05, Avg Reward: -147.092605842, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.0423207283\n",
      "[NOR] Episode: 30280, Length: 193, e: 0.05, Avg Reward: -133.647680387, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.7317466736\n",
      "[NOR] Episode: 30290, Length: 219, e: 0.05, Avg Reward: -184.701459697, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.201368451118\n",
      "[NOR] Episode: 30300, Length: 214, e: 0.05, Avg Reward: -191.411899991, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.13167381287\n",
      "[NOR] Episode: 30310, Length: 198, e: 0.05, Avg Reward: -120.118458024, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.2047958374\n",
      "[NOR] Episode: 30320, Length: 99, e: 0.05, Avg Reward: -176.36306063, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.9637432098\n",
      "[NOR] Episode: 30330, Length: 113, e: 0.05, Avg Reward: -134.447075543, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.488035202\n",
      "[NOR] Episode: 30340, Length: 74, e: 0.05, Avg Reward: -198.792323748, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.53357696533\n",
      "[NOR] Episode: 30350, Length: 186, e: 0.05, Avg Reward: -178.15514002, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.1130046844\n",
      "[NOR] Episode: 30360, Length: 155, e: 0.05, Avg Reward: -137.068449563, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.81278419495\n",
      "[NOR] Episode: 30370, Length: 228, e: 0.05, Avg Reward: -23.8551312013, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.60561656952\n",
      "[NOR] Episode: 30380, Length: 77, e: 0.05, Avg Reward: -79.8102769955, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.29151058197\n",
      "[NOR] Episode: 30390, Length: 87, e: 0.05, Avg Reward: -67.7949374373, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.579000473\n",
      "[NOR] Episode: 30400, Length: 369, e: 0.05, Avg Reward: -147.074071112, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.0780582428\n",
      "[NOR] Episode: 30410, Length: 98, e: 0.05, Avg Reward: -67.5056727573, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.36563253403\n",
      "[NOR] Episode: 30420, Length: 157, e: 0.05, Avg Reward: -113.923053871, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.02941846848\n",
      "[NOR] Episode: 30430, Length: 139, e: 0.05, Avg Reward: -150.045124657, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.99125909805\n",
      "[NOR] Episode: 30440, Length: 368, e: 0.05, Avg Reward: -98.9706504809, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.4616184235\n",
      "[NOR] Episode: 30450, Length: 66, e: 0.05, Avg Reward: -154.56136988, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.81849074364\n",
      "[NOR] Episode: 30460, Length: 70, e: 0.05, Avg Reward: -150.921040373, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.00931119919\n",
      "[NOR] Episode: 30470, Length: 103, e: 0.05, Avg Reward: -81.9332535526, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.89572763443\n",
      "[NOR] Episode: 30480, Length: 66, e: 0.05, Avg Reward: -145.624173598, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.30043792725\n",
      "[NOR] Episode: 30490, Length: 69, e: 0.05, Avg Reward: -135.341026242, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.2846660614\n",
      "[NOR] Episode: 30500, Length: 109, e: 0.05, Avg Reward: -105.74374942, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.28601408005\n",
      "[NOR] Episode: 30510, Length: 60, e: 0.05, Avg Reward: -114.989304878, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.00020885468\n",
      "[NOR] Episode: 30520, Length: 64, e: 0.05, Avg Reward: -86.140720042, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.4757318497\n",
      "[NOR] Episode: 30530, Length: 109, e: 0.05, Avg Reward: -115.201239212, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.41355037689\n",
      "[NOR] Episode: 30540, Length: 155, e: 0.05, Avg Reward: -85.9760818364, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.49154472351\n",
      "[NOR] Episode: 30550, Length: 385, e: 0.05, Avg Reward: -116.279776707, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.6670820713\n",
      "[NOR] Episode: 30560, Length: 153, e: 0.05, Avg Reward: -157.331546211, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.1613273621\n",
      "[NOR] Episode: 30570, Length: 125, e: 0.05, Avg Reward: -117.977412648, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.37947511673\n",
      "[NOR] Episode: 30580, Length: 103, e: 0.05, Avg Reward: -148.59398937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.54063987732\n",
      "[NOR] Episode: 30590, Length: 82, e: 0.05, Avg Reward: -101.683955505, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.65267276764\n",
      "[NOR] Episode: 30600, Length: 83, e: 0.05, Avg Reward: -153.697899471, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.46630907059\n",
      "[NOR] Episode: 30610, Length: 66, e: 0.05, Avg Reward: -154.124405373, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.898900032\n",
      "[NOR] Episode: 30620, Length: 97, e: 0.05, Avg Reward: -136.178693546, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.45813798904\n",
      "[NOR] Episode: 30630, Length: 89, e: 0.05, Avg Reward: -135.603015557, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.64320373535\n",
      "[NOR] Episode: 30640, Length: 84, e: 0.05, Avg Reward: -145.789491785, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.30601549149\n",
      "[NOR] Episode: 30650, Length: 98, e: 0.05, Avg Reward: -123.206563304, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.84408247471\n",
      "[NOR] Episode: 30660, Length: 75, e: 0.05, Avg Reward: -127.221582502, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.51982688904\n",
      "[NOR] Episode: 30670, Length: 89, e: 0.05, Avg Reward: -116.274823508, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.81771945953\n",
      "[NOR] Episode: 30680, Length: 71, e: 0.05, Avg Reward: -117.197069533, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.46236491203\n",
      "[NOR] Episode: 30690, Length: 57, e: 0.05, Avg Reward: -128.19863095, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.66443252563\n",
      "[NOR] Episode: 30700, Length: 90, e: 0.05, Avg Reward: -154.290736668, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.488319397\n",
      "[NOR] Episode: 30710, Length: 78, e: 0.05, Avg Reward: -130.050058412, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.5698184967\n",
      "[NOR] Episode: 30720, Length: 80, e: 0.05, Avg Reward: -103.672016859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.03676605225\n",
      "[NOR] Episode: 30730, Length: 64, e: 0.05, Avg Reward: -123.190879565, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.905250251293\n",
      "[NOR] Episode: 30740, Length: 94, e: 0.05, Avg Reward: -97.2923142555, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.1228199005\n",
      "[NOR] Episode: 30750, Length: 89, e: 0.05, Avg Reward: -148.429642691, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.1154079437\n",
      "[NOR] Episode: 30760, Length: 75, e: 0.05, Avg Reward: -175.634989316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.24111914635\n",
      "[NOR] Episode: 30770, Length: 138, e: 0.05, Avg Reward: -203.009564916, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.84267520905\n",
      "[NOR] Episode: 30780, Length: 69, e: 0.05, Avg Reward: -188.305100663, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0484325885773\n",
      "[NOR] Episode: 30790, Length: 165, e: 0.05, Avg Reward: -191.832948386, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.05207443237\n",
      "[NOR] Episode: 30800, Length: 184, e: 0.05, Avg Reward: -158.735360536, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.90388333797\n",
      "[NOR] Episode: 30810, Length: 68, e: 0.05, Avg Reward: -193.040617793, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.0016937256\n",
      "[NOR] Episode: 30820, Length: 83, e: 0.05, Avg Reward: -192.801977932, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.19112920761\n",
      "[NOR] Episode: 30830, Length: 101, e: 0.05, Avg Reward: -192.98075499, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.5443954468\n",
      "[NOR] Episode: 30840, Length: 95, e: 0.05, Avg Reward: -161.925802057, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.02233982086\n",
      "[NOR] Episode: 30850, Length: 115, e: 0.05, Avg Reward: -207.055362574, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.151355743408\n",
      "[NOR] Episode: 30860, Length: 83, e: 0.05, Avg Reward: -224.444387796, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.34146404266\n",
      "[NOR] Episode: 30870, Length: 114, e: 0.05, Avg Reward: -189.021302375, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.67881250381\n",
      "[NOR] Episode: 30880, Length: 60, e: 0.05, Avg Reward: -215.85036555, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.62999153137\n",
      "[NOR] Episode: 30890, Length: 157, e: 0.05, Avg Reward: -188.322667519, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.84184217453\n",
      "[NOR] Episode: 30900, Length: 146, e: 0.05, Avg Reward: -213.385097562, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.2388920784\n",
      "[NOR] Episode: 30910, Length: 132, e: 0.05, Avg Reward: -232.088131765, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.00932598114\n",
      "[NOR] Episode: 30920, Length: 228, e: 0.05, Avg Reward: -129.649663906, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.45576238632\n",
      "[NOR] Episode: 30930, Length: 157, e: 0.05, Avg Reward: -194.853166502, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.5349998474\n",
      "[NOR] Episode: 30940, Length: 96, e: 0.05, Avg Reward: -169.559314507, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.01581478119\n",
      "[NOR] Episode: 30950, Length: 239, e: 0.05, Avg Reward: -162.924974247, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.3282413483\n",
      "[NOR] Episode: 30960, Length: 122, e: 0.05, Avg Reward: -203.745204961, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.09316444397\n",
      "[NOR] Episode: 30970, Length: 93, e: 0.05, Avg Reward: -148.085612365, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.18561458588\n",
      "[NOR] Episode: 30980, Length: 112, e: 0.05, Avg Reward: -240.324934918, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.0310049057\n",
      "[NOR] Episode: 30990, Length: 83, e: 0.05, Avg Reward: -182.255458273, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.372069478035\n",
      "[NOR] Episode: 31000, Length: 143, e: 0.05, Avg Reward: -196.974335496, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.4880828857\n",
      "[NOR] Episode: 31010, Length: 153, e: 0.05, Avg Reward: -206.9881924, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.138340115547\n",
      "[NOR] Episode: 31020, Length: 107, e: 0.05, Avg Reward: -235.12751284, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.7982997894\n",
      "[NOR] Episode: 31030, Length: 96, e: 0.05, Avg Reward: -171.793828538, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.8487377167\n",
      "[NOR] Episode: 31040, Length: 136, e: 0.05, Avg Reward: -272.627480233, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.39579534531\n",
      "[NOR] Episode: 31050, Length: 92, e: 0.05, Avg Reward: -232.570210894, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.19222974777\n",
      "[NOR] Episode: 31060, Length: 116, e: 0.05, Avg Reward: -171.236877405, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.62807750702\n",
      "[NOR] Episode: 31070, Length: 87, e: 0.05, Avg Reward: -136.002716875, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.34195423126\n",
      "[NOR] Episode: 31080, Length: 95, e: 0.05, Avg Reward: -168.527490439, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.3730621338\n",
      "[NOR] Episode: 31090, Length: 64, e: 0.05, Avg Reward: -124.083836703, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.14608049393\n",
      "[NOR] Episode: 31100, Length: 180, e: 0.05, Avg Reward: -259.923003338, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -64.4705657959\n",
      "[NOR] Episode: 31110, Length: 108, e: 0.05, Avg Reward: -214.763135528, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.0060462952\n",
      "[NOR] Episode: 31120, Length: 98, e: 0.05, Avg Reward: -172.046004731, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 113.496047974\n",
      "[NOR] Episode: 31130, Length: 119, e: 0.05, Avg Reward: -189.107901291, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.92784404755\n",
      "[NOR] Episode: 31140, Length: 148, e: 0.05, Avg Reward: -147.131700135, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.08265686035\n",
      "[NOR] Episode: 31150, Length: 62, e: 0.05, Avg Reward: -121.215984519, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.3797626495\n",
      "[NOR] Episode: 31160, Length: 245, e: 0.05, Avg Reward: -161.629053927, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.78970623016\n",
      "[NOR] Episode: 31170, Length: 250, e: 0.05, Avg Reward: -140.38222919, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.72251152992\n",
      "[NOR] Episode: 31180, Length: 79, e: 0.05, Avg Reward: -94.5519818267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.2780570984\n",
      "[NOR] Episode: 31190, Length: 94, e: 0.05, Avg Reward: -135.120748285, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.320057153702\n",
      "[NOR] Episode: 31200, Length: 96, e: 0.05, Avg Reward: -158.838576415, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.4018774033\n",
      "[NOR] Episode: 31210, Length: 102, e: 0.05, Avg Reward: -160.287755494, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.982257843\n",
      "[NOR] Episode: 31220, Length: 161, e: 0.05, Avg Reward: -146.069489154, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.04882025719\n",
      "[NOR] Episode: 31230, Length: 80, e: 0.05, Avg Reward: -110.508435569, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.1830234528\n",
      "[NOR] Episode: 31240, Length: 197, e: 0.05, Avg Reward: -150.33433391, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.779520988464\n",
      "[NOR] Episode: 31250, Length: 106, e: 0.05, Avg Reward: -159.686701748, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.08789730072\n",
      "[NOR] Episode: 31260, Length: 105, e: 0.05, Avg Reward: -195.411562183, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.33908653259\n",
      "[NOR] Episode: 31270, Length: 66, e: 0.05, Avg Reward: -132.226492727, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.58858466148\n",
      "[NOR] Episode: 31280, Length: 214, e: 0.05, Avg Reward: -177.939670388, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.1721763611\n",
      "[NOR] Episode: 31290, Length: 112, e: 0.05, Avg Reward: -202.919585597, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.8766746521\n",
      "[NOR] Episode: 31300, Length: 154, e: 0.05, Avg Reward: -160.484358102, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.58490610123\n",
      "[NOR] Episode: 31310, Length: 94, e: 0.05, Avg Reward: -177.907662292, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.9071273804\n",
      "[NOR] Episode: 31320, Length: 108, e: 0.05, Avg Reward: -125.74395733, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.2274112701\n",
      "[NOR] Episode: 31330, Length: 77, e: 0.05, Avg Reward: -139.441149134, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.72039604187\n",
      "[NOR] Episode: 31340, Length: 226, e: 0.05, Avg Reward: -182.316232317, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.14427089691\n",
      "[NOR] Episode: 31350, Length: 235, e: 0.05, Avg Reward: -118.646808029, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.6371631622\n",
      "[NOR] Episode: 31360, Length: 69, e: 0.05, Avg Reward: -166.543168282, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.82672357559\n",
      "[NOR] Episode: 31370, Length: 111, e: 0.05, Avg Reward: -225.031253677, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.86127853394\n",
      "[NOR] Episode: 31380, Length: 143, e: 0.05, Avg Reward: -193.309957446, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.80138015747\n",
      "[NOR] Episode: 31390, Length: 135, e: 0.05, Avg Reward: -195.356403002, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.14150506258\n",
      "[NOR] Episode: 31400, Length: 106, e: 0.05, Avg Reward: -182.954939883, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.208760261536\n",
      "[NOR] Episode: 31410, Length: 70, e: 0.05, Avg Reward: -129.296924097, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.7244682312\n",
      "[NOR] Episode: 31420, Length: 434, e: 0.05, Avg Reward: -210.747229577, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.6851272583\n",
      "[NOR] Episode: 31430, Length: 191, e: 0.05, Avg Reward: -159.001635433, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.8609275818\n",
      "[NOR] Episode: 31440, Length: 112, e: 0.05, Avg Reward: -204.151981662, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.3619060516\n",
      "[NOR] Episode: 31450, Length: 92, e: 0.05, Avg Reward: -139.783174164, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.17113780975\n",
      "[NOR] Episode: 31460, Length: 61, e: 0.05, Avg Reward: -213.447005729, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.54175949097\n",
      "[NOR] Episode: 31470, Length: 72, e: 0.05, Avg Reward: -157.41415089, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.0817990303\n",
      "[NOR] Episode: 31480, Length: 123, e: 0.05, Avg Reward: -229.245196017, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.01068687439\n",
      "[NOR] Episode: 31490, Length: 109, e: 0.05, Avg Reward: -162.193234223, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.78055000305\n",
      "[NOR] Episode: 31500, Length: 99, e: 0.05, Avg Reward: -191.755739077, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.838558197\n",
      "[NOR] Episode: 31510, Length: 66, e: 0.05, Avg Reward: -66.0080973509, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.7246837616\n",
      "[NOR] Episode: 31520, Length: 80, e: 0.05, Avg Reward: -74.4022779438, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.7761211395\n",
      "[NOR] Episode: 31530, Length: 112, e: 0.05, Avg Reward: -155.056782934, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.19094848633\n",
      "[NOR] Episode: 31540, Length: 97, e: 0.05, Avg Reward: -103.834974429, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.62101268768\n",
      "[NOR] Episode: 31550, Length: 117, e: 0.05, Avg Reward: -122.820828907, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.33005809784\n",
      "[NOR] Episode: 31560, Length: 276, e: 0.05, Avg Reward: -118.545645104, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.03416776657\n",
      "[NOR] Episode: 31570, Length: 402, e: 0.05, Avg Reward: -142.033712456, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.10031604767\n",
      "[NOR] Episode: 31580, Length: 104, e: 0.05, Avg Reward: -136.785909867, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.2290906906\n",
      "[NOR] Episode: 31590, Length: 109, e: 0.05, Avg Reward: -120.859136254, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.1880817413\n",
      "[NOR] Episode: 31600, Length: 101, e: 0.05, Avg Reward: -188.333501775, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.0904121399\n",
      "[NOR] Episode: 31610, Length: 143, e: 0.05, Avg Reward: -71.9331883225, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.62848758698\n",
      "[NOR] Episode: 31620, Length: 86, e: 0.05, Avg Reward: -102.697258683, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.00182342529297\n",
      "[NOR] Episode: 31630, Length: 84, e: 0.05, Avg Reward: -161.951020517, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.49961054325\n",
      "[NOR] Episode: 31640, Length: 211, e: 0.05, Avg Reward: -143.169318954, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.29166901112\n",
      "[NOR] Episode: 31650, Length: 100, e: 0.05, Avg Reward: -144.084029448, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.07306718826\n",
      "[NOR] Episode: 31660, Length: 187, e: 0.05, Avg Reward: -194.721653544, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.82452392578\n",
      "[NOR] Episode: 31670, Length: 81, e: 0.05, Avg Reward: -68.8047567517, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.788063049316\n",
      "[NOR] Episode: 31680, Length: 76, e: 0.05, Avg Reward: -104.18806045, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.4296579361\n",
      "[NOR] Episode: 31690, Length: 91, e: 0.05, Avg Reward: -163.697758701, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.975028038\n",
      "[NOR] Episode: 31700, Length: 64, e: 0.05, Avg Reward: -165.147022543, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.862840235233\n",
      "[NOR] Episode: 31710, Length: 85, e: 0.05, Avg Reward: -179.923415768, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.30400514603\n",
      "[NOR] Episode: 31720, Length: 80, e: 0.05, Avg Reward: -171.443900711, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.103410243988\n",
      "[NOR] Episode: 31730, Length: 63, e: 0.05, Avg Reward: -135.797260324, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.82583522797\n",
      "[NOR] Episode: 31740, Length: 68, e: 0.05, Avg Reward: -109.80081995, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.25762271881\n",
      "[NOR] Episode: 31750, Length: 233, e: 0.05, Avg Reward: -34.8496994393, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.52439260483\n",
      "[NOR] Episode: 31760, Length: 221, e: 0.05, Avg Reward: -172.715227437, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.61232709885\n",
      "[NOR] Episode: 31770, Length: 91, e: 0.05, Avg Reward: -101.539723182, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.83216953278\n",
      "[NOR] Episode: 31780, Length: 313, e: 0.05, Avg Reward: -95.5677484108, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 55.4375724792\n",
      "[NOR] Episode: 31790, Length: 130, e: 0.05, Avg Reward: -126.506232665, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.76778411865\n",
      "[NOR] Episode: 31800, Length: 227, e: 0.05, Avg Reward: -84.1820837048, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.336605072\n",
      "[NOR] Episode: 31810, Length: 85, e: 0.05, Avg Reward: -119.339917786, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.60731065273\n",
      "[NOR] Episode: 31820, Length: 121, e: 0.05, Avg Reward: -173.579289367, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.49467515945\n",
      "[NOR] Episode: 31830, Length: 96, e: 0.05, Avg Reward: -185.666452213, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.6390037537\n",
      "[NOR] Episode: 31840, Length: 101, e: 0.05, Avg Reward: -122.744143465, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.3905620575\n",
      "[NOR] Episode: 31850, Length: 178, e: 0.05, Avg Reward: -75.1537833418, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.61512184143\n",
      "[NOR] Episode: 31860, Length: 79, e: 0.05, Avg Reward: -99.9880972617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.8287086487\n",
      "[NOR] Episode: 31870, Length: 85, e: 0.05, Avg Reward: -117.237944052, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.96842336655\n",
      "[NOR] Episode: 31880, Length: 78, e: 0.05, Avg Reward: -132.477736885, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.2682952881\n",
      "[NOR] Episode: 31890, Length: 224, e: 0.05, Avg Reward: -85.5521261478, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.2699890137\n",
      "[NOR] Episode: 31900, Length: 352, e: 0.05, Avg Reward: -80.3229893677, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.92088079453\n",
      "[NOR] Episode: 31910, Length: 57, e: 0.05, Avg Reward: -121.650078385, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.41445446014\n",
      "[NOR] Episode: 31920, Length: 85, e: 0.05, Avg Reward: -67.6914484588, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.0719661713\n",
      "[NOR] Episode: 31930, Length: 67, e: 0.05, Avg Reward: -143.740638647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 45.2802772522\n",
      "[NOR] Episode: 31940, Length: 225, e: 0.05, Avg Reward: -122.02597145, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.35892057419\n",
      "[NOR] Episode: 31950, Length: 104, e: 0.05, Avg Reward: -139.026985055, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.07174277306\n",
      "[NOR] Episode: 31960, Length: 223, e: 0.05, Avg Reward: -82.0091962085, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.193853497505\n",
      "[NOR] Episode: 31970, Length: 71, e: 0.05, Avg Reward: -136.72729597, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.01811695099\n",
      "[NOR] Episode: 31980, Length: 302, e: 0.05, Avg Reward: -102.017911045, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.92967176437\n",
      "[NOR] Episode: 31990, Length: 71, e: 0.05, Avg Reward: -167.909958457, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.22403168678\n",
      "[NOR] Episode: 32000, Length: 192, e: 0.05, Avg Reward: -132.267679359, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.43922424316\n",
      "[NOR] Episode: 32010, Length: 115, e: 0.05, Avg Reward: -146.268410128, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.9113025665\n",
      "[NOR] Episode: 32020, Length: 93, e: 0.05, Avg Reward: -122.944957215, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.5022258759\n",
      "[NOR] Episode: 32030, Length: 75, e: 0.05, Avg Reward: -89.1357939175, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.65375900269\n",
      "[NOR] Episode: 32040, Length: 88, e: 0.05, Avg Reward: -122.622683804, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.5513381958\n",
      "[NOR] Episode: 32050, Length: 69, e: 0.05, Avg Reward: -130.771027953, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.80845117569\n",
      "[NOR] Episode: 32060, Length: 63, e: 0.05, Avg Reward: -134.260360431, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.47827339172\n",
      "[NOR] Episode: 32070, Length: 104, e: 0.05, Avg Reward: -109.764477701, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.7412014008\n",
      "[NOR] Episode: 32080, Length: 148, e: 0.05, Avg Reward: -152.522483738, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.3103733063\n",
      "[NOR] Episode: 32090, Length: 119, e: 0.05, Avg Reward: -107.940866495, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.99992609024\n",
      "[NOR] Episode: 32100, Length: 152, e: 0.05, Avg Reward: -123.250475614, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.308398246765\n",
      "[NOR] Episode: 32110, Length: 93, e: 0.05, Avg Reward: -123.413646675, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.1001815796\n",
      "[NOR] Episode: 32120, Length: 115, e: 0.05, Avg Reward: -90.1743102627, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.3005437851\n",
      "[NOR] Episode: 32130, Length: 132, e: 0.05, Avg Reward: -113.218342874, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.35357940197\n",
      "[NOR] Episode: 32140, Length: 75, e: 0.05, Avg Reward: -139.282273218, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.82286047935\n",
      "[NOR] Episode: 32150, Length: 53, e: 0.05, Avg Reward: -134.268602995, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.28380537033\n",
      "[NOR] Episode: 32160, Length: 94, e: 0.05, Avg Reward: -128.523968923, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.77260375023\n",
      "[NOR] Episode: 32170, Length: 98, e: 0.05, Avg Reward: -154.551676554, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.3615512848\n",
      "[NOR] Episode: 32180, Length: 64, e: 0.05, Avg Reward: -119.346236608, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.42877268791\n",
      "[NOR] Episode: 32190, Length: 82, e: 0.05, Avg Reward: -97.7257378395, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.9825181961\n",
      "[NOR] Episode: 32200, Length: 88, e: 0.05, Avg Reward: -130.146345408, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.1300544739\n",
      "[NOR] Episode: 32210, Length: 94, e: 0.05, Avg Reward: -134.092908589, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.64105939865\n",
      "[NOR] Episode: 32220, Length: 70, e: 0.05, Avg Reward: -119.016333617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.184902668\n",
      "[NOR] Episode: 32230, Length: 55, e: 0.05, Avg Reward: -131.511989732, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0899155139923\n",
      "[NOR] Episode: 32240, Length: 80, e: 0.05, Avg Reward: -145.91572385, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.30577468872\n",
      "[NOR] Episode: 32250, Length: 62, e: 0.05, Avg Reward: -163.70295621, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.425573349\n",
      "[NOR] Episode: 32260, Length: 68, e: 0.05, Avg Reward: -137.287454719, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.46616601944\n",
      "[NOR] Episode: 32270, Length: 98, e: 0.05, Avg Reward: -95.7205694894, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.513181209564\n",
      "[NOR] Episode: 32280, Length: 127, e: 0.05, Avg Reward: -159.104870498, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.7677764893\n",
      "[NOR] Episode: 32290, Length: 70, e: 0.05, Avg Reward: -140.474208433, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.8626251221\n",
      "[NOR] Episode: 32300, Length: 91, e: 0.05, Avg Reward: -94.6964492745, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 39.4331817627\n",
      "[NOR] Episode: 32310, Length: 94, e: 0.05, Avg Reward: -124.628615461, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.8839836121\n",
      "[NOR] Episode: 32320, Length: 91, e: 0.05, Avg Reward: -88.0895070832, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.60899281502\n",
      "[NOR] Episode: 32330, Length: 133, e: 0.05, Avg Reward: -146.042139573, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.40447187424\n",
      "[NOR] Episode: 32340, Length: 63, e: 0.05, Avg Reward: -159.234433919, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.26335477829\n",
      "[NOR] Episode: 32350, Length: 83, e: 0.05, Avg Reward: -158.485035067, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.78173446655\n",
      "[NOR] Episode: 32360, Length: 99, e: 0.05, Avg Reward: -152.446146926, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.3609790802\n",
      "[NOR] Episode: 32370, Length: 132, e: 0.05, Avg Reward: -129.982220362, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.03406715393\n",
      "[NOR] Episode: 32380, Length: 76, e: 0.05, Avg Reward: -151.790990605, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.59516835213\n",
      "[NOR] Episode: 32390, Length: 90, e: 0.05, Avg Reward: -141.815765886, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.0536117554\n",
      "[NOR] Episode: 32400, Length: 70, e: 0.05, Avg Reward: -135.247464815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 41.8576393127\n",
      "[NOR] Episode: 32410, Length: 117, e: 0.05, Avg Reward: -161.138767543, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.66076421738\n",
      "[NOR] Episode: 32420, Length: 73, e: 0.05, Avg Reward: -133.61178714, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.06358385086\n",
      "[NOR] Episode: 32430, Length: 87, e: 0.05, Avg Reward: -142.78642276, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.94325494766\n",
      "[NOR] Episode: 32440, Length: 72, e: 0.05, Avg Reward: -156.093296685, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.15080928802\n",
      "[NOR] Episode: 32450, Length: 78, e: 0.05, Avg Reward: -175.992082455, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.940385818481\n",
      "[NOR] Episode: 32460, Length: 186, e: 0.05, Avg Reward: -133.808176854, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.6694564819\n",
      "[NOR] Episode: 32470, Length: 98, e: 0.05, Avg Reward: -132.099483253, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.17268133163\n",
      "[NOR] Episode: 32480, Length: 76, e: 0.05, Avg Reward: -185.368376432, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.6922955513\n",
      "[NOR] Episode: 32490, Length: 66, e: 0.05, Avg Reward: -154.878071139, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.57176589966\n",
      "[NOR] Episode: 32500, Length: 90, e: 0.05, Avg Reward: -114.793619723, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.76163578033\n",
      "[NOR] Episode: 32510, Length: 86, e: 0.05, Avg Reward: -162.630276539, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.9685745239\n",
      "[NOR] Episode: 32520, Length: 55, e: 0.05, Avg Reward: -126.698215403, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 98.6373062134\n",
      "[NOR] Episode: 32530, Length: 68, e: 0.05, Avg Reward: -161.089322309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.6284503937\n",
      "[NOR] Episode: 32540, Length: 95, e: 0.05, Avg Reward: -93.6104476524, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.42859363556\n",
      "[NOR] Episode: 32550, Length: 88, e: 0.05, Avg Reward: -184.008305874, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.28654646873\n",
      "[NOR] Episode: 32560, Length: 133, e: 0.05, Avg Reward: -113.671832492, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.36415910721\n",
      "[NOR] Episode: 32570, Length: 141, e: 0.05, Avg Reward: -97.5925970256, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.03646373749\n",
      "[NOR] Episode: 32580, Length: 90, e: 0.05, Avg Reward: -115.543232632, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.65905761719\n",
      "[NOR] Episode: 32590, Length: 80, e: 0.05, Avg Reward: -112.289427461, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.83540391922\n",
      "[NOR] Episode: 32600, Length: 83, e: 0.05, Avg Reward: -132.257646165, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.1786804199\n",
      "[NOR] Episode: 32610, Length: 94, e: 0.05, Avg Reward: -68.904598252, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.90070712566\n",
      "[NOR] Episode: 32620, Length: 85, e: 0.05, Avg Reward: -79.5835764511, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.17834663391\n",
      "[NOR] Episode: 32630, Length: 69, e: 0.05, Avg Reward: -132.708447515, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.69046628475\n",
      "[NOR] Episode: 32640, Length: 70, e: 0.05, Avg Reward: -128.822600713, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.681501150131\n",
      "[NOR] Episode: 32650, Length: 54, e: 0.05, Avg Reward: -143.930530345, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.20168972015\n",
      "[NOR] Episode: 32660, Length: 85, e: 0.05, Avg Reward: -94.9994388647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.59148836136\n",
      "[NOR] Episode: 32670, Length: 91, e: 0.05, Avg Reward: -116.087207597, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.141494751\n",
      "[NOR] Episode: 32680, Length: 211, e: 0.05, Avg Reward: -95.2221178334, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.41650485992\n",
      "[NOR] Episode: 32690, Length: 84, e: 0.05, Avg Reward: -97.4151018108, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.872153759\n",
      "[NOR] Episode: 32700, Length: 67, e: 0.05, Avg Reward: -127.153738097, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.6922531128\n",
      "[NOR] Episode: 32710, Length: 72, e: 0.05, Avg Reward: -103.183354789, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.25602912903\n",
      "[NOR] Episode: 32720, Length: 86, e: 0.05, Avg Reward: -107.008541997, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.52913570404\n",
      "[NOR] Episode: 32730, Length: 123, e: 0.05, Avg Reward: -106.249134487, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.37328910828\n",
      "[NOR] Episode: 32740, Length: 68, e: 0.05, Avg Reward: -166.648757076, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.05832147598\n",
      "[NOR] Episode: 32750, Length: 73, e: 0.05, Avg Reward: -122.737209899, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.66812038422\n",
      "[NOR] Episode: 32760, Length: 66, e: 0.05, Avg Reward: -173.977523624, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.84874534607\n",
      "[NOR] Episode: 32770, Length: 109, e: 0.05, Avg Reward: -84.0974018602, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.93339252472\n",
      "[NOR] Episode: 32780, Length: 279, e: 0.05, Avg Reward: -121.328096984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.9293956757\n",
      "[NOR] Episode: 32790, Length: 105, e: 0.05, Avg Reward: -117.286638693, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.1284618378\n",
      "[NOR] Episode: 32800, Length: 75, e: 0.05, Avg Reward: -113.710955486, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.66913032532\n",
      "[NOR] Episode: 32810, Length: 69, e: 0.05, Avg Reward: -163.85843929, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -39.1673240662\n",
      "[NOR] Episode: 32820, Length: 58, e: 0.05, Avg Reward: -134.682184558, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -54.6493644714\n",
      "[NOR] Episode: 32830, Length: 86, e: 0.05, Avg Reward: -136.202126851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.1296253204\n",
      "[NOR] Episode: 32840, Length: 93, e: 0.05, Avg Reward: -95.1807277712, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.12542057037\n",
      "[NOR] Episode: 32850, Length: 73, e: 0.05, Avg Reward: -110.204200054, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.2789297104\n",
      "[NOR] Episode: 32860, Length: 49, e: 0.05, Avg Reward: -129.356642711, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.38737678528\n",
      "[NOR] Episode: 32870, Length: 58, e: 0.05, Avg Reward: -162.794307714, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.79477143288\n",
      "[NOR] Episode: 32880, Length: 86, e: 0.05, Avg Reward: -116.597046238, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.0737133026\n",
      "[NOR] Episode: 32890, Length: 73, e: 0.05, Avg Reward: -154.274492546, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.3058359623\n",
      "[NOR] Episode: 32900, Length: 84, e: 0.05, Avg Reward: -75.8491401406, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.64702510834\n",
      "[NOR] Episode: 32910, Length: 102, e: 0.05, Avg Reward: -106.278514687, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.9530787468\n",
      "[NOR] Episode: 32920, Length: 93, e: 0.05, Avg Reward: -116.947123803, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.51332378387\n",
      "[NOR] Episode: 32930, Length: 90, e: 0.05, Avg Reward: -153.388665869, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 48.5374107361\n",
      "[NOR] Episode: 32940, Length: 85, e: 0.05, Avg Reward: -135.776653831, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.53888177872\n",
      "[NOR] Episode: 32950, Length: 75, e: 0.05, Avg Reward: -91.4087350284, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.2944278717\n",
      "[NOR] Episode: 32960, Length: 195, e: 0.05, Avg Reward: -92.5572389022, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.22638130188\n",
      "[NOR] Episode: 32970, Length: 76, e: 0.05, Avg Reward: -107.940498721, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.02744483948\n",
      "[NOR] Episode: 32980, Length: 67, e: 0.05, Avg Reward: -99.8047644048, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.3201522827\n",
      "[NOR] Episode: 32990, Length: 81, e: 0.05, Avg Reward: -132.327246961, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.40616321564\n",
      "[NOR] Episode: 33000, Length: 258, e: 0.05, Avg Reward: -57.3808585892, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.78898906708\n",
      "[NOR] Episode: 33010, Length: 109, e: 0.05, Avg Reward: -36.8555965698, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.383848905563\n",
      "[NOR] Episode: 33020, Length: 94, e: 0.05, Avg Reward: -155.351493727, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.12425851822\n",
      "[NOR] Episode: 33030, Length: 71, e: 0.05, Avg Reward: -97.1717613878, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -78.9981536865\n",
      "[NOR] Episode: 33040, Length: 76, e: 0.05, Avg Reward: -91.5634451841, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.679680347443\n",
      "[NOR] Episode: 33050, Length: 59, e: 0.05, Avg Reward: -118.950134339, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.63601732254\n",
      "[NOR] Episode: 33060, Length: 72, e: 0.05, Avg Reward: -163.511001834, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.80439996719\n",
      "[NOR] Episode: 33070, Length: 58, e: 0.05, Avg Reward: -106.614345225, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.751379728317\n",
      "[NOR] Episode: 33080, Length: 282, e: 0.05, Avg Reward: -64.0998040339, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 160.521682739\n",
      "[NOR] Episode: 33090, Length: 106, e: 0.05, Avg Reward: -97.1575923679, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.8731451035\n",
      "[NOR] Episode: 33100, Length: 135, e: 0.05, Avg Reward: -104.585055795, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.93056297302\n",
      "[NOR] Episode: 33110, Length: 247, e: 0.05, Avg Reward: -99.6467520821, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.83237934113\n",
      "[NOR] Episode: 33120, Length: 70, e: 0.05, Avg Reward: -119.857083961, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.39529848099\n",
      "[NOR] Episode: 33130, Length: 63, e: 0.05, Avg Reward: -121.257350599, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.88445353508\n",
      "[NOR] Episode: 33140, Length: 56, e: 0.05, Avg Reward: -158.097778686, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.34859132767\n",
      "[NOR] Episode: 33150, Length: 67, e: 0.05, Avg Reward: -147.611363312, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.87307834625\n",
      "[NOR] Episode: 33160, Length: 82, e: 0.05, Avg Reward: -143.841971092, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.45287323\n",
      "[NOR] Episode: 33170, Length: 66, e: 0.05, Avg Reward: -157.244556973, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.84023857117\n",
      "[NOR] Episode: 33180, Length: 90, e: 0.05, Avg Reward: -153.597701102, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.49879646301\n",
      "[NOR] Episode: 33190, Length: 62, e: 0.05, Avg Reward: -116.265417172, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.85970687866\n",
      "[NOR] Episode: 33200, Length: 99, e: 0.05, Avg Reward: -132.919140842, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.66428995132\n",
      "[NOR] Episode: 33210, Length: 125, e: 0.05, Avg Reward: -66.7965619539, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.68323469162\n",
      "[NOR] Episode: 33220, Length: 74, e: 0.05, Avg Reward: -124.50247864, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.34108376503\n",
      "[NOR] Episode: 33230, Length: 93, e: 0.05, Avg Reward: -194.452086874, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.0936756134\n",
      "[NOR] Episode: 33240, Length: 57, e: 0.05, Avg Reward: -148.234115701, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.94814777374\n",
      "[NOR] Episode: 33250, Length: 231, e: 0.05, Avg Reward: -58.0658497071, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 43.2596702576\n",
      "[NOR] Episode: 33260, Length: 61, e: 0.05, Avg Reward: -94.2166908032, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.61597061157\n",
      "[NOR] Episode: 33270, Length: 58, e: 0.05, Avg Reward: -143.089489444, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.67951440811\n",
      "[NOR] Episode: 33280, Length: 71, e: 0.05, Avg Reward: -143.883793341, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.17048549652\n",
      "[NOR] Episode: 33290, Length: 59, e: 0.05, Avg Reward: -157.190653151, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.25366544724\n",
      "[NOR] Episode: 33300, Length: 72, e: 0.05, Avg Reward: -138.892506189, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.06855487823\n",
      "[NOR] Episode: 33310, Length: 111, e: 0.05, Avg Reward: -123.641511838, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.53402519226\n",
      "[NOR] Episode: 33320, Length: 65, e: 0.05, Avg Reward: -123.608474994, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 171.873138428\n",
      "[NOR] Episode: 33330, Length: 85, e: 0.05, Avg Reward: -141.918192344, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.5569229126\n",
      "[NOR] Episode: 33340, Length: 90, e: 0.05, Avg Reward: -178.874674777, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.5017166138\n",
      "[NOR] Episode: 33350, Length: 128, e: 0.05, Avg Reward: -119.28098376, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.5322208405\n",
      "[NOR] Episode: 33360, Length: 67, e: 0.05, Avg Reward: -154.949553029, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.7099571228\n",
      "[NOR] Episode: 33370, Length: 137, e: 0.05, Avg Reward: -132.54679654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.39404678345\n",
      "[NOR] Episode: 33380, Length: 72, e: 0.05, Avg Reward: -106.505011777, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.71076965332\n",
      "[NOR] Episode: 33390, Length: 79, e: 0.05, Avg Reward: -133.510953981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.96807932854\n",
      "[NOR] Episode: 33400, Length: 98, e: 0.05, Avg Reward: -156.889865087, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.5766143799\n",
      "[NOR] Episode: 33410, Length: 57, e: 0.05, Avg Reward: -150.617637839, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.47646808624\n",
      "[NOR] Episode: 33420, Length: 69, e: 0.05, Avg Reward: -152.475099539, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.738305091858\n",
      "[NOR] Episode: 33430, Length: 81, e: 0.05, Avg Reward: -142.306449021, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.50579929352\n",
      "[NOR] Episode: 33440, Length: 68, e: 0.05, Avg Reward: -167.254969361, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.9389424324\n",
      "[NOR] Episode: 33450, Length: 72, e: 0.05, Avg Reward: -111.167490992, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -145.738723755\n",
      "[NOR] Episode: 33460, Length: 90, e: 0.05, Avg Reward: -114.291959713, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.7661857605\n",
      "[NOR] Episode: 33470, Length: 83, e: 0.05, Avg Reward: -119.657875708, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.96247577667\n",
      "[NOR] Episode: 33480, Length: 134, e: 0.05, Avg Reward: -110.718551055, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.88936710358\n",
      "[NOR] Episode: 33490, Length: 83, e: 0.05, Avg Reward: -130.638183951, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 46.4314842224\n",
      "[NOR] Episode: 33500, Length: 71, e: 0.05, Avg Reward: -156.633508587, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.0101280212\n",
      "[NOR] Episode: 33510, Length: 105, e: 0.05, Avg Reward: -126.658552048, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.32986164093\n",
      "[NOR] Episode: 33520, Length: 58, e: 0.05, Avg Reward: -140.763292348, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.8068313599\n",
      "[NOR] Episode: 33530, Length: 73, e: 0.05, Avg Reward: -110.258194842, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.69480276108\n",
      "[NOR] Episode: 33540, Length: 84, e: 0.05, Avg Reward: -144.961820912, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.68540048599\n",
      "[NOR] Episode: 33550, Length: 73, e: 0.05, Avg Reward: -177.37263645, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.55550289154\n",
      "[NOR] Episode: 33560, Length: 83, e: 0.05, Avg Reward: -161.313282742, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.10571455956\n",
      "[NOR] Episode: 33570, Length: 56, e: 0.05, Avg Reward: -173.778654881, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.67017221451\n",
      "[NOR] Episode: 33580, Length: 75, e: 0.05, Avg Reward: -133.921744208, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.9744644165\n",
      "[NOR] Episode: 33590, Length: 93, e: 0.05, Avg Reward: -111.682238345, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.23411750793\n",
      "[NOR] Episode: 33600, Length: 55, e: 0.05, Avg Reward: -133.695901519, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.75792598724\n",
      "[NOR] Episode: 33610, Length: 72, e: 0.05, Avg Reward: -157.909487423, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.1032037735\n",
      "[NOR] Episode: 33620, Length: 52, e: 0.05, Avg Reward: -77.7474144196, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.56964921951\n",
      "[NOR] Episode: 33630, Length: 59, e: 0.05, Avg Reward: -42.464506206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.60544157028\n",
      "[NOR] Episode: 33640, Length: 123, e: 0.05, Avg Reward: -67.2229812877, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.1849689484\n",
      "[NOR] Episode: 33650, Length: 111, e: 0.05, Avg Reward: -124.695479253, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.9619312286\n",
      "[NOR] Episode: 33660, Length: 63, e: 0.05, Avg Reward: -163.517650292, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.34168243408\n",
      "[NOR] Episode: 33670, Length: 63, e: 0.05, Avg Reward: -163.010005457, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.99208140373\n",
      "[NOR] Episode: 33680, Length: 95, e: 0.05, Avg Reward: -176.176773735, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.79090166092\n",
      "[NOR] Episode: 33690, Length: 98, e: 0.05, Avg Reward: -201.323215503, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.56192684174\n",
      "[NOR] Episode: 33700, Length: 63, e: 0.05, Avg Reward: -100.275994316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.8858776093\n",
      "[NOR] Episode: 33710, Length: 115, e: 0.05, Avg Reward: -123.401928231, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -68.5793457031\n",
      "[NOR] Episode: 33720, Length: 81, e: 0.05, Avg Reward: -127.942042416, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.99320697784\n",
      "[NOR] Episode: 33730, Length: 97, e: 0.05, Avg Reward: -141.367428359, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.00695466995\n",
      "[NOR] Episode: 33740, Length: 86, e: 0.05, Avg Reward: -168.871558204, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.65320491791\n",
      "[NOR] Episode: 33750, Length: 72, e: 0.05, Avg Reward: -137.37948206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.41345882416\n",
      "[NOR] Episode: 33760, Length: 90, e: 0.05, Avg Reward: -132.712486506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 56.4811973572\n",
      "[NOR] Episode: 33770, Length: 86, e: 0.05, Avg Reward: -156.465834821, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.48711133003\n",
      "[NOR] Episode: 33780, Length: 79, e: 0.05, Avg Reward: -85.443621693, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -29.6142463684\n",
      "[NOR] Episode: 33790, Length: 82, e: 0.05, Avg Reward: -162.502926282, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.31493282318\n",
      "[NOR] Episode: 33800, Length: 116, e: 0.05, Avg Reward: -125.591213835, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.38249206543\n",
      "[NOR] Episode: 33810, Length: 82, e: 0.05, Avg Reward: -130.984692192, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.4185342789\n",
      "[NOR] Episode: 33820, Length: 96, e: 0.05, Avg Reward: -89.6080144829, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.16137313843\n",
      "[NOR] Episode: 33830, Length: 88, e: 0.05, Avg Reward: -140.245080711, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.17120409012\n",
      "[NOR] Episode: 33840, Length: 63, e: 0.05, Avg Reward: -60.7893952936, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0160921514034\n",
      "[NOR] Episode: 33850, Length: 94, e: 0.05, Avg Reward: -131.376107844, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.47654342651\n",
      "[NOR] Episode: 33860, Length: 81, e: 0.05, Avg Reward: -102.353065482, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.85665559769\n",
      "[NOR] Episode: 33870, Length: 69, e: 0.05, Avg Reward: -152.206650214, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.82477593422\n",
      "[NOR] Episode: 33880, Length: 161, e: 0.05, Avg Reward: -139.779293089, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.1565322876\n",
      "[NOR] Episode: 33890, Length: 67, e: 0.05, Avg Reward: -181.825298574, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.85708427429\n",
      "[NOR] Episode: 33900, Length: 106, e: 0.05, Avg Reward: -155.455118713, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -78.6894683838\n",
      "[NOR] Episode: 33910, Length: 75, e: 0.05, Avg Reward: -148.670057028, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.696047544479\n",
      "[NOR] Episode: 33920, Length: 160, e: 0.05, Avg Reward: -89.7661672024, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.7891979218\n",
      "[NOR] Episode: 33930, Length: 79, e: 0.05, Avg Reward: -135.022582305, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.3169746399\n",
      "[NOR] Episode: 33940, Length: 55, e: 0.05, Avg Reward: -131.932358991, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.0770072937\n",
      "[NOR] Episode: 33950, Length: 100, e: 0.05, Avg Reward: -123.006162974, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.53391981125\n",
      "[NOR] Episode: 33960, Length: 55, e: 0.05, Avg Reward: -148.129827814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.8880853653\n",
      "[NOR] Episode: 33970, Length: 84, e: 0.05, Avg Reward: -120.10352357, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 28.7213935852\n",
      "[NOR] Episode: 33980, Length: 79, e: 0.05, Avg Reward: -127.638286463, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.20937824249\n",
      "[NOR] Episode: 33990, Length: 70, e: 0.05, Avg Reward: -179.697491224, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.99231159687\n",
      "[NOR] Episode: 34000, Length: 124, e: 0.05, Avg Reward: -124.595259545, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.256808042526\n",
      "[NOR] Episode: 34010, Length: 103, e: 0.05, Avg Reward: -137.445956225, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.899066925\n",
      "[NOR] Episode: 34020, Length: 97, e: 0.05, Avg Reward: -149.226329022, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 104.573516846\n",
      "[NOR] Episode: 34030, Length: 77, e: 0.05, Avg Reward: -73.1158889107, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.934859216213\n",
      "[NOR] Episode: 34040, Length: 100, e: 0.05, Avg Reward: -143.431911594, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.24830150604\n",
      "[NOR] Episode: 34050, Length: 76, e: 0.05, Avg Reward: -171.96115678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 71.0448608398\n",
      "[NOR] Episode: 34060, Length: 83, e: 0.05, Avg Reward: -105.492353472, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 41.359336853\n",
      "[NOR] Episode: 34070, Length: 71, e: 0.05, Avg Reward: -158.973700509, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.551268815994\n",
      "[NOR] Episode: 34080, Length: 87, e: 0.05, Avg Reward: -158.188369971, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.75736784935\n",
      "[NOR] Episode: 34090, Length: 111, e: 0.05, Avg Reward: -149.923224258, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.19636917114\n",
      "[NOR] Episode: 34100, Length: 92, e: 0.05, Avg Reward: -138.25403611, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.14159464836\n",
      "[NOR] Episode: 34110, Length: 96, e: 0.05, Avg Reward: -128.504552117, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.3874664307\n",
      "[NOR] Episode: 34120, Length: 78, e: 0.05, Avg Reward: -126.783027152, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.1826152802\n",
      "[NOR] Episode: 34130, Length: 145, e: 0.05, Avg Reward: -98.6519387759, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 26.7627506256\n",
      "[NOR] Episode: 34140, Length: 140, e: 0.05, Avg Reward: -116.391086934, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.4058151245\n",
      "[NOR] Episode: 34150, Length: 115, e: 0.05, Avg Reward: -121.921810991, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.62860941887\n",
      "[NOR] Episode: 34160, Length: 94, e: 0.05, Avg Reward: -128.174098366, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.16248750687\n",
      "[NOR] Episode: 34170, Length: 62, e: 0.05, Avg Reward: -112.730019774, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.1091575623\n",
      "[NOR] Episode: 34180, Length: 59, e: 0.05, Avg Reward: -141.430289125, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.26975059509\n",
      "[NOR] Episode: 34190, Length: 158, e: 0.05, Avg Reward: -117.743156968, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 74.8134536743\n",
      "[NOR] Episode: 34200, Length: 82, e: 0.05, Avg Reward: -122.590920939, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.4365606308\n",
      "[NOR] Episode: 34210, Length: 72, e: 0.05, Avg Reward: -158.017846495, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.8200435638\n",
      "[NOR] Episode: 34220, Length: 77, e: 0.05, Avg Reward: -136.781778884, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.7142429352\n",
      "[NOR] Episode: 34230, Length: 119, e: 0.05, Avg Reward: -171.371158002, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.77559781075\n",
      "[NOR] Episode: 34240, Length: 56, e: 0.05, Avg Reward: -167.71436412, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.57325077057\n",
      "[NOR] Episode: 34250, Length: 108, e: 0.05, Avg Reward: -121.561745269, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.86049365997\n",
      "[NOR] Episode: 34260, Length: 80, e: 0.05, Avg Reward: -187.229038097, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.6866827011\n",
      "[NOR] Episode: 34270, Length: 86, e: 0.05, Avg Reward: -134.773675171, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.87938165665\n",
      "[NOR] Episode: 34280, Length: 155, e: 0.05, Avg Reward: -107.398299838, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.4276027679\n",
      "[NOR] Episode: 34290, Length: 114, e: 0.05, Avg Reward: -164.147587673, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.12245845795\n",
      "[NOR] Episode: 34300, Length: 128, e: 0.05, Avg Reward: -163.602372223, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.6990261078\n",
      "[NOR] Episode: 34310, Length: 86, e: 0.05, Avg Reward: -140.178507098, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.413253307343\n",
      "[NOR] Episode: 34320, Length: 55, e: 0.05, Avg Reward: -176.313593946, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 22.8665542603\n",
      "[NOR] Episode: 34330, Length: 81, e: 0.05, Avg Reward: -135.66142084, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.3012933731\n",
      "[NOR] Episode: 34340, Length: 53, e: 0.05, Avg Reward: -99.4300571966, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.3289852142\n",
      "[NOR] Episode: 34350, Length: 106, e: 0.05, Avg Reward: -146.103789127, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.89968562126\n",
      "[NOR] Episode: 34360, Length: 83, e: 0.05, Avg Reward: -138.354516851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.8796024323\n",
      "[NOR] Episode: 34370, Length: 117, e: 0.05, Avg Reward: -109.215746713, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.3709230423\n",
      "[NOR] Episode: 34380, Length: 91, e: 0.05, Avg Reward: -150.760872744, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.91967594624\n",
      "[NOR] Episode: 34390, Length: 72, e: 0.05, Avg Reward: -129.284040731, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.24743437767\n",
      "[NOR] Episode: 34400, Length: 62, e: 0.05, Avg Reward: -137.688202477, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.3820495605\n",
      "[NOR] Episode: 34410, Length: 62, e: 0.05, Avg Reward: -134.057269904, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.41735363007\n",
      "[NOR] Episode: 34420, Length: 105, e: 0.05, Avg Reward: -192.367230369, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.86638307571\n",
      "[NOR] Episode: 34430, Length: 92, e: 0.05, Avg Reward: -166.342888085, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.6050453186\n",
      "[NOR] Episode: 34440, Length: 361, e: 0.05, Avg Reward: -153.914967647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.51260948181\n",
      "[NOR] Episode: 34450, Length: 73, e: 0.05, Avg Reward: -122.940163097, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.56313228607\n",
      "[NOR] Episode: 34460, Length: 75, e: 0.05, Avg Reward: -92.8823566585, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.592765331268\n",
      "[NOR] Episode: 34470, Length: 75, e: 0.05, Avg Reward: -155.90672683, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.3360671997\n",
      "[NOR] Episode: 34480, Length: 167, e: 0.05, Avg Reward: -153.752225259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.86387872696\n",
      "[NOR] Episode: 34490, Length: 83, e: 0.05, Avg Reward: -147.857485709, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.42497253418\n",
      "[NOR] Episode: 34500, Length: 98, e: 0.05, Avg Reward: -136.223311876, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.6046686172\n",
      "[NOR] Episode: 34510, Length: 88, e: 0.05, Avg Reward: -122.580333366, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -32.2833366394\n",
      "[NOR] Episode: 34520, Length: 78, e: 0.05, Avg Reward: -162.238669748, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.84474802017\n",
      "[NOR] Episode: 34530, Length: 76, e: 0.05, Avg Reward: -138.48109764, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.4564838409\n",
      "[NOR] Episode: 34540, Length: 92, e: 0.05, Avg Reward: -163.345431262, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.0296096802\n",
      "[NOR] Episode: 34550, Length: 98, e: 0.05, Avg Reward: -145.668484268, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.52821731567\n",
      "[NOR] Episode: 34560, Length: 98, e: 0.05, Avg Reward: -122.389739306, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.06145811081\n",
      "[NOR] Episode: 34570, Length: 114, e: 0.05, Avg Reward: -139.197769423, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.49195098877\n",
      "[NOR] Episode: 34580, Length: 72, e: 0.05, Avg Reward: -109.257229095, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.72782373428\n",
      "[NOR] Episode: 34590, Length: 118, e: 0.05, Avg Reward: -119.563590902, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.152051389217\n",
      "[NOR] Episode: 34600, Length: 74, e: 0.05, Avg Reward: -136.675849795, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.51711845398\n",
      "[NOR] Episode: 34610, Length: 88, e: 0.05, Avg Reward: -143.682845142, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.42094826698\n",
      "[NOR] Episode: 34620, Length: 56, e: 0.05, Avg Reward: -119.883167816, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.88980674744\n",
      "[NOR] Episode: 34630, Length: 93, e: 0.05, Avg Reward: -163.631383867, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.0062122345\n",
      "[NOR] Episode: 34640, Length: 62, e: 0.05, Avg Reward: -93.9700124429, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.58018302917\n",
      "[NOR] Episode: 34650, Length: 85, e: 0.05, Avg Reward: -154.463732498, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.43927395344\n",
      "[NOR] Episode: 34660, Length: 98, e: 0.05, Avg Reward: -91.041282825, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.96632099152\n",
      "[NOR] Episode: 34670, Length: 196, e: 0.05, Avg Reward: -115.426487819, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.34972381592\n",
      "[NOR] Episode: 34680, Length: 67, e: 0.05, Avg Reward: -153.295285555, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.40787696838\n",
      "[NOR] Episode: 34690, Length: 101, e: 0.05, Avg Reward: -83.0831942182, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.90129899979\n",
      "[NOR] Episode: 34700, Length: 66, e: 0.05, Avg Reward: -136.413866144, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.4175965786\n",
      "[NOR] Episode: 34710, Length: 64, e: 0.05, Avg Reward: -176.831120244, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.85430049896\n",
      "[NOR] Episode: 34720, Length: 77, e: 0.05, Avg Reward: -100.236700212, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.0210037231\n",
      "[NOR] Episode: 34730, Length: 70, e: 0.05, Avg Reward: -103.558571189, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.1220855713\n",
      "[NOR] Episode: 34740, Length: 79, e: 0.05, Avg Reward: -72.97017924, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.3284263611\n",
      "[NOR] Episode: 34750, Length: 77, e: 0.05, Avg Reward: -148.134897867, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.14448738098\n",
      "[NOR] Episode: 34760, Length: 165, e: 0.05, Avg Reward: -124.903177211, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.343328476\n",
      "[NOR] Episode: 34770, Length: 84, e: 0.05, Avg Reward: -86.5805419075, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.42292976379\n",
      "[NOR] Episode: 34780, Length: 83, e: 0.05, Avg Reward: -161.825648083, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.78934574127\n",
      "[NOR] Episode: 34790, Length: 98, e: 0.05, Avg Reward: -117.686071201, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.501652777195\n",
      "[NOR] Episode: 34800, Length: 80, e: 0.05, Avg Reward: -187.152856135, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.399023771286\n",
      "[NOR] Episode: 34810, Length: 92, e: 0.05, Avg Reward: -191.725866942, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.362684011459\n",
      "[NOR] Episode: 34820, Length: 84, e: 0.05, Avg Reward: -187.136217851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.65496206284\n",
      "[NOR] Episode: 34830, Length: 77, e: 0.05, Avg Reward: -121.094703351, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.71760559082\n",
      "[NOR] Episode: 34840, Length: 63, e: 0.05, Avg Reward: -119.085648573, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.45340132713\n",
      "[NOR] Episode: 34850, Length: 77, e: 0.05, Avg Reward: -162.994427071, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.79760551453\n",
      "[NOR] Episode: 34860, Length: 57, e: 0.05, Avg Reward: -113.113083799, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -46.9176139832\n",
      "[NOR] Episode: 34870, Length: 106, e: 0.05, Avg Reward: -108.155859933, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.95333147049\n",
      "[NOR] Episode: 34880, Length: 92, e: 0.05, Avg Reward: -41.3717105827, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.414540380239\n",
      "[NOR] Episode: 34890, Length: 82, e: 0.05, Avg Reward: -75.4981426759, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.67183756828\n",
      "[NOR] Episode: 34900, Length: 73, e: 0.05, Avg Reward: -145.953534545, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.58489131927\n",
      "[NOR] Episode: 34910, Length: 52, e: 0.05, Avg Reward: -140.585331838, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.93788719177\n",
      "[NOR] Episode: 34920, Length: 71, e: 0.05, Avg Reward: -125.512011087, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.8028373718\n",
      "[NOR] Episode: 34930, Length: 62, e: 0.05, Avg Reward: -153.875533193, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.84911870956\n",
      "[NOR] Episode: 34940, Length: 90, e: 0.05, Avg Reward: -136.974258559, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.7063434124\n",
      "[NOR] Episode: 34950, Length: 68, e: 0.05, Avg Reward: -119.17802747, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.7187194824\n",
      "[NOR] Episode: 34960, Length: 126, e: 0.05, Avg Reward: -152.273772279, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.3485212326\n",
      "[NOR] Episode: 34970, Length: 103, e: 0.05, Avg Reward: -153.289547775, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.227722168\n",
      "[NOR] Episode: 34980, Length: 89, e: 0.05, Avg Reward: -158.136567741, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.5527915955\n",
      "[NOR] Episode: 34990, Length: 73, e: 0.05, Avg Reward: -117.733064822, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.3216075897\n",
      "[NOR] Episode: 35000, Length: 62, e: 0.05, Avg Reward: -123.253198454, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.20521211624\n",
      "[NOR] Episode: 35010, Length: 73, e: 0.05, Avg Reward: -162.617485393, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.22280597687\n",
      "[NOR] Episode: 35020, Length: 78, e: 0.05, Avg Reward: -99.4609504981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.957632899284\n",
      "[NOR] Episode: 35030, Length: 98, e: 0.05, Avg Reward: -120.376760106, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.05288648605\n",
      "[NOR] Episode: 35040, Length: 101, e: 0.05, Avg Reward: -111.243264812, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.27564573288\n",
      "[NOR] Episode: 35050, Length: 70, e: 0.05, Avg Reward: -54.36107311, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.41439843178\n",
      "[NOR] Episode: 35060, Length: 52, e: 0.05, Avg Reward: -118.845347739, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.188331604\n",
      "[NOR] Episode: 35070, Length: 95, e: 0.05, Avg Reward: -125.296898841, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.4240245819\n",
      "[NOR] Episode: 35080, Length: 96, e: 0.05, Avg Reward: -196.534570114, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.7910394669\n",
      "[NOR] Episode: 35090, Length: 58, e: 0.05, Avg Reward: -114.777147479, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.6552724838\n",
      "[NOR] Episode: 35100, Length: 107, e: 0.05, Avg Reward: -128.006095965, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.97861862183\n",
      "[NOR] Episode: 35110, Length: 81, e: 0.05, Avg Reward: -169.870714418, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.4119815826\n",
      "[NOR] Episode: 35120, Length: 72, e: 0.05, Avg Reward: -127.557444653, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.6120700836\n",
      "[NOR] Episode: 35130, Length: 65, e: 0.05, Avg Reward: -137.319356728, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.3358688354\n",
      "[NOR] Episode: 35140, Length: 115, e: 0.05, Avg Reward: -120.475672399, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.10478854179\n",
      "[NOR] Episode: 35150, Length: 61, e: 0.05, Avg Reward: -167.496341493, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.58362388611\n",
      "[NOR] Episode: 35160, Length: 94, e: 0.05, Avg Reward: -106.536359935, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.269019812346\n",
      "[NOR] Episode: 35170, Length: 84, e: 0.05, Avg Reward: -185.234280603, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.141857147217\n",
      "[NOR] Episode: 35180, Length: 94, e: 0.05, Avg Reward: -161.542289109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.29236793518\n",
      "[NOR] Episode: 35190, Length: 197, e: 0.05, Avg Reward: -121.427994452, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.34832715988\n",
      "[NOR] Episode: 35200, Length: 65, e: 0.05, Avg Reward: -159.04520191, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.87202215195\n",
      "[NOR] Episode: 35210, Length: 85, e: 0.05, Avg Reward: -137.992414109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.04340553284\n",
      "[NOR] Episode: 35220, Length: 103, e: 0.05, Avg Reward: -145.689822123, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.18229389191\n",
      "[NOR] Episode: 35230, Length: 82, e: 0.05, Avg Reward: -103.932912457, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.23530817032\n",
      "[NOR] Episode: 35240, Length: 87, e: 0.05, Avg Reward: -142.891895817, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.4752907753\n",
      "[NOR] Episode: 35250, Length: 64, e: 0.05, Avg Reward: -163.583904758, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.05481052399\n",
      "[NOR] Episode: 35260, Length: 231, e: 0.05, Avg Reward: -110.879789791, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.253856420517\n",
      "[NOR] Episode: 35270, Length: 142, e: 0.05, Avg Reward: -118.592801438, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.6699333191\n",
      "[NOR] Episode: 35280, Length: 97, e: 0.05, Avg Reward: -109.039572354, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.10701799393\n",
      "[NOR] Episode: 35290, Length: 182, e: 0.05, Avg Reward: -145.355664466, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.05035376549\n",
      "[NOR] Episode: 35300, Length: 55, e: 0.05, Avg Reward: -153.383134305, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.9063835144\n",
      "[NOR] Episode: 35310, Length: 86, e: 0.05, Avg Reward: -145.208466833, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.8464126587\n",
      "[NOR] Episode: 35320, Length: 80, e: 0.05, Avg Reward: -124.560595329, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.58021235466\n",
      "[NOR] Episode: 35330, Length: 82, e: 0.05, Avg Reward: -122.869318861, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.763350903988\n",
      "[NOR] Episode: 35340, Length: 98, e: 0.05, Avg Reward: -153.114811279, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.9386291504\n",
      "[NOR] Episode: 35350, Length: 96, e: 0.05, Avg Reward: -148.608875087, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.21369886398\n",
      "[NOR] Episode: 35360, Length: 104, e: 0.05, Avg Reward: -151.089762372, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.402766108513\n",
      "[NOR] Episode: 35370, Length: 106, e: 0.05, Avg Reward: -132.472748458, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.65106678009\n",
      "[NOR] Episode: 35380, Length: 120, e: 0.05, Avg Reward: -144.702512121, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.18860912323\n",
      "[NOR] Episode: 35390, Length: 69, e: 0.05, Avg Reward: -111.274451887, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.7182469368\n",
      "[NOR] Episode: 35400, Length: 104, e: 0.05, Avg Reward: -115.294251161, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.01437187195\n",
      "[NOR] Episode: 35410, Length: 78, e: 0.05, Avg Reward: -145.592330743, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.05940651894\n",
      "[NOR] Episode: 35420, Length: 97, e: 0.05, Avg Reward: -143.252757688, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.91485404968\n",
      "[NOR] Episode: 35430, Length: 64, e: 0.05, Avg Reward: -142.86622574, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.34836149216\n",
      "[NOR] Episode: 35440, Length: 91, e: 0.05, Avg Reward: -144.482052427, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.09100842476\n",
      "[NOR] Episode: 35450, Length: 150, e: 0.05, Avg Reward: -105.581103649, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.80614924431\n",
      "[NOR] Episode: 35460, Length: 114, e: 0.05, Avg Reward: -159.528658274, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.79126596451\n",
      "[NOR] Episode: 35470, Length: 73, e: 0.05, Avg Reward: -106.688610173, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 27.5608329773\n",
      "[NOR] Episode: 35480, Length: 93, e: 0.05, Avg Reward: -131.641892464, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.54322338104\n",
      "[NOR] Episode: 35490, Length: 91, e: 0.05, Avg Reward: -155.476129819, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 95.9270401001\n",
      "[NOR] Episode: 35500, Length: 93, e: 0.05, Avg Reward: -148.385330355, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.01514339447\n",
      "[NOR] Episode: 35510, Length: 95, e: 0.05, Avg Reward: -107.659591191, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.33319473267\n",
      "[NOR] Episode: 35520, Length: 66, e: 0.05, Avg Reward: -133.834454178, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.2259101868\n",
      "[NOR] Episode: 35530, Length: 79, e: 0.05, Avg Reward: -136.669089437, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.60985803604\n",
      "[NOR] Episode: 35540, Length: 105, e: 0.05, Avg Reward: -105.067019264, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.42377567291\n",
      "[NOR] Episode: 35550, Length: 111, e: 0.05, Avg Reward: -122.739466514, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.02120780945\n",
      "[NOR] Episode: 35560, Length: 63, e: 0.05, Avg Reward: -179.252282082, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.35993146896\n",
      "[NOR] Episode: 35570, Length: 74, e: 0.05, Avg Reward: -140.852572799, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.21722173691\n",
      "[NOR] Episode: 35580, Length: 64, e: 0.05, Avg Reward: -63.3709756359, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.2606201172\n",
      "[NOR] Episode: 35590, Length: 134, e: 0.05, Avg Reward: -147.77628228, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.2918014526\n",
      "[NOR] Episode: 35600, Length: 95, e: 0.05, Avg Reward: -119.532088141, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.20213890076\n",
      "[NOR] Episode: 35610, Length: 70, e: 0.05, Avg Reward: -120.521299825, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.14804506302\n",
      "[NOR] Episode: 35620, Length: 106, e: 0.05, Avg Reward: -128.465570176, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.263859272\n",
      "[NOR] Episode: 35630, Length: 54, e: 0.05, Avg Reward: -144.85559266, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.6065788269\n",
      "[NOR] Episode: 35640, Length: 70, e: 0.05, Avg Reward: -131.850895107, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.4911632538\n",
      "[NOR] Episode: 35650, Length: 151, e: 0.05, Avg Reward: -43.9335664126, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.01415061951\n",
      "[NOR] Episode: 35660, Length: 114, e: 0.05, Avg Reward: -130.467928661, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.2322306633\n",
      "[NOR] Episode: 35670, Length: 64, e: 0.05, Avg Reward: -105.331015071, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0573625564575\n",
      "[NOR] Episode: 35680, Length: 107, e: 0.05, Avg Reward: -152.885013961, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 102.664787292\n",
      "[NOR] Episode: 35690, Length: 121, e: 0.05, Avg Reward: -119.258757685, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.8907165527\n",
      "[NOR] Episode: 35700, Length: 131, e: 0.05, Avg Reward: -117.901066713, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.17122209072\n",
      "[NOR] Episode: 35710, Length: 198, e: 0.05, Avg Reward: -113.347024892, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.188184723258\n",
      "[NOR] Episode: 35720, Length: 85, e: 0.05, Avg Reward: -129.868277038, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.71777319908\n",
      "[NOR] Episode: 35730, Length: 141, e: 0.05, Avg Reward: -139.368508254, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.37950134277\n",
      "[NOR] Episode: 35740, Length: 75, e: 0.05, Avg Reward: -171.557990241, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.3058142066\n",
      "[NOR] Episode: 35750, Length: 78, e: 0.05, Avg Reward: -143.487185026, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.44005775452\n",
      "[NOR] Episode: 35760, Length: 114, e: 0.05, Avg Reward: -146.088146109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.286361694336\n",
      "[NOR] Episode: 35770, Length: 59, e: 0.05, Avg Reward: -114.567197223, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.1443824768\n",
      "[NOR] Episode: 35780, Length: 58, e: 0.05, Avg Reward: -147.596986493, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.8236322403\n",
      "[NOR] Episode: 35790, Length: 97, e: 0.05, Avg Reward: -145.637998222, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.93385601044\n",
      "[NOR] Episode: 35800, Length: 95, e: 0.05, Avg Reward: -129.882695871, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0180121660233\n",
      "[NOR] Episode: 35810, Length: 108, e: 0.05, Avg Reward: -116.722857269, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.636724472\n",
      "[NOR] Episode: 35820, Length: 79, e: 0.05, Avg Reward: -138.218680781, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 63.4159965515\n",
      "[NOR] Episode: 35830, Length: 74, e: 0.05, Avg Reward: -136.207319854, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.69756507874\n",
      "[NOR] Episode: 35840, Length: 78, e: 0.05, Avg Reward: -150.619708715, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.048282623291\n",
      "[NOR] Episode: 35850, Length: 84, e: 0.05, Avg Reward: -149.062145499, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.553696393967\n",
      "[NOR] Episode: 35860, Length: 98, e: 0.05, Avg Reward: -129.854824314, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.873135328293\n",
      "[NOR] Episode: 35870, Length: 81, e: 0.05, Avg Reward: -133.537625973, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.66035938263\n",
      "[NOR] Episode: 35880, Length: 108, e: 0.05, Avg Reward: -126.149704712, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.07170772552\n",
      "[NOR] Episode: 35890, Length: 71, e: 0.05, Avg Reward: -175.017519175, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.0958738327\n",
      "[NOR] Episode: 35900, Length: 63, e: 0.05, Avg Reward: -151.301110289, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.598551332951\n",
      "[NOR] Episode: 35910, Length: 80, e: 0.05, Avg Reward: -112.798925146, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.9707489014\n",
      "[NOR] Episode: 35920, Length: 80, e: 0.05, Avg Reward: -131.76817254, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.44118118286\n",
      "[NOR] Episode: 35930, Length: 220, e: 0.05, Avg Reward: -135.625559197, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.3493270874\n",
      "[NOR] Episode: 35940, Length: 76, e: 0.05, Avg Reward: -118.355377657, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.51161289215\n",
      "[NOR] Episode: 35950, Length: 96, e: 0.05, Avg Reward: -112.381286541, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.411570549\n",
      "[NOR] Episode: 35960, Length: 278, e: 0.05, Avg Reward: -153.652495886, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.34021663666\n",
      "[NOR] Episode: 35970, Length: 108, e: 0.05, Avg Reward: -115.16902098, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.748791694641\n",
      "[NOR] Episode: 35980, Length: 69, e: 0.05, Avg Reward: -78.5698945614, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.97886514664\n",
      "[NOR] Episode: 35990, Length: 99, e: 0.05, Avg Reward: -190.313376297, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.0325050354\n",
      "[NOR] Episode: 36000, Length: 317, e: 0.05, Avg Reward: -160.921259046, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.82128572464\n",
      "[NOR] Episode: 36010, Length: 89, e: 0.05, Avg Reward: -149.42059058, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -33.0534973145\n",
      "[NOR] Episode: 36020, Length: 80, e: 0.05, Avg Reward: -88.1261513466, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.489922165871\n",
      "[NOR] Episode: 36030, Length: 93, e: 0.05, Avg Reward: -82.2446629477, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.8222925663\n",
      "[NOR] Episode: 36040, Length: 70, e: 0.05, Avg Reward: -138.993806471, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.36595821381\n",
      "[NOR] Episode: 36050, Length: 73, e: 0.05, Avg Reward: -154.024355639, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.128105342388\n",
      "[NOR] Episode: 36060, Length: 103, e: 0.05, Avg Reward: -169.321822703, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.45032787323\n",
      "[NOR] Episode: 36070, Length: 78, e: 0.05, Avg Reward: -136.00187341, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.19586038589\n",
      "[NOR] Episode: 36080, Length: 109, e: 0.05, Avg Reward: -174.899113663, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.64760828018\n",
      "[NOR] Episode: 36090, Length: 78, e: 0.05, Avg Reward: -74.4464147771, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.0695552826\n",
      "[NOR] Episode: 36100, Length: 68, e: 0.05, Avg Reward: -153.583028993, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.05816483498\n",
      "[NOR] Episode: 36110, Length: 96, e: 0.05, Avg Reward: -103.612391835, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.21922874451\n",
      "[NOR] Episode: 36120, Length: 72, e: 0.05, Avg Reward: -162.666390187, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.16618263721\n",
      "[NOR] Episode: 36130, Length: 119, e: 0.05, Avg Reward: -142.102797922, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.17940711975\n",
      "[NOR] Episode: 36140, Length: 64, e: 0.05, Avg Reward: -164.605171061, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.86352348328\n",
      "[NOR] Episode: 36150, Length: 100, e: 0.05, Avg Reward: -161.613902918, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.1359510422\n",
      "[NOR] Episode: 36160, Length: 321, e: 0.05, Avg Reward: -124.706431153, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.1861352921\n",
      "[NOR] Episode: 36170, Length: 62, e: 0.05, Avg Reward: -103.011500026, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.20988225937\n",
      "[NOR] Episode: 36180, Length: 86, e: 0.05, Avg Reward: -74.8000174788, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.63795661926\n",
      "[NOR] Episode: 36190, Length: 83, e: 0.05, Avg Reward: -190.004889876, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.15663433075\n",
      "[NOR] Episode: 36200, Length: 74, e: 0.05, Avg Reward: -117.876781868, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.27176094055\n",
      "[NOR] Episode: 36210, Length: 161, e: 0.05, Avg Reward: -185.944928839, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.79678273201\n",
      "[NOR] Episode: 36220, Length: 116, e: 0.05, Avg Reward: -188.407733829, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.27394342422\n",
      "[NOR] Episode: 36230, Length: 91, e: 0.05, Avg Reward: -158.434794582, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.141225814819\n",
      "[NOR] Episode: 36240, Length: 129, e: 0.05, Avg Reward: -202.74340746, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 34.9651489258\n",
      "[NOR] Episode: 36250, Length: 98, e: 0.05, Avg Reward: -108.235963833, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.75630283356\n",
      "[NOR] Episode: 36260, Length: 69, e: 0.05, Avg Reward: -157.147368864, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 77.8182144165\n",
      "[NOR] Episode: 36270, Length: 57, e: 0.05, Avg Reward: -164.882290728, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.09973526\n",
      "[NOR] Episode: 36280, Length: 158, e: 0.05, Avg Reward: -146.982738597, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 32.0783462524\n",
      "[NOR] Episode: 36290, Length: 107, e: 0.05, Avg Reward: -179.502389409, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.34773445129\n",
      "[NOR] Episode: 36300, Length: 104, e: 0.05, Avg Reward: -216.466201917, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.2927999496\n",
      "[NOR] Episode: 36310, Length: 120, e: 0.05, Avg Reward: -144.28432004, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -54.115032196\n",
      "[NOR] Episode: 36320, Length: 133, e: 0.05, Avg Reward: -131.010371452, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.05445098877\n",
      "[NOR] Episode: 36330, Length: 83, e: 0.05, Avg Reward: -190.273148784, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.98178672791\n",
      "[NOR] Episode: 36340, Length: 101, e: 0.05, Avg Reward: -171.601134345, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.0333757401\n",
      "[NOR] Episode: 36350, Length: 55, e: 0.05, Avg Reward: -138.536519624, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.5014257431\n",
      "[NOR] Episode: 36360, Length: 79, e: 0.05, Avg Reward: -202.149074234, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.4349040985\n",
      "[NOR] Episode: 36370, Length: 90, e: 0.05, Avg Reward: -139.08110789, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.94016718864\n",
      "[NOR] Episode: 36380, Length: 137, e: 0.05, Avg Reward: -130.76696923, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.18059158325\n",
      "[NOR] Episode: 36390, Length: 98, e: 0.05, Avg Reward: -161.666362278, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.02311992645\n",
      "[NOR] Episode: 36400, Length: 58, e: 0.05, Avg Reward: -171.965183302, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.06952142715\n",
      "[NOR] Episode: 36410, Length: 184, e: 0.05, Avg Reward: -110.393873628, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.00472640991\n",
      "[NOR] Episode: 36420, Length: 92, e: 0.05, Avg Reward: -155.318560702, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.61012125015\n",
      "[NOR] Episode: 36430, Length: 118, e: 0.05, Avg Reward: -191.308406532, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.67840862274\n",
      "[NOR] Episode: 36440, Length: 137, e: 0.05, Avg Reward: -143.404450371, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.571962714195\n",
      "[NOR] Episode: 36450, Length: 81, e: 0.05, Avg Reward: -150.477464159, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.47631692886\n",
      "[NOR] Episode: 36460, Length: 94, e: 0.05, Avg Reward: -123.934672043, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.900751113892\n",
      "[NOR] Episode: 36470, Length: 143, e: 0.05, Avg Reward: -196.201904349, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.06187057495\n",
      "[NOR] Episode: 36480, Length: 79, e: 0.05, Avg Reward: -176.920575861, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.13541793823\n",
      "[NOR] Episode: 36490, Length: 69, e: 0.05, Avg Reward: -123.225396229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.87203454971\n",
      "[NOR] Episode: 36500, Length: 75, e: 0.05, Avg Reward: -86.0145233612, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.74338722229\n",
      "[NOR] Episode: 36510, Length: 182, e: 0.05, Avg Reward: -123.3833815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.00477695465\n",
      "[NOR] Episode: 36520, Length: 82, e: 0.05, Avg Reward: -114.953057129, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.98765945435\n",
      "[NOR] Episode: 36530, Length: 79, e: 0.05, Avg Reward: -94.8199707354, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.7042222023\n",
      "[NOR] Episode: 36540, Length: 123, e: 0.05, Avg Reward: -149.931430891, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.3990802765\n",
      "[NOR] Episode: 36550, Length: 90, e: 0.05, Avg Reward: -155.254292483, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.09317588806\n",
      "[NOR] Episode: 36560, Length: 107, e: 0.05, Avg Reward: -154.941546674, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.51951694489\n",
      "[NOR] Episode: 36570, Length: 122, e: 0.05, Avg Reward: -169.649257957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.06650280952\n",
      "[NOR] Episode: 36580, Length: 104, e: 0.05, Avg Reward: -127.738524881, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.87585735321\n",
      "[NOR] Episode: 36590, Length: 84, e: 0.05, Avg Reward: -154.79739306, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.40768671036\n",
      "[NOR] Episode: 36600, Length: 67, e: 0.05, Avg Reward: -199.557398839, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.3736209869\n",
      "[NOR] Episode: 36610, Length: 83, e: 0.05, Avg Reward: -121.390590013, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.55480480194\n",
      "[NOR] Episode: 36620, Length: 91, e: 0.05, Avg Reward: -174.65820565, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.54003238678\n",
      "[NOR] Episode: 36630, Length: 114, e: 0.05, Avg Reward: -121.367426871, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.73648786545\n",
      "[NOR] Episode: 36640, Length: 93, e: 0.05, Avg Reward: -108.187429465, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.93903684616\n",
      "[NOR] Episode: 36650, Length: 79, e: 0.05, Avg Reward: -183.083846205, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.0156383514\n",
      "[NOR] Episode: 36660, Length: 95, e: 0.05, Avg Reward: -152.618175753, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.56134271622\n",
      "[NOR] Episode: 36670, Length: 101, e: 0.05, Avg Reward: -183.103092369, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.7885594368\n",
      "[NOR] Episode: 36680, Length: 235, e: 0.05, Avg Reward: -176.010547211, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.85894966125\n",
      "[NOR] Episode: 36690, Length: 206, e: 0.05, Avg Reward: -125.254261002, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.37872409821\n",
      "[NOR] Episode: 36700, Length: 91, e: 0.05, Avg Reward: -143.632006682, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.89554476738\n",
      "[NOR] Episode: 36710, Length: 73, e: 0.05, Avg Reward: -202.996342158, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.91080951691\n",
      "[NOR] Episode: 36720, Length: 154, e: 0.05, Avg Reward: -187.552236242, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -31.7852268219\n",
      "[NOR] Episode: 36730, Length: 123, e: 0.05, Avg Reward: -188.514072092, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.496175766\n",
      "[NOR] Episode: 36740, Length: 83, e: 0.05, Avg Reward: -134.746766707, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.1578216553\n",
      "[NOR] Episode: 36750, Length: 118, e: 0.05, Avg Reward: -164.432436811, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.12744665146\n",
      "[NOR] Episode: 36760, Length: 65, e: 0.05, Avg Reward: -225.731103539, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.38104403019\n",
      "[NOR] Episode: 36770, Length: 109, e: 0.05, Avg Reward: -146.567607697, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.46862030029\n",
      "[NOR] Episode: 36780, Length: 83, e: 0.05, Avg Reward: -151.547254667, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.272990226746\n",
      "[NOR] Episode: 36790, Length: 105, e: 0.05, Avg Reward: -152.997732669, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.41441297531\n",
      "[NOR] Episode: 36800, Length: 72, e: 0.05, Avg Reward: -228.204970988, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.576822757721\n",
      "[NOR] Episode: 36810, Length: 100, e: 0.05, Avg Reward: -127.411941324, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.9449319839\n",
      "[NOR] Episode: 36820, Length: 83, e: 0.05, Avg Reward: -153.584842613, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.92769646645\n",
      "[NOR] Episode: 36830, Length: 100, e: 0.05, Avg Reward: -105.22066695, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.12393951416\n",
      "[NOR] Episode: 36840, Length: 85, e: 0.05, Avg Reward: -194.143722617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.00379180908\n",
      "[NOR] Episode: 36850, Length: 66, e: 0.05, Avg Reward: -140.863852196, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.76825046539\n",
      "[NOR] Episode: 36860, Length: 73, e: 0.05, Avg Reward: -162.576506318, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.74732255936\n",
      "[NOR] Episode: 36870, Length: 76, e: 0.05, Avg Reward: -162.696690619, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.96528100967\n",
      "[NOR] Episode: 36880, Length: 104, e: 0.05, Avg Reward: -125.487743111, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.703215897083\n",
      "[NOR] Episode: 36890, Length: 85, e: 0.05, Avg Reward: -181.624629971, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.48396718502\n",
      "[NOR] Episode: 36900, Length: 85, e: 0.05, Avg Reward: -150.036993878, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.9168548584\n",
      "[NOR] Episode: 36910, Length: 103, e: 0.05, Avg Reward: -115.091003019, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.01047325134\n",
      "[NOR] Episode: 36920, Length: 93, e: 0.05, Avg Reward: -135.99032984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.57723259926\n",
      "[NOR] Episode: 36930, Length: 159, e: 0.05, Avg Reward: -157.050702041, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.71178865433\n",
      "[NOR] Episode: 36940, Length: 93, e: 0.05, Avg Reward: -173.775901535, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.7903375626\n",
      "[NOR] Episode: 36950, Length: 57, e: 0.05, Avg Reward: -110.314667075, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.815405368805\n",
      "[NOR] Episode: 36960, Length: 111, e: 0.05, Avg Reward: -159.058151649, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.08640527725\n",
      "[NOR] Episode: 36970, Length: 85, e: 0.05, Avg Reward: -228.021313954, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.93940103054\n",
      "[NOR] Episode: 36980, Length: 85, e: 0.05, Avg Reward: -132.031690142, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0713832378387\n",
      "[NOR] Episode: 36990, Length: 82, e: 0.05, Avg Reward: -199.994928407, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.56360340118\n",
      "[NOR] Episode: 37000, Length: 98, e: 0.05, Avg Reward: -180.000886992, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.75454330444\n",
      "[NOR] Episode: 37010, Length: 84, e: 0.05, Avg Reward: -193.917716291, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.0270328522\n",
      "[NOR] Episode: 37020, Length: 127, e: 0.05, Avg Reward: -209.607742743, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.4785823822\n",
      "[NOR] Episode: 37030, Length: 107, e: 0.05, Avg Reward: -211.503153851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.51597332954\n",
      "[NOR] Episode: 37040, Length: 94, e: 0.05, Avg Reward: -172.736367653, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.615685463\n",
      "[NOR] Episode: 37050, Length: 126, e: 0.05, Avg Reward: -191.821640326, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.26721477509\n",
      "[NOR] Episode: 37060, Length: 149, e: 0.05, Avg Reward: -140.500708289, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.89924812317\n",
      "[NOR] Episode: 37070, Length: 124, e: 0.05, Avg Reward: -174.326129101, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.49675536156\n",
      "[NOR] Episode: 37080, Length: 78, e: 0.05, Avg Reward: -164.204373424, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.201015949249\n",
      "[NOR] Episode: 37090, Length: 87, e: 0.05, Avg Reward: -127.987167426, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.70007658005\n",
      "[NOR] Episode: 37100, Length: 83, e: 0.05, Avg Reward: -196.025016032, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.8918371201\n",
      "[NOR] Episode: 37110, Length: 125, e: 0.05, Avg Reward: -124.561810172, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.0709276199\n",
      "[NOR] Episode: 37120, Length: 63, e: 0.05, Avg Reward: -168.648635617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.2188835144\n",
      "[NOR] Episode: 37130, Length: 83, e: 0.05, Avg Reward: -133.561861575, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.50340270996\n",
      "[NOR] Episode: 37140, Length: 117, e: 0.05, Avg Reward: -167.983032562, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.2920999527\n",
      "[NOR] Episode: 37150, Length: 96, e: 0.05, Avg Reward: -128.68859642, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.049747467\n",
      "[NOR] Episode: 37160, Length: 125, e: 0.05, Avg Reward: -112.271913707, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.0045051575\n",
      "[NOR] Episode: 37170, Length: 93, e: 0.05, Avg Reward: -156.740117437, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.620245456696\n",
      "[NOR] Episode: 37180, Length: 55, e: 0.05, Avg Reward: -153.962609017, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.2259883881\n",
      "[NOR] Episode: 37190, Length: 69, e: 0.05, Avg Reward: -153.138920609, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.867272377\n",
      "[NOR] Episode: 37200, Length: 87, e: 0.05, Avg Reward: -136.417301953, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.31993341446\n",
      "[NOR] Episode: 37210, Length: 84, e: 0.05, Avg Reward: -149.393049177, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.51405239105\n",
      "[NOR] Episode: 37220, Length: 93, e: 0.05, Avg Reward: -134.330597198, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.52275967598\n",
      "[NOR] Episode: 37230, Length: 127, e: 0.05, Avg Reward: -137.154359497, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.758187294\n",
      "[NOR] Episode: 37240, Length: 160, e: 0.05, Avg Reward: -115.366981778, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.23345017433\n",
      "[NOR] Episode: 37250, Length: 90, e: 0.05, Avg Reward: -103.024219992, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.454211235046\n",
      "[NOR] Episode: 37260, Length: 80, e: 0.05, Avg Reward: -155.342255882, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.5407829285\n",
      "[NOR] Episode: 37270, Length: 70, e: 0.05, Avg Reward: -178.240441133, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.95837593079\n",
      "[NOR] Episode: 37280, Length: 101, e: 0.05, Avg Reward: -149.664038868, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.2760372162\n",
      "[NOR] Episode: 37290, Length: 147, e: 0.05, Avg Reward: -171.170174863, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.2511755228\n",
      "[NOR] Episode: 37300, Length: 94, e: 0.05, Avg Reward: -110.328001374, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.73944020271\n",
      "[NOR] Episode: 37310, Length: 67, e: 0.05, Avg Reward: -162.079865143, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.2088298798\n",
      "[NOR] Episode: 37320, Length: 91, e: 0.05, Avg Reward: -186.210156015, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.8546142578\n",
      "[NOR] Episode: 37330, Length: 74, e: 0.05, Avg Reward: -158.366221192, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.3173847198\n",
      "[NOR] Episode: 37340, Length: 96, e: 0.05, Avg Reward: -196.511607724, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.26741790771\n",
      "[NOR] Episode: 37350, Length: 91, e: 0.05, Avg Reward: -154.69969211, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.1821651459\n",
      "[NOR] Episode: 37360, Length: 84, e: 0.05, Avg Reward: -123.558701174, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.89643454552\n",
      "[NOR] Episode: 37370, Length: 116, e: 0.05, Avg Reward: -250.20005669, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.02730584145\n",
      "[NOR] Episode: 37380, Length: 82, e: 0.05, Avg Reward: -118.468736407, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.7254123688\n",
      "[NOR] Episode: 37390, Length: 89, e: 0.05, Avg Reward: -125.988044143, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -37.10105896\n",
      "[NOR] Episode: 37400, Length: 103, e: 0.05, Avg Reward: -188.063001105, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.08677220345\n",
      "[NOR] Episode: 37410, Length: 89, e: 0.05, Avg Reward: -162.267663913, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.7686729431\n",
      "[NOR] Episode: 37420, Length: 117, e: 0.05, Avg Reward: -146.643853676, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.620432734489\n",
      "[NOR] Episode: 37430, Length: 105, e: 0.05, Avg Reward: -140.388820091, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.6321334839\n",
      "[NOR] Episode: 37440, Length: 97, e: 0.05, Avg Reward: -144.091450512, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.18347120285\n",
      "[NOR] Episode: 37450, Length: 113, e: 0.05, Avg Reward: -162.530666931, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.2480201721\n",
      "[NOR] Episode: 37460, Length: 56, e: 0.05, Avg Reward: -117.520055605, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.864369988441\n",
      "[NOR] Episode: 37470, Length: 65, e: 0.05, Avg Reward: -168.212926332, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.6419811249\n",
      "[NOR] Episode: 37480, Length: 57, e: 0.05, Avg Reward: -190.054451949, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.74539077282\n",
      "[NOR] Episode: 37490, Length: 107, e: 0.05, Avg Reward: -141.395485869, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.611997008324\n",
      "[NOR] Episode: 37500, Length: 127, e: 0.05, Avg Reward: -156.849814523, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.85958147049\n",
      "[NOR] Episode: 37510, Length: 107, e: 0.05, Avg Reward: -129.620595705, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 36.8283615112\n",
      "[NOR] Episode: 37520, Length: 90, e: 0.05, Avg Reward: -148.932022411, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.60345745087\n",
      "[NOR] Episode: 37530, Length: 101, e: 0.05, Avg Reward: -105.767675735, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.53675031662\n",
      "[NOR] Episode: 37540, Length: 95, e: 0.05, Avg Reward: -149.142763356, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.9762916565\n",
      "[NOR] Episode: 37550, Length: 61, e: 0.05, Avg Reward: -146.398784977, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.0741195679\n",
      "[NOR] Episode: 37560, Length: 99, e: 0.05, Avg Reward: -185.923360038, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 48.821685791\n",
      "[NOR] Episode: 37570, Length: 85, e: 0.05, Avg Reward: -152.914401155, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.84872913361\n",
      "[NOR] Episode: 37580, Length: 71, e: 0.05, Avg Reward: -146.086433598, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.9681186676\n",
      "[NOR] Episode: 37590, Length: 186, e: 0.05, Avg Reward: -123.068184628, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.08105182648\n",
      "[NOR] Episode: 37600, Length: 138, e: 0.05, Avg Reward: -127.460089779, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.89635944366\n",
      "[NOR] Episode: 37610, Length: 88, e: 0.05, Avg Reward: -120.178082242, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.4228323102\n",
      "[NOR] Episode: 37620, Length: 79, e: 0.05, Avg Reward: -144.861906565, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.809624433517\n",
      "[NOR] Episode: 37630, Length: 121, e: 0.05, Avg Reward: -154.213390297, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.27274274826\n",
      "[NOR] Episode: 37640, Length: 293, e: 0.05, Avg Reward: -147.787603163, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.168343544006\n",
      "[NOR] Episode: 37650, Length: 82, e: 0.05, Avg Reward: -148.032425109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.75979185104\n",
      "[NOR] Episode: 37660, Length: 76, e: 0.05, Avg Reward: -172.131798206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.9963684082\n",
      "[NOR] Episode: 37670, Length: 76, e: 0.05, Avg Reward: -145.96595237, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.99047708511\n",
      "[NOR] Episode: 37680, Length: 77, e: 0.05, Avg Reward: -183.227268779, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.56843852997\n",
      "[NOR] Episode: 37690, Length: 103, e: 0.05, Avg Reward: -203.088553828, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.20055437088\n",
      "[NOR] Episode: 37700, Length: 171, e: 0.05, Avg Reward: -74.6129181465, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.4638051987\n",
      "[NOR] Episode: 37710, Length: 98, e: 0.05, Avg Reward: -164.239752626, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.45562076569\n",
      "[NOR] Episode: 37720, Length: 110, e: 0.05, Avg Reward: -177.287337015, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.24944067001\n",
      "[NOR] Episode: 37730, Length: 66, e: 0.05, Avg Reward: -179.871154968, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.58588552475\n",
      "[NOR] Episode: 37740, Length: 99, e: 0.05, Avg Reward: -176.179825965, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.08562612534\n",
      "[NOR] Episode: 37750, Length: 72, e: 0.05, Avg Reward: -133.614113245, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.63337898254\n",
      "[NOR] Episode: 37760, Length: 120, e: 0.05, Avg Reward: -163.791991072, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.95232546329\n",
      "[NOR] Episode: 37770, Length: 87, e: 0.05, Avg Reward: -139.237062913, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.98683929443\n",
      "[NOR] Episode: 37780, Length: 97, e: 0.05, Avg Reward: -135.442348985, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.53197789192\n",
      "[NOR] Episode: 37790, Length: 98, e: 0.05, Avg Reward: -170.66824591, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.48017978668\n",
      "[NOR] Episode: 37800, Length: 58, e: 0.05, Avg Reward: -161.300701631, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.29380083084\n",
      "[NOR] Episode: 37810, Length: 49, e: 0.05, Avg Reward: -122.460389875, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.70933866501\n",
      "[NOR] Episode: 37820, Length: 80, e: 0.05, Avg Reward: -152.176917063, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.6027088165\n",
      "[NOR] Episode: 37830, Length: 107, e: 0.05, Avg Reward: -126.891867393, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.100721955299\n",
      "[NOR] Episode: 37840, Length: 162, e: 0.05, Avg Reward: -126.796086249, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.2489795685\n",
      "[NOR] Episode: 37850, Length: 83, e: 0.05, Avg Reward: -125.025889701, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.3915784359\n",
      "[NOR] Episode: 37860, Length: 71, e: 0.05, Avg Reward: -158.833794845, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.49191379547\n",
      "[NOR] Episode: 37870, Length: 82, e: 0.05, Avg Reward: -140.189104924, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.80089521408\n",
      "[NOR] Episode: 37880, Length: 90, e: 0.05, Avg Reward: -151.663482818, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.06745576859\n",
      "[NOR] Episode: 37890, Length: 88, e: 0.05, Avg Reward: -145.596222118, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.29714441299\n",
      "[NOR] Episode: 37900, Length: 86, e: 0.05, Avg Reward: -90.6525693912, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.6142745018\n",
      "[NOR] Episode: 37910, Length: 98, e: 0.05, Avg Reward: -188.573863544, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 60.2958297729\n",
      "[NOR] Episode: 37920, Length: 66, e: 0.05, Avg Reward: -146.836461644, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.23169612885\n",
      "[NOR] Episode: 37930, Length: 71, e: 0.05, Avg Reward: -183.620571371, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.7545375824\n",
      "[NOR] Episode: 37940, Length: 54, e: 0.05, Avg Reward: -162.044455149, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.02233695984\n",
      "[NOR] Episode: 37950, Length: 88, e: 0.05, Avg Reward: -187.748317115, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.77897930145\n",
      "[NOR] Episode: 37960, Length: 94, e: 0.05, Avg Reward: -89.2187712204, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.0439786911\n",
      "[NOR] Episode: 37970, Length: 63, e: 0.05, Avg Reward: -108.915101818, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.3110275269\n",
      "[NOR] Episode: 37980, Length: 65, e: 0.05, Avg Reward: -144.950615686, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.7288198471\n",
      "[NOR] Episode: 37990, Length: 59, e: 0.05, Avg Reward: -134.039441125, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.0533008575\n",
      "[NOR] Episode: 38000, Length: 95, e: 0.05, Avg Reward: -80.1968232004, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.28684592247\n",
      "[NOR] Episode: 38010, Length: 67, e: 0.05, Avg Reward: -117.102268154, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.38982629776\n",
      "[NOR] Episode: 38020, Length: 97, e: 0.05, Avg Reward: -136.69154114, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.09742736816\n",
      "[NOR] Episode: 38030, Length: 93, e: 0.05, Avg Reward: -109.698790414, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.4659528732\n",
      "[NOR] Episode: 38040, Length: 63, e: 0.05, Avg Reward: -144.32493658, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.103359460831\n",
      "[NOR] Episode: 38050, Length: 90, e: 0.05, Avg Reward: -156.522111858, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.67189311981\n",
      "[NOR] Episode: 38060, Length: 80, e: 0.05, Avg Reward: -173.030385364, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.45189094543\n",
      "[NOR] Episode: 38070, Length: 142, e: 0.05, Avg Reward: -115.78237431, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.795463204384\n",
      "[NOR] Episode: 38080, Length: 90, e: 0.05, Avg Reward: -137.128698756, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.28894519806\n",
      "[NOR] Episode: 38090, Length: 66, e: 0.05, Avg Reward: -147.338199025, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.3999347687\n",
      "[NOR] Episode: 38100, Length: 88, e: 0.05, Avg Reward: -121.880056842, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.30782222748\n",
      "[NOR] Episode: 38110, Length: 83, e: 0.05, Avg Reward: -79.2915705553, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.056823849678\n",
      "[NOR] Episode: 38120, Length: 72, e: 0.05, Avg Reward: -138.698351096, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.48864454031\n",
      "[NOR] Episode: 38130, Length: 99, e: 0.05, Avg Reward: -127.344218292, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.7059636116\n",
      "[NOR] Episode: 38140, Length: 79, e: 0.05, Avg Reward: -148.080159705, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.36921834946\n",
      "[NOR] Episode: 38150, Length: 93, e: 0.05, Avg Reward: -87.0303147058, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.1333694458\n",
      "[NOR] Episode: 38160, Length: 71, e: 0.05, Avg Reward: -166.861968262, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.14295458794\n",
      "[NOR] Episode: 38170, Length: 91, e: 0.05, Avg Reward: -128.846087843, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.1002130508\n",
      "[NOR] Episode: 38180, Length: 61, e: 0.05, Avg Reward: -128.155935584, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.23036575317\n",
      "[NOR] Episode: 38190, Length: 70, e: 0.05, Avg Reward: -124.673029274, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.94145202637\n",
      "[NOR] Episode: 38200, Length: 89, e: 0.05, Avg Reward: -95.198064001, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.47507190704\n",
      "[NOR] Episode: 38210, Length: 62, e: 0.05, Avg Reward: -65.5966872357, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.97088336945\n",
      "[NOR] Episode: 38220, Length: 183, e: 0.05, Avg Reward: -51.3122950211, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.9983663559\n",
      "[NOR] Episode: 38230, Length: 90, e: 0.05, Avg Reward: -74.2145164412, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.59932374954\n",
      "[NOR] Episode: 38240, Length: 94, e: 0.05, Avg Reward: -131.765456459, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.14926433563\n",
      "[NOR] Episode: 38250, Length: 101, e: 0.05, Avg Reward: -128.088235747, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.32334470749\n",
      "[NOR] Episode: 38260, Length: 53, e: 0.05, Avg Reward: -89.9718790316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.98453760147\n",
      "[NOR] Episode: 38270, Length: 90, e: 0.05, Avg Reward: -132.544220967, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.44760382175\n",
      "[NOR] Episode: 38280, Length: 65, e: 0.05, Avg Reward: -154.384195916, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.97376823425\n",
      "[NOR] Episode: 38290, Length: 112, e: 0.05, Avg Reward: -126.286000389, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.8684768677\n",
      "[NOR] Episode: 38300, Length: 65, e: 0.05, Avg Reward: -149.682492239, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 63.1450004578\n",
      "[NOR] Episode: 38310, Length: 79, e: 0.05, Avg Reward: -134.870362598, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.3789978027\n",
      "[NOR] Episode: 38320, Length: 99, e: 0.05, Avg Reward: -112.397297612, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.48249840736\n",
      "[NOR] Episode: 38330, Length: 81, e: 0.05, Avg Reward: -94.9748752517, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.0940055847\n",
      "[NOR] Episode: 38340, Length: 134, e: 0.05, Avg Reward: -60.5046559193, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.6417579651\n",
      "[NOR] Episode: 38350, Length: 70, e: 0.05, Avg Reward: -169.314243664, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.188371658325\n",
      "[NOR] Episode: 38360, Length: 72, e: 0.05, Avg Reward: -98.8762120668, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.73907184601\n",
      "[NOR] Episode: 38370, Length: 105, e: 0.05, Avg Reward: -119.649665193, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.07752227783\n",
      "[NOR] Episode: 38380, Length: 78, e: 0.05, Avg Reward: -125.842693569, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.821412920952\n",
      "[NOR] Episode: 38390, Length: 61, e: 0.05, Avg Reward: -119.152120381, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.7299175262\n",
      "[NOR] Episode: 38400, Length: 62, e: 0.05, Avg Reward: -148.426722722, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.8547210693\n",
      "[NOR] Episode: 38410, Length: 58, e: 0.05, Avg Reward: -127.978897741, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.1912603378\n",
      "[NOR] Episode: 38420, Length: 67, e: 0.05, Avg Reward: -111.843328592, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.75837492943\n",
      "[NOR] Episode: 38430, Length: 79, e: 0.05, Avg Reward: -110.244868094, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.0320863724\n",
      "[NOR] Episode: 38440, Length: 82, e: 0.05, Avg Reward: -69.8933288666, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.32664060593\n",
      "[NOR] Episode: 38450, Length: 83, e: 0.05, Avg Reward: -175.897289514, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.4106063843\n",
      "[NOR] Episode: 38460, Length: 89, e: 0.05, Avg Reward: -140.318761817, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.61168217659\n",
      "[NOR] Episode: 38470, Length: 79, e: 0.05, Avg Reward: -140.025348955, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.87979602814\n",
      "[NOR] Episode: 38480, Length: 87, e: 0.05, Avg Reward: -84.0232741259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.25926399231\n",
      "[NOR] Episode: 38490, Length: 83, e: 0.05, Avg Reward: -104.712306915, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.4074573517\n",
      "[NOR] Episode: 38500, Length: 59, e: 0.05, Avg Reward: -190.285413848, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.26881122589\n",
      "[NOR] Episode: 38510, Length: 95, e: 0.05, Avg Reward: -103.621583926, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.50213241577\n",
      "[NOR] Episode: 38520, Length: 97, e: 0.05, Avg Reward: -133.778465988, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.832172513008\n",
      "[NOR] Episode: 38530, Length: 202, e: 0.05, Avg Reward: -65.3534316483, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.246492147446\n",
      "[NOR] Episode: 38540, Length: 152, e: 0.05, Avg Reward: -121.622563247, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.6044197083\n",
      "[NOR] Episode: 38550, Length: 86, e: 0.05, Avg Reward: -159.546767489, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.47733616829\n",
      "[NOR] Episode: 38560, Length: 84, e: 0.05, Avg Reward: -68.6091110157, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.27528858185\n",
      "[NOR] Episode: 38570, Length: 102, e: 0.05, Avg Reward: -120.050014019, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.9769639969\n",
      "[NOR] Episode: 38580, Length: 83, e: 0.05, Avg Reward: -102.236986002, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.14563941956\n",
      "[NOR] Episode: 38590, Length: 88, e: 0.05, Avg Reward: -77.0391024507, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.67591309547\n",
      "[NOR] Episode: 38600, Length: 85, e: 0.05, Avg Reward: -138.247833381, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.81151628494\n",
      "[NOR] Episode: 38610, Length: 98, e: 0.05, Avg Reward: -130.595275628, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.96483969688\n",
      "[NOR] Episode: 38620, Length: 301, e: 0.05, Avg Reward: -58.5859985195, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.8035564423\n",
      "[NOR] Episode: 38630, Length: 106, e: 0.05, Avg Reward: -127.334892068, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.3651561737\n",
      "[NOR] Episode: 38640, Length: 77, e: 0.05, Avg Reward: -141.240374329, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.01847553253\n",
      "[NOR] Episode: 38650, Length: 133, e: 0.05, Avg Reward: -101.766012027, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.4140310287\n",
      "[NOR] Episode: 38660, Length: 63, e: 0.05, Avg Reward: -117.071653703, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.4204111099\n",
      "[NOR] Episode: 38670, Length: 64, e: 0.05, Avg Reward: -129.764023968, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.09024763107\n",
      "[NOR] Episode: 38680, Length: 65, e: 0.05, Avg Reward: -114.522394967, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.9306716919\n",
      "[NOR] Episode: 38690, Length: 65, e: 0.05, Avg Reward: -126.791979028, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.73303031921\n",
      "[NOR] Episode: 38700, Length: 56, e: 0.05, Avg Reward: -92.0336711214, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.1080589294\n",
      "[NOR] Episode: 38710, Length: 55, e: 0.05, Avg Reward: -138.381412132, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.28361701965\n",
      "[NOR] Episode: 38720, Length: 64, e: 0.05, Avg Reward: -126.856879336, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.4695558548\n",
      "[NOR] Episode: 38730, Length: 79, e: 0.05, Avg Reward: -132.959306887, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.8377931118\n",
      "[NOR] Episode: 38740, Length: 69, e: 0.05, Avg Reward: -95.2661342856, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.673186302185\n",
      "[NOR] Episode: 38750, Length: 58, e: 0.05, Avg Reward: -136.74819282, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.06718635559\n",
      "[NOR] Episode: 38760, Length: 88, e: 0.05, Avg Reward: -155.475155455, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.01232147217\n",
      "[NOR] Episode: 38770, Length: 67, e: 0.05, Avg Reward: -158.013263576, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 33.4223632812\n",
      "[NOR] Episode: 38780, Length: 85, e: 0.05, Avg Reward: -85.194912589, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.86819553375\n",
      "[NOR] Episode: 38790, Length: 74, e: 0.05, Avg Reward: -88.7066941303, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.42040157318\n",
      "[NOR] Episode: 38800, Length: 52, e: 0.05, Avg Reward: -200.807446937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.0986995697\n",
      "[NOR] Episode: 38810, Length: 71, e: 0.05, Avg Reward: -160.454652797, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -56.7214393616\n",
      "[NOR] Episode: 38820, Length: 64, e: 0.05, Avg Reward: -89.2199427129, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.62506151199\n",
      "[NOR] Episode: 38830, Length: 93, e: 0.05, Avg Reward: -165.493561685, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.95591688156\n",
      "[NOR] Episode: 38840, Length: 68, e: 0.05, Avg Reward: -147.843274173, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.58516144753\n",
      "[NOR] Episode: 38850, Length: 89, e: 0.05, Avg Reward: -157.737234829, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.15494585037\n",
      "[NOR] Episode: 38860, Length: 68, e: 0.05, Avg Reward: -150.325417765, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.08956336975\n",
      "[NOR] Episode: 38870, Length: 90, e: 0.05, Avg Reward: -128.402189888, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.8962001801\n",
      "[NOR] Episode: 38880, Length: 82, e: 0.05, Avg Reward: -140.752667556, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.2616119385\n",
      "[NOR] Episode: 38890, Length: 72, e: 0.05, Avg Reward: -166.603288516, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.00448966026\n",
      "[NOR] Episode: 38900, Length: 68, e: 0.05, Avg Reward: -144.231313984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.03484988213\n",
      "[NOR] Episode: 38910, Length: 65, e: 0.05, Avg Reward: -143.468347774, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.03051948547\n",
      "[NOR] Episode: 38920, Length: 63, e: 0.05, Avg Reward: -185.265189355, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.65064573288\n",
      "[NOR] Episode: 38930, Length: 60, e: 0.05, Avg Reward: -155.860347174, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.7624745369\n",
      "[NOR] Episode: 38940, Length: 102, e: 0.05, Avg Reward: -128.064154136, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.86408567429\n",
      "[NOR] Episode: 38950, Length: 76, e: 0.05, Avg Reward: -46.8520244552, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.4852771759\n",
      "[NOR] Episode: 38960, Length: 64, e: 0.05, Avg Reward: -29.5898565241, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.6358890533\n",
      "[NOR] Episode: 38970, Length: 87, e: 0.05, Avg Reward: -104.054388386, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.2163257599\n",
      "[NOR] Episode: 38980, Length: 83, e: 0.05, Avg Reward: -107.278996024, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.39569807053\n",
      "[NOR] Episode: 38990, Length: 75, e: 0.05, Avg Reward: -166.506707798, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.57943201065\n",
      "[NOR] Episode: 39000, Length: 60, e: 0.05, Avg Reward: -146.266732537, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.1713981628\n",
      "[NOR] Episode: 39010, Length: 57, e: 0.05, Avg Reward: -151.10849668, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.36002206802\n",
      "[NOR] Episode: 39020, Length: 78, e: 0.05, Avg Reward: -135.932444655, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.1289639473\n",
      "[NOR] Episode: 39030, Length: 82, e: 0.05, Avg Reward: -93.1053048624, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.46962547302\n",
      "[NOR] Episode: 39040, Length: 60, e: 0.05, Avg Reward: -148.340323832, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.40908312798\n",
      "[NOR] Episode: 39050, Length: 66, e: 0.05, Avg Reward: -126.366608629, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.99677181244\n",
      "[NOR] Episode: 39060, Length: 97, e: 0.05, Avg Reward: -162.595407377, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.32479715347\n",
      "[NOR] Episode: 39070, Length: 80, e: 0.05, Avg Reward: -143.169360728, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.93548774719\n",
      "[NOR] Episode: 39080, Length: 50, e: 0.05, Avg Reward: -137.587276623, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.46810865402\n",
      "[NOR] Episode: 39090, Length: 90, e: 0.05, Avg Reward: -149.305545595, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.1241226196\n",
      "[NOR] Episode: 39100, Length: 80, e: 0.05, Avg Reward: -114.46859229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.2466602325\n",
      "[NOR] Episode: 39110, Length: 83, e: 0.05, Avg Reward: -199.611904992, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.50692152977\n",
      "[NOR] Episode: 39120, Length: 50, e: 0.05, Avg Reward: -185.972374644, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 27.7510261536\n",
      "[NOR] Episode: 39130, Length: 111, e: 0.05, Avg Reward: -115.205967669, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.23687601089\n",
      "[NOR] Episode: 39140, Length: 93, e: 0.05, Avg Reward: -123.530994337, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -88.7617874146\n",
      "[NOR] Episode: 39150, Length: 86, e: 0.05, Avg Reward: -140.486462518, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.81974315643\n",
      "[NOR] Episode: 39160, Length: 82, e: 0.05, Avg Reward: -141.443820038, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.64884853363\n",
      "[NOR] Episode: 39170, Length: 69, e: 0.05, Avg Reward: -77.1364315583, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.5530629158\n",
      "[NOR] Episode: 39180, Length: 89, e: 0.05, Avg Reward: -152.89470064, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.16234207153\n",
      "[NOR] Episode: 39190, Length: 72, e: 0.05, Avg Reward: -156.436082582, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.32339048386\n",
      "[NOR] Episode: 39200, Length: 84, e: 0.05, Avg Reward: -137.296843766, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.7202339172\n",
      "[NOR] Episode: 39210, Length: 82, e: 0.05, Avg Reward: -163.511526544, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.3658256531\n",
      "[NOR] Episode: 39220, Length: 98, e: 0.05, Avg Reward: -146.881663535, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -171.53024292\n",
      "[NOR] Episode: 39230, Length: 73, e: 0.05, Avg Reward: -152.749192329, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.07624340057\n",
      "[NOR] Episode: 39240, Length: 69, e: 0.05, Avg Reward: -112.593533886, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.59270644188\n",
      "[NOR] Episode: 39250, Length: 64, e: 0.05, Avg Reward: -135.441521174, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.98170852661\n",
      "[NOR] Episode: 39260, Length: 58, e: 0.05, Avg Reward: -124.21174736, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.27623081207\n",
      "[NOR] Episode: 39270, Length: 91, e: 0.05, Avg Reward: -151.163334316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.97448539734\n",
      "[NOR] Episode: 39280, Length: 89, e: 0.05, Avg Reward: -111.262449505, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -97.073928833\n",
      "[NOR] Episode: 39290, Length: 86, e: 0.05, Avg Reward: -148.698787358, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.19446754456\n",
      "[NOR] Episode: 39300, Length: 89, e: 0.05, Avg Reward: -163.103710521, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.227180481\n",
      "[NOR] Episode: 39310, Length: 102, e: 0.05, Avg Reward: -157.24672488, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.04167461395\n",
      "[NOR] Episode: 39320, Length: 60, e: 0.05, Avg Reward: -93.5578279817, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.87317276\n",
      "[NOR] Episode: 39330, Length: 71, e: 0.05, Avg Reward: -143.334555999, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.25336551666\n",
      "[NOR] Episode: 39340, Length: 75, e: 0.05, Avg Reward: -84.724087014, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.45480442047\n",
      "[NOR] Episode: 39350, Length: 68, e: 0.05, Avg Reward: -133.497317361, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.24626922607\n",
      "[NOR] Episode: 39360, Length: 61, e: 0.05, Avg Reward: -132.805740309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.5207099915\n",
      "[NOR] Episode: 39370, Length: 74, e: 0.05, Avg Reward: -171.724523553, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.7541847229\n",
      "[NOR] Episode: 39380, Length: 89, e: 0.05, Avg Reward: -125.079279619, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.9238147736\n",
      "[NOR] Episode: 39390, Length: 66, e: 0.05, Avg Reward: -118.022817243, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.87522029877\n",
      "[NOR] Episode: 39400, Length: 83, e: 0.05, Avg Reward: -138.806285127, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.56019115448\n",
      "[NOR] Episode: 39410, Length: 80, e: 0.05, Avg Reward: -135.530578332, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.54817032814\n",
      "[NOR] Episode: 39420, Length: 75, e: 0.05, Avg Reward: -187.948846395, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.98436641693\n",
      "[NOR] Episode: 39430, Length: 61, e: 0.05, Avg Reward: -165.650973709, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 40.4855384827\n",
      "[NOR] Episode: 39440, Length: 78, e: 0.05, Avg Reward: -157.06152804, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.0704030991\n",
      "[NOR] Episode: 39450, Length: 63, e: 0.05, Avg Reward: -151.910139067, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.4742631912\n",
      "[NOR] Episode: 39460, Length: 93, e: 0.05, Avg Reward: -156.732046272, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.76467132568\n",
      "[NOR] Episode: 39470, Length: 82, e: 0.05, Avg Reward: -173.406384015, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.924929142\n",
      "[NOR] Episode: 39480, Length: 69, e: 0.05, Avg Reward: -157.336962363, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.512086451054\n",
      "[NOR] Episode: 39490, Length: 157, e: 0.05, Avg Reward: -113.389717619, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.27200937271\n",
      "[NOR] Episode: 39500, Length: 90, e: 0.05, Avg Reward: -127.813311685, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.862701416\n",
      "[NOR] Episode: 39510, Length: 66, e: 0.05, Avg Reward: -180.999356269, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.998282790184\n",
      "[NOR] Episode: 39520, Length: 72, e: 0.05, Avg Reward: -121.858546237, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.12631607056\n",
      "[NOR] Episode: 39530, Length: 71, e: 0.05, Avg Reward: -145.027567781, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.4586715698\n",
      "[NOR] Episode: 39540, Length: 63, e: 0.05, Avg Reward: -135.981278529, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.56950902939\n",
      "[NOR] Episode: 39550, Length: 69, e: 0.05, Avg Reward: -158.75295866, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.22145557404\n",
      "[NOR] Episode: 39560, Length: 61, e: 0.05, Avg Reward: -157.943835858, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.0092201233\n",
      "[NOR] Episode: 39570, Length: 82, e: 0.05, Avg Reward: -146.232389095, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.57297134399\n",
      "[NOR] Episode: 39580, Length: 59, e: 0.05, Avg Reward: -129.218280588, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.2434091568\n",
      "[NOR] Episode: 39590, Length: 88, e: 0.05, Avg Reward: -112.117357145, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.69053030014\n",
      "[NOR] Episode: 39600, Length: 74, e: 0.05, Avg Reward: -170.091779177, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.0676727295\n",
      "[NOR] Episode: 39610, Length: 79, e: 0.05, Avg Reward: -141.406997319, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0318237543106\n",
      "[NOR] Episode: 39620, Length: 85, e: 0.05, Avg Reward: -155.337238215, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.71590948105\n",
      "[NOR] Episode: 39630, Length: 76, e: 0.05, Avg Reward: -156.965644872, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -45.8449668884\n",
      "[NOR] Episode: 39640, Length: 66, e: 0.05, Avg Reward: -183.210919312, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -68.7440032959\n",
      "[NOR] Episode: 39650, Length: 62, e: 0.05, Avg Reward: -52.4004577002, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.2791719437\n",
      "[NOR] Episode: 39660, Length: 71, e: 0.05, Avg Reward: -132.516064204, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.81742548943\n",
      "[NOR] Episode: 39670, Length: 57, e: 0.05, Avg Reward: -135.453814483, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.3145866394\n",
      "[NOR] Episode: 39680, Length: 59, e: 0.05, Avg Reward: -103.780451721, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.80848479271\n",
      "[NOR] Episode: 39690, Length: 81, e: 0.05, Avg Reward: -153.82711128, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.68759250641\n",
      "[NOR] Episode: 39700, Length: 221, e: 0.05, Avg Reward: -97.1072526622, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.82340717316\n",
      "[NOR] Episode: 39710, Length: 94, e: 0.05, Avg Reward: -93.0690782481, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.16034650803\n",
      "[NOR] Episode: 39720, Length: 74, e: 0.05, Avg Reward: -164.673264314, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.60222005844\n",
      "[NOR] Episode: 39730, Length: 92, e: 0.05, Avg Reward: -116.994836437, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.02250099182\n",
      "[NOR] Episode: 39740, Length: 78, e: 0.05, Avg Reward: -71.9628971555, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.367753148079\n",
      "[NOR] Episode: 39750, Length: 91, e: 0.05, Avg Reward: -161.383528433, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.2846746445\n",
      "[NOR] Episode: 39760, Length: 62, e: 0.05, Avg Reward: -128.142415534, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.291416138411\n",
      "[NOR] Episode: 39770, Length: 76, e: 0.05, Avg Reward: -170.573955628, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.58029937744\n",
      "[NOR] Episode: 39780, Length: 88, e: 0.05, Avg Reward: -127.065216495, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.4607315063\n",
      "[NOR] Episode: 39790, Length: 54, e: 0.05, Avg Reward: -140.964224943, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.6111288071\n",
      "[NOR] Episode: 39800, Length: 139, e: 0.05, Avg Reward: -138.355600531, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.5359077454\n",
      "[NOR] Episode: 39810, Length: 74, e: 0.05, Avg Reward: -129.331417548, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.26686882973\n",
      "[NOR] Episode: 39820, Length: 103, e: 0.05, Avg Reward: -93.6279315, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.06624174118\n",
      "[NOR] Episode: 39830, Length: 57, e: 0.05, Avg Reward: -138.583879747, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.26356959343\n",
      "[NOR] Episode: 39840, Length: 77, e: 0.05, Avg Reward: -132.250208213, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.31720352173\n",
      "[NOR] Episode: 39850, Length: 83, e: 0.05, Avg Reward: -119.100410523, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.93912792206\n",
      "[NOR] Episode: 39860, Length: 201, e: 0.05, Avg Reward: -107.523194617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.9754242897\n",
      "[NOR] Episode: 39870, Length: 98, e: 0.05, Avg Reward: -116.044291721, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.96750926971\n",
      "[NOR] Episode: 39880, Length: 63, e: 0.05, Avg Reward: -135.932755065, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.839384079\n",
      "[NOR] Episode: 39890, Length: 100, e: 0.05, Avg Reward: -67.6641741471, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.5424015522\n",
      "[NOR] Episode: 39900, Length: 59, e: 0.05, Avg Reward: -127.637963506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.56758356094\n",
      "[NOR] Episode: 39910, Length: 91, e: 0.05, Avg Reward: -111.348153795, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.28013658524\n",
      "[NOR] Episode: 39920, Length: 62, e: 0.05, Avg Reward: -109.370269694, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.18823099136\n",
      "[NOR] Episode: 39930, Length: 80, e: 0.05, Avg Reward: -122.734946291, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.5662479401\n",
      "[NOR] Episode: 39940, Length: 75, e: 0.05, Avg Reward: -102.330609704, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.16424179077\n",
      "[NOR] Episode: 39950, Length: 81, e: 0.05, Avg Reward: -124.66594807, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.51685619354\n",
      "[NOR] Episode: 39960, Length: 62, e: 0.05, Avg Reward: -135.346526728, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0767797827721\n",
      "[NOR] Episode: 39970, Length: 63, e: 0.05, Avg Reward: -110.434293702, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.0281662941\n",
      "[NOR] Episode: 39980, Length: 105, e: 0.05, Avg Reward: -129.591568365, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.3945932388\n",
      "[NOR] Episode: 39990, Length: 94, e: 0.05, Avg Reward: -109.93250082, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.90234470367\n",
      "[NOR] Episode: 40000, Length: 104, e: 0.05, Avg Reward: -111.699464951, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.17748832703\n",
      "[NOR] Episode: 40010, Length: 106, e: 0.05, Avg Reward: -116.219226934, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.05776023865\n",
      "[NOR] Episode: 40020, Length: 57, e: 0.05, Avg Reward: -129.91689873, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.13726043701\n",
      "[NOR] Episode: 40030, Length: 81, e: 0.05, Avg Reward: -91.7188870703, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.30618524551\n",
      "[NOR] Episode: 40040, Length: 76, e: 0.05, Avg Reward: -174.655332459, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.384600639343\n",
      "[NOR] Episode: 40050, Length: 74, e: 0.05, Avg Reward: -128.50120783, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.84731292725\n",
      "[NOR] Episode: 40060, Length: 105, e: 0.05, Avg Reward: -133.445712966, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.13697004318\n",
      "[NOR] Episode: 40070, Length: 75, e: 0.05, Avg Reward: -166.608645762, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.547203064\n",
      "[NOR] Episode: 40080, Length: 50, e: 0.05, Avg Reward: -140.395294435, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.99923324585\n",
      "[NOR] Episode: 40090, Length: 69, e: 0.05, Avg Reward: -124.477949892, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.609008610249\n",
      "[NOR] Episode: 40100, Length: 111, e: 0.05, Avg Reward: -108.062194878, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.01260614395\n",
      "[NOR] Episode: 40110, Length: 77, e: 0.05, Avg Reward: -63.6899072695, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.45252752304\n",
      "[NOR] Episode: 40120, Length: 71, e: 0.05, Avg Reward: -152.194768259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.18598556519\n",
      "[NOR] Episode: 40130, Length: 70, e: 0.05, Avg Reward: -168.272369588, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 50.9529953003\n",
      "[NOR] Episode: 40140, Length: 117, e: 0.05, Avg Reward: -141.806228001, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.52435827255\n",
      "[NOR] Episode: 40150, Length: 85, e: 0.05, Avg Reward: -109.449915595, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.9755516052\n",
      "[NOR] Episode: 40160, Length: 72, e: 0.05, Avg Reward: -97.9446353773, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.50000476837\n",
      "[NOR] Episode: 40170, Length: 62, e: 0.05, Avg Reward: -138.711258112, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.30681753159\n",
      "[NOR] Episode: 40180, Length: 60, e: 0.05, Avg Reward: -71.5933098377, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.52325487137\n",
      "[NOR] Episode: 40190, Length: 243, e: 0.05, Avg Reward: -93.2713567383, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.8610744476\n",
      "[NOR] Episode: 40200, Length: 78, e: 0.05, Avg Reward: -143.934832249, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.213157296181\n",
      "[NOR] Episode: 40210, Length: 76, e: 0.05, Avg Reward: -129.434832933, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.102596283\n",
      "[NOR] Episode: 40220, Length: 103, e: 0.05, Avg Reward: -79.4267347302, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.32542538643\n",
      "[NOR] Episode: 40230, Length: 72, e: 0.05, Avg Reward: -80.0766626662, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.33017063141\n",
      "[NOR] Episode: 40240, Length: 119, e: 0.05, Avg Reward: -133.934255814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.94042110443\n",
      "[NOR] Episode: 40250, Length: 119, e: 0.05, Avg Reward: -112.82349785, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.493933200836\n",
      "[NOR] Episode: 40260, Length: 85, e: 0.05, Avg Reward: -130.937111357, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.06607341766\n",
      "[NOR] Episode: 40270, Length: 55, e: 0.05, Avg Reward: -129.709559652, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.57803463936\n",
      "[NOR] Episode: 40280, Length: 187, e: 0.05, Avg Reward: -85.0870986108, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.4071674347\n",
      "[NOR] Episode: 40290, Length: 84, e: 0.05, Avg Reward: -108.594000799, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.68126487732\n",
      "[NOR] Episode: 40300, Length: 93, e: 0.05, Avg Reward: -173.715961767, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.82352137566\n",
      "[NOR] Episode: 40310, Length: 88, e: 0.05, Avg Reward: -104.088867146, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.97988176346\n",
      "[NOR] Episode: 40320, Length: 61, e: 0.05, Avg Reward: -93.1361111078, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.606225132942\n",
      "[NOR] Episode: 40330, Length: 82, e: 0.05, Avg Reward: -74.8213738939, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.96585202217\n",
      "[NOR] Episode: 40340, Length: 294, e: 0.05, Avg Reward: -105.488723026, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.38111495972\n",
      "[NOR] Episode: 40350, Length: 114, e: 0.05, Avg Reward: -49.3231197226, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.08863925934\n",
      "[NOR] Episode: 40360, Length: 62, e: 0.05, Avg Reward: -109.66616572, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.407450556755\n",
      "[NOR] Episode: 40370, Length: 109, e: 0.05, Avg Reward: -29.4853667874, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.2642374039\n",
      "[NOR] Episode: 40380, Length: 63, e: 0.05, Avg Reward: -100.788276171, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.135095715523\n",
      "[NOR] Episode: 40390, Length: 77, e: 0.05, Avg Reward: -76.8987660371, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.04148674011\n",
      "[NOR] Episode: 40400, Length: 89, e: 0.05, Avg Reward: -143.791072927, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.59723949432\n",
      "[NOR] Episode: 40410, Length: 72, e: 0.05, Avg Reward: -62.2736711896, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.43271064758\n",
      "[NOR] Episode: 40420, Length: 63, e: 0.05, Avg Reward: -104.789442328, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.10212993622\n",
      "[NOR] Episode: 40430, Length: 101, e: 0.05, Avg Reward: -105.350472353, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.16621208191\n",
      "[NOR] Episode: 40440, Length: 114, e: 0.05, Avg Reward: -76.0255212022, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.602749466896\n",
      "[NOR] Episode: 40450, Length: 88, e: 0.05, Avg Reward: -164.448445833, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.50366377831\n",
      "[NOR] Episode: 40460, Length: 100, e: 0.05, Avg Reward: -92.6896133023, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.22982501984\n",
      "[NOR] Episode: 40470, Length: 87, e: 0.05, Avg Reward: -141.921441618, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.07305920124\n",
      "[NOR] Episode: 40480, Length: 107, e: 0.05, Avg Reward: -103.152426749, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.3404827118\n",
      "[NOR] Episode: 40490, Length: 242, e: 0.05, Avg Reward: -124.268066238, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.6184883118\n",
      "[NOR] Episode: 40500, Length: 52, e: 0.05, Avg Reward: -64.9529731936, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.3178720474\n",
      "[NOR] Episode: 40510, Length: 320, e: 0.05, Avg Reward: -59.1201007194, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.44401550293\n",
      "[NOR] Episode: 40520, Length: 195, e: 0.05, Avg Reward: -11.1248808513, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.5454349518\n",
      "[NOR] Episode: 40530, Length: 74, e: 0.05, Avg Reward: -145.301371052, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.17182588577\n",
      "[NOR] Episode: 40540, Length: 95, e: 0.05, Avg Reward: -104.056659968, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.42929649353\n",
      "[NOR] Episode: 40550, Length: 102, e: 0.05, Avg Reward: -78.298317203, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.20645999908\n",
      "[NOR] Episode: 40560, Length: 68, e: 0.05, Avg Reward: -114.575072832, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.16588914394\n",
      "[NOR] Episode: 40570, Length: 90, e: 0.05, Avg Reward: -97.5545817597, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.26630020142\n",
      "[NOR] Episode: 40580, Length: 240, e: 0.05, Avg Reward: -37.2520632373, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.1305141449\n",
      "[NOR] Episode: 40590, Length: 119, e: 0.05, Avg Reward: -97.4474849295, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.6814314127\n",
      "[NOR] Episode: 40600, Length: 87, e: 0.05, Avg Reward: -47.6206031602, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.05922698975\n",
      "[NOR] Episode: 40610, Length: 250, e: 0.05, Avg Reward: -86.18714679, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.95242881775\n",
      "[NOR] Episode: 40620, Length: 161, e: 0.05, Avg Reward: -161.218286081, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.47934436798\n",
      "[NOR] Episode: 40630, Length: 59, e: 0.05, Avg Reward: -109.206171636, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.34408760071\n",
      "[NOR] Episode: 40640, Length: 79, e: 0.05, Avg Reward: -84.1173354862, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.5082550049\n",
      "[NOR] Episode: 40650, Length: 114, e: 0.05, Avg Reward: -89.8096930348, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.774870634079\n",
      "[NOR] Episode: 40660, Length: 110, e: 0.05, Avg Reward: -124.122350466, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.58534526825\n",
      "[NOR] Episode: 40670, Length: 58, e: 0.05, Avg Reward: -31.9259645883, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.80527591705\n",
      "[NOR] Episode: 40680, Length: 363, e: 0.05, Avg Reward: -85.3942530684, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.35864520073\n",
      "[NOR] Episode: 40690, Length: 239, e: 0.05, Avg Reward: -30.2476208719, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.667547226\n",
      "[NOR] Episode: 40700, Length: 340, e: 0.05, Avg Reward: -186.26379995, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.04935455322\n",
      "[NOR] Episode: 40710, Length: 113, e: 0.05, Avg Reward: -107.428121479, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.0424499512\n",
      "[NOR] Episode: 40720, Length: 107, e: 0.05, Avg Reward: -107.345573279, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.7515220642\n",
      "[NOR] Episode: 40730, Length: 170, e: 0.05, Avg Reward: -157.009698447, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.9730587006\n",
      "[NOR] Episode: 40740, Length: 196, e: 0.05, Avg Reward: -136.074124196, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.7045583725\n",
      "[NOR] Episode: 40750, Length: 52, e: 0.05, Avg Reward: -120.959293949, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.17183971405\n",
      "[NOR] Episode: 40760, Length: 103, e: 0.05, Avg Reward: -183.430482951, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.32889032364\n",
      "[NOR] Episode: 40770, Length: 127, e: 0.05, Avg Reward: -196.920002365, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.28959798813\n",
      "[NOR] Episode: 40780, Length: 149, e: 0.05, Avg Reward: -124.70865496, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.2531404495\n",
      "[NOR] Episode: 40790, Length: 369, e: 0.05, Avg Reward: -109.180303049, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 61.7447433472\n",
      "[NOR] Episode: 40800, Length: 62, e: 0.05, Avg Reward: -195.475725101, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.0516233444\n",
      "[NOR] Episode: 40810, Length: 98, e: 0.05, Avg Reward: -90.4520722417, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.19314432144\n",
      "[NOR] Episode: 40820, Length: 87, e: 0.05, Avg Reward: -139.67468351, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.8719959259\n",
      "[NOR] Episode: 40830, Length: 137, e: 0.05, Avg Reward: -166.368533581, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.4000768661\n",
      "[NOR] Episode: 40840, Length: 426, e: 0.05, Avg Reward: -164.006829948, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.32794213295\n",
      "[NOR] Episode: 40850, Length: 100, e: 0.05, Avg Reward: -170.493362084, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.02381324768\n",
      "[NOR] Episode: 40860, Length: 150, e: 0.05, Avg Reward: -182.050255012, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.71964406967\n",
      "[NOR] Episode: 40870, Length: 197, e: 0.05, Avg Reward: -186.919605597, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.51037549973\n",
      "[NOR] Episode: 40880, Length: 173, e: 0.05, Avg Reward: -196.82060728, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.7725687027\n",
      "[NOR] Episode: 40890, Length: 178, e: 0.05, Avg Reward: -222.48058851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.42302656174\n",
      "[NOR] Episode: 40900, Length: 95, e: 0.05, Avg Reward: -172.848932066, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.6122722626\n",
      "[NOR] Episode: 40910, Length: 143, e: 0.05, Avg Reward: -197.964393602, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 41.8516921997\n",
      "[NOR] Episode: 40920, Length: 69, e: 0.05, Avg Reward: -206.402551223, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.5061893463\n",
      "[NOR] Episode: 40930, Length: 177, e: 0.05, Avg Reward: -217.261322864, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.7621088028\n",
      "[NOR] Episode: 40940, Length: 138, e: 0.05, Avg Reward: -201.389620789, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.96387290955\n",
      "[NOR] Episode: 40950, Length: 156, e: 0.05, Avg Reward: -143.242212116, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.92542147636\n",
      "[NOR] Episode: 40960, Length: 199, e: 0.05, Avg Reward: -172.911976121, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 29.8033714294\n",
      "[NOR] Episode: 40970, Length: 120, e: 0.05, Avg Reward: -217.456336321, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.4380030632\n",
      "[NOR] Episode: 40980, Length: 152, e: 0.05, Avg Reward: -114.360242549, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.7197980881\n",
      "[NOR] Episode: 40990, Length: 50, e: 0.05, Avg Reward: -141.790640636, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.3567352295\n",
      "[NOR] Episode: 41000, Length: 86, e: 0.05, Avg Reward: -146.272722529, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.80084323883\n",
      "[NOR] Episode: 41010, Length: 173, e: 0.05, Avg Reward: -145.420505626, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.1712970734\n",
      "[NOR] Episode: 41020, Length: 69, e: 0.05, Avg Reward: -148.344047956, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.52516627312\n",
      "[NOR] Episode: 41030, Length: 178, e: 0.05, Avg Reward: -154.181398101, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.93212175369\n",
      "[NOR] Episode: 41040, Length: 210, e: 0.05, Avg Reward: -125.360614272, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.4311752319\n",
      "[NOR] Episode: 41050, Length: 92, e: 0.05, Avg Reward: -175.214508548, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.2446231842\n",
      "[NOR] Episode: 41060, Length: 613, e: 0.05, Avg Reward: -156.21206259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.73350024223\n",
      "[NOR] Episode: 41070, Length: 147, e: 0.05, Avg Reward: -198.261184362, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.3962554932\n",
      "[NOR] Episode: 41080, Length: 111, e: 0.05, Avg Reward: -191.150759693, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -129.186782837\n",
      "[NOR] Episode: 41090, Length: 92, e: 0.05, Avg Reward: -182.92019523, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.72913742065\n",
      "[NOR] Episode: 41100, Length: 196, e: 0.05, Avg Reward: -128.661167729, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.04712057114\n",
      "[NOR] Episode: 41110, Length: 127, e: 0.05, Avg Reward: -210.500895134, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.1751899719\n",
      "[NOR] Episode: 41120, Length: 278, e: 0.05, Avg Reward: -207.201703357, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.3540239334\n",
      "[NOR] Episode: 41130, Length: 369, e: 0.05, Avg Reward: -218.095759039, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.10545349121\n",
      "[NOR] Episode: 41140, Length: 166, e: 0.05, Avg Reward: -271.578707127, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.24890708923\n",
      "[NOR] Episode: 41150, Length: 145, e: 0.05, Avg Reward: -252.030132534, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.17505836487\n",
      "[NOR] Episode: 41160, Length: 268, e: 0.05, Avg Reward: -253.5594918, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.205379843712\n",
      "[NOR] Episode: 41170, Length: 214, e: 0.05, Avg Reward: -288.47433383, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.98219299316\n",
      "[NOR] Episode: 41180, Length: 99, e: 0.05, Avg Reward: -235.79372176, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.74139070511\n",
      "[NOR] Episode: 41190, Length: 164, e: 0.05, Avg Reward: -250.263610057, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.91321754456\n",
      "[NOR] Episode: 41200, Length: 171, e: 0.05, Avg Reward: -200.483820841, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.92021751404\n",
      "[NOR] Episode: 41210, Length: 166, e: 0.05, Avg Reward: -264.846373528, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.57522726059\n",
      "[NOR] Episode: 41220, Length: 119, e: 0.05, Avg Reward: -229.501965778, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.28920030594\n",
      "[NOR] Episode: 41230, Length: 84, e: 0.05, Avg Reward: -138.707099243, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.4195098877\n",
      "[NOR] Episode: 41240, Length: 140, e: 0.05, Avg Reward: -209.406598065, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.3166027069\n",
      "[NOR] Episode: 41250, Length: 131, e: 0.05, Avg Reward: -227.496310161, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.74647271633\n",
      "[NOR] Episode: 41260, Length: 114, e: 0.05, Avg Reward: -221.325289154, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.42597544193\n",
      "[NOR] Episode: 41270, Length: 114, e: 0.05, Avg Reward: -217.88961694, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 18.9984760284\n",
      "[NOR] Episode: 41280, Length: 117, e: 0.05, Avg Reward: -230.541692367, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.4184608459\n",
      "[NOR] Episode: 41290, Length: 136, e: 0.05, Avg Reward: -240.44014936, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.022441864\n",
      "[NOR] Episode: 41300, Length: 121, e: 0.05, Avg Reward: -190.304516607, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 35.5756378174\n",
      "[NOR] Episode: 41310, Length: 168, e: 0.05, Avg Reward: -256.396099843, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.74794864655\n",
      "[NOR] Episode: 41320, Length: 269, e: 0.05, Avg Reward: -227.071899898, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.4928665161\n",
      "[NOR] Episode: 41330, Length: 226, e: 0.05, Avg Reward: -267.297398207, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.16021347046\n",
      "[NOR] Episode: 41340, Length: 98, e: 0.05, Avg Reward: -239.687620816, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.42560780048\n",
      "[NOR] Episode: 41350, Length: 185, e: 0.05, Avg Reward: -241.450035558, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.3661570549\n",
      "[NOR] Episode: 41360, Length: 84, e: 0.05, Avg Reward: -251.464853822, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.2612524033\n",
      "[NOR] Episode: 41370, Length: 175, e: 0.05, Avg Reward: -212.983374236, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.31416320801\n",
      "[NOR] Episode: 41380, Length: 182, e: 0.05, Avg Reward: -221.951308177, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.0585155487\n",
      "[NOR] Episode: 41390, Length: 141, e: 0.05, Avg Reward: -249.560575168, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.3016090393\n",
      "[NOR] Episode: 41400, Length: 137, e: 0.05, Avg Reward: -205.828048675, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.8647251129\n",
      "[NOR] Episode: 41410, Length: 141, e: 0.05, Avg Reward: -219.850364378, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.03837013245\n",
      "[NOR] Episode: 41420, Length: 82, e: 0.05, Avg Reward: -228.43321391, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.7671279907\n",
      "[NOR] Episode: 41430, Length: 103, e: 0.05, Avg Reward: -183.995943043, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 40.9621086121\n",
      "[NOR] Episode: 41440, Length: 100, e: 0.05, Avg Reward: -177.99489507, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.1964378357\n",
      "[NOR] Episode: 41450, Length: 142, e: 0.05, Avg Reward: -217.625128185, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.8211202621\n",
      "[NOR] Episode: 41460, Length: 280, e: 0.05, Avg Reward: -171.157685866, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.88808107376\n",
      "[NOR] Episode: 41470, Length: 125, e: 0.05, Avg Reward: -205.234349752, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.93233108521\n",
      "[NOR] Episode: 41480, Length: 198, e: 0.05, Avg Reward: -167.284417122, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.10459947586\n",
      "[NOR] Episode: 41490, Length: 73, e: 0.05, Avg Reward: -137.98411603, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.96204853058\n",
      "[NOR] Episode: 41500, Length: 176, e: 0.05, Avg Reward: -179.860859629, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.8485803604\n",
      "[NOR] Episode: 41510, Length: 138, e: 0.05, Avg Reward: -174.829720734, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.4061431885\n",
      "[NOR] Episode: 41520, Length: 93, e: 0.05, Avg Reward: -180.888308527, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -45.3277053833\n",
      "[NOR] Episode: 41530, Length: 87, e: 0.05, Avg Reward: -158.874014473, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.12585830688\n",
      "[NOR] Episode: 41540, Length: 367, e: 0.05, Avg Reward: -172.618786864, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.56896686554\n",
      "[NOR] Episode: 41550, Length: 129, e: 0.05, Avg Reward: -131.643008988, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.09122955799\n",
      "[NOR] Episode: 41560, Length: 65, e: 0.05, Avg Reward: -137.911319046, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.294702112675\n",
      "[NOR] Episode: 41570, Length: 93, e: 0.05, Avg Reward: -145.675014633, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.67224979401\n",
      "[NOR] Episode: 41580, Length: 146, e: 0.05, Avg Reward: -149.922266815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.394839525223\n",
      "[NOR] Episode: 41590, Length: 73, e: 0.05, Avg Reward: -136.229341518, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.886773347855\n",
      "[NOR] Episode: 41600, Length: 100, e: 0.05, Avg Reward: -134.215868352, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.6936635971\n",
      "[NOR] Episode: 41610, Length: 105, e: 0.05, Avg Reward: -173.380580277, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.3618736267\n",
      "[NOR] Episode: 41620, Length: 156, e: 0.05, Avg Reward: -149.942571521, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.7912826538\n",
      "[NOR] Episode: 41630, Length: 124, e: 0.05, Avg Reward: -177.555901838, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.499053001404\n",
      "[NOR] Episode: 41640, Length: 90, e: 0.05, Avg Reward: -162.857442037, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 74.7456970215\n",
      "[NOR] Episode: 41650, Length: 65, e: 0.05, Avg Reward: -137.340179284, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -58.078742981\n",
      "[NOR] Episode: 41660, Length: 128, e: 0.05, Avg Reward: -146.458944916, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.05675888062\n",
      "[NOR] Episode: 41670, Length: 91, e: 0.05, Avg Reward: -155.182405625, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.65253520012\n",
      "[NOR] Episode: 41680, Length: 237, e: 0.05, Avg Reward: -131.076000207, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.98522853851\n",
      "[NOR] Episode: 41690, Length: 133, e: 0.05, Avg Reward: -176.224446307, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.1742897034\n",
      "[NOR] Episode: 41700, Length: 66, e: 0.05, Avg Reward: -161.425475309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 38.7026634216\n",
      "[NOR] Episode: 41710, Length: 71, e: 0.05, Avg Reward: -156.757677813, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.9977722168\n",
      "[NOR] Episode: 41720, Length: 330, e: 0.05, Avg Reward: -130.758024855, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.8041100502\n",
      "[NOR] Episode: 41730, Length: 113, e: 0.05, Avg Reward: -177.133644432, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.31594586372\n",
      "[NOR] Episode: 41740, Length: 211, e: 0.05, Avg Reward: -174.061095605, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.77281332016\n",
      "[NOR] Episode: 41750, Length: 164, e: 0.05, Avg Reward: -148.962542677, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.45083618164\n",
      "[NOR] Episode: 41760, Length: 86, e: 0.05, Avg Reward: -134.714716221, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -74.3524551392\n",
      "[NOR] Episode: 41770, Length: 83, e: 0.05, Avg Reward: -186.161076349, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.0652923584\n",
      "[NOR] Episode: 41780, Length: 74, e: 0.05, Avg Reward: -148.710714904, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.45884490013\n",
      "[NOR] Episode: 41790, Length: 306, e: 0.05, Avg Reward: -140.515655717, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.2756214142\n",
      "[NOR] Episode: 41800, Length: 79, e: 0.05, Avg Reward: -155.431247984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.66162395477\n",
      "[NOR] Episode: 41810, Length: 146, e: 0.05, Avg Reward: -146.37588499, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -72.3213043213\n",
      "[NOR] Episode: 41820, Length: 148, e: 0.05, Avg Reward: -181.259051298, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.03399705887\n",
      "[NOR] Episode: 41830, Length: 123, e: 0.05, Avg Reward: -162.709952558, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.107646942139\n",
      "[NOR] Episode: 41840, Length: 123, e: 0.05, Avg Reward: -198.671523806, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.04766750336\n",
      "[NOR] Episode: 41850, Length: 142, e: 0.05, Avg Reward: -140.232760307, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.43581390381\n",
      "[NOR] Episode: 41860, Length: 173, e: 0.05, Avg Reward: -190.958576779, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.08664536476\n",
      "[NOR] Episode: 41870, Length: 145, e: 0.05, Avg Reward: -219.629313517, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.6211690903\n",
      "[NOR] Episode: 41880, Length: 154, e: 0.05, Avg Reward: -151.36586305, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.66913414\n",
      "[NOR] Episode: 41890, Length: 297, e: 0.05, Avg Reward: -213.649167291, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.70569992065\n",
      "[NOR] Episode: 41900, Length: 80, e: 0.05, Avg Reward: -193.367765842, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.6105098724\n",
      "[NOR] Episode: 41910, Length: 129, e: 0.05, Avg Reward: -149.54303607, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.73315811157\n",
      "[NOR] Episode: 41920, Length: 163, e: 0.05, Avg Reward: -200.480089531, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.46865940094\n",
      "[NOR] Episode: 41930, Length: 133, e: 0.05, Avg Reward: -151.499075901, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.06831216812\n",
      "[NOR] Episode: 41940, Length: 133, e: 0.05, Avg Reward: -146.164388192, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.3811502457\n",
      "[NOR] Episode: 41950, Length: 147, e: 0.05, Avg Reward: -169.476752261, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.3323745728\n",
      "[NOR] Episode: 41960, Length: 137, e: 0.05, Avg Reward: -178.877234516, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.834354758263\n",
      "[NOR] Episode: 41970, Length: 114, e: 0.05, Avg Reward: -169.252302024, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.32894897461\n",
      "[NOR] Episode: 41980, Length: 188, e: 0.05, Avg Reward: -176.590780539, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.82207894325\n",
      "[NOR] Episode: 41990, Length: 87, e: 0.05, Avg Reward: -192.891290196, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.34963321686\n",
      "[NOR] Episode: 42000, Length: 76, e: 0.05, Avg Reward: -163.966609354, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.29849100113\n",
      "[NOR] Episode: 42010, Length: 99, e: 0.05, Avg Reward: -174.178759155, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -41.5466918945\n",
      "[NOR] Episode: 42020, Length: 216, e: 0.05, Avg Reward: -160.105661491, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.12708377838\n",
      "[NOR] Episode: 42030, Length: 142, e: 0.05, Avg Reward: -170.080934554, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.181252479553\n",
      "[NOR] Episode: 42040, Length: 65, e: 0.05, Avg Reward: -152.194510823, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.55929136276\n",
      "[NOR] Episode: 42050, Length: 83, e: 0.05, Avg Reward: -184.120381405, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.503611683846\n",
      "[NOR] Episode: 42060, Length: 145, e: 0.05, Avg Reward: -200.737504746, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.42199230194\n",
      "[NOR] Episode: 42070, Length: 103, e: 0.05, Avg Reward: -185.723190729, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.24108982086\n",
      "[NOR] Episode: 42080, Length: 77, e: 0.05, Avg Reward: -186.613378766, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.844186306\n",
      "[NOR] Episode: 42090, Length: 132, e: 0.05, Avg Reward: -120.651234918, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0330227613449\n",
      "[NOR] Episode: 42100, Length: 70, e: 0.05, Avg Reward: -132.832379202, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.57686710358\n",
      "[NOR] Episode: 42110, Length: 239, e: 0.05, Avg Reward: -187.205143171, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.50332450867\n",
      "[NOR] Episode: 42120, Length: 93, e: 0.05, Avg Reward: -212.517198983, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0669062137604\n",
      "[NOR] Episode: 42130, Length: 125, e: 0.05, Avg Reward: -179.445763778, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.29647779465\n",
      "[NOR] Episode: 42140, Length: 120, e: 0.05, Avg Reward: -112.379986904, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.09864521027\n",
      "[NOR] Episode: 42150, Length: 149, e: 0.05, Avg Reward: -126.813021706, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.716524481773\n",
      "[NOR] Episode: 42160, Length: 84, e: 0.05, Avg Reward: -165.761805074, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 175.091369629\n",
      "[NOR] Episode: 42170, Length: 88, e: 0.05, Avg Reward: -157.980014806, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.97750139236\n",
      "[NOR] Episode: 42180, Length: 126, e: 0.05, Avg Reward: -128.428043676, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -28.0000801086\n",
      "[NOR] Episode: 42190, Length: 82, e: 0.05, Avg Reward: -166.520283779, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.9844703674\n",
      "[NOR] Episode: 42200, Length: 125, e: 0.05, Avg Reward: -150.177210405, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.72732543945\n",
      "[NOR] Episode: 42210, Length: 62, e: 0.05, Avg Reward: -96.9521270456, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.5936279297\n",
      "[NOR] Episode: 42220, Length: 105, e: 0.05, Avg Reward: -160.359283245, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.708924889565\n",
      "[NOR] Episode: 42230, Length: 104, e: 0.05, Avg Reward: -160.813165721, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.5312795639\n",
      "[NOR] Episode: 42240, Length: 75, e: 0.05, Avg Reward: -156.868697834, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.49952793121\n",
      "[NOR] Episode: 42250, Length: 96, e: 0.05, Avg Reward: -153.697524727, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.486289978\n",
      "[NOR] Episode: 42260, Length: 103, e: 0.05, Avg Reward: -170.567028612, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.531312227249\n",
      "[NOR] Episode: 42270, Length: 96, e: 0.05, Avg Reward: -148.135646778, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 52.3206138611\n",
      "[NOR] Episode: 42280, Length: 76, e: 0.05, Avg Reward: -178.240409988, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.99434995651\n",
      "[NOR] Episode: 42290, Length: 147, e: 0.05, Avg Reward: -165.024754144, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.7606830597\n",
      "[NOR] Episode: 42300, Length: 92, e: 0.05, Avg Reward: -186.152474464, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.21661520004\n",
      "[NOR] Episode: 42310, Length: 90, e: 0.05, Avg Reward: -170.125321814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.5840358734\n",
      "[NOR] Episode: 42320, Length: 74, e: 0.05, Avg Reward: -196.080259141, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.4286499023\n",
      "[NOR] Episode: 42330, Length: 95, e: 0.05, Avg Reward: -161.11241725, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.19872808456\n",
      "[NOR] Episode: 42340, Length: 98, e: 0.05, Avg Reward: -224.808365368, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 24.339799881\n",
      "[NOR] Episode: 42350, Length: 88, e: 0.05, Avg Reward: -138.267114605, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.01448917389\n",
      "[NOR] Episode: 42360, Length: 114, e: 0.05, Avg Reward: -183.962822225, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.66405105591\n",
      "[NOR] Episode: 42370, Length: 128, e: 0.05, Avg Reward: -197.039171894, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.54891824722\n",
      "[NOR] Episode: 42380, Length: 135, e: 0.05, Avg Reward: -202.095660028, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.160484075546\n",
      "[NOR] Episode: 42390, Length: 107, e: 0.05, Avg Reward: -210.078429538, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 50.2854309082\n",
      "[NOR] Episode: 42400, Length: 419, e: 0.05, Avg Reward: -140.787390792, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.62071371078\n",
      "[NOR] Episode: 42410, Length: 127, e: 0.05, Avg Reward: -162.662553179, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.97660923004\n",
      "[NOR] Episode: 42420, Length: 58, e: 0.05, Avg Reward: -147.044710337, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.327950835228\n",
      "[NOR] Episode: 42430, Length: 61, e: 0.05, Avg Reward: -162.80011634, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.5748462677\n",
      "[NOR] Episode: 42440, Length: 137, e: 0.05, Avg Reward: -168.247690654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -30.2066955566\n",
      "[NOR] Episode: 42450, Length: 131, e: 0.05, Avg Reward: -170.40149603, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.135892629623\n",
      "[NOR] Episode: 42460, Length: 76, e: 0.05, Avg Reward: -163.894887206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.49362468719\n",
      "[NOR] Episode: 42470, Length: 135, e: 0.05, Avg Reward: -156.127338637, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.53466892242\n",
      "[NOR] Episode: 42480, Length: 92, e: 0.05, Avg Reward: -194.368960961, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.4928684235\n",
      "[NOR] Episode: 42490, Length: 95, e: 0.05, Avg Reward: -145.479316216, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.70289707184\n",
      "[NOR] Episode: 42500, Length: 96, e: 0.05, Avg Reward: -182.955348852, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.6617231369\n",
      "[NOR] Episode: 42510, Length: 80, e: 0.05, Avg Reward: -207.329954647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.02159309387\n",
      "[NOR] Episode: 42520, Length: 95, e: 0.05, Avg Reward: -203.237223717, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.19823551178\n",
      "[NOR] Episode: 42530, Length: 146, e: 0.05, Avg Reward: -202.802703814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.51474571228\n",
      "[NOR] Episode: 42540, Length: 68, e: 0.05, Avg Reward: -177.622333401, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.99293637276\n",
      "[NOR] Episode: 42550, Length: 133, e: 0.05, Avg Reward: -197.584422977, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.80160999298\n",
      "[NOR] Episode: 42560, Length: 81, e: 0.05, Avg Reward: -215.514999579, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.5605201721\n",
      "[NOR] Episode: 42570, Length: 119, e: 0.05, Avg Reward: -119.208565253, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.2591848373\n",
      "[NOR] Episode: 42580, Length: 88, e: 0.05, Avg Reward: -176.833486144, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.0190048218\n",
      "[NOR] Episode: 42590, Length: 144, e: 0.05, Avg Reward: -192.249779334, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.6854972839\n",
      "[NOR] Episode: 42600, Length: 85, e: 0.05, Avg Reward: -170.097376872, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0107364654541\n",
      "[NOR] Episode: 42610, Length: 93, e: 0.05, Avg Reward: -205.526402726, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 142.986953735\n",
      "[NOR] Episode: 42620, Length: 148, e: 0.05, Avg Reward: -157.072627908, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.45636546612\n",
      "[NOR] Episode: 42630, Length: 98, e: 0.05, Avg Reward: -195.128158261, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -72.5427017212\n",
      "[NOR] Episode: 42640, Length: 104, e: 0.05, Avg Reward: -152.761484019, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.6483402252\n",
      "[NOR] Episode: 42650, Length: 98, e: 0.05, Avg Reward: -196.219332549, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.16257476807\n",
      "[NOR] Episode: 42660, Length: 118, e: 0.05, Avg Reward: -194.148697636, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.2840175629\n",
      "[NOR] Episode: 42670, Length: 66, e: 0.05, Avg Reward: -221.031964655, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.5930557251\n",
      "[NOR] Episode: 42680, Length: 64, e: 0.05, Avg Reward: -150.346484316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.1033191681\n",
      "[NOR] Episode: 42690, Length: 141, e: 0.05, Avg Reward: -196.802944053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.45117902756\n",
      "[NOR] Episode: 42700, Length: 87, e: 0.05, Avg Reward: -173.069368699, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.09856700897\n",
      "[NOR] Episode: 42710, Length: 89, e: 0.05, Avg Reward: -203.520125367, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.6935210228\n",
      "[NOR] Episode: 42720, Length: 91, e: 0.05, Avg Reward: -187.686883763, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.0674743652\n",
      "[NOR] Episode: 42730, Length: 88, e: 0.05, Avg Reward: -222.950749103, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.66245746613\n",
      "[NOR] Episode: 42740, Length: 68, e: 0.05, Avg Reward: -223.114252895, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.6034011841\n",
      "[NOR] Episode: 42750, Length: 112, e: 0.05, Avg Reward: -247.870318845, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 25.7873802185\n",
      "[NOR] Episode: 42760, Length: 83, e: 0.05, Avg Reward: -165.35446709, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.83142518997\n",
      "[NOR] Episode: 42770, Length: 65, e: 0.05, Avg Reward: -200.862576495, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.7188520432\n",
      "[NOR] Episode: 42780, Length: 110, e: 0.05, Avg Reward: -209.662025631, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.898967683315\n",
      "[NOR] Episode: 42790, Length: 50, e: 0.05, Avg Reward: -224.078115246, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.1854381561\n",
      "[NOR] Episode: 42800, Length: 108, e: 0.05, Avg Reward: -157.063679475, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.53539896011\n",
      "[NOR] Episode: 42810, Length: 101, e: 0.05, Avg Reward: -185.277716416, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.77623844147\n",
      "[NOR] Episode: 42820, Length: 113, e: 0.05, Avg Reward: -203.512580982, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.836789608\n",
      "[NOR] Episode: 42830, Length: 108, e: 0.05, Avg Reward: -194.814974775, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.7115745544\n",
      "[NOR] Episode: 42840, Length: 99, e: 0.05, Avg Reward: -172.324432071, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.13928699493\n",
      "[NOR] Episode: 42850, Length: 91, e: 0.05, Avg Reward: -152.803078051, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 31.5829048157\n",
      "[NOR] Episode: 42860, Length: 116, e: 0.05, Avg Reward: -196.289578003, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.01626157761\n",
      "[NOR] Episode: 42870, Length: 127, e: 0.05, Avg Reward: -127.908918819, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.62517738342\n",
      "[NOR] Episode: 42880, Length: 81, e: 0.05, Avg Reward: -166.48047596, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.5417547226\n",
      "[NOR] Episode: 42890, Length: 58, e: 0.05, Avg Reward: -146.012384877, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.00049591064\n",
      "[NOR] Episode: 42900, Length: 127, e: 0.05, Avg Reward: -173.891073307, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.10521495342\n",
      "[NOR] Episode: 42910, Length: 107, e: 0.05, Avg Reward: -190.740643808, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.50146865845\n",
      "[NOR] Episode: 42920, Length: 87, e: 0.05, Avg Reward: -178.600777023, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.42182159424\n",
      "[NOR] Episode: 42930, Length: 94, e: 0.05, Avg Reward: -180.367330009, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.57485866547\n",
      "[NOR] Episode: 42940, Length: 113, e: 0.05, Avg Reward: -177.599529375, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.09473252296\n",
      "[NOR] Episode: 42950, Length: 136, e: 0.05, Avg Reward: -195.625878675, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.19135928154\n",
      "[NOR] Episode: 42960, Length: 127, e: 0.05, Avg Reward: -171.513305741, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.44575214386\n",
      "[NOR] Episode: 42970, Length: 82, e: 0.05, Avg Reward: -191.750724719, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.84828329086\n",
      "[NOR] Episode: 42980, Length: 105, e: 0.05, Avg Reward: -172.802524609, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.203177213669\n",
      "[NOR] Episode: 42990, Length: 70, e: 0.05, Avg Reward: -219.200621699, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.54582023621\n",
      "[NOR] Episode: 43000, Length: 122, e: 0.05, Avg Reward: -142.496593037, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.349638938904\n",
      "[NOR] Episode: 43010, Length: 76, e: 0.05, Avg Reward: -220.801102961, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.35022497177\n",
      "[NOR] Episode: 43020, Length: 65, e: 0.05, Avg Reward: -168.877659478, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.6751947403\n",
      "[NOR] Episode: 43030, Length: 69, e: 0.05, Avg Reward: -190.444691325, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.3914680481\n",
      "[NOR] Episode: 43040, Length: 59, e: 0.05, Avg Reward: -147.065525738, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.1494140625\n",
      "[NOR] Episode: 43050, Length: 140, e: 0.05, Avg Reward: -179.587795994, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.0894393921\n",
      "[NOR] Episode: 43060, Length: 145, e: 0.05, Avg Reward: -177.584422364, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.53620624542\n",
      "[NOR] Episode: 43070, Length: 69, e: 0.05, Avg Reward: -148.968914927, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.17800331116\n",
      "[NOR] Episode: 43080, Length: 104, e: 0.05, Avg Reward: -131.872788025, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.3040142059\n",
      "[NOR] Episode: 43090, Length: 107, e: 0.05, Avg Reward: -160.879995738, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.0378789902\n",
      "[NOR] Episode: 43100, Length: 68, e: 0.05, Avg Reward: -195.74736002, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.349647522\n",
      "[NOR] Episode: 43110, Length: 119, e: 0.05, Avg Reward: -139.262119822, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.82659769058\n",
      "[NOR] Episode: 43120, Length: 159, e: 0.05, Avg Reward: -153.321760944, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.2260131836\n",
      "[NOR] Episode: 43130, Length: 120, e: 0.05, Avg Reward: -162.556459208, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.73308300972\n",
      "[NOR] Episode: 43140, Length: 131, e: 0.05, Avg Reward: -176.652721309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.02549552917\n",
      "[NOR] Episode: 43150, Length: 107, e: 0.05, Avg Reward: -173.580937859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.42253255844\n",
      "[NOR] Episode: 43160, Length: 86, e: 0.05, Avg Reward: -172.020928247, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.81431412697\n",
      "[NOR] Episode: 43170, Length: 50, e: 0.05, Avg Reward: -187.117124779, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.2952766418\n",
      "[NOR] Episode: 43180, Length: 112, e: 0.05, Avg Reward: -164.671936497, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.7423152924\n",
      "[NOR] Episode: 43190, Length: 236, e: 0.05, Avg Reward: -118.019573404, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.66173601151\n",
      "[NOR] Episode: 43200, Length: 85, e: 0.05, Avg Reward: -202.844887896, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.78737258911\n",
      "[NOR] Episode: 43210, Length: 85, e: 0.05, Avg Reward: -131.502771699, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.1821449995\n",
      "[NOR] Episode: 43220, Length: 99, e: 0.05, Avg Reward: -171.230246697, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -43.5939331055\n",
      "[NOR] Episode: 43230, Length: 66, e: 0.05, Avg Reward: -175.550730422, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.17948889732\n",
      "[NOR] Episode: 43240, Length: 70, e: 0.05, Avg Reward: -191.018479527, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.27036571503\n",
      "[NOR] Episode: 43250, Length: 82, e: 0.05, Avg Reward: -158.695627172, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.35485506058\n",
      "[NOR] Episode: 43260, Length: 104, e: 0.05, Avg Reward: -103.380140034, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.957908809185\n",
      "[NOR] Episode: 43270, Length: 126, e: 0.05, Avg Reward: -176.709742034, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.7477312088\n",
      "[NOR] Episode: 43280, Length: 229, e: 0.05, Avg Reward: -142.315228653, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.55361270905\n",
      "[NOR] Episode: 43290, Length: 98, e: 0.05, Avg Reward: -171.427905603, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.30106139183\n",
      "[NOR] Episode: 43300, Length: 174, e: 0.05, Avg Reward: -148.993190831, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.941484212875\n",
      "[NOR] Episode: 43310, Length: 141, e: 0.05, Avg Reward: -112.455499169, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.749402523041\n",
      "[NOR] Episode: 43320, Length: 103, e: 0.05, Avg Reward: -186.090719752, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.1218380928\n",
      "[NOR] Episode: 43330, Length: 60, e: 0.05, Avg Reward: -163.878626893, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.00826144218\n",
      "[NOR] Episode: 43340, Length: 138, e: 0.05, Avg Reward: -173.007401968, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.07148647308\n",
      "[NOR] Episode: 43350, Length: 88, e: 0.05, Avg Reward: -128.068405638, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.80750536919\n",
      "[NOR] Episode: 43360, Length: 104, e: 0.05, Avg Reward: -129.26118282, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.65254116058\n",
      "[NOR] Episode: 43370, Length: 159, e: 0.05, Avg Reward: -154.086023244, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.2627744675\n",
      "[NOR] Episode: 43380, Length: 140, e: 0.05, Avg Reward: -127.413938565, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.93137836456\n",
      "[NOR] Episode: 43390, Length: 112, e: 0.05, Avg Reward: -152.300624657, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.88168001175\n",
      "[NOR] Episode: 43400, Length: 121, e: 0.05, Avg Reward: -182.338529686, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.0335531235\n",
      "[NOR] Episode: 43410, Length: 57, e: 0.05, Avg Reward: -180.271430435, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.78660964966\n",
      "[NOR] Episode: 43420, Length: 112, e: 0.05, Avg Reward: -106.475545112, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.3553237915\n",
      "[NOR] Episode: 43430, Length: 144, e: 0.05, Avg Reward: -149.826186079, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.59558558464\n",
      "[NOR] Episode: 43440, Length: 120, e: 0.05, Avg Reward: -142.063824496, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.2520275116\n",
      "[NOR] Episode: 43450, Length: 140, e: 0.05, Avg Reward: -194.74958775, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.4302587509\n",
      "[NOR] Episode: 43460, Length: 192, e: 0.05, Avg Reward: -118.320079149, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.70888233185\n",
      "[NOR] Episode: 43470, Length: 111, e: 0.05, Avg Reward: -145.816643214, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.18989849091\n",
      "[NOR] Episode: 43480, Length: 206, e: 0.05, Avg Reward: -114.234384567, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.46981549263\n",
      "[NOR] Episode: 43490, Length: 130, e: 0.05, Avg Reward: -134.320730675, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.9277105331\n",
      "[NOR] Episode: 43500, Length: 85, e: 0.05, Avg Reward: -177.352859309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.91791963577\n",
      "[NOR] Episode: 43510, Length: 94, e: 0.05, Avg Reward: -134.534388559, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.5274450779\n",
      "[NOR] Episode: 43520, Length: 69, e: 0.05, Avg Reward: -166.329888445, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.03057098389\n",
      "[NOR] Episode: 43530, Length: 209, e: 0.05, Avg Reward: -139.240709441, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.5301046371\n",
      "[NOR] Episode: 43540, Length: 123, e: 0.05, Avg Reward: -143.545177146, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.7012014389\n",
      "[NOR] Episode: 43550, Length: 124, e: 0.05, Avg Reward: -111.633523978, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.318984985352\n",
      "[NOR] Episode: 43560, Length: 105, e: 0.05, Avg Reward: -150.019218678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.073117733\n",
      "[NOR] Episode: 43570, Length: 101, e: 0.05, Avg Reward: -161.635913596, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.54484367371\n",
      "[NOR] Episode: 43580, Length: 194, e: 0.05, Avg Reward: -140.772090458, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.65354824066\n",
      "[NOR] Episode: 43590, Length: 189, e: 0.05, Avg Reward: -157.82070767, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.35660159588\n",
      "[NOR] Episode: 43600, Length: 93, e: 0.05, Avg Reward: -112.661662973, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.614253520966\n",
      "[NOR] Episode: 43610, Length: 197, e: 0.05, Avg Reward: -147.373999459, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.112192809582\n",
      "[NOR] Episode: 43620, Length: 77, e: 0.05, Avg Reward: -167.977903138, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.11560297012\n",
      "[NOR] Episode: 43630, Length: 86, e: 0.05, Avg Reward: -163.005882523, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.60064554214\n",
      "[NOR] Episode: 43640, Length: 101, e: 0.05, Avg Reward: -173.378884887, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.05337619781\n",
      "[NOR] Episode: 43650, Length: 143, e: 0.05, Avg Reward: -112.732647578, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.16313290596\n",
      "[NOR] Episode: 43660, Length: 79, e: 0.05, Avg Reward: -149.534376427, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.47931957245\n",
      "[NOR] Episode: 43670, Length: 123, e: 0.05, Avg Reward: -198.370959603, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.61804676056\n",
      "[NOR] Episode: 43680, Length: 381, e: 0.05, Avg Reward: -123.597617384, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.04226350784\n",
      "[NOR] Episode: 43690, Length: 97, e: 0.05, Avg Reward: -154.709873717, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.6740732193\n",
      "[NOR] Episode: 43700, Length: 86, e: 0.05, Avg Reward: -158.659442363, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.50253534317\n",
      "[NOR] Episode: 43710, Length: 172, e: 0.05, Avg Reward: -110.321987747, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.19955182076\n",
      "[NOR] Episode: 43720, Length: 176, e: 0.05, Avg Reward: -127.541966553, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.0456943512\n",
      "[NOR] Episode: 43730, Length: 81, e: 0.05, Avg Reward: -118.063833945, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.92735862732\n",
      "[NOR] Episode: 43740, Length: 116, e: 0.05, Avg Reward: -103.125006857, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.4817609787\n",
      "[NOR] Episode: 43750, Length: 326, e: 0.05, Avg Reward: -97.0642404175, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.83463954926\n",
      "[NOR] Episode: 43760, Length: 101, e: 0.05, Avg Reward: -50.2411764431, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.37052702904\n",
      "[NOR] Episode: 43770, Length: 289, e: 0.05, Avg Reward: -50.9554317056, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.141708850861\n",
      "[NOR] Episode: 43780, Length: 81, e: 0.05, Avg Reward: -121.30852377, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.76393938065\n",
      "[NOR] Episode: 43790, Length: 196, e: 0.05, Avg Reward: -169.572682339, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.74140834808\n",
      "[NOR] Episode: 43800, Length: 129, e: 0.05, Avg Reward: -107.459840264, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.0665111542\n",
      "[NOR] Episode: 43810, Length: 72, e: 0.05, Avg Reward: -131.186225451, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.16024303436\n",
      "[NOR] Episode: 43820, Length: 174, e: 0.05, Avg Reward: -137.325531812, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.74528241158\n",
      "[NOR] Episode: 43830, Length: 79, e: 0.05, Avg Reward: -90.6472291435, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.42591094971\n",
      "[NOR] Episode: 43840, Length: 86, e: 0.05, Avg Reward: -136.47708084, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.12735843658\n",
      "[NOR] Episode: 43850, Length: 78, e: 0.05, Avg Reward: -121.525013661, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.07896471024\n",
      "[NOR] Episode: 43860, Length: 141, e: 0.05, Avg Reward: -99.6053411928, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.90801644325\n",
      "[NOR] Episode: 43870, Length: 113, e: 0.05, Avg Reward: -125.66009785, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -27.274728775\n",
      "[NOR] Episode: 43880, Length: 90, e: 0.05, Avg Reward: -116.48201166, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.3577876091\n",
      "[NOR] Episode: 43890, Length: 93, e: 0.05, Avg Reward: -144.0615251, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.55883979797\n",
      "[NOR] Episode: 43900, Length: 89, e: 0.05, Avg Reward: -131.52688296, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.19356536865\n",
      "[NOR] Episode: 43910, Length: 80, e: 0.05, Avg Reward: -38.9612718802, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.73504447937\n",
      "[NOR] Episode: 43920, Length: 59, e: 0.05, Avg Reward: -122.008609383, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.636449217796\n",
      "[NOR] Episode: 43930, Length: 99, e: 0.05, Avg Reward: -56.5103347721, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.89782905579\n",
      "[NOR] Episode: 43940, Length: 74, e: 0.05, Avg Reward: -74.4261948197, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.4963846207\n",
      "[NOR] Episode: 43950, Length: 71, e: 0.05, Avg Reward: -99.0945355784, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.83213019371\n",
      "[NOR] Episode: 43960, Length: 77, e: 0.05, Avg Reward: -133.322139527, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.08591628075\n",
      "[NOR] Episode: 43970, Length: 171, e: 0.05, Avg Reward: -122.452663822, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.873266220093\n",
      "[NOR] Episode: 43980, Length: 112, e: 0.05, Avg Reward: -99.4979407944, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.776457250118\n",
      "[NOR] Episode: 43990, Length: 72, e: 0.05, Avg Reward: -145.201334995, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.2660626173\n",
      "[NOR] Episode: 44000, Length: 267, e: 0.05, Avg Reward: -132.980694387, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.03902590275\n",
      "[NOR] Episode: 44010, Length: 99, e: 0.05, Avg Reward: -142.873607062, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.17278289795\n",
      "[NOR] Episode: 44020, Length: 184, e: 0.05, Avg Reward: -112.842391928, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.30164170265\n",
      "[NOR] Episode: 44030, Length: 145, e: 0.05, Avg Reward: -83.717276038, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.73596334457\n",
      "[NOR] Episode: 44040, Length: 124, e: 0.05, Avg Reward: -120.736982991, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.6087641716\n",
      "[NOR] Episode: 44050, Length: 76, e: 0.05, Avg Reward: -102.799849747, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.2864561081\n",
      "[NOR] Episode: 44060, Length: 84, e: 0.05, Avg Reward: -142.379278194, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 34.9011230469\n",
      "[NOR] Episode: 44070, Length: 91, e: 0.05, Avg Reward: -124.01637465, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.94212675095\n",
      "[NOR] Episode: 44080, Length: 69, e: 0.05, Avg Reward: -121.845583197, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.32664585114\n",
      "[NOR] Episode: 44090, Length: 85, e: 0.05, Avg Reward: -103.876730475, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.40803909302\n",
      "[NOR] Episode: 44100, Length: 223, e: 0.05, Avg Reward: -119.306872471, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.86302018166\n",
      "[NOR] Episode: 44110, Length: 83, e: 0.05, Avg Reward: -54.6992761604, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.29381465912\n",
      "[NOR] Episode: 44120, Length: 93, e: 0.05, Avg Reward: -160.027966308, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.26694822311\n",
      "[NOR] Episode: 44130, Length: 158, e: 0.05, Avg Reward: -92.85431777, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.22854995728\n",
      "[NOR] Episode: 44140, Length: 67, e: 0.05, Avg Reward: -134.551882905, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.613508701324\n",
      "[NOR] Episode: 44150, Length: 76, e: 0.05, Avg Reward: -75.4474794638, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.39872932434\n",
      "[NOR] Episode: 44160, Length: 90, e: 0.05, Avg Reward: -178.592297993, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.27790927887\n",
      "[NOR] Episode: 44170, Length: 84, e: 0.05, Avg Reward: -161.216426936, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.118812799454\n",
      "[NOR] Episode: 44180, Length: 151, e: 0.05, Avg Reward: -125.468517256, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.82641553879\n",
      "[NOR] Episode: 44190, Length: 289, e: 0.05, Avg Reward: -119.609431737, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.96405744553\n",
      "[NOR] Episode: 44200, Length: 62, e: 0.05, Avg Reward: -107.809111738, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.79107093811\n",
      "[NOR] Episode: 44210, Length: 209, e: 0.05, Avg Reward: -108.381561038, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.53240680695\n",
      "[NOR] Episode: 44220, Length: 67, e: 0.05, Avg Reward: -121.907530175, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.90999889374\n",
      "[NOR] Episode: 44230, Length: 77, e: 0.05, Avg Reward: -137.897736378, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.520397543907\n",
      "[NOR] Episode: 44240, Length: 173, e: 0.05, Avg Reward: -128.307909269, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.7720127106\n",
      "[NOR] Episode: 44250, Length: 87, e: 0.05, Avg Reward: -124.661235145, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.7479972839\n",
      "[NOR] Episode: 44260, Length: 68, e: 0.05, Avg Reward: -138.320390568, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.0419511795\n",
      "[NOR] Episode: 44270, Length: 62, e: 0.05, Avg Reward: -56.5182526396, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.50331687927\n",
      "[NOR] Episode: 44280, Length: 85, e: 0.05, Avg Reward: -197.988008623, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.401070594788\n",
      "[NOR] Episode: 44290, Length: 85, e: 0.05, Avg Reward: -125.671829869, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.0206184387\n",
      "[NOR] Episode: 44300, Length: 141, e: 0.05, Avg Reward: -131.542442697, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.62293696404\n",
      "[NOR] Episode: 44310, Length: 70, e: 0.05, Avg Reward: -127.14239183, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.7194690704\n",
      "[NOR] Episode: 44320, Length: 98, e: 0.05, Avg Reward: -141.859529957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.14901065826\n",
      "[NOR] Episode: 44330, Length: 75, e: 0.05, Avg Reward: -131.628651403, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.26770162582\n",
      "[NOR] Episode: 44340, Length: 68, e: 0.05, Avg Reward: -119.820708494, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.5422372818\n",
      "[NOR] Episode: 44350, Length: 90, e: 0.05, Avg Reward: -123.365760322, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.5079069138\n",
      "[NOR] Episode: 44360, Length: 52, e: 0.05, Avg Reward: -72.5791186728, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.76537322998\n",
      "[NOR] Episode: 44370, Length: 59, e: 0.05, Avg Reward: -120.273685564, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.4747104645\n",
      "[NOR] Episode: 44380, Length: 85, e: 0.05, Avg Reward: -137.659374311, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.0167007446\n",
      "[NOR] Episode: 44390, Length: 91, e: 0.05, Avg Reward: -135.317796396, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.8608407974\n",
      "[NOR] Episode: 44400, Length: 208, e: 0.05, Avg Reward: -118.491450052, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.0216255188\n",
      "[NOR] Episode: 44410, Length: 92, e: 0.05, Avg Reward: -158.760209893, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.0677022934\n",
      "[NOR] Episode: 44420, Length: 125, e: 0.05, Avg Reward: -105.472376341, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.37622046471\n",
      "[NOR] Episode: 44430, Length: 63, e: 0.05, Avg Reward: -155.995805648, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.80612707138\n",
      "[NOR] Episode: 44440, Length: 168, e: 0.05, Avg Reward: -108.041833609, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.35837268829\n",
      "[NOR] Episode: 44450, Length: 86, e: 0.05, Avg Reward: -148.601395455, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.43773174286\n",
      "[NOR] Episode: 44460, Length: 136, e: 0.05, Avg Reward: -131.661933347, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.86367797852\n",
      "[NOR] Episode: 44470, Length: 77, e: 0.05, Avg Reward: -121.78558904, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.1322021484\n",
      "[NOR] Episode: 44480, Length: 93, e: 0.05, Avg Reward: -134.042165765, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.428921818733\n",
      "[NOR] Episode: 44490, Length: 91, e: 0.05, Avg Reward: -163.392592439, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.08829927444\n",
      "[NOR] Episode: 44500, Length: 88, e: 0.05, Avg Reward: -150.44775505, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.0068092346\n",
      "[NOR] Episode: 44510, Length: 71, e: 0.05, Avg Reward: -101.533475648, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.0389251709\n",
      "[NOR] Episode: 44520, Length: 59, e: 0.05, Avg Reward: -117.129265945, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.87881278992\n",
      "[NOR] Episode: 44530, Length: 59, e: 0.05, Avg Reward: -107.543440725, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.782120525837\n",
      "[NOR] Episode: 44540, Length: 82, e: 0.05, Avg Reward: -142.823791283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.89990711212\n",
      "[NOR] Episode: 44550, Length: 75, e: 0.05, Avg Reward: -128.614256728, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.78119421005\n",
      "[NOR] Episode: 44560, Length: 64, e: 0.05, Avg Reward: -144.763847062, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.4904050827\n",
      "[NOR] Episode: 44570, Length: 167, e: 0.05, Avg Reward: -125.000304315, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.66745877266\n",
      "[NOR] Episode: 44580, Length: 89, e: 0.05, Avg Reward: -129.143607828, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.47337627411\n",
      "[NOR] Episode: 44590, Length: 87, e: 0.05, Avg Reward: -145.294834754, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.75813150406\n",
      "[NOR] Episode: 44600, Length: 119, e: 0.05, Avg Reward: -107.049108592, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.14554977417\n",
      "[NOR] Episode: 44610, Length: 88, e: 0.05, Avg Reward: -128.754751113, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.25583028793\n",
      "[NOR] Episode: 44620, Length: 69, e: 0.05, Avg Reward: -147.488416548, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.25227022171\n",
      "[NOR] Episode: 44630, Length: 86, e: 0.05, Avg Reward: -130.992169404, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.04115152359\n",
      "[NOR] Episode: 44640, Length: 82, e: 0.05, Avg Reward: -122.230672258, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.732073605061\n",
      "[NOR] Episode: 44650, Length: 110, e: 0.05, Avg Reward: -143.452523577, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.92077076435\n",
      "[NOR] Episode: 44660, Length: 86, e: 0.05, Avg Reward: -128.543718428, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.16769218445\n",
      "[NOR] Episode: 44670, Length: 93, e: 0.05, Avg Reward: -94.3956174004, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.08890044689\n",
      "[NOR] Episode: 44680, Length: 92, e: 0.05, Avg Reward: -121.19325328, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.20848274231\n",
      "[NOR] Episode: 44690, Length: 281, e: 0.05, Avg Reward: -161.265173799, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.63579797745\n",
      "[NOR] Episode: 44700, Length: 90, e: 0.05, Avg Reward: -152.663484036, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.07420158386\n",
      "[NOR] Episode: 44710, Length: 66, e: 0.05, Avg Reward: -165.245143213, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.86862850189\n",
      "[NOR] Episode: 44720, Length: 94, e: 0.05, Avg Reward: -158.99120952, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.60481071472\n",
      "[NOR] Episode: 44730, Length: 100, e: 0.05, Avg Reward: -122.516091387, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.45888888836\n",
      "[NOR] Episode: 44740, Length: 123, e: 0.05, Avg Reward: -145.194385873, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.611348629\n",
      "[NOR] Episode: 44750, Length: 193, e: 0.05, Avg Reward: -147.587365292, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 40.3241462708\n",
      "[NOR] Episode: 44760, Length: 70, e: 0.05, Avg Reward: -154.582174622, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.52057647705\n",
      "[NOR] Episode: 44770, Length: 142, e: 0.05, Avg Reward: -114.385345858, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.717736721039\n",
      "[NOR] Episode: 44780, Length: 368, e: 0.05, Avg Reward: -101.391697515, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.1202774048\n",
      "[NOR] Episode: 44790, Length: 51, e: 0.05, Avg Reward: -124.039384137, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.160269975662\n",
      "[NOR] Episode: 44800, Length: 100, e: 0.05, Avg Reward: -149.194101046, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.1599843502\n",
      "[NOR] Episode: 44810, Length: 80, e: 0.05, Avg Reward: -143.920725022, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.14734601974\n",
      "[NOR] Episode: 44820, Length: 92, e: 0.05, Avg Reward: -135.704805773, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.0058460236\n",
      "[NOR] Episode: 44830, Length: 98, e: 0.05, Avg Reward: -146.125220168, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.3099422455\n",
      "[NOR] Episode: 44840, Length: 85, e: 0.05, Avg Reward: -153.313444889, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.33005714417\n",
      "[NOR] Episode: 44850, Length: 113, e: 0.05, Avg Reward: -100.799242963, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.91856002808\n",
      "[NOR] Episode: 44860, Length: 197, e: 0.05, Avg Reward: -162.665220431, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.38716077805\n",
      "[NOR] Episode: 44870, Length: 80, e: 0.05, Avg Reward: -143.803585245, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.9415845871\n",
      "[NOR] Episode: 44880, Length: 128, e: 0.05, Avg Reward: -137.494842576, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.02797317505\n",
      "[NOR] Episode: 44890, Length: 194, e: 0.05, Avg Reward: -153.229820049, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.9271876812\n",
      "[NOR] Episode: 44900, Length: 68, e: 0.05, Avg Reward: -130.562411433, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.05257129669\n",
      "[NOR] Episode: 44910, Length: 66, e: 0.05, Avg Reward: -133.889381582, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.455881357193\n",
      "[NOR] Episode: 44920, Length: 77, e: 0.05, Avg Reward: -170.635048335, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.0724868774\n",
      "[NOR] Episode: 44930, Length: 144, e: 0.05, Avg Reward: -125.378445268, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.058347702\n",
      "[NOR] Episode: 44940, Length: 80, e: 0.05, Avg Reward: -163.712741727, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.78364562988\n",
      "[NOR] Episode: 44950, Length: 63, e: 0.05, Avg Reward: -146.671899404, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.431634903\n",
      "[NOR] Episode: 44960, Length: 99, e: 0.05, Avg Reward: -150.706640549, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.0689163208\n",
      "[NOR] Episode: 44970, Length: 79, e: 0.05, Avg Reward: -141.069895323, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.979801178\n",
      "[NOR] Episode: 44980, Length: 79, e: 0.05, Avg Reward: -143.821098217, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.65921998024\n",
      "[NOR] Episode: 44990, Length: 90, e: 0.05, Avg Reward: -172.757553643, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.483076334\n",
      "[NOR] Episode: 45000, Length: 100, e: 0.05, Avg Reward: -138.69021431, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.96436691284\n",
      "[NOR] Episode: 45010, Length: 129, e: 0.05, Avg Reward: -135.840472061, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.31618976593\n",
      "[NOR] Episode: 45020, Length: 79, e: 0.05, Avg Reward: -137.077053085, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.15463542938\n",
      "[NOR] Episode: 45030, Length: 62, e: 0.05, Avg Reward: -143.02346967, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.33053159714\n",
      "[NOR] Episode: 45040, Length: 83, e: 0.05, Avg Reward: -102.130091413, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.418006897\n",
      "[NOR] Episode: 45050, Length: 84, e: 0.05, Avg Reward: -142.177373318, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.378074645996\n",
      "[NOR] Episode: 45060, Length: 104, e: 0.05, Avg Reward: -110.467007343, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.10407090187\n",
      "[NOR] Episode: 45070, Length: 93, e: 0.05, Avg Reward: -146.362567649, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.09310770035\n",
      "[NOR] Episode: 45080, Length: 87, e: 0.05, Avg Reward: -63.2965040587, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.16334438324\n",
      "[NOR] Episode: 45090, Length: 138, e: 0.05, Avg Reward: -158.728603137, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.55206298828\n",
      "[NOR] Episode: 45100, Length: 86, e: 0.05, Avg Reward: -130.476591787, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.53220272064\n",
      "[NOR] Episode: 45110, Length: 89, e: 0.05, Avg Reward: -114.787151918, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.57996940613\n",
      "[NOR] Episode: 45120, Length: 67, e: 0.05, Avg Reward: -123.00608054, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.183363199234\n",
      "[NOR] Episode: 45130, Length: 64, e: 0.05, Avg Reward: -94.2544142793, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.62280130386\n",
      "[NOR] Episode: 45140, Length: 84, e: 0.05, Avg Reward: -150.049091725, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.5122423172\n",
      "[NOR] Episode: 45150, Length: 77, e: 0.05, Avg Reward: -146.101227248, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.75411462784\n",
      "[NOR] Episode: 45160, Length: 97, e: 0.05, Avg Reward: -148.382646007, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.3846077919\n",
      "[NOR] Episode: 45170, Length: 81, e: 0.05, Avg Reward: -133.521003542, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.571472168\n",
      "[NOR] Episode: 45180, Length: 62, e: 0.05, Avg Reward: -148.255170102, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.60729694366\n",
      "[NOR] Episode: 45190, Length: 87, e: 0.05, Avg Reward: -156.415352763, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.29210567474\n",
      "[NOR] Episode: 45200, Length: 110, e: 0.05, Avg Reward: -121.063571141, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.8279132843\n",
      "[NOR] Episode: 45210, Length: 109, e: 0.05, Avg Reward: -116.86637234, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.63853883743\n",
      "[NOR] Episode: 45220, Length: 167, e: 0.05, Avg Reward: -127.761156359, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.617857992649\n",
      "[NOR] Episode: 45230, Length: 134, e: 0.05, Avg Reward: -143.904299045, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.4694843292\n",
      "[NOR] Episode: 45240, Length: 84, e: 0.05, Avg Reward: -167.887701627, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.46693730354\n",
      "[NOR] Episode: 45250, Length: 96, e: 0.05, Avg Reward: -139.158215723, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.74275112152\n",
      "[NOR] Episode: 45260, Length: 72, e: 0.05, Avg Reward: -152.510615399, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.65056991577\n",
      "[NOR] Episode: 45270, Length: 64, e: 0.05, Avg Reward: -156.406830378, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.5966615677\n",
      "[NOR] Episode: 45280, Length: 102, e: 0.05, Avg Reward: -161.796396675, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0305467247963\n",
      "[NOR] Episode: 45290, Length: 59, e: 0.05, Avg Reward: -152.600719246, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.15301334858\n",
      "[NOR] Episode: 45300, Length: 117, e: 0.05, Avg Reward: -123.078085175, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.55641531944\n",
      "[NOR] Episode: 45310, Length: 81, e: 0.05, Avg Reward: -148.070268176, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.28718852997\n",
      "[NOR] Episode: 45320, Length: 72, e: 0.05, Avg Reward: -144.636946284, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.71550655365\n",
      "[NOR] Episode: 45330, Length: 69, e: 0.05, Avg Reward: -77.7985989073, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.5464572906\n",
      "[NOR] Episode: 45340, Length: 95, e: 0.05, Avg Reward: -201.108937686, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.74910259247\n",
      "[NOR] Episode: 45350, Length: 71, e: 0.05, Avg Reward: -151.435087016, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.149574816227\n",
      "[NOR] Episode: 45360, Length: 70, e: 0.05, Avg Reward: -154.564795315, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 23.486787796\n",
      "[NOR] Episode: 45370, Length: 78, e: 0.05, Avg Reward: -134.209945059, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.357249617577\n",
      "[NOR] Episode: 45380, Length: 103, e: 0.05, Avg Reward: -181.391622756, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.37849235535\n",
      "[NOR] Episode: 45390, Length: 119, e: 0.05, Avg Reward: -142.665528514, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.02105617523\n",
      "[NOR] Episode: 45400, Length: 70, e: 0.05, Avg Reward: -127.588445424, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0223168730736\n",
      "[NOR] Episode: 45410, Length: 164, e: 0.05, Avg Reward: -132.169409707, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.91075992584\n",
      "[NOR] Episode: 45420, Length: 80, e: 0.05, Avg Reward: -152.083254864, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.37845659256\n",
      "[NOR] Episode: 45430, Length: 135, e: 0.05, Avg Reward: -125.537791998, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.966306567192\n",
      "[NOR] Episode: 45440, Length: 73, e: 0.05, Avg Reward: -153.504626913, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0319283008575\n",
      "[NOR] Episode: 45450, Length: 89, e: 0.05, Avg Reward: -165.756027044, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.45754098892\n",
      "[NOR] Episode: 45460, Length: 178, e: 0.05, Avg Reward: -153.415316972, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.851468920708\n",
      "[NOR] Episode: 45470, Length: 68, e: 0.05, Avg Reward: -154.043974018, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.44156217575\n",
      "[NOR] Episode: 45480, Length: 105, e: 0.05, Avg Reward: -135.865341451, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.68271398544\n",
      "[NOR] Episode: 45490, Length: 90, e: 0.05, Avg Reward: -159.857629519, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.14841556549\n",
      "[NOR] Episode: 45500, Length: 113, e: 0.05, Avg Reward: -135.543126621, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.83335399628\n",
      "[NOR] Episode: 45510, Length: 118, e: 0.05, Avg Reward: -87.4834299113, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.6515007019\n",
      "[NOR] Episode: 45520, Length: 59, e: 0.05, Avg Reward: -140.75031072, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.14541399479\n",
      "[NOR] Episode: 45530, Length: 70, e: 0.05, Avg Reward: -98.6763089576, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.10654067993\n",
      "[NOR] Episode: 45540, Length: 130, e: 0.05, Avg Reward: -124.060970977, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.89720821381\n",
      "[NOR] Episode: 45550, Length: 125, e: 0.05, Avg Reward: -134.524901272, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.71105575562\n",
      "[NOR] Episode: 45560, Length: 189, e: 0.05, Avg Reward: -140.375505164, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.63036823273\n",
      "[NOR] Episode: 45570, Length: 93, e: 0.05, Avg Reward: -104.669467383, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.05724334717\n",
      "[NOR] Episode: 45580, Length: 86, e: 0.05, Avg Reward: -119.162221152, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.40491986275\n",
      "[NOR] Episode: 45590, Length: 399, e: 0.05, Avg Reward: -87.1938160894, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.34748935699\n",
      "[NOR] Episode: 45600, Length: 67, e: 0.05, Avg Reward: -128.284915666, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.05762314796\n",
      "[NOR] Episode: 45610, Length: 82, e: 0.05, Avg Reward: -122.906306655, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.87526845932\n",
      "[NOR] Episode: 45620, Length: 140, e: 0.05, Avg Reward: -135.122997491, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.89923000336\n",
      "[NOR] Episode: 45630, Length: 59, e: 0.05, Avg Reward: -113.851448459, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.86910820007\n",
      "[NOR] Episode: 45640, Length: 90, e: 0.05, Avg Reward: -95.0495450587, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.22286987305\n",
      "[NOR] Episode: 45650, Length: 129, e: 0.05, Avg Reward: -98.0513591977, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.44606208801\n",
      "[NOR] Episode: 45660, Length: 70, e: 0.05, Avg Reward: -120.503773474, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.89515185356\n",
      "[NOR] Episode: 45670, Length: 302, e: 0.05, Avg Reward: -86.6915946285, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.49300789833\n",
      "[NOR] Episode: 45680, Length: 88, e: 0.05, Avg Reward: -150.501695418, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.2408256531\n",
      "[NOR] Episode: 45690, Length: 82, e: 0.05, Avg Reward: -67.3945186748, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.43432116508\n",
      "[NOR] Episode: 45700, Length: 198, e: 0.05, Avg Reward: -135.420681557, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.2220954895\n",
      "[NOR] Episode: 45710, Length: 121, e: 0.05, Avg Reward: -135.866694811, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.4195194244\n",
      "[NOR] Episode: 45720, Length: 84, e: 0.05, Avg Reward: -134.305453418, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.7510433197\n",
      "[NOR] Episode: 45730, Length: 73, e: 0.05, Avg Reward: -95.8629910608, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.95217990875\n",
      "[NOR] Episode: 45740, Length: 115, e: 0.05, Avg Reward: -122.857948578, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.2715702057\n",
      "[NOR] Episode: 45750, Length: 93, e: 0.05, Avg Reward: -138.204429947, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.29658508301\n",
      "[NOR] Episode: 45760, Length: 54, e: 0.05, Avg Reward: -99.5932408017, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.6068210602\n",
      "[NOR] Episode: 45770, Length: 101, e: 0.05, Avg Reward: -103.277957918, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.22577285767\n",
      "[NOR] Episode: 45780, Length: 84, e: 0.05, Avg Reward: -93.3089445578, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.568361282349\n",
      "[NOR] Episode: 45790, Length: 98, e: 0.05, Avg Reward: -102.469961832, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.43219661713\n",
      "[NOR] Episode: 45800, Length: 154, e: 0.05, Avg Reward: -97.4330537867, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.679075956345\n",
      "[NOR] Episode: 45810, Length: 192, e: 0.05, Avg Reward: -103.442644516, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.0598859787\n",
      "[NOR] Episode: 45820, Length: 68, e: 0.05, Avg Reward: -135.697287648, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.59004712105\n",
      "[NOR] Episode: 45830, Length: 84, e: 0.05, Avg Reward: -161.118766258, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.16983389854\n",
      "[NOR] Episode: 45840, Length: 65, e: 0.05, Avg Reward: -53.5418931423, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 37.29637146\n",
      "[NOR] Episode: 45850, Length: 73, e: 0.05, Avg Reward: -134.130231458, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.5079107285\n",
      "[NOR] Episode: 45860, Length: 80, e: 0.05, Avg Reward: -115.148981588, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.51344203949\n",
      "[NOR] Episode: 45870, Length: 298, e: 0.05, Avg Reward: -67.7292750181, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.91626548767\n",
      "[NOR] Episode: 45880, Length: 106, e: 0.05, Avg Reward: -141.43249239, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 28.7330436707\n",
      "[NOR] Episode: 45890, Length: 56, e: 0.05, Avg Reward: -125.738288109, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.88332605362\n",
      "[NOR] Episode: 45900, Length: 85, e: 0.05, Avg Reward: -113.256249469, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 28.3873577118\n",
      "[NOR] Episode: 45910, Length: 77, e: 0.05, Avg Reward: -180.896914967, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.96259784698\n",
      "[NOR] Episode: 45920, Length: 70, e: 0.05, Avg Reward: -126.010894918, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.82046794891\n",
      "[NOR] Episode: 45930, Length: 141, e: 0.05, Avg Reward: -118.098950401, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.3479042053\n",
      "[NOR] Episode: 45940, Length: 70, e: 0.05, Avg Reward: -144.134893589, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.2039699554\n",
      "[NOR] Episode: 45950, Length: 73, e: 0.05, Avg Reward: -165.936269279, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.89901709557\n",
      "[NOR] Episode: 45960, Length: 118, e: 0.05, Avg Reward: -112.772172512, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.380324006081\n",
      "[NOR] Episode: 45970, Length: 63, e: 0.05, Avg Reward: -126.65543999, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.44057273865\n",
      "[NOR] Episode: 45980, Length: 80, e: 0.05, Avg Reward: -154.418689674, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.43466448784\n",
      "[NOR] Episode: 45990, Length: 85, e: 0.05, Avg Reward: -133.271820554, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.8556003571\n",
      "[NOR] Episode: 46000, Length: 87, e: 0.05, Avg Reward: -135.670311432, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.32019519806\n",
      "[NOR] Episode: 46010, Length: 77, e: 0.05, Avg Reward: -117.031486444, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.224132061\n",
      "[NOR] Episode: 46020, Length: 69, e: 0.05, Avg Reward: -136.994854513, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.78670692444\n",
      "[NOR] Episode: 46030, Length: 103, e: 0.05, Avg Reward: -175.772950623, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.94165325165\n",
      "[NOR] Episode: 46040, Length: 90, e: 0.05, Avg Reward: -137.454561021, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.4873790741\n",
      "[NOR] Episode: 46050, Length: 60, e: 0.05, Avg Reward: -131.072545935, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.71746015549\n",
      "[NOR] Episode: 46060, Length: 66, e: 0.05, Avg Reward: -173.910315604, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.2656269073\n",
      "[NOR] Episode: 46070, Length: 694, e: 0.05, Avg Reward: -130.965410469, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.591772735119\n",
      "[NOR] Episode: 46080, Length: 81, e: 0.05, Avg Reward: -151.465841742, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.19072341919\n",
      "[NOR] Episode: 46090, Length: 95, e: 0.05, Avg Reward: -159.127141483, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.50032997131\n",
      "[NOR] Episode: 46100, Length: 85, e: 0.05, Avg Reward: -158.15510043, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.94447588921\n",
      "[NOR] Episode: 46110, Length: 91, e: 0.05, Avg Reward: -71.2556501084, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.79476451874\n",
      "[NOR] Episode: 46120, Length: 66, e: 0.05, Avg Reward: -150.231987042, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.95638990402\n",
      "[NOR] Episode: 46130, Length: 52, e: 0.05, Avg Reward: -180.920324833, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.444359600544\n",
      "[NOR] Episode: 46140, Length: 86, e: 0.05, Avg Reward: -162.247265758, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.93573904037\n",
      "[NOR] Episode: 46150, Length: 92, e: 0.05, Avg Reward: -109.404389053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.58506011963\n",
      "[NOR] Episode: 46160, Length: 201, e: 0.05, Avg Reward: -128.733920236, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.03462362289\n",
      "[NOR] Episode: 46170, Length: 112, e: 0.05, Avg Reward: -103.045185074, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.69536495209\n",
      "[NOR] Episode: 46180, Length: 65, e: 0.05, Avg Reward: -101.397527371, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.216606914997\n",
      "[NOR] Episode: 46190, Length: 96, e: 0.05, Avg Reward: -147.890803667, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.41700172424\n",
      "[NOR] Episode: 46200, Length: 109, e: 0.05, Avg Reward: -148.139801115, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.88858604431\n",
      "[NOR] Episode: 46210, Length: 238, e: 0.05, Avg Reward: -105.002002937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -20.931186676\n",
      "[NOR] Episode: 46220, Length: 231, e: 0.05, Avg Reward: -143.954218018, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.69147777557\n",
      "[NOR] Episode: 46230, Length: 113, e: 0.05, Avg Reward: -120.390056031, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.03543186188\n",
      "[NOR] Episode: 46240, Length: 54, e: 0.05, Avg Reward: -157.713968647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.3743972778\n",
      "[NOR] Episode: 46250, Length: 67, e: 0.05, Avg Reward: -142.7814703, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.30696392059\n",
      "[NOR] Episode: 46260, Length: 137, e: 0.05, Avg Reward: -152.607133342, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.63177919388\n",
      "[NOR] Episode: 46270, Length: 153, e: 0.05, Avg Reward: -138.012867078, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.819367706776\n",
      "[NOR] Episode: 46280, Length: 138, e: 0.05, Avg Reward: -168.418486445, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.45147848129\n",
      "[NOR] Episode: 46290, Length: 97, e: 0.05, Avg Reward: -164.795283574, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.87528800964\n",
      "[NOR] Episode: 46300, Length: 108, e: 0.05, Avg Reward: -134.263818983, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.51061344147\n",
      "[NOR] Episode: 46310, Length: 61, e: 0.05, Avg Reward: -122.511712591, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.84020233154\n",
      "[NOR] Episode: 46320, Length: 57, e: 0.05, Avg Reward: -126.70339604, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.81005334854\n",
      "[NOR] Episode: 46330, Length: 57, e: 0.05, Avg Reward: -101.889410682, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.14795541763\n",
      "[NOR] Episode: 46340, Length: 80, e: 0.05, Avg Reward: -157.083864416, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.70446181297\n",
      "[NOR] Episode: 46350, Length: 82, e: 0.05, Avg Reward: -134.809872464, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.09139347076\n",
      "[NOR] Episode: 46360, Length: 71, e: 0.05, Avg Reward: -136.665764771, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.95504999161\n",
      "[NOR] Episode: 46370, Length: 108, e: 0.05, Avg Reward: -103.5370229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.38013386726\n",
      "[NOR] Episode: 46380, Length: 82, e: 0.05, Avg Reward: -105.368168636, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.21451067924\n",
      "[NOR] Episode: 46390, Length: 156, e: 0.05, Avg Reward: -177.421383696, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.23293280602\n",
      "[NOR] Episode: 46400, Length: 127, e: 0.05, Avg Reward: -178.542198322, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.97279834747\n",
      "[NOR] Episode: 46410, Length: 132, e: 0.05, Avg Reward: -149.677025599, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 21.9478874207\n",
      "[NOR] Episode: 46420, Length: 96, e: 0.05, Avg Reward: -159.187112909, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.51228046417\n",
      "[NOR] Episode: 46430, Length: 103, e: 0.05, Avg Reward: -136.140796385, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.03260803223\n",
      "[NOR] Episode: 46440, Length: 131, e: 0.05, Avg Reward: -139.577896267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.8100810051\n",
      "[NOR] Episode: 46450, Length: 86, e: 0.05, Avg Reward: -122.748515762, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.0136141777\n",
      "[NOR] Episode: 46460, Length: 108, e: 0.05, Avg Reward: -111.336854914, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.56076169014\n",
      "[NOR] Episode: 46470, Length: 61, e: 0.05, Avg Reward: -141.675768987, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.465614080429\n",
      "[NOR] Episode: 46480, Length: 96, e: 0.05, Avg Reward: -107.257392656, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.99184417725\n",
      "[NOR] Episode: 46490, Length: 97, e: 0.05, Avg Reward: -142.198239723, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.6635684967\n",
      "[NOR] Episode: 46500, Length: 315, e: 0.05, Avg Reward: -119.117375345, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.6041507721\n",
      "[NOR] Episode: 46510, Length: 75, e: 0.05, Avg Reward: -132.518888507, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.611379265785\n",
      "[NOR] Episode: 46520, Length: 66, e: 0.05, Avg Reward: -151.494088947, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.1207971573\n",
      "[NOR] Episode: 46530, Length: 71, e: 0.05, Avg Reward: -128.692193486, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.996697664261\n",
      "[NOR] Episode: 46540, Length: 88, e: 0.05, Avg Reward: -144.209334718, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.83878421783\n",
      "[NOR] Episode: 46550, Length: 136, e: 0.05, Avg Reward: -117.965551581, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.01274633408\n",
      "[NOR] Episode: 46560, Length: 67, e: 0.05, Avg Reward: -45.3405381937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.95768642426\n",
      "[NOR] Episode: 46570, Length: 110, e: 0.05, Avg Reward: -95.3132055708, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.58585643768\n",
      "[NOR] Episode: 46580, Length: 102, e: 0.05, Avg Reward: -84.7689232324, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.70547771454\n",
      "[NOR] Episode: 46590, Length: 85, e: 0.05, Avg Reward: -139.238244839, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.9441337585\n",
      "[NOR] Episode: 46600, Length: 178, e: 0.05, Avg Reward: -126.299261102, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.48247671127\n",
      "[NOR] Episode: 46610, Length: 89, e: 0.05, Avg Reward: -128.030146915, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.56993961334\n",
      "[NOR] Episode: 46620, Length: 91, e: 0.05, Avg Reward: -119.658025134, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.18248128891\n",
      "[NOR] Episode: 46630, Length: 132, e: 0.05, Avg Reward: -147.703562429, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.11596107483\n",
      "[NOR] Episode: 46640, Length: 72, e: 0.05, Avg Reward: -144.15312744, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.34016942978\n",
      "[NOR] Episode: 46650, Length: 113, e: 0.05, Avg Reward: -145.333154638, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.49537944794\n",
      "[NOR] Episode: 46660, Length: 118, e: 0.05, Avg Reward: -152.023070068, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0758118629456\n",
      "[NOR] Episode: 46670, Length: 108, e: 0.05, Avg Reward: -196.664862246, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.8719768524\n",
      "[NOR] Episode: 46680, Length: 84, e: 0.05, Avg Reward: -95.4943648068, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.24570322037\n",
      "[NOR] Episode: 46690, Length: 86, e: 0.05, Avg Reward: -136.901569873, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -42.2004928589\n",
      "[NOR] Episode: 46700, Length: 150, e: 0.05, Avg Reward: -130.528180447, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.55867242813\n",
      "[NOR] Episode: 46710, Length: 62, e: 0.05, Avg Reward: -158.423590509, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.14905548096\n",
      "[NOR] Episode: 46720, Length: 264, e: 0.05, Avg Reward: -93.0487725058, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.61029148102\n",
      "[NOR] Episode: 46730, Length: 161, e: 0.05, Avg Reward: -104.888793582, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.35631752014\n",
      "[NOR] Episode: 46740, Length: 94, e: 0.05, Avg Reward: -123.15645545, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.79128742218\n",
      "[NOR] Episode: 46750, Length: 181, e: 0.05, Avg Reward: -174.60284509, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.4734344482\n",
      "[NOR] Episode: 46760, Length: 251, e: 0.05, Avg Reward: -142.226300757, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.49069786072\n",
      "[NOR] Episode: 46770, Length: 141, e: 0.05, Avg Reward: -163.021386857, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.6293401718\n",
      "[NOR] Episode: 46780, Length: 85, e: 0.05, Avg Reward: -146.691412894, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.7021312714\n",
      "[NOR] Episode: 46790, Length: 97, e: 0.05, Avg Reward: -122.66585111, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.7763834\n",
      "[NOR] Episode: 46800, Length: 109, e: 0.05, Avg Reward: -201.603051377, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.600639939308\n",
      "[NOR] Episode: 46810, Length: 211, e: 0.05, Avg Reward: -180.208302896, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.50309920311\n",
      "[NOR] Episode: 46820, Length: 155, e: 0.05, Avg Reward: -141.648029976, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.08199262619\n",
      "[NOR] Episode: 46830, Length: 193, e: 0.05, Avg Reward: -170.327385783, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -25.8368377686\n",
      "[NOR] Episode: 46840, Length: 79, e: 0.05, Avg Reward: -134.722330009, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.28938889503\n",
      "[NOR] Episode: 46850, Length: 103, e: 0.05, Avg Reward: -123.405013627, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.75073289871\n",
      "[NOR] Episode: 46860, Length: 84, e: 0.05, Avg Reward: -145.006588531, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.423340797424\n",
      "[NOR] Episode: 46870, Length: 86, e: 0.05, Avg Reward: -107.649952002, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.98354673386\n",
      "[NOR] Episode: 46880, Length: 96, e: 0.05, Avg Reward: -127.185511577, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.62791895866\n",
      "[NOR] Episode: 46890, Length: 85, e: 0.05, Avg Reward: -82.359086784, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.66359519958\n",
      "[NOR] Episode: 46900, Length: 103, e: 0.05, Avg Reward: -214.961862172, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.20612335205\n",
      "[NOR] Episode: 46910, Length: 175, e: 0.05, Avg Reward: -70.9045764983, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.78849983215\n",
      "[NOR] Episode: 46920, Length: 93, e: 0.05, Avg Reward: -138.594391954, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.02782952785\n",
      "[NOR] Episode: 46930, Length: 99, e: 0.05, Avg Reward: -114.775252769, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.55431461334\n",
      "[NOR] Episode: 46940, Length: 82, e: 0.05, Avg Reward: -159.425562845, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.653351426125\n",
      "[NOR] Episode: 46950, Length: 86, e: 0.05, Avg Reward: -135.641783649, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.3725662231\n",
      "[NOR] Episode: 46960, Length: 109, e: 0.05, Avg Reward: -131.026381965, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.240776658058\n",
      "[NOR] Episode: 46970, Length: 92, e: 0.05, Avg Reward: -102.087245705, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.4579086304\n",
      "[NOR] Episode: 46980, Length: 151, e: 0.05, Avg Reward: -183.471360023, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.56970214844\n",
      "[NOR] Episode: 46990, Length: 187, e: 0.05, Avg Reward: -186.361584937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.50842666626\n",
      "[NOR] Episode: 47000, Length: 101, e: 0.05, Avg Reward: -88.3654641455, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.3341293335\n",
      "[NOR] Episode: 47010, Length: 105, e: 0.05, Avg Reward: -154.777969136, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.8499815464\n",
      "[NOR] Episode: 47020, Length: 88, e: 0.05, Avg Reward: -71.7997672191, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.78329563141\n",
      "[NOR] Episode: 47030, Length: 88, e: 0.05, Avg Reward: -145.363499453, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.435714483261\n",
      "[NOR] Episode: 47040, Length: 96, e: 0.05, Avg Reward: -171.63411958, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.1543951035\n",
      "[NOR] Episode: 47050, Length: 134, e: 0.05, Avg Reward: -107.009254695, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.17098617554\n",
      "[NOR] Episode: 47060, Length: 131, e: 0.05, Avg Reward: -183.087300771, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.3796901703\n",
      "[NOR] Episode: 47070, Length: 149, e: 0.05, Avg Reward: -195.53709539, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.26727950573\n",
      "[NOR] Episode: 47080, Length: 183, e: 0.05, Avg Reward: -254.235375623, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.193604946136\n",
      "[NOR] Episode: 47090, Length: 562, e: 0.05, Avg Reward: -199.322862506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.1127243042\n",
      "[NOR] Episode: 47100, Length: 108, e: 0.05, Avg Reward: -168.910111596, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.63390564919\n",
      "[NOR] Episode: 47110, Length: 277, e: 0.05, Avg Reward: -226.143766918, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.4412317276\n",
      "[NOR] Episode: 47120, Length: 127, e: 0.05, Avg Reward: -205.78964299, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.2325468063\n",
      "[NOR] Episode: 47130, Length: 139, e: 0.05, Avg Reward: -194.104575884, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.78934025764\n",
      "[NOR] Episode: 47140, Length: 110, e: 0.05, Avg Reward: -239.024502611, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.25866746902\n",
      "[NOR] Episode: 47150, Length: 108, e: 0.05, Avg Reward: -179.838699326, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.4351892471\n",
      "[NOR] Episode: 47160, Length: 182, e: 0.05, Avg Reward: -182.892090786, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.0554060936\n",
      "[NOR] Episode: 47170, Length: 110, e: 0.05, Avg Reward: -115.901111891, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.29398679733\n",
      "[NOR] Episode: 47180, Length: 94, e: 0.05, Avg Reward: -118.196021331, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.878872036934\n",
      "[NOR] Episode: 47190, Length: 178, e: 0.05, Avg Reward: -150.936953066, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.0715885162\n",
      "[NOR] Episode: 47200, Length: 89, e: 0.05, Avg Reward: -93.6042595065, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.08817768097\n",
      "[NOR] Episode: 47210, Length: 129, e: 0.05, Avg Reward: -64.3126745974, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.70411086082\n",
      "[NOR] Episode: 47220, Length: 120, e: 0.05, Avg Reward: -139.783885187, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.43021583557\n",
      "[NOR] Episode: 47230, Length: 86, e: 0.05, Avg Reward: -112.726653502, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.657421469688\n",
      "[NOR] Episode: 47240, Length: 74, e: 0.05, Avg Reward: -144.9144732, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.7586259842\n",
      "[NOR] Episode: 47250, Length: 89, e: 0.05, Avg Reward: -103.708594883, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.70836031437\n",
      "[NOR] Episode: 47260, Length: 136, e: 0.05, Avg Reward: -113.085896209, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.27904009819\n",
      "[NOR] Episode: 47270, Length: 175, e: 0.05, Avg Reward: -158.015312526, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.72995948792\n",
      "[NOR] Episode: 47280, Length: 102, e: 0.05, Avg Reward: -127.499582602, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.04346942902\n",
      "[NOR] Episode: 47290, Length: 361, e: 0.05, Avg Reward: 7.07289578844, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 189.906600952\n",
      "[NOR] Episode: 47300, Length: 270, e: 0.05, Avg Reward: -119.22653188, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.61641192436\n",
      "[NOR] Episode: 47310, Length: 87, e: 0.05, Avg Reward: -86.9430742685, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.27917671204\n",
      "[NOR] Episode: 47320, Length: 109, e: 0.05, Avg Reward: -69.4845104984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.2091608047\n",
      "[NOR] Episode: 47330, Length: 126, e: 0.05, Avg Reward: -150.020070432, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.513366937637\n",
      "[NOR] Episode: 47340, Length: 90, e: 0.05, Avg Reward: -115.920613066, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.762185812\n",
      "[NOR] Episode: 47350, Length: 81, e: 0.05, Avg Reward: -183.052759226, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.07000589371\n",
      "[NOR] Episode: 47360, Length: 109, e: 0.05, Avg Reward: -128.96536983, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.09378147125\n",
      "[NOR] Episode: 47370, Length: 104, e: 0.05, Avg Reward: -72.2001550613, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.41332101822\n",
      "[NOR] Episode: 47380, Length: 264, e: 0.05, Avg Reward: -96.8097696283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.353162646294\n",
      "[NOR] Episode: 47390, Length: 115, e: 0.05, Avg Reward: -133.159688268, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.37935066223\n",
      "[NOR] Episode: 47400, Length: 233, e: 0.05, Avg Reward: -42.4515172424, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.01801633835\n",
      "[NOR] Episode: 47410, Length: 137, e: 0.05, Avg Reward: -109.057088291, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.93512582779\n",
      "[NOR] Episode: 47420, Length: 120, e: 0.05, Avg Reward: -92.0339907178, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.54452800751\n",
      "[NOR] Episode: 47430, Length: 101, e: 0.05, Avg Reward: -62.4878366609, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.38194942474\n",
      "[NOR] Episode: 47440, Length: 269, e: 0.05, Avg Reward: -119.07882584, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.49990701675\n",
      "[NOR] Episode: 47450, Length: 191, e: 0.05, Avg Reward: -134.100372996, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.88947463036\n",
      "[NOR] Episode: 47460, Length: 161, e: 0.05, Avg Reward: -120.074091713, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.40559959412\n",
      "[NOR] Episode: 47470, Length: 106, e: 0.05, Avg Reward: -112.337954806, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.82635259628\n",
      "[NOR] Episode: 47480, Length: 89, e: 0.05, Avg Reward: -95.0733830166, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.60332918167\n",
      "[NOR] Episode: 47490, Length: 1578, e: 0.05, Avg Reward: -68.7393788474, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.563220262527\n",
      "[NOR] Episode: 47500, Length: 150, e: 0.05, Avg Reward: -79.3160744419, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.25946903229\n",
      "[NOR] Episode: 47510, Length: 88, e: 0.05, Avg Reward: -40.396238766, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.49706554413\n",
      "[NOR] Episode: 47520, Length: 77, e: 0.05, Avg Reward: -88.0574446614, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -47.072353363\n",
      "[NOR] Episode: 47530, Length: 133, e: 0.05, Avg Reward: -73.9000565363, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.17444479465\n",
      "[NOR] Episode: 47540, Length: 78, e: 0.05, Avg Reward: -110.472498271, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.32817006111\n",
      "[NOR] Episode: 47550, Length: 139, e: 0.05, Avg Reward: -68.6676631918, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.61925649643\n",
      "[NOR] Episode: 47560, Length: 84, e: 0.05, Avg Reward: -159.720622336, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.9241771698\n",
      "[NOR] Episode: 47570, Length: 73, e: 0.05, Avg Reward: -78.8677826473, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.83714103699\n",
      "[NOR] Episode: 47580, Length: 261, e: 0.05, Avg Reward: -121.921874014, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.2449464798\n",
      "[NOR] Episode: 47590, Length: 219, e: 0.05, Avg Reward: 19.9619802558, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.62610244751\n",
      "[NOR] Episode: 47600, Length: 98, e: 0.05, Avg Reward: -9.12727317506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.00543391704559\n",
      "[NOR] Episode: 47610, Length: 289, e: 0.05, Avg Reward: -84.9601049051, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.795466184616\n",
      "[NOR] Episode: 47620, Length: 69, e: 0.05, Avg Reward: -66.36394229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.57893741131\n",
      "[NOR] Episode: 47630, Length: 182, e: 0.05, Avg Reward: -93.6562469108, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.06972503662\n",
      "[NOR] Episode: 47640, Length: 92, e: 0.05, Avg Reward: -104.734941506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.29037618637\n",
      "[NOR] Episode: 47650, Length: 186, e: 0.05, Avg Reward: -165.665288601, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.30477714539\n",
      "[NOR] Episode: 47660, Length: 140, e: 0.05, Avg Reward: -111.048227295, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.47929239273\n",
      "[NOR] Episode: 47670, Length: 100, e: 0.05, Avg Reward: 24.6678079739, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.597594380379\n",
      "[NOR] Episode: 47680, Length: 78, e: 0.05, Avg Reward: -134.293406832, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.513927996159\n",
      "[NOR] Episode: 47690, Length: 104, e: 0.05, Avg Reward: -143.021785677, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.08375406265\n",
      "[NOR] Episode: 47700, Length: 154, e: 0.05, Avg Reward: -149.002775034, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.462542533875\n",
      "[NOR] Episode: 47710, Length: 184, e: 0.05, Avg Reward: -121.385894927, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.57163858414\n",
      "[NOR] Episode: 47720, Length: 86, e: 0.05, Avg Reward: -164.71016584, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.2149066925\n",
      "[NOR] Episode: 47730, Length: 124, e: 0.05, Avg Reward: -176.724856066, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.1924667358\n",
      "[NOR] Episode: 47740, Length: 83, e: 0.05, Avg Reward: -190.38923796, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.32523870468\n",
      "[NOR] Episode: 47750, Length: 108, e: 0.05, Avg Reward: -103.448223815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.96086359024\n",
      "[NOR] Episode: 47760, Length: 143, e: 0.05, Avg Reward: -103.257822104, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.39797091484\n",
      "[NOR] Episode: 47770, Length: 134, e: 0.05, Avg Reward: -103.221346699, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.25422310829\n",
      "[NOR] Episode: 47780, Length: 79, e: 0.05, Avg Reward: -169.067563538, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.64896440506\n",
      "[NOR] Episode: 47790, Length: 201, e: 0.05, Avg Reward: -164.207874552, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.666666507721\n",
      "[NOR] Episode: 47800, Length: 117, e: 0.05, Avg Reward: -145.4972161, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.16452980042\n",
      "[NOR] Episode: 47810, Length: 120, e: 0.05, Avg Reward: -162.397181103, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.91241788864\n",
      "[NOR] Episode: 47820, Length: 187, e: 0.05, Avg Reward: -204.287173645, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.3175773621\n",
      "[NOR] Episode: 47830, Length: 127, e: 0.05, Avg Reward: -214.814103269, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.5446815491\n",
      "[NOR] Episode: 47840, Length: 211, e: 0.05, Avg Reward: -169.268656891, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.1256737709\n",
      "[NOR] Episode: 47850, Length: 169, e: 0.05, Avg Reward: -217.111208212, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.1421687603\n",
      "[NOR] Episode: 47860, Length: 171, e: 0.05, Avg Reward: -174.836652018, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.9943614006\n",
      "[NOR] Episode: 47870, Length: 116, e: 0.05, Avg Reward: -155.880679692, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.20535254478\n",
      "[NOR] Episode: 47880, Length: 78, e: 0.05, Avg Reward: -151.29437405, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.77600049973\n",
      "[NOR] Episode: 47890, Length: 134, e: 0.05, Avg Reward: -184.257963021, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.1643686295\n",
      "[NOR] Episode: 47900, Length: 75, e: 0.05, Avg Reward: -182.277742391, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.9104449749\n",
      "[NOR] Episode: 47910, Length: 323, e: 0.05, Avg Reward: -118.10496197, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.59911584854\n",
      "[NOR] Episode: 47920, Length: 111, e: 0.05, Avg Reward: -132.02556859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.85577917099\n",
      "[NOR] Episode: 47930, Length: 223, e: 0.05, Avg Reward: -94.9674390909, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.46374225616\n",
      "[NOR] Episode: 47940, Length: 86, e: 0.05, Avg Reward: -187.796013755, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.680287957191\n",
      "[NOR] Episode: 47950, Length: 128, e: 0.05, Avg Reward: -97.0615657615, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.89719581604\n",
      "[NOR] Episode: 47960, Length: 239, e: 0.05, Avg Reward: -148.965157033, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.35880804062\n",
      "[NOR] Episode: 47970, Length: 141, e: 0.05, Avg Reward: -132.349725353, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.63552117348\n",
      "[NOR] Episode: 47980, Length: 142, e: 0.05, Avg Reward: -143.878579944, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.74032449722\n",
      "[NOR] Episode: 47990, Length: 91, e: 0.05, Avg Reward: -173.859253746, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.10339546204\n",
      "[NOR] Episode: 48000, Length: 79, e: 0.05, Avg Reward: -191.338826524, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.31005764008\n",
      "[NOR] Episode: 48010, Length: 166, e: 0.05, Avg Reward: -177.712219215, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.0757266283\n",
      "[NOR] Episode: 48020, Length: 128, e: 0.05, Avg Reward: -128.309523506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.10442733765\n",
      "[NOR] Episode: 48030, Length: 194, e: 0.05, Avg Reward: -153.508204521, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.32713544369\n",
      "[NOR] Episode: 48040, Length: 153, e: 0.05, Avg Reward: -154.345929678, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.03883886337\n",
      "[NOR] Episode: 48050, Length: 114, e: 0.05, Avg Reward: -190.258809451, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.0766487122\n",
      "[NOR] Episode: 48060, Length: 156, e: 0.05, Avg Reward: -161.075345101, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.86005449295\n",
      "[NOR] Episode: 48070, Length: 174, e: 0.05, Avg Reward: -163.128086835, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.54203748703\n",
      "[NOR] Episode: 48080, Length: 96, e: 0.05, Avg Reward: -123.729911761, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.58177232742\n",
      "[NOR] Episode: 48090, Length: 130, e: 0.05, Avg Reward: -212.535217788, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.30233764648\n",
      "[NOR] Episode: 48100, Length: 217, e: 0.05, Avg Reward: -157.316473368, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.81440329552\n",
      "[NOR] Episode: 48110, Length: 102, e: 0.05, Avg Reward: -110.335242872, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.14835929871\n",
      "[NOR] Episode: 48120, Length: 122, e: 0.05, Avg Reward: -174.958589133, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.4496614933\n",
      "[NOR] Episode: 48130, Length: 115, e: 0.05, Avg Reward: -133.480527329, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.99558162689\n",
      "[NOR] Episode: 48140, Length: 189, e: 0.05, Avg Reward: -137.617394452, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.94273996353\n",
      "[NOR] Episode: 48150, Length: 103, e: 0.05, Avg Reward: -120.189975462, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.14425754547\n",
      "[NOR] Episode: 48160, Length: 64, e: 0.05, Avg Reward: -165.237921023, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.142906189\n",
      "[NOR] Episode: 48170, Length: 118, e: 0.05, Avg Reward: -124.266760385, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.23766964674\n",
      "[NOR] Episode: 48180, Length: 77, e: 0.05, Avg Reward: -138.099506993, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.79779434204\n",
      "[NOR] Episode: 48190, Length: 116, e: 0.05, Avg Reward: -158.785967285, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.67373371124\n",
      "[NOR] Episode: 48200, Length: 119, e: 0.05, Avg Reward: -129.870124171, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.29264974594\n",
      "[NOR] Episode: 48210, Length: 119, e: 0.05, Avg Reward: -153.443027071, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.82045888901\n",
      "[NOR] Episode: 48220, Length: 86, e: 0.05, Avg Reward: -124.664147482, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.74604201317\n",
      "[NOR] Episode: 48230, Length: 228, e: 0.05, Avg Reward: -121.399854042, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.1909246445\n",
      "[NOR] Episode: 48240, Length: 71, e: 0.05, Avg Reward: -158.484387657, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.11373329163\n",
      "[NOR] Episode: 48250, Length: 97, e: 0.05, Avg Reward: -97.3586065013, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.54627990723\n",
      "[NOR] Episode: 48260, Length: 106, e: 0.05, Avg Reward: -78.2161447889, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.835407674313\n",
      "[NOR] Episode: 48270, Length: 99, e: 0.05, Avg Reward: -43.213613903, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.25539422035\n",
      "[NOR] Episode: 48280, Length: 113, e: 0.05, Avg Reward: -175.348225306, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.02687335014\n",
      "[NOR] Episode: 48290, Length: 137, e: 0.05, Avg Reward: -142.030999929, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.1849937439\n",
      "[NOR] Episode: 48300, Length: 126, e: 0.05, Avg Reward: -124.352168917, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.09358978271\n",
      "[NOR] Episode: 48310, Length: 138, e: 0.05, Avg Reward: -119.220344422, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.63956809044\n",
      "[NOR] Episode: 48320, Length: 109, e: 0.05, Avg Reward: -125.852413022, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.62370288372\n",
      "[NOR] Episode: 48330, Length: 89, e: 0.05, Avg Reward: -150.91511465, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.897784113884\n",
      "[NOR] Episode: 48340, Length: 214, e: 0.05, Avg Reward: -100.918528277, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.06480932236\n",
      "[NOR] Episode: 48350, Length: 160, e: 0.05, Avg Reward: -116.878616277, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.12315273285\n",
      "[NOR] Episode: 48360, Length: 177, e: 0.05, Avg Reward: -113.787025226, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.78839921951\n",
      "[NOR] Episode: 48370, Length: 207, e: 0.05, Avg Reward: -97.1614315074, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.21673583984\n",
      "[NOR] Episode: 48380, Length: 180, e: 0.05, Avg Reward: -153.582316975, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.482890605927\n",
      "[NOR] Episode: 48390, Length: 69, e: 0.05, Avg Reward: -127.867607447, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.0272808075\n",
      "[NOR] Episode: 48400, Length: 204, e: 0.05, Avg Reward: -135.39912883, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.3267519474\n",
      "[NOR] Episode: 48410, Length: 177, e: 0.05, Avg Reward: -153.04328573, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.7547369003\n",
      "[NOR] Episode: 48420, Length: 220, e: 0.05, Avg Reward: -127.559989652, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.12987089157\n",
      "[NOR] Episode: 48430, Length: 126, e: 0.05, Avg Reward: -145.134734457, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.710565209389\n",
      "[NOR] Episode: 48440, Length: 252, e: 0.05, Avg Reward: -143.2933942, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.95691013336\n",
      "[NOR] Episode: 48450, Length: 78, e: 0.05, Avg Reward: -134.723295676, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.19430851936\n",
      "[NOR] Episode: 48460, Length: 85, e: 0.05, Avg Reward: -115.092180054, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.16368770599\n",
      "[NOR] Episode: 48470, Length: 88, e: 0.05, Avg Reward: -174.755083455, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.0040426254\n",
      "[NOR] Episode: 48480, Length: 127, e: 0.05, Avg Reward: -148.127868035, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.64255070686\n",
      "[NOR] Episode: 48490, Length: 88, e: 0.05, Avg Reward: -86.8819163482, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.242486417294\n",
      "[NOR] Episode: 48500, Length: 338, e: 0.05, Avg Reward: -133.557873673, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.272368907928\n",
      "[NOR] Episode: 48510, Length: 157, e: 0.05, Avg Reward: -118.929987132, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.63064575195\n",
      "[NOR] Episode: 48520, Length: 135, e: 0.05, Avg Reward: -222.330419309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.675162374973\n",
      "[NOR] Episode: 48530, Length: 97, e: 0.05, Avg Reward: -163.639702107, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 19.6564712524\n",
      "[NOR] Episode: 48540, Length: 285, e: 0.05, Avg Reward: -101.992647413, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.07970452309\n",
      "[NOR] Episode: 48550, Length: 117, e: 0.05, Avg Reward: -207.013764703, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.379894256592\n",
      "[NOR] Episode: 48560, Length: 90, e: 0.05, Avg Reward: -245.217731102, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.26614522934\n",
      "[NOR] Episode: 48570, Length: 79, e: 0.05, Avg Reward: -124.559779155, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.4545373917\n",
      "[NOR] Episode: 48580, Length: 185, e: 0.05, Avg Reward: -156.7018882, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.82468032837\n",
      "[NOR] Episode: 48590, Length: 212, e: 0.05, Avg Reward: -155.489902217, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.854092121124\n",
      "[NOR] Episode: 48600, Length: 103, e: 0.05, Avg Reward: -184.362225301, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.56432199478\n",
      "[NOR] Episode: 48610, Length: 176, e: 0.05, Avg Reward: -159.018835749, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.4438247681\n",
      "[NOR] Episode: 48620, Length: 138, e: 0.05, Avg Reward: -152.820288954, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.930352211\n",
      "[NOR] Episode: 48630, Length: 137, e: 0.05, Avg Reward: -127.16249854, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.40070641041\n",
      "[NOR] Episode: 48640, Length: 130, e: 0.05, Avg Reward: -181.927668116, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.14164543152\n",
      "[NOR] Episode: 48650, Length: 160, e: 0.05, Avg Reward: -233.946523919, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.91160345078\n",
      "[NOR] Episode: 48660, Length: 232, e: 0.05, Avg Reward: -176.119611868, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.3326946497\n",
      "[NOR] Episode: 48670, Length: 91, e: 0.05, Avg Reward: -201.818960093, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0360666513443\n",
      "[NOR] Episode: 48680, Length: 240, e: 0.05, Avg Reward: -170.214518267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.50235748291\n",
      "[NOR] Episode: 48690, Length: 172, e: 0.05, Avg Reward: -197.088085893, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.29268264771\n",
      "[NOR] Episode: 48700, Length: 106, e: 0.05, Avg Reward: -171.52165048, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.17457127571\n",
      "[NOR] Episode: 48710, Length: 235, e: 0.05, Avg Reward: -169.850422911, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.53393149376\n",
      "[NOR] Episode: 48720, Length: 185, e: 0.05, Avg Reward: -175.907083637, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.29570102692\n",
      "[NOR] Episode: 48730, Length: 262, e: 0.05, Avg Reward: -134.781323652, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.83033943176\n",
      "[NOR] Episode: 48740, Length: 438, e: 0.05, Avg Reward: -176.896063518, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.60572910309\n",
      "[NOR] Episode: 48750, Length: 209, e: 0.05, Avg Reward: -198.69620372, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.47319459915\n",
      "[NOR] Episode: 48760, Length: 211, e: 0.05, Avg Reward: -182.70969773, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.529927968979\n",
      "[NOR] Episode: 48770, Length: 214, e: 0.05, Avg Reward: -132.761412235, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.246185779572\n",
      "[NOR] Episode: 48780, Length: 241, e: 0.05, Avg Reward: -136.099367221, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.00640869141\n",
      "[NOR] Episode: 48790, Length: 83, e: 0.05, Avg Reward: -114.489268305, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.140561103821\n",
      "[NOR] Episode: 48800, Length: 403, e: 0.05, Avg Reward: -135.200312387, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.71983242035\n",
      "[NOR] Episode: 48810, Length: 78, e: 0.05, Avg Reward: -240.476403253, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.76962995529\n",
      "[NOR] Episode: 48820, Length: 88, e: 0.05, Avg Reward: -152.152438092, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.20825481415\n",
      "[NOR] Episode: 48830, Length: 80, e: 0.05, Avg Reward: -161.400211469, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.25792622566\n",
      "[NOR] Episode: 48840, Length: 214, e: 0.05, Avg Reward: -158.061165488, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.97391116619\n",
      "[NOR] Episode: 48850, Length: 112, e: 0.05, Avg Reward: -181.098216512, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.6342728138\n",
      "[NOR] Episode: 48860, Length: 313, e: 0.05, Avg Reward: -155.874230211, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.54138183594\n",
      "[NOR] Episode: 48870, Length: 167, e: 0.05, Avg Reward: -211.593292398, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.967708170414\n",
      "[NOR] Episode: 48880, Length: 167, e: 0.05, Avg Reward: -125.957407729, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.39400815964\n",
      "[NOR] Episode: 48890, Length: 246, e: 0.05, Avg Reward: -109.459323351, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.93550729752\n",
      "[NOR] Episode: 48900, Length: 201, e: 0.05, Avg Reward: -124.531036464, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.732055723667\n",
      "[NOR] Episode: 48910, Length: 340, e: 0.05, Avg Reward: -101.851293543, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.26255655289\n",
      "[NOR] Episode: 48920, Length: 197, e: 0.05, Avg Reward: -76.168627871, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.27501678467\n",
      "[NOR] Episode: 48930, Length: 120, e: 0.05, Avg Reward: -85.1019158337, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.48548197746\n",
      "[NOR] Episode: 48940, Length: 72, e: 0.05, Avg Reward: -62.567950072, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.94869852066\n",
      "[NOR] Episode: 48950, Length: 79, e: 0.05, Avg Reward: -135.059084789, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.26615476608\n",
      "[NOR] Episode: 48960, Length: 304, e: 0.05, Avg Reward: -89.3937297176, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.6657142639\n",
      "[NOR] Episode: 48970, Length: 100, e: 0.05, Avg Reward: -100.911145482, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.61776638031\n",
      "[NOR] Episode: 48980, Length: 66, e: 0.05, Avg Reward: -114.517883142, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.45489621162\n",
      "[NOR] Episode: 48990, Length: 90, e: 0.05, Avg Reward: -129.551429561, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.08150434494\n",
      "[NOR] Episode: 49000, Length: 95, e: 0.05, Avg Reward: -108.130470708, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.997570633888\n",
      "[NOR] Episode: 49010, Length: 248, e: 0.05, Avg Reward: -86.991139859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.89005756378\n",
      "[NOR] Episode: 49020, Length: 75, e: 0.05, Avg Reward: -64.747358168, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.45580673218\n",
      "[NOR] Episode: 49030, Length: 76, e: 0.05, Avg Reward: -143.045453265, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.01422417164\n",
      "[NOR] Episode: 49040, Length: 70, e: 0.05, Avg Reward: -124.632707548, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.43593978882\n",
      "[NOR] Episode: 49050, Length: 124, e: 0.05, Avg Reward: -124.053404841, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.85384631157\n",
      "[NOR] Episode: 49060, Length: 230, e: 0.05, Avg Reward: -100.405287802, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.9884595871\n",
      "[NOR] Episode: 49070, Length: 138, e: 0.05, Avg Reward: -108.605477604, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.68078613281\n",
      "[NOR] Episode: 49080, Length: 98, e: 0.05, Avg Reward: -161.610482536, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.72183609009\n",
      "[NOR] Episode: 49090, Length: 341, e: 0.05, Avg Reward: -60.2224421476, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.6399765015\n",
      "[NOR] Episode: 49100, Length: 87, e: 0.05, Avg Reward: -68.2166829227, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.13809633255\n",
      "[NOR] Episode: 49110, Length: 344, e: 0.05, Avg Reward: -49.3170305749, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.184130191803\n",
      "[NOR] Episode: 49120, Length: 299, e: 0.05, Avg Reward: -144.781997001, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.58227705956\n",
      "[NOR] Episode: 49130, Length: 115, e: 0.05, Avg Reward: -87.9480800003, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.09597873688\n",
      "[NOR] Episode: 49140, Length: 137, e: 0.05, Avg Reward: -107.560317852, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.12168765068\n",
      "[NOR] Episode: 49150, Length: 81, e: 0.05, Avg Reward: -89.8234492533, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.5403752327\n",
      "[NOR] Episode: 49160, Length: 116, e: 0.05, Avg Reward: -60.7810002511, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.1223287582\n",
      "[NOR] Episode: 49170, Length: 177, e: 0.05, Avg Reward: -146.201572309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.4910917282\n",
      "[NOR] Episode: 49180, Length: 100, e: 0.05, Avg Reward: -101.954502056, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.09918737411\n",
      "[NOR] Episode: 49190, Length: 147, e: 0.05, Avg Reward: -44.43345284, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.6701822281\n",
      "[NOR] Episode: 49200, Length: 131, e: 0.05, Avg Reward: -99.1879559365, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.84998321533\n",
      "[NOR] Episode: 49210, Length: 77, e: 0.05, Avg Reward: -47.0039482915, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.57002472878\n",
      "[NOR] Episode: 49220, Length: 86, e: 0.05, Avg Reward: -77.6907467312, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.5966472626\n",
      "[NOR] Episode: 49230, Length: 124, e: 0.05, Avg Reward: -13.7289306859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.22690439224\n",
      "[NOR] Episode: 49240, Length: 82, e: 0.05, Avg Reward: -143.580078815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.79137372971\n",
      "[NOR] Episode: 49250, Length: 104, e: 0.05, Avg Reward: -95.8383779628, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.45703220367\n",
      "[NOR] Episode: 49260, Length: 79, e: 0.05, Avg Reward: -102.451011963, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.100219964981\n",
      "[NOR] Episode: 49270, Length: 104, e: 0.05, Avg Reward: -109.356559546, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.4510614872\n",
      "[NOR] Episode: 49280, Length: 70, e: 0.05, Avg Reward: -140.825746592, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.83658409119\n",
      "[NOR] Episode: 49290, Length: 66, e: 0.05, Avg Reward: -121.535046351, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.01419067383\n",
      "[NOR] Episode: 49300, Length: 114, e: 0.05, Avg Reward: -148.717627095, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.55461621284\n",
      "[NOR] Episode: 49310, Length: 63, e: 0.05, Avg Reward: -161.299185092, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.7897148132\n",
      "[NOR] Episode: 49320, Length: 75, e: 0.05, Avg Reward: -128.59445602, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 109.722221375\n",
      "[NOR] Episode: 49330, Length: 103, e: 0.05, Avg Reward: -142.284887114, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0289198160172\n",
      "[NOR] Episode: 49340, Length: 86, e: 0.05, Avg Reward: -126.005513691, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.792797446251\n",
      "[NOR] Episode: 49350, Length: 85, e: 0.05, Avg Reward: -133.654022129, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.22828722\n",
      "[NOR] Episode: 49360, Length: 69, e: 0.05, Avg Reward: -113.489768521, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.49623465538\n",
      "[NOR] Episode: 49370, Length: 73, e: 0.05, Avg Reward: -154.383179728, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.99424338341\n",
      "[NOR] Episode: 49380, Length: 81, e: 0.05, Avg Reward: -167.117437424, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.9567184448\n",
      "[NOR] Episode: 49390, Length: 78, e: 0.05, Avg Reward: -120.800888356, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.95163989067\n",
      "[NOR] Episode: 49400, Length: 195, e: 0.05, Avg Reward: -149.962297935, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.59539890289\n",
      "[NOR] Episode: 49410, Length: 74, e: 0.05, Avg Reward: -112.94444517, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.893375277519\n",
      "[NOR] Episode: 49420, Length: 113, e: 0.05, Avg Reward: -122.012346858, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.19814252853\n",
      "[NOR] Episode: 49430, Length: 69, e: 0.05, Avg Reward: -101.945815764, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0237529277802\n",
      "[NOR] Episode: 49440, Length: 72, e: 0.05, Avg Reward: -130.899252712, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.836373806\n",
      "[NOR] Episode: 49450, Length: 97, e: 0.05, Avg Reward: -69.8794888201, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -22.3426818848\n",
      "[NOR] Episode: 49460, Length: 115, e: 0.05, Avg Reward: -131.592591001, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.298299789429\n",
      "[NOR] Episode: 49470, Length: 83, e: 0.05, Avg Reward: -123.83081835, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.64029312134\n",
      "[NOR] Episode: 49480, Length: 98, e: 0.05, Avg Reward: -116.912939506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.00423431396\n",
      "[NOR] Episode: 49490, Length: 116, e: 0.05, Avg Reward: -109.062933767, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.70848703384\n",
      "[NOR] Episode: 49500, Length: 92, e: 0.05, Avg Reward: -169.019946021, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.31881809235\n",
      "[NOR] Episode: 49510, Length: 98, e: 0.05, Avg Reward: -148.58310234, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.545837163925\n",
      "[NOR] Episode: 49520, Length: 92, e: 0.05, Avg Reward: -116.360044908, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.73038935661\n",
      "[NOR] Episode: 49530, Length: 126, e: 0.05, Avg Reward: -64.9333206231, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.472624063492\n",
      "[NOR] Episode: 49540, Length: 88, e: 0.05, Avg Reward: -90.0985866597, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0234095305204\n",
      "[NOR] Episode: 49550, Length: 63, e: 0.05, Avg Reward: -118.393929977, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.67784976959\n",
      "[NOR] Episode: 49560, Length: 299, e: 0.05, Avg Reward: -112.311791236, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.71737766266\n",
      "[NOR] Episode: 49570, Length: 86, e: 0.05, Avg Reward: -126.949399552, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.99778366089\n",
      "[NOR] Episode: 49580, Length: 111, e: 0.05, Avg Reward: -86.0516706752, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.01334095\n",
      "[NOR] Episode: 49590, Length: 112, e: 0.05, Avg Reward: -79.0990660262, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.824527740479\n",
      "[NOR] Episode: 49600, Length: 147, e: 0.05, Avg Reward: -125.959597094, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.46602249146\n",
      "[NOR] Episode: 49610, Length: 92, e: 0.05, Avg Reward: -90.1439207616, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.16582334042\n",
      "[NOR] Episode: 49620, Length: 93, e: 0.05, Avg Reward: -125.175951025, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.506221711636\n",
      "[NOR] Episode: 49630, Length: 105, e: 0.05, Avg Reward: -104.239272036, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.2466392517\n",
      "[NOR] Episode: 49640, Length: 84, e: 0.05, Avg Reward: -168.958139628, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.4903087616\n",
      "[NOR] Episode: 49650, Length: 101, e: 0.05, Avg Reward: -188.573496371, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.00457787513733\n",
      "[NOR] Episode: 49660, Length: 78, e: 0.05, Avg Reward: -149.347265217, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.34975910187\n",
      "[NOR] Episode: 49670, Length: 112, e: 0.05, Avg Reward: -167.126995333, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.95197725296\n",
      "[NOR] Episode: 49680, Length: 97, e: 0.05, Avg Reward: -135.930670877, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.33467617631\n",
      "[NOR] Episode: 49690, Length: 78, e: 0.05, Avg Reward: -172.227466227, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.97644591331\n",
      "[NOR] Episode: 49700, Length: 83, e: 0.05, Avg Reward: -150.76015467, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.21042585373\n",
      "[NOR] Episode: 49710, Length: 79, e: 0.05, Avg Reward: -101.429592805, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.06213665009\n",
      "[NOR] Episode: 49720, Length: 118, e: 0.05, Avg Reward: -123.007738964, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.30114269257\n",
      "[NOR] Episode: 49730, Length: 108, e: 0.05, Avg Reward: -127.249519484, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.10428237915\n",
      "[NOR] Episode: 49740, Length: 107, e: 0.05, Avg Reward: -115.408452313, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.15381479263\n",
      "[NOR] Episode: 49750, Length: 74, e: 0.05, Avg Reward: -151.396666441, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.10001778603\n",
      "[NOR] Episode: 49760, Length: 84, e: 0.05, Avg Reward: -102.343456429, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.8549592495\n",
      "[NOR] Episode: 49770, Length: 95, e: 0.05, Avg Reward: -142.403366294, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.70882976055\n",
      "[NOR] Episode: 49780, Length: 123, e: 0.05, Avg Reward: -63.486896513, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.97071027756\n",
      "[NOR] Episode: 49790, Length: 317, e: 0.05, Avg Reward: -78.3347887249, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.3410415649\n",
      "[NOR] Episode: 49800, Length: 105, e: 0.05, Avg Reward: -108.150031056, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.55289411545\n",
      "[NOR] Episode: 49810, Length: 280, e: 0.05, Avg Reward: -19.2633608275, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.98862791061\n",
      "[NOR] Episode: 49820, Length: 108, e: 0.05, Avg Reward: -133.012421138, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.50400257111\n",
      "[NOR] Episode: 49830, Length: 278, e: 0.05, Avg Reward: -86.6268835591, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.64860010147\n",
      "[NOR] Episode: 49840, Length: 73, e: 0.05, Avg Reward: -111.832256614, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.96939229965\n",
      "[NOR] Episode: 49850, Length: 97, e: 0.05, Avg Reward: -71.8592155793, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.05357933044\n",
      "[NOR] Episode: 49860, Length: 76, e: 0.05, Avg Reward: -81.5253096833, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.49127531052\n",
      "[NOR] Episode: 49870, Length: 63, e: 0.05, Avg Reward: -106.23274624, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.56912565231\n",
      "[NOR] Episode: 49880, Length: 87, e: 0.05, Avg Reward: -130.006070514, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.51181793213\n",
      "[NOR] Episode: 49890, Length: 81, e: 0.05, Avg Reward: -105.045172877, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.32739019394\n",
      "[NOR] Episode: 49900, Length: 90, e: 0.05, Avg Reward: -124.159985796, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.67017650604\n",
      "[NOR] Episode: 49910, Length: 71, e: 0.05, Avg Reward: -169.972414761, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.4122262001\n",
      "[NOR] Episode: 49920, Length: 95, e: 0.05, Avg Reward: -146.357540998, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.5365715027\n",
      "[NOR] Episode: 49930, Length: 100, e: 0.05, Avg Reward: -126.324441597, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.85106015205\n",
      "[NOR] Episode: 49940, Length: 92, e: 0.05, Avg Reward: -77.653520513, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.97806406021\n",
      "[NOR] Episode: 49950, Length: 75, e: 0.05, Avg Reward: -115.881167417, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.513860046864\n",
      "[NOR] Episode: 49960, Length: 74, e: 0.05, Avg Reward: -114.50655795, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.2343196869\n",
      "[NOR] Episode: 49970, Length: 73, e: 0.05, Avg Reward: -121.343498169, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.55293941498\n",
      "[NOR] Episode: 49980, Length: 67, e: 0.05, Avg Reward: -97.6613061251, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.99320173264\n",
      "[NOR] Episode: 49990, Length: 65, e: 0.05, Avg Reward: -123.246244032, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.619214713573\n",
      "[NOR] Episode: 50000, Length: 67, e: 0.05, Avg Reward: -122.065067549, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.23346757889\n",
      "[NOR] Episode: 50010, Length: 87, e: 0.05, Avg Reward: -110.131628585, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.32298088074\n",
      "[NOR] Episode: 50020, Length: 119, e: 0.05, Avg Reward: -101.489239589, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.31129741669\n",
      "[NOR] Episode: 50030, Length: 116, e: 0.05, Avg Reward: -137.892925072, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.88558864594\n",
      "[NOR] Episode: 50040, Length: 81, e: 0.05, Avg Reward: -111.688752078, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.45695924759\n",
      "[NOR] Episode: 50050, Length: 110, e: 0.05, Avg Reward: -123.333510872, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.99740338326\n",
      "[NOR] Episode: 50060, Length: 86, e: 0.05, Avg Reward: -109.636728985, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.3541431427\n",
      "[NOR] Episode: 50070, Length: 81, e: 0.05, Avg Reward: -82.4131704252, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.21023273468\n",
      "[NOR] Episode: 50080, Length: 85, e: 0.05, Avg Reward: -163.78045773, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.52505636215\n",
      "[NOR] Episode: 50090, Length: 143, e: 0.05, Avg Reward: -124.455771011, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.70868086815\n",
      "[NOR] Episode: 50100, Length: 97, e: 0.05, Avg Reward: -166.241571458, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.66323518753\n",
      "[NOR] Episode: 50110, Length: 63, e: 0.05, Avg Reward: -147.129234508, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.65948390961\n",
      "[NOR] Episode: 50120, Length: 54, e: 0.05, Avg Reward: -126.963119471, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.42474031448\n",
      "[NOR] Episode: 50130, Length: 218, e: 0.05, Avg Reward: -99.9764205338, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.03722763062\n",
      "[NOR] Episode: 50140, Length: 75, e: 0.05, Avg Reward: -105.093685618, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.894763469696\n",
      "[NOR] Episode: 50150, Length: 77, e: 0.05, Avg Reward: -154.634914898, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.875766515732\n",
      "[NOR] Episode: 50160, Length: 139, e: 0.05, Avg Reward: -104.925146119, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.29332256317\n",
      "[NOR] Episode: 50170, Length: 81, e: 0.05, Avg Reward: -110.586486996, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.3827514648\n",
      "[NOR] Episode: 50180, Length: 86, e: 0.05, Avg Reward: -111.059784442, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.59526538849\n",
      "[NOR] Episode: 50190, Length: 79, e: 0.05, Avg Reward: -116.658038397, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.974940776825\n",
      "[NOR] Episode: 50200, Length: 91, e: 0.05, Avg Reward: -117.044745557, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.57765197754\n",
      "[NOR] Episode: 50210, Length: 66, e: 0.05, Avg Reward: -131.357213951, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.20471477509\n",
      "[NOR] Episode: 50220, Length: 65, e: 0.05, Avg Reward: -95.0286237103, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.22605168819\n",
      "[NOR] Episode: 50230, Length: 75, e: 0.05, Avg Reward: -98.5161478957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.9323158264\n",
      "[NOR] Episode: 50240, Length: 76, e: 0.05, Avg Reward: -83.8161243787, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.88723039627\n",
      "[NOR] Episode: 50250, Length: 65, e: 0.05, Avg Reward: -123.76991225, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.3884468079\n",
      "[NOR] Episode: 50260, Length: 102, e: 0.05, Avg Reward: -96.1273714501, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.585936784744\n",
      "[NOR] Episode: 50270, Length: 167, e: 0.05, Avg Reward: -141.179200063, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.35390853882\n",
      "[NOR] Episode: 50280, Length: 64, e: 0.05, Avg Reward: -93.6694822952, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.85868752003\n",
      "[NOR] Episode: 50290, Length: 110, e: 0.05, Avg Reward: -119.159674313, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -52.1993408203\n",
      "[NOR] Episode: 50300, Length: 73, e: 0.05, Avg Reward: -140.374744882, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.3490717411\n",
      "[NOR] Episode: 50310, Length: 98, e: 0.05, Avg Reward: -94.5889373025, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.5703086853\n",
      "[NOR] Episode: 50320, Length: 124, e: 0.05, Avg Reward: -109.123491068, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.736058354378\n",
      "[NOR] Episode: 50330, Length: 122, e: 0.05, Avg Reward: -111.066831983, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.06229782104\n",
      "[NOR] Episode: 50340, Length: 82, e: 0.05, Avg Reward: -121.813464011, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.357456207275\n",
      "[NOR] Episode: 50350, Length: 347, e: 0.05, Avg Reward: -84.3845945312, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.3636684418\n",
      "[NOR] Episode: 50360, Length: 162, e: 0.05, Avg Reward: -33.5028949379, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.66743206978\n",
      "[NOR] Episode: 50370, Length: 111, e: 0.05, Avg Reward: -86.065557846, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0752522945404\n",
      "[NOR] Episode: 50380, Length: 101, e: 0.05, Avg Reward: -104.460180469, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.208323955536\n",
      "[NOR] Episode: 50390, Length: 88, e: 0.05, Avg Reward: -106.426946282, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.84688520432\n",
      "[NOR] Episode: 50400, Length: 112, e: 0.05, Avg Reward: -76.6332167253, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.360757887363\n",
      "[NOR] Episode: 50410, Length: 211, e: 0.05, Avg Reward: -109.077954035, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.21992623806\n",
      "[NOR] Episode: 50420, Length: 92, e: 0.05, Avg Reward: -116.693218813, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.96995103359\n",
      "[NOR] Episode: 50430, Length: 81, e: 0.05, Avg Reward: -156.907555117, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.0544295311\n",
      "[NOR] Episode: 50440, Length: 105, e: 0.05, Avg Reward: -122.552304141, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.72161197662\n",
      "[NOR] Episode: 50450, Length: 55, e: 0.05, Avg Reward: -131.521782113, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.538952589035\n",
      "[NOR] Episode: 50460, Length: 92, e: 0.05, Avg Reward: -94.3141742945, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.1655406952\n",
      "[NOR] Episode: 50470, Length: 125, e: 0.05, Avg Reward: -121.216377021, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -26.8864212036\n",
      "[NOR] Episode: 50480, Length: 104, e: 0.05, Avg Reward: -116.052991457, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.225987762213\n",
      "[NOR] Episode: 50490, Length: 96, e: 0.05, Avg Reward: -116.139846786, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.4438247681\n",
      "[NOR] Episode: 50500, Length: 109, e: 0.05, Avg Reward: -67.9378605503, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.7493228912\n",
      "[NOR] Episode: 50510, Length: 86, e: 0.05, Avg Reward: -119.752692937, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.35858535767\n",
      "[NOR] Episode: 50520, Length: 212, e: 0.05, Avg Reward: -36.7741163215, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.45036220551\n",
      "[NOR] Episode: 50530, Length: 76, e: 0.05, Avg Reward: -81.1267072869, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.20821642876\n",
      "[NOR] Episode: 50540, Length: 74, e: 0.05, Avg Reward: -117.348399228, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.23677062988\n",
      "[NOR] Episode: 50550, Length: 101, e: 0.05, Avg Reward: -117.754463938, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.07592320442\n",
      "[NOR] Episode: 50560, Length: 253, e: 0.05, Avg Reward: -80.6070674209, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.75401926041\n",
      "[NOR] Episode: 50570, Length: 194, e: 0.05, Avg Reward: -93.7567815827, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.87810015678\n",
      "[NOR] Episode: 50580, Length: 146, e: 0.05, Avg Reward: -135.60986164, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.33005094528\n",
      "[NOR] Episode: 50590, Length: 192, e: 0.05, Avg Reward: -142.690118379, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.50895798206\n",
      "[NOR] Episode: 50600, Length: 221, e: 0.05, Avg Reward: -48.7635364727, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.19758987427\n",
      "[NOR] Episode: 50610, Length: 55, e: 0.05, Avg Reward: -109.02061364, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.56707954407\n",
      "[NOR] Episode: 50620, Length: 72, e: 0.05, Avg Reward: -122.083714787, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.581635952\n",
      "[NOR] Episode: 50630, Length: 107, e: 0.05, Avg Reward: -146.72150796, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.45515549183\n",
      "[NOR] Episode: 50640, Length: 86, e: 0.05, Avg Reward: -46.4403228034, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.1815547943\n",
      "[NOR] Episode: 50650, Length: 242, e: 0.05, Avg Reward: -113.870907898, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.121026039124\n",
      "[NOR] Episode: 50660, Length: 74, e: 0.05, Avg Reward: -97.4439367982, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.08243346214\n",
      "[NOR] Episode: 50670, Length: 148, e: 0.05, Avg Reward: -63.4850188489, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.0338973999\n",
      "[NOR] Episode: 50680, Length: 92, e: 0.05, Avg Reward: -51.1583432038, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.15255069733\n",
      "[NOR] Episode: 50690, Length: 87, e: 0.05, Avg Reward: -77.0184613982, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.25132155418\n",
      "[NOR] Episode: 50700, Length: 84, e: 0.05, Avg Reward: -129.585627367, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.15967464447\n",
      "[NOR] Episode: 50710, Length: 60, e: 0.05, Avg Reward: -110.211608833, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.31785476208\n",
      "[NOR] Episode: 50720, Length: 91, e: 0.05, Avg Reward: -167.491565843, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.07984828949\n",
      "[NOR] Episode: 50730, Length: 144, e: 0.05, Avg Reward: -83.2296799078, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.611907958984\n",
      "[NOR] Episode: 50740, Length: 115, e: 0.05, Avg Reward: -43.781704948, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.41464805603\n",
      "[NOR] Episode: 50750, Length: 94, e: 0.05, Avg Reward: -33.4881875405, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.63975667953\n",
      "[NOR] Episode: 50760, Length: 149, e: 0.05, Avg Reward: -70.2864954395, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0831820368767\n",
      "[NOR] Episode: 50770, Length: 307, e: 0.05, Avg Reward: -75.6735001689, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.65588355064\n",
      "[NOR] Episode: 50780, Length: 152, e: 0.05, Avg Reward: -135.775899126, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.82046127319\n",
      "[NOR] Episode: 50790, Length: 87, e: 0.05, Avg Reward: -82.9544223794, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.12473773956\n",
      "[NOR] Episode: 50800, Length: 99, e: 0.05, Avg Reward: -65.892967135, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.6437358856\n",
      "[NOR] Episode: 50810, Length: 73, e: 0.05, Avg Reward: -51.9682792856, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.943112611771\n",
      "[NOR] Episode: 50820, Length: 94, e: 0.05, Avg Reward: -44.3468487585, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.31088495255\n",
      "[NOR] Episode: 50830, Length: 285, e: 0.05, Avg Reward: -6.16157534942, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.320769071579\n",
      "[NOR] Episode: 50840, Length: 116, e: 0.05, Avg Reward: -42.748676953, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.544497430325\n",
      "[NOR] Episode: 50850, Length: 69, e: 0.05, Avg Reward: -123.881708475, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.21313905716\n",
      "[NOR] Episode: 50860, Length: 98, e: 0.05, Avg Reward: -116.34710577, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.15722036362\n",
      "[NOR] Episode: 50870, Length: 108, e: 0.05, Avg Reward: -33.1710166158, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.78353977203\n",
      "[NOR] Episode: 50880, Length: 76, e: 0.05, Avg Reward: -123.21382721, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.97075128555\n",
      "[NOR] Episode: 50890, Length: 107, e: 0.05, Avg Reward: -113.392092483, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.787045180798\n",
      "[NOR] Episode: 50900, Length: 113, e: 0.05, Avg Reward: -142.759602203, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.34061098099\n",
      "[NOR] Episode: 50910, Length: 91, e: 0.05, Avg Reward: -70.769728097, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.68935108185\n",
      "[NOR] Episode: 50920, Length: 69, e: 0.05, Avg Reward: -94.2403762484, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.670095682144\n",
      "[NOR] Episode: 50930, Length: 106, e: 0.05, Avg Reward: -52.780807073, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.77157354355\n",
      "[NOR] Episode: 50940, Length: 200, e: 0.05, Avg Reward: -52.067191707, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.64307832718\n",
      "[NOR] Episode: 50950, Length: 125, e: 0.05, Avg Reward: -133.702425803, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.05858230591\n",
      "[NOR] Episode: 50960, Length: 111, e: 0.05, Avg Reward: -90.954390786, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.0070476532\n",
      "[NOR] Episode: 50970, Length: 75, e: 0.05, Avg Reward: -106.735347502, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.1494541168\n",
      "[NOR] Episode: 50980, Length: 55, e: 0.05, Avg Reward: -124.079677299, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.68659830093\n",
      "[NOR] Episode: 50990, Length: 75, e: 0.05, Avg Reward: -84.8662341819, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.51865613461\n",
      "[NOR] Episode: 51000, Length: 103, e: 0.05, Avg Reward: -115.746917207, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.07518768311\n",
      "[NOR] Episode: 51010, Length: 257, e: 0.05, Avg Reward: -82.5559519175, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.44582271576\n",
      "[NOR] Episode: 51020, Length: 129, e: 0.05, Avg Reward: -42.2242893316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.99255800247\n",
      "[NOR] Episode: 51030, Length: 120, e: 0.05, Avg Reward: -70.9157433329, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.34323549271\n",
      "[NOR] Episode: 51040, Length: 155, e: 0.05, Avg Reward: -77.2672741862, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.677857935429\n",
      "[NOR] Episode: 51050, Length: 73, e: 0.05, Avg Reward: -90.9450217481, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.02415418625\n",
      "[NOR] Episode: 51060, Length: 154, e: 0.05, Avg Reward: -112.594208303, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.12619018555\n",
      "[NOR] Episode: 51070, Length: 130, e: 0.05, Avg Reward: -64.7161823232, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.91914343834\n",
      "[NOR] Episode: 51080, Length: 168, e: 0.05, Avg Reward: -65.5481237578, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.92082810402\n",
      "[NOR] Episode: 51090, Length: 116, e: 0.05, Avg Reward: -125.707797928, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.71849441528\n",
      "[NOR] Episode: 51100, Length: 205, e: 0.05, Avg Reward: -28.6170276282, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.3543739319\n",
      "[NOR] Episode: 51110, Length: 112, e: 0.05, Avg Reward: -126.490330517, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.27689981461\n",
      "[NOR] Episode: 51120, Length: 81, e: 0.05, Avg Reward: -127.865686959, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.41347408295\n",
      "[NOR] Episode: 51130, Length: 283, e: 0.05, Avg Reward: -88.5034703128, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.14810657501\n",
      "[NOR] Episode: 51140, Length: 74, e: 0.05, Avg Reward: -129.895262771, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.29321432114\n",
      "[NOR] Episode: 51150, Length: 138, e: 0.05, Avg Reward: -75.0108071191, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.00124835968\n",
      "[NOR] Episode: 51160, Length: 309, e: 0.05, Avg Reward: -58.3911862963, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.298828125\n",
      "[NOR] Episode: 51170, Length: 62, e: 0.05, Avg Reward: -114.778726715, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.92939853668\n",
      "[NOR] Episode: 51180, Length: 192, e: 0.05, Avg Reward: -123.301559498, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0658181905746\n",
      "[NOR] Episode: 51190, Length: 257, e: 0.05, Avg Reward: -66.7218120859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.575883328915\n",
      "[NOR] Episode: 51200, Length: 65, e: 0.05, Avg Reward: -82.9561183964, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.401677280664\n",
      "[NOR] Episode: 51210, Length: 108, e: 0.05, Avg Reward: -52.7507077632, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.27137184143\n",
      "[NOR] Episode: 51220, Length: 88, e: 0.05, Avg Reward: -126.640504821, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.65536928177\n",
      "[NOR] Episode: 51230, Length: 89, e: 0.05, Avg Reward: -123.151821189, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.50677871704\n",
      "[NOR] Episode: 51240, Length: 87, e: 0.05, Avg Reward: -103.621284824, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.04816603661\n",
      "[NOR] Episode: 51250, Length: 142, e: 0.05, Avg Reward: -78.6583947418, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.994292140007\n",
      "[NOR] Episode: 51260, Length: 160, e: 0.05, Avg Reward: -105.781463235, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.36586689949\n",
      "[NOR] Episode: 51270, Length: 182, e: 0.05, Avg Reward: -73.650383586, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.34671068192\n",
      "[NOR] Episode: 51280, Length: 71, e: 0.05, Avg Reward: -81.7815489804, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.69503116608\n",
      "[NOR] Episode: 51290, Length: 274, e: 0.05, Avg Reward: -31.8775729497, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.74954593182\n",
      "[NOR] Episode: 51300, Length: 75, e: 0.05, Avg Reward: -123.429097796, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.18179535866\n",
      "[NOR] Episode: 51310, Length: 65, e: 0.05, Avg Reward: -101.873826744, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.43161344528\n",
      "[NOR] Episode: 51320, Length: 198, e: 0.05, Avg Reward: -100.92500116, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.34287929535\n",
      "[NOR] Episode: 51330, Length: 129, e: 0.05, Avg Reward: -77.8354974396, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.13771772385\n",
      "[NOR] Episode: 51340, Length: 127, e: 0.05, Avg Reward: -131.443787493, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.17586755753\n",
      "[NOR] Episode: 51350, Length: 66, e: 0.05, Avg Reward: -91.3074223647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.00237083435\n",
      "[NOR] Episode: 51360, Length: 65, e: 0.05, Avg Reward: -63.7110556534, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.901494979858\n",
      "[NOR] Episode: 51370, Length: 67, e: 0.05, Avg Reward: -122.926120593, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.28762030602\n",
      "[NOR] Episode: 51380, Length: 74, e: 0.05, Avg Reward: -148.134758906, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.66152381897\n",
      "[NOR] Episode: 51390, Length: 87, e: 0.05, Avg Reward: -92.748218964, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.14256978035\n",
      "[NOR] Episode: 51400, Length: 92, e: 0.05, Avg Reward: -100.307689502, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.51725006104\n",
      "[NOR] Episode: 51410, Length: 141, e: 0.05, Avg Reward: -97.5632161943, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.30154800415\n",
      "[NOR] Episode: 51420, Length: 76, e: 0.05, Avg Reward: -94.4826635412, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.07007169724\n",
      "[NOR] Episode: 51430, Length: 130, e: 0.05, Avg Reward: -87.2040459569, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.499456167221\n",
      "[NOR] Episode: 51440, Length: 65, e: 0.05, Avg Reward: -120.466789923, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.29536938667\n",
      "[NOR] Episode: 51450, Length: 74, e: 0.05, Avg Reward: -114.859567463, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.9983894825\n",
      "[NOR] Episode: 51460, Length: 171, e: 0.05, Avg Reward: -113.968479681, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.75351905823\n",
      "[NOR] Episode: 51470, Length: 106, e: 0.05, Avg Reward: -80.2274622637, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.36309862137\n",
      "[NOR] Episode: 51480, Length: 99, e: 0.05, Avg Reward: -116.125145857, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.20686763525\n",
      "[NOR] Episode: 51490, Length: 104, e: 0.05, Avg Reward: -125.198813171, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.18003082275\n",
      "[NOR] Episode: 51500, Length: 75, e: 0.05, Avg Reward: -114.627313654, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.307331800461\n",
      "[NOR] Episode: 51510, Length: 198, e: 0.05, Avg Reward: -147.465748292, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.81220722198\n",
      "[NOR] Episode: 51520, Length: 77, e: 0.05, Avg Reward: -133.231868118, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.42318511009\n",
      "[NOR] Episode: 51530, Length: 73, e: 0.05, Avg Reward: -75.4420666233, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.05417656898\n",
      "[NOR] Episode: 51540, Length: 63, e: 0.05, Avg Reward: -122.228508587, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.67967271805\n",
      "[NOR] Episode: 51550, Length: 134, e: 0.05, Avg Reward: -139.762631348, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.549030304\n",
      "[NOR] Episode: 51560, Length: 114, e: 0.05, Avg Reward: -149.006502733, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.2880859375\n",
      "[NOR] Episode: 51570, Length: 65, e: 0.05, Avg Reward: -111.547614442, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.78998303413\n",
      "[NOR] Episode: 51580, Length: 157, e: 0.05, Avg Reward: -121.9188074, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.99156713486\n",
      "[NOR] Episode: 51590, Length: 61, e: 0.05, Avg Reward: -127.811899309, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.19568109512\n",
      "[NOR] Episode: 51600, Length: 87, e: 0.05, Avg Reward: -100.154403467, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.55191040039\n",
      "[NOR] Episode: 51610, Length: 57, e: 0.05, Avg Reward: -88.5178053885, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.9013671875\n",
      "[NOR] Episode: 51620, Length: 76, e: 0.05, Avg Reward: -81.9801759178, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.34786891937\n",
      "[NOR] Episode: 51630, Length: 208, e: 0.05, Avg Reward: -106.824924236, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.86983776093\n",
      "[NOR] Episode: 51640, Length: 95, e: 0.05, Avg Reward: -123.340063041, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.79838228226\n",
      "[NOR] Episode: 51650, Length: 104, e: 0.05, Avg Reward: -88.3734129599, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.35235786438\n",
      "[NOR] Episode: 51660, Length: 317, e: 0.05, Avg Reward: -112.089098572, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.39467048645\n",
      "[NOR] Episode: 51670, Length: 73, e: 0.05, Avg Reward: -48.5180864809, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.88059878349\n",
      "[NOR] Episode: 51680, Length: 93, e: 0.05, Avg Reward: -23.6781548055, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.65677261353\n",
      "[NOR] Episode: 51690, Length: 93, e: 0.05, Avg Reward: -143.927153924, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.11503243446\n",
      "[NOR] Episode: 51700, Length: 69, e: 0.05, Avg Reward: -82.9073199092, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.08742237091\n",
      "[NOR] Episode: 51710, Length: 92, e: 0.05, Avg Reward: -118.721601146, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 10.0982093811\n",
      "[NOR] Episode: 51720, Length: 62, e: 0.05, Avg Reward: -131.386536358, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.14600419998\n",
      "[NOR] Episode: 51730, Length: 108, e: 0.05, Avg Reward: -57.8404418572, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.30252385139\n",
      "[NOR] Episode: 51740, Length: 97, e: 0.05, Avg Reward: -80.1111598886, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.99953842163\n",
      "[NOR] Episode: 51750, Length: 93, e: 0.05, Avg Reward: -99.7175784229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.18167924881\n",
      "[NOR] Episode: 51760, Length: 104, e: 0.05, Avg Reward: -103.062389365, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.94907045364\n",
      "[NOR] Episode: 51770, Length: 73, e: 0.05, Avg Reward: -112.294065467, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.2894592285\n",
      "[NOR] Episode: 51780, Length: 105, e: 0.05, Avg Reward: -106.960515454, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.66683483124\n",
      "[NOR] Episode: 51790, Length: 67, e: 0.05, Avg Reward: -110.845767069, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.96794271469\n",
      "[NOR] Episode: 51800, Length: 63, e: 0.05, Avg Reward: -64.1554979797, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -14.7713689804\n",
      "[NOR] Episode: 51810, Length: 101, e: 0.05, Avg Reward: -111.37929504, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.47023940086\n",
      "[NOR] Episode: 51820, Length: 120, e: 0.05, Avg Reward: -77.0434190724, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 27.8195323944\n",
      "[NOR] Episode: 51830, Length: 122, e: 0.05, Avg Reward: -70.8786861126, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.25819778442\n",
      "[NOR] Episode: 51840, Length: 97, e: 0.05, Avg Reward: -100.875630612, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.90290641785\n",
      "[NOR] Episode: 51850, Length: 91, e: 0.05, Avg Reward: -135.214531777, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.80601549149\n",
      "[NOR] Episode: 51860, Length: 90, e: 0.05, Avg Reward: -71.9233453158, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.54175853729\n",
      "[NOR] Episode: 51870, Length: 91, e: 0.05, Avg Reward: -121.302997386, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.879449248314\n",
      "[NOR] Episode: 51880, Length: 68, e: 0.05, Avg Reward: -136.321854119, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.16796004772\n",
      "[NOR] Episode: 51890, Length: 96, e: 0.05, Avg Reward: -110.477694676, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.70882177353\n",
      "[NOR] Episode: 51900, Length: 156, e: 0.05, Avg Reward: -94.0979430714, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.26074075699\n",
      "[NOR] Episode: 51910, Length: 87, e: 0.05, Avg Reward: -105.53750453, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.06492853165\n",
      "[NOR] Episode: 51920, Length: 208, e: 0.05, Avg Reward: -105.377845965, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.33021640778\n",
      "[NOR] Episode: 51930, Length: 94, e: 0.05, Avg Reward: -102.159240182, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.69673037529\n",
      "[NOR] Episode: 51940, Length: 97, e: 0.05, Avg Reward: -98.0408070358, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.256156206131\n",
      "[NOR] Episode: 51950, Length: 69, e: 0.05, Avg Reward: -112.49267348, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.67260408401\n",
      "[NOR] Episode: 51960, Length: 76, e: 0.05, Avg Reward: -131.251632473, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.54660701752\n",
      "[NOR] Episode: 51970, Length: 71, e: 0.05, Avg Reward: -148.288010283, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.97915756702\n",
      "[NOR] Episode: 51980, Length: 149, e: 0.05, Avg Reward: -89.240034559, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.27565991879\n",
      "[NOR] Episode: 51990, Length: 103, e: 0.05, Avg Reward: -76.9887552931, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.95320749283\n",
      "[NOR] Episode: 52000, Length: 96, e: 0.05, Avg Reward: -145.635951473, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.08039236069\n",
      "[NOR] Episode: 52010, Length: 276, e: 0.05, Avg Reward: -103.33414832, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.733632922173\n",
      "[NOR] Episode: 52020, Length: 94, e: 0.05, Avg Reward: -94.1423378762, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.434835434\n",
      "[NOR] Episode: 52030, Length: 78, e: 0.05, Avg Reward: -129.30719779, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.627605199814\n",
      "[NOR] Episode: 52040, Length: 94, e: 0.05, Avg Reward: -92.1811743536, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.961043417454\n",
      "[NOR] Episode: 52050, Length: 138, e: 0.05, Avg Reward: -101.839437019, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.58572387695\n",
      "[NOR] Episode: 52060, Length: 75, e: 0.05, Avg Reward: -82.2658072861, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.011292219162\n",
      "[NOR] Episode: 52070, Length: 77, e: 0.05, Avg Reward: -125.151630622, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.73103380203\n",
      "[NOR] Episode: 52080, Length: 90, e: 0.05, Avg Reward: -93.4347862456, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.96472263336\n",
      "[NOR] Episode: 52090, Length: 129, e: 0.05, Avg Reward: -99.2205563261, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.090922832489\n",
      "[NOR] Episode: 52100, Length: 135, e: 0.05, Avg Reward: -114.249771036, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.40155017376\n",
      "[NOR] Episode: 52110, Length: 103, e: 0.05, Avg Reward: -131.570019478, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.19957685471\n",
      "[NOR] Episode: 52120, Length: 87, e: 0.05, Avg Reward: -106.834444595, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.77777099609\n",
      "[NOR] Episode: 52130, Length: 112, e: 0.05, Avg Reward: -116.621073859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.1964635849\n",
      "[NOR] Episode: 52140, Length: 70, e: 0.05, Avg Reward: -126.961255481, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.65032434464\n",
      "[NOR] Episode: 52150, Length: 112, e: 0.05, Avg Reward: -84.5172200332, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.28843891621\n",
      "[NOR] Episode: 52160, Length: 103, e: 0.05, Avg Reward: -154.591870071, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.82891941071\n",
      "[NOR] Episode: 52170, Length: 171, e: 0.05, Avg Reward: -114.596672549, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.10181474686\n",
      "[NOR] Episode: 52180, Length: 95, e: 0.05, Avg Reward: -92.8506515393, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.52552318573\n",
      "[NOR] Episode: 52190, Length: 125, e: 0.05, Avg Reward: -81.3136800874, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -11.660153389\n",
      "[NOR] Episode: 52200, Length: 82, e: 0.05, Avg Reward: -92.226855674, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.3899474144\n",
      "[NOR] Episode: 52210, Length: 121, e: 0.05, Avg Reward: -66.8490524484, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.02979707718\n",
      "[NOR] Episode: 52220, Length: 155, e: 0.05, Avg Reward: -104.868024925, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.57446622849\n",
      "[NOR] Episode: 52230, Length: 139, e: 0.05, Avg Reward: -55.6040937419, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.03409123421\n",
      "[NOR] Episode: 52240, Length: 82, e: 0.05, Avg Reward: -220.011586173, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.18837881088\n",
      "[NOR] Episode: 52250, Length: 100, e: 0.05, Avg Reward: -84.4949265064, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.1448459625\n",
      "[NOR] Episode: 52260, Length: 97, e: 0.05, Avg Reward: -76.1770764672, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.7913851738\n",
      "[NOR] Episode: 52270, Length: 70, e: 0.05, Avg Reward: -109.094199844, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.40668106079\n",
      "[NOR] Episode: 52280, Length: 128, e: 0.05, Avg Reward: -135.031868866, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.572756588459\n",
      "[NOR] Episode: 52290, Length: 67, e: 0.05, Avg Reward: -49.1126475215, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.4693994522\n",
      "[NOR] Episode: 52300, Length: 84, e: 0.05, Avg Reward: -82.2345571476, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.4415204525\n",
      "[NOR] Episode: 52310, Length: 222, e: 0.05, Avg Reward: -81.1392926341, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.70889282227\n",
      "[NOR] Episode: 52320, Length: 157, e: 0.05, Avg Reward: -114.353023925, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.47890949249\n",
      "[NOR] Episode: 52330, Length: 67, e: 0.05, Avg Reward: -102.679956383, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.5476347208\n",
      "[NOR] Episode: 52340, Length: 82, e: 0.05, Avg Reward: -120.935531977, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.744663476944\n",
      "[NOR] Episode: 52350, Length: 235, e: 0.05, Avg Reward: -40.8194816236, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.19000506401\n",
      "[NOR] Episode: 52360, Length: 89, e: 0.05, Avg Reward: -77.035225143, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.06172275543\n",
      "[NOR] Episode: 52370, Length: 99, e: 0.05, Avg Reward: -102.924028017, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.579119503498\n",
      "[NOR] Episode: 52380, Length: 86, e: 0.05, Avg Reward: -118.17541151, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.40744972229\n",
      "[NOR] Episode: 52390, Length: 129, e: 0.05, Avg Reward: -96.8411239311, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.05602645874\n",
      "[NOR] Episode: 52400, Length: 70, e: 0.05, Avg Reward: -61.6563689062, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.54072380066\n",
      "[NOR] Episode: 52410, Length: 85, e: 0.05, Avg Reward: -34.7933929897, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.37372684479\n",
      "[NOR] Episode: 52420, Length: 113, e: 0.05, Avg Reward: -65.1665557726, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.57757639885\n",
      "[NOR] Episode: 52430, Length: 384, e: 0.05, Avg Reward: 17.1016514087, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.79892301559\n",
      "[NOR] Episode: 52440, Length: 91, e: 0.05, Avg Reward: -130.476495912, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.29038524628\n",
      "[NOR] Episode: 52450, Length: 102, e: 0.05, Avg Reward: -108.70413179, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.50498664379\n",
      "[NOR] Episode: 52460, Length: 132, e: 0.05, Avg Reward: -136.76172494, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 17.3716049194\n",
      "[NOR] Episode: 52470, Length: 106, e: 0.05, Avg Reward: -38.1178471522, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.27364039421\n",
      "[NOR] Episode: 52480, Length: 94, e: 0.05, Avg Reward: -67.874765345, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.00081253052\n",
      "[NOR] Episode: 52490, Length: 180, e: 0.05, Avg Reward: -61.4649846842, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.39765620232\n",
      "[NOR] Episode: 52500, Length: 173, e: 0.05, Avg Reward: -69.717910588, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.33227622509\n",
      "[NOR] Episode: 52510, Length: 137, e: 0.05, Avg Reward: -158.460572478, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.640697240829\n",
      "[NOR] Episode: 52520, Length: 102, e: 0.05, Avg Reward: -144.016451395, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.84086513519\n",
      "[NOR] Episode: 52530, Length: 139, e: 0.05, Avg Reward: -71.3039759672, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.3147706985\n",
      "[NOR] Episode: 52540, Length: 173, e: 0.05, Avg Reward: -107.606767267, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.506148457527\n",
      "[NOR] Episode: 52550, Length: 79, e: 0.05, Avg Reward: -108.120363602, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.55659031868\n",
      "[NOR] Episode: 52560, Length: 257, e: 0.05, Avg Reward: -108.089580339, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.91173553467\n",
      "[NOR] Episode: 52570, Length: 78, e: 0.05, Avg Reward: -114.418157863, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.75425052643\n",
      "[NOR] Episode: 52580, Length: 142, e: 0.05, Avg Reward: -89.8951618754, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.9433479309\n",
      "[NOR] Episode: 52590, Length: 178, e: 0.05, Avg Reward: -114.513997282, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -17.9974746704\n",
      "[NOR] Episode: 52600, Length: 208, e: 0.05, Avg Reward: -93.9516110638, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -19.1526908875\n",
      "[NOR] Episode: 52610, Length: 108, e: 0.05, Avg Reward: -105.369122525, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.11103725433\n",
      "[NOR] Episode: 52620, Length: 111, e: 0.05, Avg Reward: -85.9261785472, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.0739112794399\n",
      "[NOR] Episode: 52630, Length: 97, e: 0.05, Avg Reward: -177.60946901, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.43038415909\n",
      "[NOR] Episode: 52640, Length: 195, e: 0.05, Avg Reward: -33.4699367559, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.61435270309\n",
      "[NOR] Episode: 52650, Length: 120, e: 0.05, Avg Reward: -95.4432088175, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.32460510731\n",
      "[NOR] Episode: 52660, Length: 84, e: 0.05, Avg Reward: -125.83033889, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -35.9036102295\n",
      "[NOR] Episode: 52670, Length: 110, e: 0.05, Avg Reward: -86.4367429647, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.229608654976\n",
      "[NOR] Episode: 52680, Length: 390, e: 0.05, Avg Reward: -76.0118676229, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.2799706459\n",
      "[NOR] Episode: 52690, Length: 80, e: 0.05, Avg Reward: -152.090034005, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.13662362099\n",
      "[NOR] Episode: 52700, Length: 131, e: 0.05, Avg Reward: -128.371956939, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.79547476768\n",
      "[NOR] Episode: 52710, Length: 111, e: 0.05, Avg Reward: -49.1253300486, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.72548007965\n",
      "[NOR] Episode: 52720, Length: 117, e: 0.05, Avg Reward: -77.9732643352, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.28623914719\n",
      "[NOR] Episode: 52730, Length: 110, e: 0.05, Avg Reward: -65.7632640493, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.40796864033\n",
      "[NOR] Episode: 52740, Length: 64, e: 0.05, Avg Reward: -104.205260206, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.6196782589\n",
      "[NOR] Episode: 52750, Length: 91, e: 0.05, Avg Reward: -96.1639165255, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.33356428146\n",
      "[NOR] Episode: 52760, Length: 132, e: 0.05, Avg Reward: -49.2938731933, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.69558334351\n",
      "[NOR] Episode: 52770, Length: 116, e: 0.05, Avg Reward: -101.214198539, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.97423362732\n",
      "[NOR] Episode: 52780, Length: 290, e: 0.05, Avg Reward: -72.3749187374, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.31456184387\n",
      "[NOR] Episode: 52790, Length: 131, e: 0.05, Avg Reward: -88.0395306058, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.45143508911\n",
      "[NOR] Episode: 52800, Length: 150, e: 0.05, Avg Reward: -117.9902004, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.89728355408\n",
      "[NOR] Episode: 52810, Length: 62, e: 0.05, Avg Reward: -105.195928452, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.7506942749\n",
      "[NOR] Episode: 52820, Length: 75, e: 0.05, Avg Reward: -88.0673617112, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.45874452591\n",
      "[NOR] Episode: 52830, Length: 78, e: 0.05, Avg Reward: -78.1916471966, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.37468290329\n",
      "[NOR] Episode: 52840, Length: 75, e: 0.05, Avg Reward: -100.804561607, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.78521251678\n",
      "[NOR] Episode: 52850, Length: 66, e: 0.05, Avg Reward: -123.796479095, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 11.3972816467\n",
      "[NOR] Episode: 52860, Length: 115, e: 0.05, Avg Reward: -133.814840389, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.18629872799\n",
      "[NOR] Episode: 52870, Length: 174, e: 0.05, Avg Reward: -169.166409974, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.61030960083\n",
      "[NOR] Episode: 52880, Length: 164, e: 0.05, Avg Reward: -111.842350458, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.480988621712\n",
      "[NOR] Episode: 52890, Length: 96, e: 0.05, Avg Reward: -108.796256662, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.47423172\n",
      "[NOR] Episode: 52900, Length: 119, e: 0.05, Avg Reward: -209.643513501, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.84126091003\n",
      "[NOR] Episode: 52910, Length: 64, e: 0.05, Avg Reward: -59.9037412898, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.74520540237\n",
      "[NOR] Episode: 52920, Length: 195, e: 0.05, Avg Reward: -183.894361068, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.2468271255\n",
      "[NOR] Episode: 52930, Length: 124, e: 0.05, Avg Reward: -144.586681905, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.99090099335\n",
      "[NOR] Episode: 52940, Length: 182, e: 0.05, Avg Reward: -145.280359297, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.62469387054\n",
      "[NOR] Episode: 52950, Length: 122, e: 0.05, Avg Reward: -131.643591791, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.40596795082\n",
      "[NOR] Episode: 52960, Length: 143, e: 0.05, Avg Reward: -122.994819452, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.732266545296\n",
      "[NOR] Episode: 52970, Length: 143, e: 0.05, Avg Reward: -165.228772772, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 38.3045082092\n",
      "[NOR] Episode: 52980, Length: 54, e: 0.05, Avg Reward: -110.514524385, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.10943126678\n",
      "[NOR] Episode: 52990, Length: 159, e: 0.05, Avg Reward: -132.335503831, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.18648564816\n",
      "[NOR] Episode: 53000, Length: 220, e: 0.05, Avg Reward: -171.221997838, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.99148917198\n",
      "[NOR] Episode: 53010, Length: 162, e: 0.05, Avg Reward: -195.803385431, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.15213346481\n",
      "[NOR] Episode: 53020, Length: 145, e: 0.05, Avg Reward: -180.922262985, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.349249184132\n",
      "[NOR] Episode: 53030, Length: 308, e: 0.05, Avg Reward: -111.537524234, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.0673847198\n",
      "[NOR] Episode: 53040, Length: 133, e: 0.05, Avg Reward: -85.4957707815, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.580504179001\n",
      "[NOR] Episode: 53050, Length: 136, e: 0.05, Avg Reward: -172.059048887, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.45791721344\n",
      "[NOR] Episode: 53060, Length: 82, e: 0.05, Avg Reward: -144.903914966, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.85646760464\n",
      "[NOR] Episode: 53070, Length: 213, e: 0.05, Avg Reward: -146.426695431, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 34.17603302\n",
      "[NOR] Episode: 53080, Length: 346, e: 0.05, Avg Reward: -202.699810396, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.25494289398\n",
      "[NOR] Episode: 53090, Length: 103, e: 0.05, Avg Reward: -206.02024583, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.633031487465\n",
      "[NOR] Episode: 53100, Length: 141, e: 0.05, Avg Reward: -170.402975374, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.6183795929\n",
      "[NOR] Episode: 53110, Length: 86, e: 0.05, Avg Reward: -199.406603449, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.338832974434\n",
      "[NOR] Episode: 53120, Length: 145, e: 0.05, Avg Reward: -183.352601166, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.4965171814\n",
      "[NOR] Episode: 53130, Length: 69, e: 0.05, Avg Reward: -121.217764145, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.17754554749\n",
      "[NOR] Episode: 53140, Length: 74, e: 0.05, Avg Reward: -168.167333905, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.99594783783\n",
      "[NOR] Episode: 53150, Length: 117, e: 0.05, Avg Reward: -84.9976422297, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 16.9778709412\n",
      "[NOR] Episode: 53160, Length: 334, e: 0.05, Avg Reward: -172.183872887, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.02838969231\n",
      "[NOR] Episode: 53170, Length: 87, e: 0.05, Avg Reward: -131.746289783, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.66854119301\n",
      "[NOR] Episode: 53180, Length: 173, e: 0.05, Avg Reward: -141.127757197, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.41516366601\n",
      "[NOR] Episode: 53190, Length: 68, e: 0.05, Avg Reward: -169.654790682, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.42144620419\n",
      "[NOR] Episode: 53200, Length: 70, e: 0.05, Avg Reward: -180.776781881, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.982586145401\n",
      "[NOR] Episode: 53210, Length: 119, e: 0.05, Avg Reward: -145.976748005, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.129236638546\n",
      "[NOR] Episode: 53220, Length: 157, e: 0.05, Avg Reward: -158.594935753, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.62617397308\n",
      "[NOR] Episode: 53230, Length: 111, e: 0.05, Avg Reward: -189.685364692, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.929292619228\n",
      "[NOR] Episode: 53240, Length: 178, e: 0.05, Avg Reward: -205.931190981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.635493397713\n",
      "[NOR] Episode: 53250, Length: 81, e: 0.05, Avg Reward: -171.374780397, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.320542573929\n",
      "[NOR] Episode: 53260, Length: 83, e: 0.05, Avg Reward: -168.88045792, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.73690986633\n",
      "[NOR] Episode: 53270, Length: 112, e: 0.05, Avg Reward: -153.179969146, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.33751297\n",
      "[NOR] Episode: 53280, Length: 169, e: 0.05, Avg Reward: -176.069686906, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.31586551666\n",
      "[NOR] Episode: 53290, Length: 130, e: 0.05, Avg Reward: -92.9861244919, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.38461589813\n",
      "[NOR] Episode: 53300, Length: 136, e: 0.05, Avg Reward: -152.950680859, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.3766212463\n",
      "[NOR] Episode: 53310, Length: 150, e: 0.05, Avg Reward: -172.621929212, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.99820101261\n",
      "[NOR] Episode: 53320, Length: 314, e: 0.05, Avg Reward: -96.558726617, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.38331961632\n",
      "[NOR] Episode: 53330, Length: 97, e: 0.05, Avg Reward: -191.773352153, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.84620475769\n",
      "[NOR] Episode: 53340, Length: 229, e: 0.05, Avg Reward: -120.054708876, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.62780666351\n",
      "[NOR] Episode: 53350, Length: 71, e: 0.05, Avg Reward: -155.815065188, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.24528026581\n",
      "[NOR] Episode: 53360, Length: 163, e: 0.05, Avg Reward: -146.04134751, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.83912706375\n",
      "[NOR] Episode: 53370, Length: 521, e: 0.05, Avg Reward: -156.826613726, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.39297580719\n",
      "[NOR] Episode: 53380, Length: 195, e: 0.05, Avg Reward: -123.737771923, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.39041042328\n",
      "[NOR] Episode: 53390, Length: 114, e: 0.05, Avg Reward: -135.268485143, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -13.2709331512\n",
      "[NOR] Episode: 53400, Length: 77, e: 0.05, Avg Reward: -142.698559371, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -23.7612667084\n",
      "[NOR] Episode: 53410, Length: 94, e: 0.05, Avg Reward: -93.5316996108, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.39709234238\n",
      "[NOR] Episode: 53420, Length: 99, e: 0.05, Avg Reward: -185.481680838, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.19517660141\n",
      "[NOR] Episode: 53430, Length: 201, e: 0.05, Avg Reward: -160.49058293, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.30899572372\n",
      "[NOR] Episode: 53440, Length: 94, e: 0.05, Avg Reward: -143.628067901, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.65129256248\n",
      "[NOR] Episode: 53450, Length: 115, e: 0.05, Avg Reward: -136.062361214, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.4083313942\n",
      "[NOR] Episode: 53460, Length: 91, e: 0.05, Avg Reward: -153.314092889, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.0111732483\n",
      "[NOR] Episode: 53470, Length: 119, e: 0.05, Avg Reward: -134.45292804, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.467597007751\n",
      "[NOR] Episode: 53480, Length: 72, e: 0.05, Avg Reward: -159.591003316, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.74040043354\n",
      "[NOR] Episode: 53490, Length: 114, e: 0.05, Avg Reward: -87.4916743891, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.53682994843\n",
      "[NOR] Episode: 53500, Length: 55, e: 0.05, Avg Reward: -148.676620632, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.07476854324\n",
      "[NOR] Episode: 53510, Length: 67, e: 0.05, Avg Reward: -132.553182449, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 49.2496643066\n",
      "[NOR] Episode: 53520, Length: 94, e: 0.05, Avg Reward: -94.9591806553, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.16834104061\n",
      "[NOR] Episode: 53530, Length: 363, e: 0.05, Avg Reward: -80.854685981, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.33596801758\n",
      "[NOR] Episode: 53540, Length: 212, e: 0.05, Avg Reward: -106.376021893, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.74615693092\n",
      "[NOR] Episode: 53550, Length: 70, e: 0.05, Avg Reward: -81.6499235583, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.2861828804\n",
      "[NOR] Episode: 53560, Length: 216, e: 0.05, Avg Reward: -167.19848451, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.06024837494\n",
      "[NOR] Episode: 53570, Length: 163, e: 0.05, Avg Reward: -158.10577263, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.7860212326\n",
      "[NOR] Episode: 53580, Length: 90, e: 0.05, Avg Reward: -155.845795506, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.35099053383\n",
      "[NOR] Episode: 53590, Length: 153, e: 0.05, Avg Reward: -72.2212953896, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.76233863831\n",
      "[NOR] Episode: 53600, Length: 243, e: 0.05, Avg Reward: -83.6857714723, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.41931629181\n",
      "[NOR] Episode: 53610, Length: 121, e: 0.05, Avg Reward: -142.699039322, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.223487854\n",
      "[NOR] Episode: 53620, Length: 80, e: 0.05, Avg Reward: -99.9074117516, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.232845246792\n",
      "[NOR] Episode: 53630, Length: 167, e: 0.05, Avg Reward: -118.647984552, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -67.6488571167\n",
      "[NOR] Episode: 53640, Length: 217, e: 0.05, Avg Reward: -74.3818566519, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.459245353937\n",
      "[NOR] Episode: 53650, Length: 208, e: 0.05, Avg Reward: -291.103155895, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.12671113014\n",
      "[NOR] Episode: 53660, Length: 147, e: 0.05, Avg Reward: -174.007505628, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.44643187523\n",
      "[NOR] Episode: 53670, Length: 153, e: 0.05, Avg Reward: -145.670703862, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.91762065887\n",
      "[NOR] Episode: 53680, Length: 158, e: 0.05, Avg Reward: -23.4123104336, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.64497220516\n",
      "[NOR] Episode: 53690, Length: 224, e: 0.05, Avg Reward: -120.226500832, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.25853347778\n",
      "[NOR] Episode: 53700, Length: 256, e: 0.05, Avg Reward: -152.32989106, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.68683719635\n",
      "[NOR] Episode: 53710, Length: 301, e: 0.05, Avg Reward: -131.502968663, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.64244365692\n",
      "[NOR] Episode: 53720, Length: 67, e: 0.05, Avg Reward: -167.044399246, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.8949546814\n",
      "[NOR] Episode: 53730, Length: 95, e: 0.05, Avg Reward: -173.590312671, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 34.774269104\n",
      "[NOR] Episode: 53740, Length: 91, e: 0.05, Avg Reward: -190.579082359, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.01409912109\n",
      "[NOR] Episode: 53750, Length: 153, e: 0.05, Avg Reward: -53.6426234593, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.21164941788\n",
      "[NOR] Episode: 53760, Length: 134, e: 0.05, Avg Reward: -55.5938424947, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.92395877838\n",
      "[NOR] Episode: 53770, Length: 79, e: 0.05, Avg Reward: -72.4290111018, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.95799160004\n",
      "[NOR] Episode: 53780, Length: 115, e: 0.05, Avg Reward: -12.0523576573, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.73155593872\n",
      "[NOR] Episode: 53790, Length: 376, e: 0.05, Avg Reward: -136.027322619, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.19549179077\n",
      "[NOR] Episode: 53800, Length: 214, e: 0.05, Avg Reward: -96.1222105731, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.97734797001\n",
      "[NOR] Episode: 53810, Length: 96, e: 0.05, Avg Reward: -152.146207338, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.512565135956\n",
      "[NOR] Episode: 53820, Length: 120, e: 0.05, Avg Reward: -98.0210106769, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.56066513062\n",
      "[NOR] Episode: 53830, Length: 232, e: 0.05, Avg Reward: -90.7122489954, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.29896831512\n",
      "[NOR] Episode: 53840, Length: 95, e: 0.05, Avg Reward: -69.1713863357, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.22661434114\n",
      "[NOR] Episode: 53850, Length: 89, e: 0.05, Avg Reward: -42.3683280349, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.06605362892\n",
      "[NOR] Episode: 53860, Length: 102, e: 0.05, Avg Reward: -37.9356502696, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.34121227264\n",
      "[NOR] Episode: 53870, Length: 186, e: 0.05, Avg Reward: -94.6400870334, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 30.0906620026\n",
      "[NOR] Episode: 53880, Length: 83, e: 0.05, Avg Reward: -109.175289093, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.12852811813\n",
      "[NOR] Episode: 53890, Length: 83, e: 0.05, Avg Reward: -107.051059113, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -18.3530578613\n",
      "[NOR] Episode: 53900, Length: 84, e: 0.05, Avg Reward: -81.9142335401, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 20.3454418182\n",
      "[NOR] Episode: 53910, Length: 126, e: 0.05, Avg Reward: -175.498130597, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.20761537552\n",
      "[NOR] Episode: 53920, Length: 290, e: 0.05, Avg Reward: -155.615204434, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.50099468231\n",
      "[NOR] Episode: 53930, Length: 69, e: 0.05, Avg Reward: -152.987551199, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.62827539444\n",
      "[NOR] Episode: 53940, Length: 162, e: 0.05, Avg Reward: -142.136864487, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.42876791954\n",
      "[NOR] Episode: 53950, Length: 98, e: 0.05, Avg Reward: -56.9025641348, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.47549843788\n",
      "[NOR] Episode: 53960, Length: 243, e: 0.05, Avg Reward: -105.460811891, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.24426269531\n",
      "[NOR] Episode: 53970, Length: 106, e: 0.05, Avg Reward: -145.989737013, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.3731430769\n",
      "[NOR] Episode: 53980, Length: 114, e: 0.05, Avg Reward: -175.073334314, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.35281479359\n",
      "[NOR] Episode: 53990, Length: 117, e: 0.05, Avg Reward: -187.972845986, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 28.6410903931\n",
      "[NOR] Episode: 54000, Length: 108, e: 0.05, Avg Reward: -252.742883402, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.974684596062\n",
      "[NOR] Episode: 54010, Length: 166, e: 0.05, Avg Reward: -167.909246425, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.99299526215\n",
      "[NOR] Episode: 54020, Length: 91, e: 0.05, Avg Reward: -219.089193793, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.09430575371\n",
      "[NOR] Episode: 54030, Length: 143, e: 0.05, Avg Reward: -170.554623529, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.29253149033\n",
      "[NOR] Episode: 54040, Length: 59, e: 0.05, Avg Reward: -172.995262277, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.59510564804\n",
      "[NOR] Episode: 54050, Length: 116, e: 0.05, Avg Reward: -192.196595758, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.62312889099\n",
      "[NOR] Episode: 54060, Length: 130, e: 0.05, Avg Reward: -123.83878259, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.420440644026\n",
      "[NOR] Episode: 54070, Length: 170, e: 0.05, Avg Reward: -157.761420454, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -16.8646774292\n",
      "[NOR] Episode: 54080, Length: 99, e: 0.05, Avg Reward: -107.263131129, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.4280796051\n",
      "[NOR] Episode: 54090, Length: 73, e: 0.05, Avg Reward: -123.099950537, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.8045027256\n",
      "[NOR] Episode: 54100, Length: 372, e: 0.05, Avg Reward: -48.8167244787, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.0809696614742\n",
      "[NOR] Episode: 54110, Length: 345, e: 0.05, Avg Reward: -99.5048748308, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.8507578373\n",
      "[NOR] Episode: 54120, Length: 94, e: 0.05, Avg Reward: -124.568772558, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.08197426796\n",
      "[NOR] Episode: 54130, Length: 56, e: 0.05, Avg Reward: -97.2897359938, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.38069009781\n",
      "[NOR] Episode: 54140, Length: 183, e: 0.05, Avg Reward: -148.225025725, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.80094432831\n",
      "[NOR] Episode: 54150, Length: 241, e: 0.05, Avg Reward: -92.311766312, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.58676624298\n",
      "[NOR] Episode: 54160, Length: 56, e: 0.05, Avg Reward: -97.039062531, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.13390874863\n",
      "[NOR] Episode: 54170, Length: 89, e: 0.05, Avg Reward: -138.423274537, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.61429309845\n",
      "[NOR] Episode: 54180, Length: 84, e: 0.05, Avg Reward: -108.389509551, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.39596843719\n",
      "[NOR] Episode: 54190, Length: 70, e: 0.05, Avg Reward: -71.6106598769, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.42732596397\n",
      "[NOR] Episode: 54200, Length: 76, e: 0.05, Avg Reward: -113.932613388, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.9769268036\n",
      "[NOR] Episode: 54210, Length: 64, e: 0.05, Avg Reward: -88.962007613, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.01752519608\n",
      "[NOR] Episode: 54220, Length: 441, e: 0.05, Avg Reward: -60.2594473186, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -21.2967224121\n",
      "[NOR] Episode: 54230, Length: 87, e: 0.05, Avg Reward: -131.711990957, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.9830725193\n",
      "[NOR] Episode: 54240, Length: 110, e: 0.05, Avg Reward: -79.4568136682, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.773563385\n",
      "[NOR] Episode: 54250, Length: 106, e: 0.05, Avg Reward: -114.729313014, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.63322782516\n",
      "[NOR] Episode: 54260, Length: 146, e: 0.05, Avg Reward: -104.280853105, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.68082523346\n",
      "[NOR] Episode: 54270, Length: 80, e: 0.05, Avg Reward: -40.1059905695, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.30503559113\n",
      "[NOR] Episode: 54280, Length: 107, e: 0.05, Avg Reward: -82.970090276, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -12.789853096\n",
      "[NOR] Episode: 54290, Length: 241, e: 0.05, Avg Reward: -35.8285643906, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.151053786278\n",
      "[NOR] Episode: 54300, Length: 158, e: 0.05, Avg Reward: -102.520928625, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.13959312439\n",
      "[NOR] Episode: 54310, Length: 80, e: 0.05, Avg Reward: -125.382498787, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.42041516304\n",
      "[NOR] Episode: 54320, Length: 53, e: 0.05, Avg Reward: -118.516080699, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.216837883\n",
      "[NOR] Episode: 54330, Length: 117, e: 0.05, Avg Reward: -128.718517985, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.922599554062\n",
      "[NOR] Episode: 54340, Length: 147, e: 0.05, Avg Reward: -63.2951752472, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.05234766006\n",
      "[NOR] Episode: 54350, Length: 92, e: 0.05, Avg Reward: -87.0613544416, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.57788562775\n",
      "[NOR] Episode: 54360, Length: 94, e: 0.05, Avg Reward: -133.725441012, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.15025520325\n",
      "[NOR] Episode: 54370, Length: 66, e: 0.05, Avg Reward: -144.355730026, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.94553565979\n",
      "[NOR] Episode: 54380, Length: 66, e: 0.05, Avg Reward: -108.208139489, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.925804495811\n",
      "[NOR] Episode: 54390, Length: 52, e: 0.05, Avg Reward: -154.756820839, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.19299483299\n",
      "[NOR] Episode: 54400, Length: 51, e: 0.05, Avg Reward: -105.642457522, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.88760232925\n",
      "[NOR] Episode: 54410, Length: 88, e: 0.05, Avg Reward: -128.458184093, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.6306638718\n",
      "[NOR] Episode: 54420, Length: 57, e: 0.05, Avg Reward: -138.091073192, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.82296586037\n",
      "[NOR] Episode: 54430, Length: 82, e: 0.05, Avg Reward: -121.086413497, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.81288051605\n",
      "[NOR] Episode: 54440, Length: 72, e: 0.05, Avg Reward: -111.120460037, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.53772521019\n",
      "[NOR] Episode: 54450, Length: 239, e: 0.05, Avg Reward: -131.603091301, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.556377410889\n",
      "[NOR] Episode: 54460, Length: 238, e: 0.05, Avg Reward: -126.047732558, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -9.21450710297\n",
      "[NOR] Episode: 54470, Length: 72, e: 0.05, Avg Reward: -159.747234532, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.3974161148\n",
      "[NOR] Episode: 54480, Length: 99, e: 0.05, Avg Reward: -103.242075192, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.28608512878\n",
      "[NOR] Episode: 54490, Length: 77, e: 0.05, Avg Reward: -123.986396982, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.79867458344\n",
      "[NOR] Episode: 54500, Length: 77, e: 0.05, Avg Reward: -100.574114851, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -10.9564609528\n",
      "[NOR] Episode: 54510, Length: 188, e: 0.05, Avg Reward: -98.1914130611, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.90200185776\n",
      "[NOR] Episode: 54520, Length: 62, e: 0.05, Avg Reward: -115.953789308, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.20751953125\n",
      "[NOR] Episode: 54530, Length: 127, e: 0.05, Avg Reward: -132.715778811, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.74656367302\n",
      "[NOR] Episode: 54540, Length: 73, e: 0.05, Avg Reward: -139.739318547, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -15.9863672256\n",
      "[NOR] Episode: 54550, Length: 76, e: 0.05, Avg Reward: -151.855241838, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.85755157471\n",
      "[NOR] Episode: 54560, Length: 65, e: 0.05, Avg Reward: -171.244918869, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.38750839233\n",
      "[NOR] Episode: 54570, Length: 58, e: 0.05, Avg Reward: -57.5543696801, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.64923858643\n",
      "[NOR] Episode: 54580, Length: 77, e: 0.05, Avg Reward: -112.846525618, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 7.646525383\n",
      "[NOR] Episode: 54590, Length: 74, e: 0.05, Avg Reward: -126.746551278, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.104071140289\n",
      "[NOR] Episode: 54600, Length: 71, e: 0.05, Avg Reward: -138.774229085, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.59760320187\n",
      "[NOR] Episode: 54610, Length: 124, e: 0.05, Avg Reward: -158.571517837, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.26814031601\n",
      "[NOR] Episode: 54620, Length: 62, e: 0.05, Avg Reward: -161.173971639, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.10293722153\n",
      "[NOR] Episode: 54630, Length: 121, e: 0.05, Avg Reward: -80.5232061493, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.6137638092\n",
      "[NOR] Episode: 54640, Length: 80, e: 0.05, Avg Reward: -110.737058149, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.68457245827\n",
      "[NOR] Episode: 54650, Length: 86, e: 0.05, Avg Reward: -106.199913372, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.03489112854\n",
      "[NOR] Episode: 54660, Length: 282, e: 0.05, Avg Reward: -120.755047979, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.18810415268\n",
      "[NOR] Episode: 54670, Length: 235, e: 0.05, Avg Reward: -71.1053535029, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -7.19122838974\n",
      "[NOR] Episode: 54680, Length: 249, e: 0.05, Avg Reward: -96.4061032595, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.17034482956\n",
      "[NOR] Episode: 54690, Length: 70, e: 0.05, Avg Reward: -136.524321052, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.78195810318\n",
      "[NOR] Episode: 54700, Length: 98, e: 0.05, Avg Reward: -105.426080959, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.65641069412\n",
      "[NOR] Episode: 54710, Length: 109, e: 0.05, Avg Reward: -128.985749469, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.369958400726\n",
      "[NOR] Episode: 54720, Length: 137, e: 0.05, Avg Reward: -108.801452415, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.66923141479\n",
      "[NOR] Episode: 54730, Length: 220, e: 0.05, Avg Reward: -99.5679345037, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.909058094025\n",
      "[NOR] Episode: 54740, Length: 61, e: 0.05, Avg Reward: -103.338034192, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.64734363556\n",
      "[NOR] Episode: 54750, Length: 109, e: 0.05, Avg Reward: -95.3051840053, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.985504031181\n",
      "[NOR] Episode: 54760, Length: 83, e: 0.05, Avg Reward: -135.599426065, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -5.64327669144\n",
      "[NOR] Episode: 54770, Length: 118, e: 0.05, Avg Reward: -115.338230847, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.15411186218\n",
      "[NOR] Episode: 54780, Length: 89, e: 0.05, Avg Reward: -129.804185898, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.97649860382\n",
      "[NOR] Episode: 54790, Length: 63, e: 0.05, Avg Reward: -133.307618984, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.766645789146\n",
      "[NOR] Episode: 54800, Length: 89, e: 0.05, Avg Reward: -74.2872472938, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.81023144722\n",
      "[NOR] Episode: 54810, Length: 164, e: 0.05, Avg Reward: -123.100838829, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.00978076457977\n",
      "[NOR] Episode: 54820, Length: 62, e: 0.05, Avg Reward: -134.442699244, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.863608598709\n",
      "[NOR] Episode: 54830, Length: 75, e: 0.05, Avg Reward: -117.049186991, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -24.9822406769\n",
      "[NOR] Episode: 54840, Length: 87, e: 0.05, Avg Reward: -118.481170311, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.53871059418\n",
      "[NOR] Episode: 54850, Length: 72, e: 0.05, Avg Reward: -130.286389197, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.48935699463\n",
      "[NOR] Episode: 54860, Length: 63, e: 0.05, Avg Reward: -107.823699521, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.22323083878\n",
      "[NOR] Episode: 54870, Length: 59, e: 0.05, Avg Reward: -159.646481788, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.60628032684\n",
      "[NOR] Episode: 54880, Length: 96, e: 0.05, Avg Reward: -115.136717832, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.77899360657\n",
      "[NOR] Episode: 54890, Length: 94, e: 0.05, Avg Reward: -114.021764536, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 9.23874664307\n",
      "[NOR] Episode: 54900, Length: 74, e: 0.05, Avg Reward: -94.9737473487, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.00737476349\n",
      "[NOR] Episode: 54910, Length: 63, e: 0.05, Avg Reward: -132.585524961, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 14.3324832916\n",
      "[NOR] Episode: 54920, Length: 223, e: 0.05, Avg Reward: -125.363798964, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.90369319916\n",
      "[NOR] Episode: 54930, Length: 79, e: 0.05, Avg Reward: -88.6187015574, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 15.494184494\n",
      "[NOR] Episode: 54940, Length: 76, e: 0.05, Avg Reward: -115.86072065, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.566893339157\n",
      "[NOR] Episode: 54950, Length: 84, e: 0.05, Avg Reward: -51.0106852451, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.16451740265\n",
      "[NOR] Episode: 54960, Length: 61, e: 0.05, Avg Reward: -100.454277296, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.87266731262\n",
      "[NOR] Episode: 54970, Length: 104, e: 0.05, Avg Reward: -111.280790459, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 12.2032470703\n",
      "[NOR] Episode: 54980, Length: 178, e: 0.05, Avg Reward: -151.137509225, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.286159902811\n",
      "[NOR] Episode: 54990, Length: 378, e: 0.05, Avg Reward: -107.209011192, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.49070310593\n",
      "[NOR] Episode: 55000, Length: 96, e: 0.05, Avg Reward: -141.227268726, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.34417486191\n",
      "[NOR] Episode: 55010, Length: 79, e: 0.05, Avg Reward: -89.4318458719, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 5.19233083725\n",
      "[NOR] Episode: 55020, Length: 74, e: 0.05, Avg Reward: -91.2661025585, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 13.3559675217\n",
      "[NOR] Episode: 55030, Length: 112, e: 0.05, Avg Reward: -96.9097896584, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.15595293045\n",
      "[NOR] Episode: 55040, Length: 313, e: 0.05, Avg Reward: -53.0415626137, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -8.0233745575\n",
      "[NOR] Episode: 55050, Length: 143, e: 0.05, Avg Reward: -102.061449706, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -6.03595209122\n",
      "[NOR] Episode: 55060, Length: 105, e: 0.05, Avg Reward: -153.750027973, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.63031101227\n",
      "[NOR] Episode: 55070, Length: 72, e: 0.05, Avg Reward: -83.2845705379, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.71706914902\n",
      "[NOR] Episode: 55080, Length: 100, e: 0.05, Avg Reward: -100.195317356, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 6.94181632996\n",
      "[NOR] Episode: 55090, Length: 397, e: 0.05, Avg Reward: -88.2646440254, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.94018876553\n",
      "[NOR] Episode: 55100, Length: 89, e: 0.05, Avg Reward: -68.3418852705, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.92802011967\n",
      "[NOR] Episode: 55110, Length: 78, e: 0.05, Avg Reward: -134.695933363, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.56474399567\n",
      "[NOR] Episode: 55120, Length: 96, e: 0.05, Avg Reward: -152.900498865, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.38002443314\n",
      "[NOR] Episode: 55130, Length: 82, e: 0.05, Avg Reward: -94.982801551, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.71188044548\n",
      "[NOR] Episode: 55140, Length: 84, e: 0.05, Avg Reward: -101.309876029, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.772182226181\n",
      "[NOR] Episode: 55150, Length: 95, e: 0.05, Avg Reward: -136.998933131, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.89601564407\n",
      "[NOR] Episode: 55160, Length: 121, e: 0.05, Avg Reward: -127.048209611, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.35188031197\n",
      "[NOR] Episode: 55170, Length: 71, e: 0.05, Avg Reward: -87.6394456814, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 2.15929102898\n",
      "[NOR] Episode: 55180, Length: 226, e: 0.05, Avg Reward: -89.5543381121, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.96918737888\n",
      "[NOR] Episode: 55190, Length: 89, e: 0.05, Avg Reward: -83.7231066909, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.69845151901\n",
      "[NOR] Episode: 55200, Length: 85, e: 0.05, Avg Reward: -124.11090247, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.711208701134\n",
      "[NOR] Episode: 55210, Length: 226, e: 0.05, Avg Reward: -100.458836725, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.46856546402\n",
      "[NOR] Episode: 55220, Length: 72, e: 0.05, Avg Reward: -106.077284518, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 4.39495801926\n",
      "[NOR] Episode: 55230, Length: 61, e: 0.05, Avg Reward: -84.608428945, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.45373678207\n",
      "[NOR] Episode: 55240, Length: 64, e: 0.05, Avg Reward: -106.8108068, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.89047908783\n",
      "[NOR] Episode: 55250, Length: 101, e: 0.05, Avg Reward: -91.7213301542, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 1.0690612793\n",
      "[NOR] Episode: 55260, Length: 195, e: 0.05, Avg Reward: -130.250269503, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -1.17706441879\n",
      "[NOR] Episode: 55270, Length: 123, e: 0.05, Avg Reward: -113.59330543, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 8.57824707031\n",
      "[NOR] Episode: 55280, Length: 92, e: 0.05, Avg Reward: -54.8657872023, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.63971447945\n",
      "[NOR] Episode: 55290, Length: 97, e: 0.05, Avg Reward: 38.6192267782, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.72071695328\n",
      "[NOR] Episode: 55300, Length: 80, e: 0.05, Avg Reward: -162.653622679, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -0.910894155502\n",
      "[NOR] Episode: 55310, Length: 96, e: 0.05, Avg Reward: -22.7998433219, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -2.80782699585\n",
      "[NOR] Episode: 55320, Length: 76, e: 0.05, Avg Reward: -91.1616306239, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.77545499802\n",
      "[NOR] Episode: 55330, Length: 217, e: 0.05, Avg Reward: -89.0843199498, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.44176483154\n",
      "[NOR] Episode: 55340, Length: 64, e: 0.05, Avg Reward: -92.1849537943, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.592170119286\n",
      "[NOR] Episode: 55350, Length: 81, e: 0.05, Avg Reward: -120.487976612, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -4.08158874512\n",
      "[NOR] Episode: 55360, Length: 196, e: 0.05, Avg Reward: -89.4077223363, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 0.278118848801\n",
      "[NOR] Episode: 55370, Length: 169, e: 0.05, Avg Reward: -81.2859213593, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: -3.12818813324\n",
      "[NOR] Episode: 55380, Length: 91, e: 0.05, Avg Reward: -151.350248417, Learning Rate: 0.01, buffer_len: 500000\n",
      "Loss: 3.45255899429\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5518e221e50e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mupdate_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mkeep_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m )\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-5fd8004c45af>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, env, keep_prob, e, learning_rate, print_step, update_target, episodes, max_episode_length, batch_size)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mep_step\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_episode_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mepisode_length\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m                 \u001b[0mep_step\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "k = 40000.\n",
    "model.fit(\n",
    "    env, print_step=10, \n",
    "    episodes=int(1e5), max_episode_length=10000, batch_size=32,\n",
    "    learning_rate = 0.01, # lambda t: 0.05 * k / (k + t)\n",
    "    e = interp1d([0, 400000], [0.3, 0.05], fill_value=0.05, bounds_error=False),\n",
    "    update_target = 1,\n",
    "    keep_prob = 0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-03-04 19:55:36,425] Making new env: LunarLander-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Discrete(4)\n",
      "176.540326468\n",
      "156.436842996\n",
      "143.810052028\n",
      "8.39406075299\n",
      "124.878813456\n",
      "135.241647795\n",
      "125.904473818\n",
      "-1.87422575196\n",
      "117.471052701\n",
      "160.104958639\n",
      "191.297729203\n",
      "250.12545112\n",
      "7.01496596446\n",
      "219.47940431\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "argument 2: <type 'exceptions.TypeError'>: wrong type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-921da6990744>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gym/core.pyc\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedMode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unsupported rendering mode: {}. (Supported modes for {}: {})'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gym/envs/box2d/lunar_lander.pyc\u001b[0m in \u001b[0;36m_render\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    354\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_polygon\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflagy2\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mviewer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreturn_rgb_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'rgb_array'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLunarLanderContinuous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLunarLander\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/gym/envs/classic_control/rendering.pyc\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, return_rgb_array)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswitch_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_events\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgeom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeoms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/pyglet/window/xlib/__init__.pyc\u001b[0m in \u001b[0;36mdispatch_events\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;31m# Check for the events specific to this window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         while xlib.XCheckWindowEvent(_x_display, _window,\n\u001b[0;32m--> 853\u001b[0;31m                                      0x1ffffff, byref(e)):\n\u001b[0m\u001b[1;32m    854\u001b[0m             \u001b[0;31m# Key events are filtered by the xlib window event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# handler so they get a shot at the prefiltered event.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument 2: <type 'exceptions.TypeError'>: wrong type"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "env = gym.make(\"LunarLander-v2\")\n",
    "env = ExpandedStateEnv(env, 3)\n",
    "print(env.action_space)\n",
    "n_actions = env.action_space.n\n",
    "n_states = env.observation_space.shape[0] * 3\n",
    "model_path = os.getcwd() + \"/actor-critic.model\"\n",
    "logs_path = \"logs/run0\"\n",
    "\n",
    "\n",
    "model_run = LanderAC(\n",
    "    n_actions, n_states,\n",
    "    model_path = model_path,\n",
    "    flush_secs = 3.0,\n",
    "    restore = True\n",
    ")\n",
    "\n",
    "for i in range(100):\n",
    "    s = env.reset()\n",
    "    done = False\n",
    "    total = 0.\n",
    "    ep = 0\n",
    "    while not done and ep < 700:\n",
    "        ep += 1\n",
    "        a = model_run.choose_action(s, 1.0)\n",
    "        s, r, done, info = env.step(a)\n",
    "        total += r\n",
    "        env.render()\n",
    "        time.sleep(0.01)\n",
    "    print(total)\n",
    "env.render(close=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# gym.upload(\"tmp/monitor{}\".format(run), api_key='sk_WASyK12rQxais3gwyG4Vg', ignore_open_monitors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gym.upload?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coconut (Python 2)",
   "language": "coconut",
   "name": "coconut2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3.6
   },
   "file_extension": ".coco",
   "mimetype": "text/x-python3",
   "name": "coconut",
   "pygments_lexer": "coconut"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
