{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 not supported (please install/reinstall h5py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-29 01:54:24,928] Making new env: CartPole-v1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from numpy.random import choice\n",
    "import random\n",
    "from tensorbuilder.api import *\n",
    "import tensorflow as tf\n",
    "\n",
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'softmax_layer/Reshape_1:0' shape=(?, 12, 2) dtype=float32>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def select_columns(tensor, indexes):\n",
    "    idx = tf.stack((tf.range(tf.shape(indexes)[0]), indexes), 1)\n",
    "    return tf.gather_nd(tensor, idx)\n",
    "\n",
    "def discount(rewards, y):\n",
    "    r_accum = 0.0\n",
    "    gains = []\n",
    "    for r in reversed(list(rewards)):\n",
    "        r_accum = r + y * r_accum \n",
    "        gains.insert(0, r_accum)\n",
    "        \n",
    "    return gains\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_name = \"policy-gradient-cartpole.model\"\n",
    "model_path = \"/models/\" + model_name\n",
    "n_actions = env.action_space.n\n",
    "n_states_env = env.observation_space.shape[0]\n",
    "n_states = n_states_env * 3\n",
    "\n",
    "class Model(object):\n",
    "    \n",
    "    def __init__(self, y, restore=False):\n",
    "        \n",
    "        self.graph = tf.Graph()\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "        \n",
    "        with self.graph.as_default():\n",
    "            with tf.device(\"cpu:0\"):\n",
    "                s = tf.placeholder(tf.float32, [None, n_states], name='s')\n",
    "                a = tf.placeholder(tf.int32, [None], name='a')\n",
    "                r = tf.placeholder(tf.float32, [None], name='r')\n",
    "                lr = tf.placeholder(tf.float32, [], name='lr')\n",
    "                \n",
    "                trainer = tf.train.GradientDescentOptimizer(lr)\n",
    "\n",
    "                ops = dict(trainable=True, weights_initializer=tf.random_uniform_initializer(minval=0.0, maxval=0.01), biases_initializer=None) #tf.random_uniform_initializer(minval=0, maxval=0.01))\n",
    "\n",
    "                with tf.variable_scope(\"actor\"):\n",
    "                    Ps = Pipe(\n",
    "                        s,\n",
    "                        T\n",
    "                        .relu_layer(16, **ops)\n",
    "                        .softmax_layer(n_actions, scope='softmax_layer', **ops)\n",
    "                    )\n",
    "                Psws = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"actor\")\n",
    "\n",
    "                Psa = select_columns(Ps, a)\n",
    "                \n",
    "                base = tf.Variable(0.0)\n",
    "                \n",
    "                error = r - base\n",
    "\n",
    "                loss = -tf.reduce_sum(tf.log(Psa) * error)\n",
    "                gradients = trainer.compute_gradients(loss, var_list=Psws)\n",
    "                gradients = [ (tf.clip_by_value(g, -5.0, 5.0), w) for g, w in gradients ]\n",
    "                update = trainer.apply_gradients(gradients)\n",
    "                \n",
    "                loss_base = Pipe(error, tf.nn.l2_loss, tf.reduce_sum)\n",
    "                gradients = trainer.compute_gradients(loss_base, var_list=[base])\n",
    "                gradients = [ (tf.clip_by_value(g, -2.0, 2.0), w) for g, w in gradients ]\n",
    "                update_base = trainer.apply_gradients(gradients)\n",
    "\n",
    "                self.writer = tf.summary.FileWriter('/logs/' +  model_name)\n",
    "                self.saver = tf.train.Saver()\n",
    "                \n",
    "                self.variables_initializer = tf.global_variables_initializer()\n",
    "                \n",
    "        \n",
    "\n",
    "            if restore:\n",
    "                self.saver.restore(self.sess, model_path)\n",
    "            else:\n",
    "                self.sess.run(self.variables_initializer)\n",
    "\n",
    "        self.s = s; self.a = a; self.r = r;\n",
    "        self.Ps = Ps; self.Psa = Psa; self.update = update; self.update_base = update_base\n",
    "        self.lr = lr\n",
    "                \n",
    "    def next_action(self, state):\n",
    "        actions = self.sess.run(self.Ps, feed_dict={self.s: [state]})[0]\n",
    "        n = len(actions)\n",
    "\n",
    "        return choice(n, p=actions)\n",
    "\n",
    "    def train(self, s, a, r, s1, lr):\n",
    "        #train\n",
    "        self.train_offline([s], [a], [r], [s1], lr)\n",
    "        \n",
    "    def train_offline(self, S, A, R, S1, lr):\n",
    "        #train\n",
    "        self.sess.run(self.update, feed_dict={\n",
    "            self.s: S, self.a: A, self.r: R, \n",
    "            self.lr: lr\n",
    "        })\n",
    "        \n",
    "        self.sess.run(self.update_base, feed_dict={\n",
    "            self.s: S, self.a: A, self.r: R, \n",
    "            self.lr: lr\n",
    "        })\n",
    "\n",
    "    def save(self, model_path):\n",
    "        self.saver.save(self.sess, model_path)\n",
    "\n",
    "    def restore(self, model_path):\n",
    "        self.sess.close()\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "        self.saver.restore(self.sess, model_path)\n",
    "\n",
    "    @staticmethod\n",
    "    def learning_rate(t, b, k):\n",
    "        return b * k / (k + t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68 , lr: 0.1\n",
      "17.86 , lr: 0.0975609756098\n",
      "10.54 , lr: 0.0952380952381\n",
      "11.12 , lr: 0.093023255814\n",
      "17.12 , lr: 0.0909090909091\n",
      "18.26 , lr: 0.0888888888889\n",
      "12.5 , lr: 0.0869565217391\n",
      "9.7 , lr: 0.0851063829787\n",
      "10.28 , lr: 0.0833333333333\n",
      "9.84 , lr: 0.0816326530612\n",
      "9.88 , lr: 0.08\n",
      "10.76 , lr: 0.078431372549\n",
      "11.14 , lr: 0.0769230769231\n",
      "15.68 , lr: 0.0754716981132\n",
      "44.62 , lr: 0.0740740740741\n",
      "27.0 , lr: 0.0727272727273\n",
      "15.12 , lr: 0.0714285714286\n",
      "9.68 , lr: 0.0701754385965\n",
      "9.9 , lr: 0.0689655172414\n",
      "9.62 , lr: 0.0677966101695\n",
      "9.5 , lr: 0.0666666666667\n",
      "9.82 , lr: 0.0655737704918\n",
      "9.56 , lr: 0.0645161290323\n",
      "9.78 , lr: 0.0634920634921\n",
      "9.68 , lr: 0.0625\n",
      "9.78 , lr: 0.0615384615385\n",
      "11.72 , lr: 0.0606060606061\n",
      "22.4 , lr: 0.0597014925373\n",
      "27.36 , lr: 0.0588235294118\n",
      "28.64 , lr: 0.0579710144928\n",
      "25.68 , lr: 0.0571428571429\n",
      "26.62 , lr: 0.056338028169\n",
      "26.4 , lr: 0.0555555555556\n",
      "29.24 , lr: 0.0547945205479\n",
      "39.92 , lr: 0.0540540540541\n",
      "42.7 , lr: 0.0533333333333\n",
      "40.84 , lr: 0.0526315789474\n",
      "39.62 , lr: 0.0519480519481\n",
      "40.32 , lr: 0.0512820512821\n",
      "41.0 , lr: 0.0506329113924\n",
      "41.54 , lr: 0.05\n",
      "41.34 , lr: 0.0493827160494\n",
      "44.26 , lr: 0.0487804878049\n",
      "37.88 , lr: 0.0481927710843\n",
      "41.04 , lr: 0.047619047619\n",
      "39.56 , lr: 0.0470588235294\n",
      "42.08 , lr: 0.046511627907\n",
      "37.32 , lr: 0.0459770114943\n",
      "38.02 , lr: 0.0454545454545\n",
      "40.24 , lr: 0.0449438202247\n",
      "35.1 , lr: 0.0444444444444\n",
      "40.3 , lr: 0.043956043956\n",
      "36.74 , lr: 0.0434782608696\n",
      "34.54 , lr: 0.0430107526882\n",
      "38.32 , lr: 0.0425531914894\n",
      "40.32 , lr: 0.0421052631579\n",
      "32.54 , lr: 0.0416666666667\n",
      "36.44 , lr: 0.0412371134021\n",
      "47.32 , lr: 0.0408163265306\n",
      "52.36 , lr: 0.040404040404\n",
      "52.38 , lr: 0.04\n",
      "52.18 , lr: 0.039603960396\n",
      "43.68 , lr: 0.0392156862745\n",
      "60.64 , lr: 0.0388349514563\n",
      "46.24 , lr: 0.0384615384615\n",
      "50.78 , lr: 0.0380952380952\n",
      "87.3 , lr: 0.0377358490566\n",
      "74.76 , lr: 0.0373831775701\n",
      "68.16 , lr: 0.037037037037\n",
      "74.68 , lr: 0.0366972477064\n",
      "54.7 , lr: 0.0363636363636\n",
      "56.2 , lr: 0.036036036036\n",
      "89.48 , lr: 0.0357142857143\n",
      "88.36 , lr: 0.0353982300885\n",
      "139.68 , lr: 0.0350877192982\n",
      "304.22 , lr: 0.0347826086957\n",
      "270.7 , lr: 0.0344827586207\n",
      "294.86 , lr: 0.034188034188\n",
      "1951.04 , lr: 0.0338983050847\n",
      "3749.08 , lr: 0.0336134453782\n",
      "6700.78 , lr: 0.0333333333333\n",
      "8032.06 , lr: 0.0330578512397\n",
      "2111.2 , lr: 0.0327868852459\n",
      "2062.28 , lr: 0.0325203252033\n",
      "2978.16 , lr: 0.0322580645161\n",
      "7493.94 , lr: 0.032\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-f0e3c412df23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#next action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m#take step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-55-b028503498ae>\u001b[0m in \u001b[0;36mnext_action\u001b[0;34m(self, state)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    911\u001b[0m     \u001b[0;31m# Validate and process feed_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 913\u001b[0;31m       \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten_dict_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    914\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msubfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfeed_val\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_feed_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/nest.pyc\u001b[0m in \u001b[0;36mflatten_dict_items\u001b[0;34m(dictionary)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"input must be a dictionary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m   \u001b[0mflat_dictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflat_dictionary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/six.pyc\u001b[0m in \u001b[0;36miteritems\u001b[0;34m(d, **kw)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterlists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "y = 0.98\n",
    "b = 0.1\n",
    "k = 2000.0\n",
    "\n",
    "model = Model(y, restore=False)\n",
    "\n",
    "r_total = 0.0\n",
    "max_r = 0.0\n",
    "\n",
    "for t in range(200000):\n",
    "    lr = model.learning_rate(t, b, k)\n",
    "    s = env.reset()\n",
    "    s = np.hstack((s,s,s))\n",
    "    \n",
    "    S = []; A = []; R = []; S1 = []\n",
    "    \n",
    "    \n",
    "    for j in range(10000):\n",
    "        #next action\n",
    "        a = model.next_action(s)\n",
    "\n",
    "        #take step\n",
    "        s1, r, done, info = env.step(a)\n",
    "        n = s1.shape[0]\n",
    "        \n",
    "        s1 = np.hstack((s[n_states_env:], s1))\n",
    "        \n",
    "        r_total += r\n",
    "        \n",
    "        #append values\n",
    "        S.append(s); A.append(a); R.append(r); S1.append(s1)\n",
    "        \n",
    "        #update state\n",
    "        s = s1\n",
    "        \n",
    "        if done: break\n",
    "        \n",
    "    R = discount(R, y)\n",
    "        \n",
    "    #train\n",
    "    model.train_offline(S, A, R, S1, lr)\n",
    "\n",
    "    save_period = 50\n",
    "    if t % save_period == 0:\n",
    "        print r_total / save_period, \", lr:\", lr\n",
    "        r_total = 0\n",
    "        model.save(model_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.get_variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Down)\n",
      "\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Up)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Down)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Right)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Right)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FF\u001b[41mF\u001b[0mH\n",
      "HFFG\n",
      "  (Down)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Left)\n",
      "\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "  (Down)\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "s = np.hstack((s,s,s))\n",
    "    \n",
    "for i in range(100):\n",
    "    a = model.next_action(s)\n",
    "    s1, r, done, info = env.step(a)\n",
    "    s = np.hstack((s[n_states_env:], s1))\n",
    "    env.render()\n",
    "    print(\"\")\n",
    "\n",
    "    if done:\n",
    "        print(r)\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
