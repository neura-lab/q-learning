{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from numpy.random import choice\n",
    "import random\n",
    "from phi.api import *\n",
    "import tensorflow as tf\n",
    "from tfinterface.reinforcement import OnBatchModel, ExperienceReplay\n",
    "from tfinterface.interfaces import EnvironmentInterface\n",
    "from tfinterface.model_base import ModelBase\n",
    "from tensorflow.python import debug as tf_debug\n",
    "import os\n",
    "from scipy.interpolate import interp1d\n",
    "import numbers\n",
    "\n",
    "\n",
    "def get_run():\n",
    "    try:\n",
    "        with open(\"run.txt\") as f:\n",
    "            run = int(f.read().split(\"/n\")[0])\n",
    "    except:\n",
    "        run = -1\n",
    "    \n",
    "    with open(\"run.txt\", 'w+') as f:\n",
    "        run += 1\n",
    "        \n",
    "        f.seek(0)\n",
    "        f.write(str(run))\n",
    "        f.truncate()\n",
    "        \n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-02-26 06:42:02,527] Making new env: CartPole-v1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 167\n"
     ]
    }
   ],
   "source": [
    "def select_columns(tensor, indexes):\n",
    "    idx = tf.stack((tf.range(tf.shape(indexes)[0]), indexes), 1)\n",
    "    return tf.gather_nd(tensor, idx)\n",
    "\n",
    "def soft_if(cond, then, else_):\n",
    "    return (cond * then) + (1.0 - cond) * else_\n",
    "\n",
    "\n",
    "def map_gradients(gradients, clip_fun):\n",
    "    return [ (clip_fun(g), v) for g, v in gradients ]\n",
    "\n",
    "class ExpandedStateEnv(EnvironmentInterface):\n",
    "    \n",
    "    def __init__(self, env):\n",
    "        self.env = gym.make(env) if type(env) is str else env\n",
    "        \n",
    "    def reset(self):\n",
    "        s = self.env.reset()\n",
    "        self.s = np.hstack((s,s,s))\n",
    "        return self.s\n",
    "    \n",
    "    def step(self, a):\n",
    "        s, r, done, info = self.env.step(a)\n",
    "        n = len(s)\n",
    "        self.s = np.hstack((self.s[n:], s))\n",
    "        \n",
    "        return self.s, r, done, info\n",
    "    \n",
    "    def __getattr__(self, attr):\n",
    "        return getattr(self.env, attr)\n",
    "    \n",
    "        \n",
    "\n",
    "class Inputs(object):\n",
    "    def __init__(self, n_states, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            self.episode_length = tf.placeholder(tf.int64, [], name='episode_length')\n",
    "\n",
    "            self.s = tf.placeholder(tf.float32, [None, n_states], name='s')\n",
    "            self.a = tf.placeholder(tf.int32, [None], name='a')\n",
    "            self.r = tf.placeholder(tf.float32, [None], name='r')\n",
    "            self.V1 = tf.placeholder(tf.float32, [None], name='V1')\n",
    "            self.done = tf.placeholder(tf.float32, [None], name='done')\n",
    "            self.learning_rate = tf.placeholder(tf.float32, [], name='learning_rate')\n",
    "            self.keep_prob = tf.placeholder(tf.float32, [], name='training')\n",
    "    \n",
    "    def fit_feed(self, S, A, R, V1, Done, learning_rate, keep_prob):\n",
    "        return {\n",
    "            self.s: S, self.a: A, self.r: R, self.V1: V1, self.done: Done, \n",
    "            self.learning_rate: learning_rate, self.keep_prob: keep_prob\n",
    "        }\n",
    "            \n",
    "            \n",
    "class Critic(object):\n",
    "    def __init__(self, inputs, n_actions, n_states, y, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            \n",
    "\n",
    "            ops = dict(\n",
    "                trainable=True, \n",
    "                kernel_initializer=tf.random_uniform_initializer(minval=0.0, maxval=0.01),\n",
    "                use_bias=False,\n",
    "                bias_initializer=None\n",
    "            )\n",
    "\n",
    "\n",
    "            net = tf.layers.dense(inputs.s, 32, activation=tf.nn.relu, name='relu_layer', **ops)\n",
    "            net = tf.nn.dropout(net, inputs.keep_prob)\n",
    "            self.V = tf.layers.dense(net, 1, name='linear_layer', **ops)[:, 0]\n",
    "\n",
    "            self.target = soft_if(inputs.done, inputs.r,  inputs.r + y * inputs.V1)\n",
    "\n",
    "            self.error = self.target - self.V\n",
    "            self.loss = Pipe(self.error, tf.nn.l2_loss, tf.reduce_mean)\n",
    "\n",
    "            self.variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=scope)\n",
    "            \n",
    "            self.update = tf.train.AdamOptimizer(inputs.learning_rate).minimize(self.loss, var_list=self.variables)\n",
    "            \n",
    "            avg_error, std_error = tf.nn.moments(self.error, [0])\n",
    "            self.summaries = tf.summary.merge([\n",
    "                tf.summary.scalar('loss', self.loss),\n",
    "                tf.summary.scalar('avg_target', tf.reduce_mean(self.target)),\n",
    "                tf.summary.scalar('variables_sum', sum([ tf.reduce_sum(v) for v in self.variables ])),\n",
    "                tf.summary.scalar('avg_error', avg_error),\n",
    "                tf.summary.scalar('std_error', std_error),\n",
    "                tf.summary.histogram(\n",
    "                    'avg_action', Pipe(\n",
    "                    inputs.a,\n",
    "                    Then(tf.one_hot, n_actions),\n",
    "                    Then(tf.reduce_mean, axis=0)\n",
    "                ))\n",
    "            ]+[\n",
    "                tf.summary.histogram('var{}'.format(i), self.variables[i]) for i in range(len(self.variables))\n",
    "            ])\n",
    "            \n",
    "            \n",
    "            \n",
    "class Actor(object):\n",
    "    def __init__(self, inputs, target_critic, n_actions, n_states, y, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            \n",
    "            ops = dict(\n",
    "                trainable=True, \n",
    "                kernel_initializer=tf.random_uniform_initializer(minval=0.0, maxval=0.01),\n",
    "                use_bias=False,\n",
    "                bias_initializer=None\n",
    "            )\n",
    "\n",
    "\n",
    "            net = tf.layers.dense(inputs.s, 32, activation=tf.nn.relu, name='relu_layer', **ops)\n",
    "            net = tf.nn.dropout(net, inputs.keep_prob)\n",
    "            self.P = tf.layers.dense(net, n_actions, activation=tf.nn.softmax, name='softmax_layer', **ops)\n",
    "            \n",
    "            self.Pa = select_columns(self.P, inputs.a)\n",
    "\n",
    "            self.loss = - tf.log(tf.clip_by_value(self.Pa, 1e-3, 1.0)) * target_critic.error\n",
    "            self.loss = tf.reduce_mean(self.loss)\n",
    "            \n",
    "            self.variables = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=scope)\n",
    "            \n",
    "            self.update = tf.train.AdamOptimizer(inputs.learning_rate).minimize(self.loss, var_list=self.variables)\n",
    "            \n",
    "            self.summaries = tf.summary.merge([\n",
    "                tf.summary.scalar('loss', self.loss),\n",
    "                tf.summary.scalar('Pa0', tf.reduce_mean(self.P[:,0])),\n",
    "                tf.summary.scalar('Pa1', tf.reduce_mean(self.P[:,1])),\n",
    "                tf.summary.scalar('variables_sum', sum([ tf.reduce_sum(v) for v in self.variables ])),\n",
    "                tf.summary.histogram(\n",
    "                    'avg_action', Pipe(\n",
    "                    inputs.a,\n",
    "                    Then(tf.one_hot, n_actions),\n",
    "                    Then(tf.reduce_mean, axis=0)\n",
    "                ))\n",
    "            ]+[\n",
    "                tf.summary.histogram('var{}'.format(i), self.variables[i]) for i in range(len(self.variables))\n",
    "            ])\n",
    "\n",
    "class Model(ModelBase):\n",
    "    \n",
    "    def define_model(self, n_actions, n_states, y=0.98, buffer_length=50000, pi=0.01):\n",
    "        self.global_max = 0.0\n",
    "        self.replay_buffer = ExperienceReplay(max_length=buffer_length)\n",
    "        \n",
    "        \n",
    "        with self.graph.as_default(), tf.device(\"cpu:0\"):\n",
    "            \n",
    "            self.inputs = Inputs(n_states, \"inputs\")\n",
    "            \n",
    "            self.critic = Critic(self.inputs, n_actions, n_states, y, \"critic\")\n",
    "            self.target_critic = Critic(self.inputs, n_actions, n_states, y, \"target_critic\")\n",
    "            self.actor = Actor(self.inputs, self.target_critic, n_actions, n_states, y, \"actor\")\n",
    "            \n",
    "            self.update = tf.group(self.critic.update, self.actor.update)\n",
    "            \n",
    "            self.episode_length_summary = tf.summary.scalar('episode_length', self.inputs.episode_length)\n",
    "            \n",
    "            self.summaries = tf.summary.merge([self.actor.summaries, self.critic.summaries, self.target_critic.summaries])\n",
    "            \n",
    "            self.update_target = tf.group(*[\n",
    "                t.assign_add(pi * (a - t)) for t, a in zip(self.target_critic.variables, self.critic.variables)\n",
    "            ])\n",
    "        \n",
    "                              \n",
    "    def fit_feed(self, *args, **kwargs): return self.inputs.fit_feed(*args, **kwargs)\n",
    "                \n",
    "    def choose_action(self, state, keep_prob, e=0.0):\n",
    "        actions = self.sess.run(self.actor.P, feed_dict={\n",
    "            self.inputs.s: [state],\n",
    "            self.inputs.keep_prob: keep_prob\n",
    "        })[0]\n",
    "        n = len(actions)\n",
    "        \n",
    "        if random.random() < e:\n",
    "            return random.randint(0, n-1)\n",
    "        else:\n",
    "            return np.random.choice(n, p=actions)\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def fit(self, env, keep_prob=0.5, learning_rate=0.01, print_step=10, update_target=32, episodes=100000, max_episode_length=float('inf'), batch_size=32):\n",
    "        \n",
    "        for episode in range(episodes):\n",
    "            done = False\n",
    "            ep_step = 0\n",
    "            s = env.reset()\n",
    "            episode_length = 0\n",
    "                \n",
    "            \n",
    "            while not done and ep_step <= max_episode_length:\n",
    "                self.global_step += 1\n",
    "                episode_length += 1\n",
    "                ep_step += 1\n",
    "                \n",
    "                a = self.choose_action(s, keep_prob)\n",
    "                s1, r, done, info = env.step(a)\n",
    "                \n",
    "                self.replay_buffer.append((s, a, r, s1, float(done)))\n",
    "                \n",
    "                S, A, R, S1, Done = self.replay_buffer.random_batch(batch_size).unzip()\n",
    "                V1 = self.sess.run(self.target_critic.V, feed_dict={self.inputs.s: S1, self.inputs.keep_prob: 1.0})\n",
    "                \n",
    "                feed_dict = self.fit_feed(S, A, R, V1, Done, learning_rate, True)\n",
    "                \n",
    "                if self.global_step > 1:\n",
    "                    _, summaries = self.sess.run([self.update, self.summaries], feed_dict=feed_dict)\n",
    "                    self.writer.add_summary(summaries)\n",
    "                \n",
    "                if self.global_step % update_target == 0:\n",
    "                    self.sess.run(self.update_target)\n",
    "                \n",
    "                s = s1\n",
    "                \n",
    "            \n",
    "            \n",
    "            episode_length_summary = self.sess.run(self.episode_length_summary, \n",
    "                                                   feed_dict={self.inputs.episode_length: episode_length})\n",
    "            self.writer.add_summary(episode_length_summary)\n",
    "            \n",
    "            \n",
    "            if episode_length >= self.global_max:\n",
    "                print(\"[MAX] Episode: {}, Length: {}, buffer_len: {}\".format(episode, episode_length, len(self.replay_buffer)))\n",
    "                self.save(model_path = self.model_path + \".max\")\n",
    "                self.global_max = episode_length\n",
    "\n",
    "            \n",
    "            \n",
    "            \n",
    "            if episode % print_step == 0:\n",
    "                actor_loss = self.sess.run(self.actor.loss, feed_dict=feed_dict)\n",
    "                print(\"[NOR] Episode: {}, Length: {}, Learning Rate: {}, buffer_len: {}\".format(episode, episode_length, learning_rate, len(self.replay_buffer)))\n",
    "                print(\"Loss: {}\".format(actor_loss))\n",
    "                self.save()\n",
    "            \n",
    "run = get_run()\n",
    "env = ExpandedStateEnv(\"CartPole-v1\")\n",
    "n_actions = env.action_space.n\n",
    "n_states = env.observation_space.shape[0] * 3\n",
    "model_path = os.getcwd() + \"/actor-critic.model\"\n",
    "logs_path = \"/logs/run{}\".format(run)\n",
    "\n",
    "print(\"Run: {}\".format(run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    n_actions, n_states, y=0.9999, \n",
    "    buffer_length=1000000, pi=0.1,\n",
    "    model_path = model_path,\n",
    "    logs_path = logs_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MAX] Episode: 0, Length: 12, buffer_len: 12\n",
      "[NOR] Episode: 0, Length: 12, Learning Rate: 0.01, buffer_len: 12\n",
      "Loss: 0.693122327328\n",
      "[MAX] Episode: 2, Length: 14, buffer_len: 36\n",
      "[MAX] Episode: 4, Length: 23, buffer_len: 68\n",
      "[NOR] Episode: 10, Length: 8, Learning Rate: 0.01, buffer_len: 142\n",
      "Loss: 0.552762031555\n",
      "[NOR] Episode: 20, Length: 12, Learning Rate: 0.01, buffer_len: 280\n",
      "Loss: 0.512374162674\n",
      "[MAX] Episode: 27, Length: 28, buffer_len: 385\n",
      "[NOR] Episode: 30, Length: 19, Learning Rate: 0.01, buffer_len: 424\n",
      "Loss: 0.385224342346\n",
      "[NOR] Episode: 40, Length: 9, Learning Rate: 0.01, buffer_len: 547\n",
      "Loss: 0.291245102882\n",
      "[NOR] Episode: 50, Length: 9, Learning Rate: 0.01, buffer_len: 677\n",
      "Loss: 0.476347327232\n",
      "[NOR] Episode: 60, Length: 9, Learning Rate: 0.01, buffer_len: 792\n",
      "Loss: 0.53714710474\n",
      "[NOR] Episode: 70, Length: 9, Learning Rate: 0.01, buffer_len: 913\n",
      "Loss: 0.290581226349\n",
      "[MAX] Episode: 71, Length: 30, buffer_len: 943\n",
      "[NOR] Episode: 80, Length: 11, Learning Rate: 0.01, buffer_len: 1073\n",
      "Loss: 0.386096507311\n",
      "[NOR] Episode: 90, Length: 13, Learning Rate: 0.01, buffer_len: 1195\n",
      "Loss: 0.536435961723\n",
      "[NOR] Episode: 100, Length: 9, Learning Rate: 0.01, buffer_len: 1348\n",
      "Loss: 0.467390745878\n",
      "[MAX] Episode: 104, Length: 49, buffer_len: 1436\n",
      "[NOR] Episode: 110, Length: 12, Learning Rate: 0.01, buffer_len: 1511\n",
      "Loss: 0.449565649033\n",
      "[NOR] Episode: 120, Length: 10, Learning Rate: 0.01, buffer_len: 1693\n",
      "Loss: 0.449881732464\n",
      "[NOR] Episode: 130, Length: 9, Learning Rate: 0.01, buffer_len: 1842\n",
      "Loss: -0.0956897139549\n",
      "[NOR] Episode: 140, Length: 13, Learning Rate: 0.01, buffer_len: 1993\n",
      "Loss: 0.414724588394\n",
      "[NOR] Episode: 150, Length: 20, Learning Rate: 0.01, buffer_len: 2147\n",
      "Loss: 0.753705084324\n",
      "[NOR] Episode: 160, Length: 27, Learning Rate: 0.01, buffer_len: 2332\n",
      "Loss: 1.02228212357\n",
      "[NOR] Episode: 170, Length: 29, Learning Rate: 0.01, buffer_len: 2516\n",
      "Loss: -3.07351326942\n",
      "[NOR] Episode: 180, Length: 29, Learning Rate: 0.01, buffer_len: 2691\n",
      "Loss: -0.146309897304\n",
      "[NOR] Episode: 190, Length: 12, Learning Rate: 0.01, buffer_len: 2829\n",
      "Loss: 0.551507174969\n",
      "[NOR] Episode: 200, Length: 21, Learning Rate: 0.01, buffer_len: 2970\n",
      "Loss: 0.288507521152\n",
      "[NOR] Episode: 210, Length: 12, Learning Rate: 0.01, buffer_len: 3156\n",
      "Loss: -1.31431317329\n",
      "[NOR] Episode: 220, Length: 23, Learning Rate: 0.01, buffer_len: 3292\n",
      "Loss: -0.129526630044\n",
      "[NOR] Episode: 230, Length: 11, Learning Rate: 0.01, buffer_len: 3465\n",
      "Loss: -2.50280880928\n",
      "[NOR] Episode: 240, Length: 15, Learning Rate: 0.01, buffer_len: 3597\n",
      "Loss: -0.0708477199078\n",
      "[NOR] Episode: 250, Length: 11, Learning Rate: 0.01, buffer_len: 3736\n",
      "Loss: -0.308492511511\n",
      "[MAX] Episode: 251, Length: 52, buffer_len: 3788\n",
      "[NOR] Episode: 260, Length: 11, Learning Rate: 0.01, buffer_len: 3921\n",
      "Loss: -2.47837758064\n",
      "[NOR] Episode: 270, Length: 29, Learning Rate: 0.01, buffer_len: 4043\n",
      "Loss: -1.73611235619\n",
      "[MAX] Episode: 277, Length: 57, buffer_len: 4293\n",
      "[MAX] Episode: 278, Length: 69, buffer_len: 4362\n",
      "[MAX] Episode: 279, Length: 79, buffer_len: 4441\n",
      "[MAX] Episode: 280, Length: 113, buffer_len: 4554\n",
      "[NOR] Episode: 280, Length: 113, Learning Rate: 0.01, buffer_len: 4554\n",
      "Loss: -0.868885695934\n",
      "[NOR] Episode: 290, Length: 42, Learning Rate: 0.01, buffer_len: 5102\n",
      "Loss: -1.71259641647\n",
      "[MAX] Episode: 295, Length: 152, buffer_len: 5445\n",
      "[MAX] Episode: 296, Length: 179, buffer_len: 5624\n",
      "[NOR] Episode: 300, Length: 73, Learning Rate: 0.01, buffer_len: 6023\n",
      "Loss: -5.85280227661\n",
      "[MAX] Episode: 301, Length: 212, buffer_len: 6235\n",
      "[NOR] Episode: 310, Length: 125, Learning Rate: 0.01, buffer_len: 7368\n",
      "Loss: -4.27436351776\n",
      "[NOR] Episode: 320, Length: 140, Learning Rate: 0.01, buffer_len: 8702\n",
      "Loss: -4.65144920349\n",
      "[NOR] Episode: 330, Length: 144, Learning Rate: 0.01, buffer_len: 10112\n",
      "Loss: -2.95319795609\n",
      "[MAX] Episode: 340, Length: 268, buffer_len: 11704\n",
      "[NOR] Episode: 340, Length: 268, Learning Rate: 0.01, buffer_len: 11704\n",
      "Loss: -4.83461427689\n",
      "[MAX] Episode: 343, Length: 282, buffer_len: 12304\n",
      "[MAX] Episode: 344, Length: 292, buffer_len: 12596\n",
      "[MAX] Episode: 346, Length: 324, buffer_len: 13038\n",
      "[NOR] Episode: 350, Length: 199, Learning Rate: 0.01, buffer_len: 13754\n",
      "Loss: -8.41009712219\n",
      "[MAX] Episode: 355, Length: 328, buffer_len: 14823\n",
      "[MAX] Episode: 358, Length: 403, buffer_len: 15714\n",
      "[NOR] Episode: 360, Length: 244, Learning Rate: 0.01, buffer_len: 16180\n",
      "Loss: -2.52464437485\n",
      "[NOR] Episode: 370, Length: 388, Learning Rate: 0.01, buffer_len: 18505\n",
      "Loss: -5.96804523468\n",
      "[MAX] Episode: 372, Length: 758, buffer_len: 19569\n",
      "[NOR] Episode: 380, Length: 174, Learning Rate: 0.01, buffer_len: 21857\n",
      "Loss: -10.4117593765\n",
      "[NOR] Episode: 390, Length: 294, Learning Rate: 0.01, buffer_len: 25027\n",
      "Loss: -12.0482292175\n",
      "[NOR] Episode: 400, Length: 162, Learning Rate: 0.01, buffer_len: 26612\n",
      "Loss: -6.67799186707\n",
      "[NOR] Episode: 410, Length: 160, Learning Rate: 0.01, buffer_len: 28286\n",
      "Loss: -13.4081821442\n",
      "[NOR] Episode: 420, Length: 261, Learning Rate: 0.01, buffer_len: 30280\n",
      "Loss: -8.51589488983\n",
      "[NOR] Episode: 430, Length: 306, Learning Rate: 0.01, buffer_len: 32395\n",
      "Loss: -10.600484848\n",
      "[NOR] Episode: 440, Length: 195, Learning Rate: 0.01, buffer_len: 34425\n",
      "Loss: -8.97119522095\n",
      "[NOR] Episode: 450, Length: 216, Learning Rate: 0.01, buffer_len: 36723\n",
      "Loss: 4.89442253113\n",
      "[NOR] Episode: 460, Length: 122, Learning Rate: 0.01, buffer_len: 38401\n",
      "Loss: -1.3906788826\n",
      "[NOR] Episode: 470, Length: 316, Learning Rate: 0.01, buffer_len: 41014\n",
      "Loss: -7.19265508652\n",
      "[NOR] Episode: 480, Length: 405, Learning Rate: 0.01, buffer_len: 43825\n",
      "Loss: -7.87452697754\n",
      "[NOR] Episode: 490, Length: 343, Learning Rate: 0.01, buffer_len: 48071\n",
      "Loss: -8.0001373291\n",
      "[MAX] Episode: 496, Length: 1015, buffer_len: 50815\n",
      "[MAX] Episode: 500, Length: 1477, buffer_len: 52894\n",
      "[NOR] Episode: 500, Length: 1477, Learning Rate: 0.01, buffer_len: 52894\n",
      "Loss: 2.92610120773\n",
      "[NOR] Episode: 510, Length: 581, Learning Rate: 0.01, buffer_len: 56436\n",
      "Loss: 0.856991827488\n",
      "[NOR] Episode: 520, Length: 372, Learning Rate: 0.01, buffer_len: 59699\n",
      "Loss: -9.63891029358\n",
      "[MAX] Episode: 527, Length: 1979, buffer_len: 66492\n",
      "[NOR] Episode: 530, Length: 639, Learning Rate: 0.01, buffer_len: 68634\n",
      "Loss: -14.1350278854\n",
      "[MAX] Episode: 534, Length: 2200, buffer_len: 73573\n",
      "[MAX] Episode: 536, Length: 22357, buffer_len: 96995\n",
      "[MAX] Episode: 539, Length: 200001, buffer_len: 300459\n",
      "[MAX] Episode: 540, Length: 200001, buffer_len: 500460\n",
      "[NOR] Episode: 540, Length: 200001, Learning Rate: 0.01, buffer_len: 500460\n",
      "Loss: -15.0837802887\n",
      "[NOR] Episode: 550, Length: 267, Learning Rate: 0.01, buffer_len: 602490\n",
      "Loss: -9.36311435699\n",
      "[NOR] Episode: 560, Length: 202, Learning Rate: 0.01, buffer_len: 619773\n",
      "Loss: -51.7770881653\n",
      "[NOR] Episode: 570, Length: 5258, Learning Rate: 0.01, buffer_len: 650721\n",
      "Loss: -9.57609367371\n",
      "[NOR] Episode: 580, Length: 2358, Learning Rate: 0.01, buffer_len: 759722\n",
      "Loss: -55.3886413574\n",
      "[MAX] Episode: 588, Length: 200001, buffer_len: 1000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-faf44c3b6efa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(\n\u001b[1;32m      2\u001b[0m     \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_episode_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200e3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m<ipython-input-40-71c17ebe89d2>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, env, keep_prob, learning_rate, print_step, update_target, episodes, max_episode_length, batch_size)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummaries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    env, keep_prob=0.5, learning_rate=0.01, print_step=10, \n",
    "    episodes=int(1e5), max_episode_length=200e3, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "model_run = Model(\n",
    "    n_actions, n_states,\n",
    "    model_path = model_path + \".max\",\n",
    "    flush_secs = 3.0,\n",
    "    restore = True\n",
    ")\n",
    "env = ExpandedStateEnv(\"CartPole-v1\")\n",
    "s = env.reset()\n",
    "done = False\n",
    "total = 0\n",
    "while not done:\n",
    "    total += 1\n",
    "    a = model_run.choose_action(s, 1.0, e=0.)\n",
    "    s, r, done, info = env.step(a)\n",
    "    env.render()\n",
    "    time.sleep(0.01)\n",
    "    \n",
    "print total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
