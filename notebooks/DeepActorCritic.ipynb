{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hdf5 not supported (please install/reinstall h5py)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-25 16:46:04,936] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from numpy.random import choice\n",
    "import random\n",
    "from tensorbuilder.api import *\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make(\"FrozenLake-v0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_actions = env.action_space.n\n",
    "n_states = env.observation_space.n\n",
    "learning_rate = 0.85\n",
    "y = 0.9\n",
    "model_name = \"deep-policy-gradient.model\"\n",
    "model_path = \"/models/\" + model_name\n",
    "\n",
    "graph = tf.Graph()\n",
    "gsess = tf.InteractiveSession(graph=graph)\n",
    "with graph.as_default():\n",
    "    with tf.device(\"cpu:0\"):\n",
    "        s = tf.placeholder(tf.int32, ())\n",
    "        step = tf.placeholder(tf.int32, ())\n",
    "        a = tf.placeholder(tf.int32, ())\n",
    "        r = tf.placeholder(tf.float32, ())\n",
    "        \n",
    "\n",
    "        ops = dict(trainable=True, weights_initializer=tf.random_uniform_initializer(minval=0, maxval=0.01), biases_initializer=None) #tf.random_uniform_initializer(minval=0, maxval=0.01))\n",
    "\n",
    "\n",
    "        Ps = Pipe(\n",
    "            s,\n",
    "            T.one_hot(n_states).expand_dims(0)\n",
    "            .relu_layer(32, scope='relu_layer', variables_collections=[\"actor\"], **ops)\n",
    "            .softmax_layer(n_actions, scope='softmax_layer', variables_collections=[\"actor\"], **ops),\n",
    "            T[0]\n",
    "        )\n",
    "        Psa = Ps[a]\n",
    "        \n",
    "        V = Pipe(\n",
    "            s,\n",
    "            T.one_hot(n_states).expand_dims(0)\n",
    "            .relu_layer(32, scope='relu_layer_critic', variables_collections=[\"critic\"], **ops)\n",
    "            .linear_layer(1, scope='linear_layer_critic', variables_collections=[\"critic\"], **ops),\n",
    "            T[0, 0]\n",
    "        )\n",
    "        \n",
    "        ws_actor = tf.get_collection(\"actor\")\n",
    "        gradients_actor = tf.gradients(tf.log(Psa), ws_actor)\n",
    "        dws_actor = [ tf.placeholder(dw.dtype, dw.get_shape()) for dw in gradients_actor ]\n",
    "        update_actor = [ tf.assign_add(w, ws) for w, ws in zip(ws_actor, dws_actor) ]\n",
    "        \n",
    "        ws_critic = tf.get_collection(\"critic\")\n",
    "        gradients_critic = tf.gradients(V, ws_critic)\n",
    "        dws_critic = [ tf.placeholder(dw.dtype, dw.get_shape()) for dw in gradients_critic ]\n",
    "        update_critic = [ tf.assign_add(w, ws) for w, ws in zip(ws_critic, dws_critic) ]\n",
    "        \n",
    "\n",
    "        writer = tf.summary.FileWriter('/logs/' +  model_name)\n",
    "        saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 'of', 500)\n",
      "(9, 'of', 500)\n",
      "(10, 'of', 500)\n",
      "(4, 'of', 500)\n",
      "(2, 'of', 500)\n",
      "(8, 'of', 500)\n",
      "(9, 'of', 500)\n",
      "(16, 'of', 500)\n",
      "(16, 'of', 500)\n",
      "(11, 'of', 500)\n",
      "(14, 'of', 500)\n",
      "(14, 'of', 500)\n",
      "(21, 'of', 500)\n",
      "(43, 'of', 500)\n",
      "(55, 'of', 500)\n",
      "(85, 'of', 500)\n",
      "(111, 'of', 500)\n",
      "(118, 'of', 500)\n",
      "(122, 'of', 500)\n",
      "(98, 'of', 500)\n",
      "(93, 'of', 500)\n",
      "(108, 'of', 500)\n",
      "(96, 'of', 500)\n",
      "(117, 'of', 500)\n",
      "(105, 'of', 500)\n",
      "(89, 'of', 500)\n",
      "(123, 'of', 500)\n",
      "(97, 'of', 500)\n",
      "(100, 'of', 500)\n",
      "(95, 'of', 500)\n",
      "(108, 'of', 500)\n",
      "(103, 'of', 500)\n",
      "(100, 'of', 500)\n",
      "(122, 'of', 500)\n",
      "(98, 'of', 500)\n",
      "(135, 'of', 500)\n",
      "(115, 'of', 500)\n",
      "(99, 'of', 500)\n",
      "(105, 'of', 500)\n",
      "(111, 'of', 500)\n",
      "(111, 'of', 500)\n",
      "(123, 'of', 500)\n",
      "(120, 'of', 500)\n",
      "(107, 'of', 500)\n",
      "(121, 'of', 500)\n",
      "(101, 'of', 500)\n",
      "(106, 'of', 500)\n",
      "(130, 'of', 500)\n",
      "(123, 'of', 500)\n",
      "(107, 'of', 500)\n",
      "(105, 'of', 500)\n",
      "(124, 'of', 500)\n",
      "(126, 'of', 500)\n",
      "(120, 'of', 500)\n",
      "(196, 'of', 500)\n",
      "(216, 'of', 500)\n",
      "(222, 'of', 500)\n",
      "(199, 'of', 500)\n",
      "(215, 'of', 500)\n",
      "(228, 'of', 500)\n",
      "(232, 'of', 500)\n",
      "(191, 'of', 500)\n",
      "(209, 'of', 500)\n",
      "(223, 'of', 500)\n",
      "(221, 'of', 500)\n",
      "(204, 'of', 500)\n",
      "(244, 'of', 500)\n",
      "(214, 'of', 500)\n",
      "(189, 'of', 500)\n",
      "(217, 'of', 500)\n",
      "(222, 'of', 500)\n",
      "(199, 'of', 500)\n",
      "(185, 'of', 500)\n",
      "(210, 'of', 500)\n",
      "(198, 'of', 500)\n",
      "(199, 'of', 500)\n",
      "(217, 'of', 500)\n",
      "(223, 'of', 500)\n",
      "(230, 'of', 500)\n",
      "(218, 'of', 500)\n",
      "(217, 'of', 500)\n",
      "(228, 'of', 500)\n",
      "(208, 'of', 500)\n",
      "(220, 'of', 500)\n",
      "(229, 'of', 500)\n",
      "(235, 'of', 500)\n",
      "(224, 'of', 500)\n",
      "(222, 'of', 500)\n",
      "(214, 'of', 500)\n",
      "(226, 'of', 500)\n",
      "(210, 'of', 500)\n",
      "(230, 'of', 500)\n",
      "(217, 'of', 500)\n",
      "(217, 'of', 500)\n",
      "(233, 'of', 500)\n",
      "(226, 'of', 500)\n",
      "(207, 'of', 500)\n",
      "(221, 'of', 500)\n",
      "(232, 'of', 500)\n",
      "(228, 'of', 500)\n",
      "(205, 'of', 500)\n",
      "(213, 'of', 500)\n",
      "(212, 'of', 500)\n",
      "(215, 'of', 500)\n",
      "(223, 'of', 500)\n",
      "(219, 'of', 500)\n",
      "(205, 'of', 500)\n",
      "(237, 'of', 500)\n",
      "(211, 'of', 500)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-b7a6b05e6b84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_updates_critic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_actor\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mupdate_critic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;31m#update state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    764\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    765\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 766\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    767\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    962\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 964\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    965\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1014\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1015\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1019\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1022\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1001\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1002\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1003\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def next_action(actions, get_max=False):\n",
    "    n = actions.shape[0]\n",
    "    return choice(n, p=actions) if not get_max else np.argmax(actions)\n",
    "    \n",
    "def discount(rewards, y):\n",
    "    r_accum = 0.0\n",
    "    for i in reversed(range(len(rewards))):\n",
    "        r_accum = rewards[i] = rewards[i] + y * r_accum\n",
    "        \n",
    "    return rewards\n",
    "            \n",
    "            \n",
    "with tf.Session(graph=graph, config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "#     saver.restore(sess, model_path)\n",
    "    \n",
    "    r_total = 0\n",
    "    \n",
    "    for t in range(200000):\n",
    "        k = 20000.0\n",
    "        lr = 0.5 * k / (k + t)\n",
    "#         lr = 0.2\n",
    "        \n",
    "        _s = env.reset()\n",
    "        I = 1.0\n",
    "        \n",
    "        while True:\n",
    "            #calculate Ps\n",
    "            [_ps, _v]= sess.run([Ps, V], feed_dict={s: _s})\n",
    "            \n",
    "            #select action\n",
    "            _a = next_action(_ps)\n",
    "            \n",
    "            #take step\n",
    "            _s1, _r, done, info = env.step(_a)\n",
    "            r_total += _r\n",
    "            \n",
    "            #\n",
    "            _v1 = sess.run(V, feed_dict={s: _s1})\n",
    "            \n",
    "            #train\n",
    "            [_gradients_actor, _gradients_critic] = sess.run([gradients_actor, gradients_critic], {s: _s, a: _a})\n",
    "            \n",
    "            \n",
    "            _updates_actor = { dw: lr * dp_dw * (_r + y * _v1 - _v) for dw, dp_dw in zip(dws_actor, _gradients_actor)}\n",
    "            _updates_critic = { dw: lr * dv_dw * (_r + y * _v1 - _v) for dw, dv_dw in zip(dws_critic, _gradients_critic)}\n",
    "            \n",
    "            feed_dict = {}\n",
    "            feed_dict.update(_updates_actor)\n",
    "            feed_dict.update(_updates_critic)\n",
    "            \n",
    "            sess.run(update_actor + update_critic, feed_dict=feed_dict)\n",
    "            \n",
    "            #update state\n",
    "            _s = _s1\n",
    "#             I *= y\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "            \n",
    "        \n",
    "\n",
    "        if t % 500 == 0:\n",
    "            print(int(r_total), \"of\", 500)\n",
    "#             print(t_ward)\n",
    "            r_total = 0\n",
    "#             saver.save(sess, model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.gather(Ps, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0.99920779, 0.00078097288, 9.0313206e-06, 2.1757803e-06] 0\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "4\n",
      "\n",
      "4\n",
      "[0.99929619, 0.00069224928, 8.7665958e-06, 2.6709235e-06] 0\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "0\n",
      "\n",
      "0\n",
      "[0.99920779, 0.00078097288, 9.0313206e-06, 2.1757803e-06] 0\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "4\n",
      "\n",
      "4\n",
      "[0.99929619, 0.00069224928, 8.7665958e-06, 2.6709235e-06] 0\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "0\n",
      "\n",
      "0\n",
      "[0.99920779, 0.00078097288, 9.0313206e-06, 2.1757803e-06] 0\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "0\n",
      "\n",
      "0\n",
      "[0.99920779, 0.00078097288, 9.0313206e-06, 2.1757803e-06] 0\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "0\n",
      "\n",
      "0\n",
      "[0.99920779, 0.00078097288, 9.0313206e-06, 2.1757803e-06] 0\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "0\n",
      "\n",
      "0\n",
      "[0.99920779, 0.00078097288, 9.0313206e-06, 2.1757803e-06] 0\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "0\n",
      "\n",
      "0\n",
      "[0.99920779, 0.00078097288, 9.0313206e-06, 2.1757803e-06] 0\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "4\n",
      "\n",
      "4\n",
      "[0.99929619, 0.00069224928, 8.7665958e-06, 2.6709235e-06] 0\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "0\n",
      "\n",
      "0\n",
      "[0.99920779, 0.00078097288, 9.0313206e-06, 2.1757803e-06] 0\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "0\n",
      "\n",
      "0\n",
      "[0.99920779, 0.00078097288, 9.0313206e-06, 2.1757803e-06] 0\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "4\n",
      "\n",
      "4\n",
      "[0.99929619, 0.00069224928, 8.7665958e-06, 2.6709235e-06] 0\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "8\n",
      "\n",
      "8\n",
      "[2.6267395e-07, 0.00017042999, 7.6365395e-06, 0.99982172] 3\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "4\n",
      "\n",
      "4\n",
      "[0.99929619, 0.00069224928, 8.7665958e-06, 2.6709235e-06] 0\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "8\n",
      "\n",
      "8\n",
      "[2.6267395e-07, 0.00017042999, 7.6365395e-06, 0.99982172] 3\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "8\n",
      "\n",
      "8\n",
      "[2.6267395e-07, 0.00017042999, 7.6365395e-06, 0.99982172] 3\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "8\n",
      "\n",
      "8\n",
      "[2.6267395e-07, 0.00017042999, 7.6365395e-06, 0.99982172] 3\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Up)\n",
      "4\n",
      "\n",
      "4\n",
      "[0.99929619, 0.00069224928, 8.7665958e-06, 2.6709235e-06] 0\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "4\n",
      "\n",
      "4\n",
      "[0.99929619, 0.00069224928, 8.7665958e-06, 2.6709235e-06] 0\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "0\n",
      "\n",
      "0\n",
      "[0.99920779, 0.00078097288, 9.0313206e-06, 2.1757803e-06] 0\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "4\n",
      "\n",
      "4\n",
      "[0.99929619, 0.00069224928, 8.7665958e-06, 2.6709235e-06] 0\n",
      "SFFF\n",
      "FHFH\n",
      "\u001b[41mF\u001b[0mFFH\n",
      "HFFG\n",
      "  (Left)\n",
      "8\n",
      "\n",
      "8\n",
      "[2.6267395e-07, 0.00017042999, 7.6365395e-06, 0.99982172] 3\n",
      "SFFF\n",
      "FHFH\n",
      "F\u001b[41mF\u001b[0mFH\n",
      "HFFG\n",
      "  (Up)\n",
      "9\n",
      "\n",
      "9\n",
      "[5.1284869e-06, 0.99993849, 1.0911181e-05, 4.545107e-05] 1\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Down)\n",
      "13\n",
      "\n",
      "13\n",
      "[1.7193646e-06, 8.5256812e-05, 0.99991035, 2.7467038e-06] 2\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Right)\n",
      "14\n",
      "\n",
      "14\n",
      "[1.4893742e-05, 0.99984479, 0.00011666849, 2.365452e-05] 1\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "H\u001b[41mF\u001b[0mFG\n",
      "  (Down)\n",
      "13\n",
      "\n",
      "13\n",
      "[1.7193646e-06, 8.5256812e-05, 0.99991035, 2.7467038e-06] 2\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Right)\n",
      "14\n",
      "\n",
      "14\n",
      "[1.4893742e-05, 0.99984479, 0.00011666849, 2.365452e-05] 1\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HF\u001b[41mF\u001b[0mG\n",
      "  (Down)\n",
      "14\n",
      "\n",
      "14\n",
      "[1.4893742e-05, 0.99984479, 0.00011666849, 2.365452e-05] 1\n",
      "SFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFF\u001b[41mG\u001b[0m\n",
      "  (Down)\n",
      "15\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "_s = env.reset()\n",
    "done = False\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    saver.restore(sess, model_path)\n",
    "    \n",
    "    for i in range(1000):\n",
    "        \n",
    "        _ps = sess.run(Ps, feed_dict={s: _s})\n",
    "        _a = next_action(_ps, 0)\n",
    "        \n",
    "        \n",
    "        print _s\n",
    "        \n",
    "        print [_psa for _psa in _ps], _a\n",
    "        \n",
    "        _s, _r, done, info = env.step(_a)\n",
    "        env.render()\n",
    "        \n",
    "        print _s\n",
    "        \n",
    "        print(\"\")\n",
    "\n",
    "        if done:\n",
    "            print(_r)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
